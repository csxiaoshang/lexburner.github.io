{"meta":{"title":"徐靖峰|个人博客","subtitle":null,"description":null,"author":"徐靖峰","url":"http://lexburner.github.io"},"pages":[{"title":"Categories","date":"2018-11-20T11:10:40.361Z","updated":"2018-11-20T11:10:40.361Z","comments":true,"path":"categories/index.html","permalink":"http://lexburner.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2018-11-20T11:10:40.361Z","updated":"2018-11-20T11:10:40.361Z","comments":true,"path":"tags/index.html","permalink":"http://lexburner.github.io/tags/index.html","excerpt":"","text":""},{"title":"徐靖峰","date":"2019-03-23T02:21:40.484Z","updated":"2019-03-17T06:46:04.423Z","comments":true,"path":"about/index.html","permalink":"http://lexburner.github.io/about/index.html","excerpt":"","text":"「技术分享」某种程度上，是让作者和读者，不那么孤独的东西。「Kirito的技术分享」致力于探讨 Java 生态的知识点，内容覆盖分布式服务治理，微服务，性能调优，各类源码分析。追求有深度并兼具表达力的文字。 联系方式 Email：kirito.moe@foxmail.com 微信号：xiayimiaoshenghua（添加好友请注明：姓名+公司+来意） 个人信息 徐靖峰/男/1995 Github：https://github.com/lexburner 目前在杭州，就职于阿里巴巴，主要负责方向：分布式服务治理框架 微信公众号Kirito的技术分享"}],"posts":[{"title":"一文聊透 Dubbo 元数据中心","slug":"dubbo-metadata","date":"2019-11-03T07:05:50.000Z","updated":"2019-11-04T02:40:13.942Z","comments":true,"path":"dubbo-metadata/","link":"","permalink":"http://lexburner.github.io/dubbo-metadata/","excerpt":"前言如果让你在本地构建一个 Dubbo 应用，你会需要额外搭建哪些中间件呢？如果没猜错的话，你的第一反应应该是注册中心，类 Dubbo 的大多数服务治理框架都有注册中心的概念。你可以部署一个 Zookeeper，或者一个 Nacos，看你的喜好。但在 Apache Dubbo 的 2.7 版本后，额外引入了两个中间件：元数据中心和配置中心。 在今年年初 Dubbo 2.7 刚发布时，我就写了一篇文章 《Dubbo 2.7 三大新特性详解》，介绍了包含元数据中心改造在内的三大新特性，但一些细节介绍没有详细呈现出来，在这篇文章中，我将会以 Dubbo 为例，跟大家一起探讨一下服务治理框架中元数据中心的意义与集成细节。","text":"前言如果让你在本地构建一个 Dubbo 应用，你会需要额外搭建哪些中间件呢？如果没猜错的话，你的第一反应应该是注册中心，类 Dubbo 的大多数服务治理框架都有注册中心的概念。你可以部署一个 Zookeeper，或者一个 Nacos，看你的喜好。但在 Apache Dubbo 的 2.7 版本后，额外引入了两个中间件：元数据中心和配置中心。 在今年年初 Dubbo 2.7 刚发布时，我就写了一篇文章 《Dubbo 2.7 三大新特性详解》，介绍了包含元数据中心改造在内的三大新特性，但一些细节介绍没有详细呈现出来，在这篇文章中，我将会以 Dubbo 为例，跟大家一起探讨一下服务治理框架中元数据中心的意义与集成细节。 元数据中心介绍服务治理中的元数据（Metadata）指的是服务分组、服务版本、服务名、方法列表、方法参数列表、超时时间等，这些信息将会存储在元数据中心之中。与元数据平起平坐的一个概念是服务的注册信息，即：服务分组、服务版本、服务名、地址列表等，这些信息将会存储在注册中心中。稍微一对比可以发现，元数据中心和注册中心存储了一部分共同的服务信息，例如服务名。两者也有差异性，元数据中心还会存储方法列表即参数列表，注册中心存储了服务地址。上述的概述，体现出了元数据中心和注册中心在服务治理过程中，担任着不同的角色。为了有一个直观的对比，我整理出了下面的表格： 元数据 注册信息 职责 描述服务，定义服务的基本属性 存储地址列表 变化频繁度 基本不变 随着服务上下线而不断变更 数据量 大 小 数据交互/存储模型 消费者/提供者上报，控制台查询 PubSub 模型，提供者上报，消费者订阅 主要使用场景 服务测试、服务 MOCK 服务调用 可用性要求 元数据中心可用性要求不高，不影响主流程 注册中心可用性要求高，影响到服务调用的主流程 下面我会对每个对比点进行单独分析，以加深对元数据中心的理解。 职责在 Dubbo 2.7 版本之前，并没有元数据中心的概念，那时候注册信息和元数据都耦合在一起。Dubbo Provider 的服务配置有接近 30 个配置项，排除一部分注册中心服务治理需要的参数，很大一部分配置项仅仅是 Provider 自己使用，不需要透传给消费者；Dubbo Consumer 也有 20 多个配置项。在注册中心之中，服务消费者列表中只需要关注 application，version，group，ip，dubbo 版本等少量配置。这部分数据不需要进入注册中心，而只需要以 key-value 形式持久化存储在元数据中心即可。从职责来看，将不同职责的数据存储在对应的组件中，会使得逻辑更加清晰。 变化频繁度注册信息和元数据耦合在一起会导致注册中心数据量的膨胀，进而增大注册中心的网络开销，直接造成了服务地址推送慢等负面影响。服务上下线会随时发生，变化的其实是注册信息，元数据是相对不变的。 数据量由于元数据包含了服务的方法列表以及参数列表，这部分数据会导致元数据要比注册信息大很多。注册信息被设计得精简会直接直接影响到服务推送的 SLA。 数据交互/存储模型注册中心采用的是 PubSub 模型，这属于大家的共识，所以注册中心组件的选型一般都会要求其有 notify 的机制。而元数据中心并没有 notify 的诉求，一般只需要组件能够提供 key-value 的存储结构即可。 主要使用场景在服务治理中，注册中心充当了通讯录的职责，在复杂的分布式场景下，让消费者能找到提供者。而元数据中心存储的元数据，主要适用于服务测试、服务 MOCK 等场景，这些场景都对方法列表、参数列表有所诉求。在下面的小节中，我也会对使用场景进行更加详细的介绍。 可用性要求注册中心宕机或者网络不通会直接影响到服务的可用性，它影响了服务调用的主路径。但一般而言，元数据中心出现问题，不会影响到服务调用，它提供的能力是可被降级的。这也阐释了一点，为什么很多用户在 Dubbo 2.7 中没有配置元数据中心，也没有影响到正常的使用。元数据中心在服务治理中扮演的是锦上添花的一个角色。在组件选型时，我们一般也会对注册中心的可用性要求比较高，元数据中心则可以放宽要求。 元数据中心的价值小孩子才分对错，成年人只看利弊。额外引入一个元数据中心，必然带来运维成本、理解成本、迁移成本等问题，那么它具备怎样的价值，来说服大家选择它呢？上面我们介绍元数据中心时已经提到了服务测试、服务 MOCK 等场景，这一节我们重点探讨一下元数据中心的价值。 降低地址推送的时延由于注册中心采用的是 PubSub 模型，数据量的大小会直接影响到服务地址推送时间，不知道你有没有遇到过 No provider available 的报错呢？明明提供者已经启动了，但由于注册中心推送慢会导致很多问题，一方面会影响到服务的可用性，一方面也会增加排查问题的难度。 在一次杭州 Dubbo Meetup 中，网易考拉分享了他们对 Zookeeper 的改造，根源就是 推送量大 -&gt; 存储数据量大 -&gt; 网络传输量大 -&gt; 延迟严重 这一实际案例佐证了元数据改造并不是凭空产生的需求，而是切实解决了一个痛点。 服务测试 &amp; 服务 MOCK在 Dubbo 2.7 之前，虽然注册中心耦合存储了不少本应属于元数据的数据，但也漏掉了一部分元数据，例如服务的方法列表，参数列表。这些是服务测试和服务 MOCK 必备的数据，想要使用这些能力，就必须引入元数据中心。例如开源的 Dubbo Admin 就实现了服务测试功能，用户可以在控制台上对已经发布的服务提供者进行功能测试。可能你之前有过这样的疑惑：为什么只有 Dubbo 2.7 才支持了服务测试呢？啊哈，原因就是 Dubbo 2.7 才有了元数据中心的概念。当然，服务 MOCK 也是如此。 其他场景可以这么理解，任何依赖元数据的功能，都需要元数据中心的支持。其他场景还包括了网关应用获取元数据来进行泛化调用、服务自动化测试等等。再描述一个可能的场景，抛砖引玉。在一次南京 Dubbo Meetup 上，dubbo.js 的作者提及的一个场景，希望根据元数据自动生成 NodeJs 代码，以简化前端的开发量，也是元数据的作用之一。这里就需要发挥各位的想象力了 Dubbo 配置元数据中心目前 Dubbo 最新的版本为 2.7.4，目前支持的几种元数据中心可以从源码中得知（官方文档尚未更新）： 支持 consul、etcd、nacos、redis、zookeeper 这五种组件。 配置方式如下： 1dubbo.metadata-report.address=nacos://127.0.0.1:8848 元数据存储格式剖析前面我们介绍了元数据中心的由来以及价值，还是飘在天上的概念，这一节将会让概念落地。元数据是以怎么样一个格式存储的呢？ 以 DemoService 服务为例： 12&lt;dubbo:service interface=\"com.alibaba.dubbo.demo.DemoService\" ref=\"demoService\" executes=\"4500\" retries=\"7\" owner=\"kirito\"/&gt;&lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\" /&gt; 首先观察在 Dubbo 2.6.x 中，注册中心如何存储这个服务的信息： 123456789dubbo://30.5.120.185:20880/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello&amp;bean.name=com.alibaba.dubbo.demo.DemoService&amp;dubbo=2.0.2&amp;executes=4500&amp;generic=false&amp;owner=kirito&amp;pid=84228&amp;retries=7&amp;side=provider&amp;timestamp=1552965771067 例如 bean.name 和 owner 这些属性，肯定是没必要注册上来的。 接着，我们在 Dubbo 2.7 中使用最佳实践，为 registry 配置 simplified=true： 123&lt;dubbo:service interface=\"com.alibaba.dubbo.demo.DemoService\" ref=\"demoService\" executes=\"4500\" retries=\"7\" owner=\"kirito\"/&gt;&lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\" simplified=\"true\" /&gt;&lt;dubbo:metadata-report address=\"nacos://127.0.0.1:8848\"/&gt; 之后再观察注册中心的数据，已经变得相当精简了： 12345dubbo://30.5.120.185:20880/org.apache.dubbo.demo.api.DemoService?application=demo-provider&amp;dubbo=2.0.2&amp;release=2.7.0&amp;timestamp=1552975501873 被精简省略的数据不代表没有用了，而是转移到了元数据中心之中，我们观察一下此时元数据中心中的数据： 最佳实践元数据中心是服务治理中的一个关键组件，但对于大多数用户来说还是一个比较新的概念，我整理了一些我认为的最佳实践，分享给大家。 从 Dubbo 2.6 迁移到 Dubbo 2.7 时，可以采取三步走的策略来平滑迁移元数据。第一步：Dubbo 2.6 + 注册中心，第二步：Dubbo 2.7 + 注册中心 + 元数据中心，第三步：Dubbo 2.7 + 注册中心（simplified=true） + 元数据中心。在未来 Dubbo 的升级版本中，registry 的 simplified 默认值将会变成 true，目前是 false，预留给用户一个升级的时间。 应用在启动时，会发布一次元数据，在此之后会有定时器，一天同步一次元数据，以上报那些运行时生成的 Bean，目前用户不可以配置元数据上报的周期，但可以通过 -Dcycle.report 关闭这一定时器。 元数据中心推荐选型：Nacos 和 Redis。 Dubbo 2.7 还有很多有意思的特性，如果你对 Dubbo 有什么感兴趣的问题，欢迎在文末或者后台进行留言，后面我会继续更新 Dubbo 系列的文章。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"}]},{"title":"一个看板娘入住你的个人博客只需要三步","slug":"live2d","date":"2019-10-09T11:01:38.000Z","updated":"2019-10-23T07:11:43.493Z","comments":true,"path":"live2d/","link":"","permalink":"http://lexburner.github.io/live2d/","excerpt":"最近在浏览别人博客时，一个萌物给了我意外的惊喜，原来博客还可以这么玩 于是果断审查元素，发现这个萌萌哒的看板娘背后使用的是一个叫 live2d 的技术，并且凭借 Google 迅速找到对应的开源代码：https://github.com/xiazeyu/live2d-widget.js，https://github.com/EYHN/hexo-helper-live2d 你可以在我的博客中先目睹下它的实际效果：https://www.cnkirito.moe/，点击会有音效哦~ 在浏览 live2-widget.js 的说明文档时，发现它对 hexo 的支持非常友好，恰好我的博客是通过 hexo 搭建的，所以本文会介绍一下如何为 hexo 集成一只看板娘。","text":"最近在浏览别人博客时，一个萌物给了我意外的惊喜，原来博客还可以这么玩 于是果断审查元素，发现这个萌萌哒的看板娘背后使用的是一个叫 live2d 的技术，并且凭借 Google 迅速找到对应的开源代码：https://github.com/xiazeyu/live2d-widget.js，https://github.com/EYHN/hexo-helper-live2d 你可以在我的博客中先目睹下它的实际效果：https://www.cnkirito.moe/，点击会有音效哦~ 在浏览 live2-widget.js 的说明文档时，发现它对 hexo 的支持非常友好，恰好我的博客是通过 hexo 搭建的，所以本文会介绍一下如何为 hexo 集成一只看板娘。 安装使用 npm 在 hexo 下安装 hexo-helper-live2d，它将 live2d-widget.js 与 hexo 进行了整合，使得我们只需要通过简单的配置，即可生效 1npm install --save hexo-helper-live2d 接着下载一个 Kirito 良心推荐的看板娘：shizuku，也是我正在用的 1npm install live2d-widget-model-shizuku 如果安装成功，我们可以在 node_modules 目录中找到 live2d-widget 和 live2d-widget-model-shizuku 两个目录 配置向 hexo 的 _config.yml 添加如下的配置 123456789101112131415161718live2d: enable: true scriptFrom: local pluginRootPath: node_modules/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-shizuku display: position: right width: 150 height: 300 mobile: show: true react: opacity: 0.7 需要留意的是 live2d.model.use 这个标签的值，是用于指定博客使用哪一个看板娘模型的。 发布接着只需要正常编译并发布，你的 hexo 博客就获得了一枚萌妹子了 12hexo ghexo d 模型推荐除了上述推荐的 shizuku 看板娘，作者还提供了其他一些不错的模型，下面罗列一部分，不知道你会 pick 哪一个呢？ miku haru koharu haruto nipsilon shizuku z16 hibiki Unitychan hijiki 尾记Live2d 的确是很有意思的一个技术，可以让静态博客有了一些生机，如果你对其感兴趣，还可以自己采集模型，自己发布模型，甚至在了解这样技术的同时，我还见识到一些科技感满满的博主把 AI 机器人的特性添加给了看板娘，让其可以与正在使用鼠标浏览的你进行互动，这些我就不过多介绍了，如果你也有一个博客，那就赶紧试试这个 idea 吧。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"live2d","slug":"live2d","permalink":"http://lexburner.github.io/tags/live2d/"}]},{"title":"Linux 环境写文件如何稳定跑满磁盘 I/O 带宽?","slug":"linux-io-benchmark","date":"2019-10-09T11:01:38.000Z","updated":"2019-11-03T07:20:20.636Z","comments":true,"path":"linux-io-benchmark/","link":"","permalink":"http://lexburner.github.io/linux-io-benchmark/","excerpt":"准备 要求 机器配置 测试磁盘 IO 性能 实验一: Buffer IO 写入 实验二: 4K 单次 Direct IO 写入 实验三: mmap 写入 实验四: 改进的 mmap 写入 结论","text":"准备 要求 机器配置 测试磁盘 IO 性能 实验一: Buffer IO 写入 实验二: 4K 单次 Direct IO 写入 实验三: mmap 写入 实验四: 改进的 mmap 写入 结论 准备要求在 限制内存 的情况下，假定我们每次写入 4k 的数据，如何保证 kill -9 不丢数据的情况下，仍然稳定的跑满磁盘的 IO？因为需要保证 kill -9 不丢数据，所以 fwrite() 就不在我们的考虑范围之内了. 又因为限制内存，所以直观的想法是直接 Direct IO, 但 Direct IO 能否跑满磁盘 IO 呢? 机器配置CPU: 64 核 Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz 磁盘 : Intel Optane SSD 测试磁盘 IO 性能官方称读 / 写带宽是 2400/2000 MB/s, 我们利用 fio 来进行实测: 顺序读性能: 1sudo fio --filename=test -iodepth=64 -ioengine=libaio --direct=1 --rw=read --bs=2m --size=2g --numjobs=4 --runtime=10 --group_reporting --name=test-read 结果: 1READ: bw=2566MiB/s (2691MB/s), 2566MiB/s-2566MiB/s (2691MB/s-2691MB/s), io=8192MiB (8590MB), run=3192-3192msec 顺序写性能: 1sudo fio --filename=test -iodepth=64 -ioengine=libaio -direct=1 -rw=write -bs=1m -size=2g -numjobs=4 -runtime=20 -group_reporting -name=test-write 结果: 1WRITE: bw=2181MiB/s (2287MB/s), 2181MiB/s-2181MiB/s (2287MB/s-2287MB/s), io=8192MiB (8590MB), run=3756-3756msec 实测读写带宽: 2566/2181 MB/s 实验一: Buffer IO 写入因为是限制内存，所以 Buffer IO 不在我们的考虑范围内，但是我们先来测试一下 Buffer IO 的具体性能到底如何? 我们使用最简单的方法，因为我们的 CPU 核数是 64，所以直接 64 线程单次 4K 字节 Buffer IO 写入, 即通过操作系统的 Page Cache 的策略来缓存，刷盘: 代码片段 : 完整代码 12345678910111213141516171819202122static char data[4096] attribute((aligned(4096))) = &#123;&apos;a&apos;&#125;; void writer(int index) &#123; std::string fname = &quot;data&quot; + std::to_string(index); int data_fd = ::open(fname.c_str(), O_RDWR | O_CREAT | O_APPEND, 0645); for (int32_t i = 0; i &lt; 1000000; i++) &#123; ::write(data_fd, data, 4096); &#125; close(data_fd); &#125; int main() &#123; std::vectorstd::thread threads; for(int i = 0; i &lt; 64; i++) &#123; std::thread worker(writer, i); threads.push_back(std::move(worker)); &#125; for (int i = 0; i &lt; 64; i++) &#123; threads[i].join(); &#125; return 0; &#125; 我们通过 O_APPEND 单次 4k 追加写入，之后通过 vmstat 来保留 120s 的写入带宽: 1vmstat 1 120 &gt; buffer_io 经过最后的测试数据整理，我们发现 Buffer IO 的性能基本能稳定跑满带宽, 其中只有一次 I/O 抖动: 实验二: 4K 单次 Direct IO 写入Buffer IO 利用 Page Cache 帮助我们缓存了大量的数据，其实必然提高了写入带宽，但假如在限制内存的情况下，Buffer IO 就不是正确的解决方案了，这次我们绕过 Page Cache, 直接 Direct IO 单次 4K 写入: 代码片段 : 完整代码 唯一需要修改的地方就是在 open() 中加入 O_DIRECT 标志: 1int data_fd = ::open(fname.c_str(), O_RDWR | O_CREAT | O_APPEND | O_DIRECT, 0645); 通过 vmstat 获取写入带宽数据, 整理如下: 通过数据我们发现，单次 4k 的 Direct IO 写入无法跑满磁盘的 I/O 带宽，仅仅只有 800MB/S 实验三: mmap 写入通过前面这两个实验我们发现，Buffer IO 是可以跑满磁盘 I/O 的，那我们可以尝试模拟 Buffer IO 的写入方式，使用较少的内存来达到 Buffer IO 的写入效果. 我们使用 mmap 来实现 Buffer IO 写入，通过限定的 Buffer Block 来模拟 Page Cache 的聚合效果, 实验中我们使用 memcpy 来完成数据拷贝，Buffer Block 我们设定为 4K * 4, 与 Direct IO 的不同，我们这次限定即 16KB 的单次写入: 代码片段: 完整代码 main() 函数不变，修改线程的 writer() 函数: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static char data[4096] attribute((aligned(4096))) = &#123;&apos;a&apos;&#125;;static int32_t map_size = 4096 * 4;void MapRegion(int fd, uint64_t file_offset, char** base) &#123; void* ptr = mmap(nullptr, map_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, file_offset); if (unlikely(ptr == MAP_FAILED)) &#123; *base = nullptr; return; &#125; base = reinterpret_cast&lt;char&gt;(ptr); &#125; void UnMapRegion(char* base) &#123; munmap(base, map_size); &#125; void writer(int index) &#123; std::string fname = &quot;data&quot; + std::to_string(index); char* base = nullptr; char* cursor = nullptr; uint64_t mmap_offset = 0, file_offset = 0; int data_fd = ::open(fname.c_str(), O_RDWR | O_CREAT, 0645); posix_fallocate(data_fd, 0, (4096UL * 1000000)); MapRegion(data_fd, 0, &amp;base); if (unlikely(base == nullptr)) &#123; return; &#125; cursor = base; file_offset += map_size; for (int32_t i = 0; i &lt; 1000000; i++) &#123; if (unlikely(mmap_offset &gt;= map_size)) &#123; UnMapRegion(base); MapRegion(data_fd, file_offset, &amp;base); if (unlikely(base == nullptr)) &#123; return; &#125; cursor = base; file_offset += map_size; mmap_offset = 0; &#125; memcpy(cursor, data, 4096); cursor += 4096; mmap_offset += 4096; &#125; UnMapRegion(base); close(data_fd); &#125; 我们通过 vmstat 来获取写入带宽数据，我们发现 mmap 的 16K 写入可以跑满磁盘带宽，但 I/O 抖动较大，无法类似于 Buffer IO 稳定的写入. 我们通过 perf 生成火焰图分析: 通过 pref 生成分析瓶颈时发现，写入 writer() 时触发了大量的 Page Fault, 即缺页中断，而 mmap() 本身的调用也有一定的消耗 (关于 mmap() 的源码分析，我们在后面的文章会详细分析 )，我们实验三的思路是: 首先 fallocate 一个大文件，然后 mmap() 内存映射 16k 的 Block, memcpy() 写满之后，游标右移重新 mmap()，以此循环. 实验四: 改进的 mmap 写入为了避免 mmap() 的开销，我们使用临时文件在写入之前 mmap() 映射，之后循环利用这 16K 的 Block, 避免 mmap() 的巨大开销: 代码片段: 完整代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void MapRegion(int fd, uint64_t file_offset, char** base) &#123; void* ptr = mmap(nullptr, map_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, file_offset); if (unlikely(ptr == MAP_FAILED)) &#123; *base = nullptr; return; &#125; *base = reinterpret_cast&lt;char*&gt;(ptr);&#125;void UnMapRegion(char* base) &#123; munmap(base, map_size);&#125;void writer(int index) &#123; std::string fname = &quot;data&quot; + std::to_string(index); std::string batch = &quot;batch&quot; + std::to_string(index); char* base = nullptr; char* cursor = nullptr; uint64_t mmap_offset = 0, file_offset = 0; int data_fd = ::open(fname.c_str(), O_RDWR | O_CREAT | O_DIRECT, 0645); int batch_fd = ::open(batch.c_str(), O_RDWR | O_CREAT | O_DIRECT, 0645); posix_fallocate(data_fd, 0, (4096UL * 1000000)); posix_fallocate(batch_fd, 0, map_size); MapRegion(batch_fd, 0, &amp;base); if (unlikely(base == nullptr)) &#123; return; &#125; cursor = base; file_offset += map_size; for (int32_t i = 0; i &lt; 1000000; i++) &#123; if (unlikely(mmap_offset &gt;= map_size)) &#123; pwrite64(data_fd, base, map_size, file_offset); cursor = base; file_offset += map_size; mmap_offset = 0; &#125; memcpy(cursor, data, 4096); cursor += 4096; mmap_offset += 4096; &#125; UnMapRegion(base); close(data_fd); close(batch_fd);&#125; 使用 vmstat 来获取写入速度的数据, 整理如下: 这次避免了 mmap() 的开销，写入速度可以稳定保持在 2180 MB/S 左右，且没有 I/O 抖动. 内存使用也仅仅只有 18000KB, 大约 18M: 结论下面是四种方式的写入速度对比: 在限制内存，且需要 kill -9 不丢数据的情况下，我们可以使用 mmap() 来模拟 Buffer IO，但为了避免频繁 mmap() 的开销，我们需要临时文件来做我们的内存映射. 这种方法可以保证我们的写入速度稳定且 kill -9 不至于丢失数据.","categories":[{"name":"数据库","slug":"数据库","permalink":"http://lexburner.github.io/categories/数据库/"}],"tags":[{"name":"文件 IO","slug":"文件-IO","permalink":"http://lexburner.github.io/tags/文件-IO/"}]},{"title":"一文聊透 Dubbo 优雅停机","slug":"dubbo-gracefully-shutdown","date":"2019-09-29T14:46:55.000Z","updated":"2019-10-08T06:07:36.232Z","comments":true,"path":"dubbo-gracefully-shutdown/","link":"","permalink":"http://lexburner.github.io/dubbo-gracefully-shutdown/","excerpt":"1 前言一年之前，我曾经写过一篇《研究优雅停机时的一点思考》，主要介绍了 kill -9，kill -15 两个 Linux 指令的含义，并且针对性的聊到了 Spring Boot 应用如何正确的优雅停机，算是本文的前置文章，如果你对上述概念不甚了解，建议先去浏览一遍，再回头来看这篇文章。这篇文章将会以 Dubbo 为例，既聊架构设计，也聊源码，聊聊服务治理框架要真正实现优雅停机，需要注意哪些细节。 本文的写作思路是从 Dubbo 2.5.x 开始，围绕优雅停机这个优化点，一直追溯到最新的 2.7.x。先对 Dubbo 版本做一个简单的科普：2.7.x 和 2.6.x 是目前官方推荐使用的版本，其中 2.7.x 是捐献给 Apache 的版本，具备了很多新的特性，目前最新的 release 版本是 2.7.4，处于生产基本可用的状态；2.6.x 处于维护态，主要以 bugfix 为主，但经过了很多公司线上环境的验证，所以求稳的话，可以使用 2.6.x 分支最新的版本。至于 2.5.x，社区已经放弃了维护，并且 2.5.x 存在一定数量的 bug，本文介绍的 Dubbo 优雅停机特性便体现了这一点。","text":"1 前言一年之前，我曾经写过一篇《研究优雅停机时的一点思考》，主要介绍了 kill -9，kill -15 两个 Linux 指令的含义，并且针对性的聊到了 Spring Boot 应用如何正确的优雅停机，算是本文的前置文章，如果你对上述概念不甚了解，建议先去浏览一遍，再回头来看这篇文章。这篇文章将会以 Dubbo 为例，既聊架构设计，也聊源码，聊聊服务治理框架要真正实现优雅停机，需要注意哪些细节。 本文的写作思路是从 Dubbo 2.5.x 开始，围绕优雅停机这个优化点，一直追溯到最新的 2.7.x。先对 Dubbo 版本做一个简单的科普：2.7.x 和 2.6.x 是目前官方推荐使用的版本，其中 2.7.x 是捐献给 Apache 的版本，具备了很多新的特性，目前最新的 release 版本是 2.7.4，处于生产基本可用的状态；2.6.x 处于维护态，主要以 bugfix 为主，但经过了很多公司线上环境的验证，所以求稳的话，可以使用 2.6.x 分支最新的版本。至于 2.5.x，社区已经放弃了维护，并且 2.5.x 存在一定数量的 bug，本文介绍的 Dubbo 优雅停机特性便体现了这一点。 2 优雅停机的意义优雅停机一直是一个非常严谨的话题，但由于其仅仅存在于重启、下线这样的部署阶段，导致很多人忽视了它的重要性，但没有它，你永远不能得到一个完整的应用生命周期，永远会对系统的健壮性持怀疑态度。 同时，优雅停机又是一个庞大的话题 操作系统层面，提供了 kill -9 （SIGKILL）和 kill -15（SIGTERM） 两种停机策略 语言层面，Java 应用有 JVM shutdown hook 这样的概念 框架层面，Spring Boot 提供了 actuator 的下线 endpoint，提供了 ContextClosedEvent 事件 容器层面，Docker ：当执行 docker stop 命令时，容器内的进程会收到 SIGTERM 信号，那么 Docker Daemon 会在 10s 后，发出 SIGKILL 信号；K8S 在管理容器生命周期阶段中提供了 prestop 钩子方法 应用架构层面，不同架构存在不同的部署方案。单体式应用中，一般依靠 nginx 这样的负载均衡组件进行手动切流，逐步部署集群；微服务架构中，各个节点之间有复杂的调用关系，上述这种方案就显得不可靠了，需要有自动化的机制。 为避免该话题过度发散，本文的重点将会集中在框架和应用架构层面，探讨以 Dubbo 为代表的微服务架构在优雅停机上的最佳实践。Dubbo 的优雅下线主要依赖于注册中心组件，由其通知消费者摘除下线的节点，如下图所示： 上述的操作旨在让服务消费者避开已经下线的机器，但这样就算实现了优雅停机了吗？似乎还漏掉了一步，在应用停机时，可能还存在执行到了一半的任务，试想这样一个场景：一个 Dubbo 请求刚到达提供者，服务端正在处理请求，收到停机指令后，提供者直接停机，留给消费者的只会是一个没有处理完毕的超时请求。 结合上述的案例，我们总结出 Dubbo 优雅停机需要满足两点基本诉求： 服务消费者不应该请求到已经下线的服务提供者 在途请求需要处理完毕，不能被停机指令中断 优雅停机的意义：应用的重启、停机等操作，不影响业务的连续性。 3 优雅停机初始方案 — 2.5.x为了让读者对 Dubbo 的优雅停机有一个最基础的理解，我们首先研究下 Dubbo 2.5.x 的版本，这个版本实现优雅停机的方案相对简单，容易理解。 3.1 入口类：AbstractConfig123456789public abstract class AbstractConfig implements Serializable &#123; static &#123; Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() &#123; public void run() &#123; ProtocolConfig.destroyAll(); &#125; &#125;, \"DubboShutdownHook\")); &#125;&#125; 在 AbstractConfig 的静态块中，Dubbo 注册了一个 shutdown hook，用于执行 Dubbo 预设的一些停机逻辑，继续跟进 ProtocolConfig.destroyAll() 。 3.2 ProtocolConfig12345678910111213141516171819202122232425public static void destroyAll() &#123; if (!destroyed.compareAndSet(false, true)) &#123; return; &#125; AbstractRegistryFactory.destroyAll(); // ①注册中心注销 // Wait for registry notification try &#123; Thread.sleep(ConfigUtils.getServerShutdownTimeout()); // ② sleep 等待 &#125; catch (InterruptedException e) &#123; logger.warn(\"Interrupted unexpectedly when waiting for registry notification during shutdown process!\"); &#125; ExtensionLoader&lt;Protocol&gt; loader = ExtensionLoader.getExtensionLoader(Protocol.class); for (String protocolName : loader.getLoadedExtensions()) &#123; try &#123; Protocol protocol = loader.getLoadedExtension(protocolName); if (protocol != null) &#123; protocol.destroy(); // ③协议/流程注销 &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125;&#125; Dubbo 中的 Protocol 这个词不太能望文生义，它一般被翻译为”协议”，但我更习惯将它理解为“流程”，从 Protocol 接口的三个方法反而更加容易理解。 12345public interface Protocol &#123; &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; void destroy();&#125; 它定义了暴露、订阅、注销这三个生命周期方法，所以不难理解为什么 Dubbo 会把 shutdown hook 触发后的注销方法定义在 ProtocolConfig 中了。 回到 ProtocolConfig 的源码中，我把 ProtocolConfig 中执行的优雅停机逻辑分成了三部分，其中第 1，2 部分和注册中心（Registry）相关，第 3 部分和协议/流程（Protocol）相关，分成下面的 3.3 和 3.4 两部分来介绍。 3.3 注册中心注销逻辑123456789101112131415161718public abstract class AbstractRegistryFactory implements RegistryFactory &#123; public static void destroyAll() &#123; LOCK.lock(); try &#123; for (Registry registry : getRegistries()) &#123; try &#123; registry.destroy(); &#125; catch (Throwable e) &#123; LOGGER.error(e.getMessage(), e); &#125; &#125; REGISTRIES.clear(); &#125; finally &#123; // Release the lock LOCK.unlock(); &#125; &#125;&#125; 这段代码对应了 3.2 小节 ProtocolConfig 源码的第 1 部分，代表了注册中心的注销逻辑，更深一层的源码不需要 debug 进去了，大致的逻辑就是删除掉注册中心中本节点对应的服务提供者地址。 123456// Wait for registry notificationtry &#123; Thread.sleep(ConfigUtils.getServerShutdownTimeout());&#125; catch (InterruptedException e) &#123; logger.warn(\"Interrupted unexpectedly when waiting for registry notification during shutdown process!\");&#125; 这段代码对应了 3.2 小节 ProtocolConfig 源码的第 2 部分，ConfigUtils.getServerShutdownTimeout() 默认值是 10s，为什么需要在 shutdown hook 中等待 10s 呢？在注释中可以发现这段代码的端倪，原来是为了给服务消费者一点时间，确保等到注册中心的通知。10s 显然是一个经验值，这里也不妨和大家探讨一下，如何稳妥地设置这个值呢？ 设置的过短。由于注册中心通知消费者取消订阅某个地址是异步通知过去的，可能消费者还没收到通知，提供者这边就停机了，这就违背了我们的诉求 1：服务消费者不应该请求到已经下线的服务提供者。 设置的过长。这会导致发布时间变长，带来不必要的等待。 两个情况对比下，起码可以得出一个实践经验：如果拿捏不准等待时间，尽量设置一个宽松的一点的等待时间。 这个值主要取决三点因素： 集群规模的大小。如果只有几个服务，每个服务只有几个实例，那么再弱鸡的注册中心也能很快的下发通知。 注册中心的选型。以 Naocs 和 Zookeeper 为例，同等规模服务实例下 Nacos 在推送地址方面的能力远超 Zookeeper。 网络状况。服务提供者和服务消费者与注册中心的交互逻辑走的 TCP 通信，网络状况也会影响到推送时间。 所以需要根据实际部署场景测量出最合适的值。 3.4 协议/流程注销逻辑1234567891011ExtensionLoader&lt;Protocol&gt; loader = ExtensionLoader.getExtensionLoader(Protocol.class);for (String protocolName : loader.getLoadedExtensions()) &#123; try &#123; Protocol protocol = loader.getLoadedExtension(protocolName); if (protocol != null) &#123; protocol.destroy(); &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125;&#125; 这段代码对应了 3.2 小节 ProtocolConfig 源码的第 3 部分，在运行时，loader.getLoadedExtension(protocolName) 这段代码会加载到两个协议 ：DubboProtocol 和 Injvm 。后者 Injvm 实在没啥好讲的，主要来分析一下 DubboProtocol 的逻辑。 DubboProtocol 实现了我们前面提到的 Protocol 接口，它的 destory 方法是我们重点要看的。 123456789101112131415161718192021222324252627public class DubboProtocol extends AbstractProtocol &#123; public void destroy() &#123; for (String key : new ArrayList&lt;String&gt;(serverMap.keySet())) &#123; ExchangeServer server = serverMap.remove(key); if (server != null) &#123; server.close(ConfigUtils.getServerShutdownTimeout()); &#125; &#125; for (String key : new ArrayList&lt;String&gt;(referenceClientMap.keySet())) &#123; ExchangeClient client = referenceClientMap.remove(key); if (client != null) &#123; client.close(ConfigUtils.getServerShutdownTimeout()); &#125; &#125; for (String key : new ArrayList&lt;String&gt;(ghostClientMap.keySet())) &#123; ExchangeClient client = ghostClientMap.remove(key); if (client != null) &#123; client.close(ConfigUtils.getServerShutdownTimeout()); &#125; &#125; stubServiceMethodsMap.clear(); super.destroy(); &#125;&#125; 主要分成了两部分注销逻辑：server 和 client，注意这里是先注销了服务提供者后，再注销了服务消费者，这样做是有意为之。在 RPC 调用中，经常是一个远程调用触发一个远程调用，所以在关闭一个节点时，应该先切断上游的流量，所以这里是先注销了服务提供者，这样从一定程度上，降低了后面服务消费者被调用到的可能性（当然，服务消费者也有可能被单独调用到）。由于 server 和 client 的流程类似，所以我只选取了 server 部分来分析具体的注销逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public void close(final int timeout) &#123; startClose(); if (timeout &gt; 0) &#123; final long max = (long) timeout; final long start = System.currentTimeMillis(); if (getUrl().getParameter(Constants.CHANNEL_SEND_READONLYEVENT_KEY, true)) &#123; // 如果注册中心有延迟，会立即受到readonly事件，下次不会再调用这台机器，当前已经调用的会处理完 sendChannelReadOnlyEvent(); &#125; while (HeaderExchangeServer.this.isRunning() // ① &amp;&amp; System.currentTimeMillis() - start &lt; max) &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; &#125; doClose(); // ② server.close(timeout); // ③ &#125; private boolean isRunning() &#123; Collection&lt;Channel&gt; channels = getChannels(); for (Channel channel : channels) &#123; if (DefaultFuture.hasFuture(channel)) &#123; return true; &#125; &#125; return false; &#125;private void doClose() &#123; if (!closed.compareAndSet(false, true)) &#123; return; &#125; stopHeartbeatTimer(); try &#123; scheduled.shutdown(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; 化繁为简，这里只挑选上面代码中打标的两个地方进行分析 判断服务端是否还在处理请求，在超时时间内一直等待到所有任务处理完毕 关闭心跳检测 关闭 NettyServer 特别需要关注第一点，正符合我们在一开始提出的优雅停机的诉求 2：“在途请求需要处理完毕，不能被停机指令中断”。 3.5 优雅停机初始方案总结上述介绍的几个类构成了 Dubbo 2.5.x 的优雅停机方案，简单做一下总结，Dubbo 的优雅停机逻辑时序如下： 123456789101112Registry 注销等待 -Ddubbo.service.shutdown.wait 秒，等待消费方收到下线通知Protocol 注销 DubboProtocol 注销 NettyServer 注销 等待处理中的请求完毕 停止发送心跳 关闭 Netty 相关资源 NettyClient 注销 停止发送心跳 等待处理中的请求完毕 关闭 Netty 相关资源 Dubbo 2.5.3 优雅停机的缺陷 如果你正在使用的 Dubbo 版本 &lt;= 2.5.3，一些并发问题和代码缺陷会导致你的应用不能很好的实现优雅停机功能，请尽快升级。 详情可以参考该 pull request 的变更：https://github.com/apache/dubbo/pull/568 4 Spring 容器下 Dubbo 的优雅停机上述的方案在不使用 Spring 时的确是无懈可击的，但由于现在大多数开发者选择使用 Spring 构建 Dubbo 应用，上述的方案会存在一些缺陷。 由于 Spring 框架本身也依赖于 shutdown hook 执行优雅停机，并且与 Dubbo 的优雅停机会并发执行，而 Dubbo 的一些 Bean 受 Spring 托管，当 Spring 容器优先关闭时，会导致 Dubbo 的优雅停机流程无法获取相关的 Bean，从而优雅停机失效。 Dubbo 开发者们迅速意识到了 shutdown hook 并发执行的问题，开始了一系列的补救措施。 4.1 增加 ShutdownHookListenerSpring 如此受欢迎的原因之一便是它的扩展点非常丰富，例如它提供了 ApplicationListener 接口，开发者可以实现这个接口监听到 Spring 容器的关闭事件，为解决 shutdown hook 并发执行的问题，在 Dubbo 2.6.3 中新增了 ShutdownHookListener 类，用作 Spring 容器下的关闭 Dubbo 应用的钩子。 123456789101112private static class ShutdownHookListener implements ApplicationListener &#123; @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ContextClosedEvent) &#123; // we call it anyway since dubbo shutdown hook make sure its destroyAll() is re-entrant. // pls. note we should not remove dubbo shutdown hook when spring framework is present, this is because // its shutdown hook may not be installed. DubboShutdownHook shutdownHook = DubboShutdownHook.getDubboShutdownHook(); shutdownHook.destroyAll(); &#125; &#125;&#125; 当服务提供者 ServiceBean 和服务消费者 ReferenceBean 被初始化时，会触发该钩子被创建。 再来看看 AbstractConfig 中的代码，依旧保留了 JVM 的 shutdown hook 12345public abstract class AbstractConfig implements Serializable &#123; static &#123; Runtime.getRuntime().addShutdownHook(DubboShutdownHook.getDubboShutdownHook()); &#125;&#125; 也就是说，在 Spring 环境下会注册两个钩子，在 Non-Spring 环境下只会有一个钩子，但看到 2.6.x 的实现大家是否意识到了两个问题呢？ 两个钩子并发执行不会报错吗？ 为什么在 Spring 下不取消 JVM 的钩子，只保留 Spring 的钩子不就可以工作了吗？ 先解释第一个问题，这个按照我的理解，这段代码的 Commiter 可能认为只需要有一个 Spring 的钩子能正常注销就完事了，不需要考虑另外一个报不报错，因为都是独立的线程，不会有很大的影响。 再解释第二个问题，其实这个疑问的答案就藏在上面 ShutdownHookListener 代码的注释中，这段注释的意思是说：在 Spring 框架下不能直接移除原先的 JVM 钩子，因为 Spring 框架可能没有注册 ContextClosed 事件。啥意思呢？这里涉及到 Spring 框架生命周期的一个细节，我打算单独介绍一下。 4.2 Spring 的容器关闭事件详解在 Spring 中，我们可以使用至少三种方式来注册容器关闭时一些收尾工作： 使用 DisposableBean 接口 1234567public class TestDisposableBean implements DisposableBean &#123; @Override public void destroy() throws Exception &#123; System.out.println(\"== invoke DisposableBean ==\"); &#125;&#125; 使用 @PreDestroy 注解 12345678public class TestPreDestroy &#123; @PreDestroy public void preDestroy()&#123; System.out.println(\"== invoke preDestroy ==\"); &#125;&#125; 使用 ApplicationListener 监听 ContextClosedEvent 12345678applicationContext.addApplicationListener(new ApplicationListener&lt;ApplicationEvent&gt;() &#123; @Override public void onApplicationEvent(ApplicationEvent applicationEvent) &#123; if (applicationEvent instanceof ContextClosedEvent) &#123; System.out.println(\"== receive context closed event ==\"); &#125; &#125;&#125;); 但需要注意的是，在使用 SpringBoot 内嵌 Tomcat 容器时，容器关闭钩子是自动被注册，但使用纯粹的 Spring 框架或者外部 Tomcat 容器，需要显式的调用 context.registerShutdownHook(); 接口进行注册 1234567891011ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"spring/beans.xml\");context.start();context.registerShutdownHook();context.addApplicationListener(new ApplicationListener&lt;ApplicationEvent&gt;() &#123; @Override public void onApplicationEvent(ApplicationEvent applicationEvent) &#123; if (applicationEvent instanceof ContextClosedEvent) &#123; System.out.println(\"== receive context closed event ==\"); &#125; &#125;&#125;); 否则，上述三种回收方法都无法工作。我们来看看 registerShutdownHook() 都干了啥 123456789101112131415161718public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext, DisposableBean&#123; @Override public void registerShutdownHook() &#123; if (this.shutdownHook == null) &#123; // No shutdown hook registered yet. this.shutdownHook = new Thread() &#123; @Override public void run() &#123; synchronized (startupShutdownMonitor) &#123; doClose(); &#125; &#125; &#125;; Runtime.getRuntime().addShutdownHook(this.shutdownHook); // 重点！ &#125; &#125;&#125; 其实也就是显式注册了一个属于 Spring 的钩子。这也解释上了 4.1 小节中，为什么有那段注释了，注册了事件不一定管用，还得保证 Spring 容器注册了它自己的钩子。 4.3 Dubbo 优雅停机中级方案总结第 4 节主要介绍了 Dubbo 开发者们在 Spring 环境下解决 Dubbo 优雅停机并发执行 shutdown hook 时的缺陷问题，但其实还不完善，因为在 Spring 环境下，如果没有显式注册 Spring 的 shutdown， 还是会存在缺陷的，准确的说，Dubbo 2.6.x 版本可以很好的在 Non-Spring、Spring Boot、Spring + ContextClosedEvent 环境下很好的工作。 5 Dubbo 2.7 最终方案12345678910public class SpringExtensionFactory implements ExtensionFactory &#123; public static void addApplicationContext(ApplicationContext context) &#123; CONTEXTS.add(context); if (context instanceof ConfigurableApplicationContext) &#123; ((ConfigurableApplicationContext) context).registerShutdownHook(); DubboShutdownHook.getDubboShutdownHook().unregister(); &#125; BeanFactoryUtils.addApplicationListener(context, SHUTDOWN_HOOK_LISTENER); &#125;&#125; 这段代码寥寥数行，却是经过了深思熟虑之后的产物，期间迭代了 3 个大版本，真是不容易。这段代码很好地解决了第 4 节提出的两个问题 担心两个钩子并发执行有问题？那就在可以注册 Spring 钩子的时候取消掉 JVM 的钩子。 担心当前 Spring 容器没有注册 Spring 钩子？那就显示调用 registerShutdownHook 进行注册。 其他细节方面的优化和 bugfix 我就不进行详细介绍了，可以见得实现一个优雅停机需要考虑的点非常之多。 6 总结优雅停机看似是一个不难的技术点，但在一个通用框架中，使用者的业务场景类型非常多，这会大大加剧整个代码实现的复杂度。 摸清楚整个 Dubbo 优雅停机演化的过程，也着实花费了我一番功夫，有很多实现需要 checkout 到非常古老的分支，同时翻阅了很多 issue、pull request 的讨论，最终才形成了这篇文章，虽然研究的过程是困难的，但获取到真相是让人喜悦的。 在开源产品的研发过程中，服务到每一个类型的用户真的是非常难的一件事，能做的是满足大部分用户。例如 2.6.x 在大多数环境下其实已经没问题了，在 2.7.x 中则是得到了更加的完善，但是我相信，在使用 Dubbo 的部分用户中，可能还是会存在优雅停机的问题，只不过还没有被发现。 商业化的思考：和开源产品一样，商业化产品的研发也同样是一个逐渐迭代的过程，需要数代开发者一起维护一份代码，使用者发现问题，开发者修复问题，这样的正反馈可以形成一个正反馈，促使产品更加优秀。 相关 pull request: 修复 2.5.3 bug 的 pr： https://github.com/apache/dubbo/pull/568 作者：@qinliujie 2.6.x Spring Shutdown Hook Enhancement: https://github.com/apache/dubbo/pull/1763 作者：@ralf0131 https://github.com/apache/dubbo/pull/1820 作者：@ralf0131 2.7.x Spring Shutdown Hook Enhancement: https://github.com/apache/dubbo/pull/3008/ 作者：@beiwei30","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"}]},{"title":"使用 JMeter 进行 Dubbo 性能测试","slug":"dubbo-perf-benchmark","date":"2019-09-05T11:45:52.000Z","updated":"2019-09-26T09:45:31.281Z","comments":true,"path":"dubbo-perf-benchmark/","link":"","permalink":"http://lexburner.github.io/dubbo-perf-benchmark/","excerpt":"1 前言说道性能测试工具，你会立刻联想到哪一个？ab（ApacheBench）、JMeter、LoadRunner、wrk…可以说市面上的压测工具实在是五花八门。那如果再问一句，对 Dubbo 进行性能压测，你会 pick 哪一个？可能大多数人就懵逼了。可以发现，大多数的压测工具对开放的协议支持地比较好，例如：HTTP 协议，但对于 Dubbo 框架的私有协议：dubbo，它们都显得力不从心了。 如果不从通用的压测工具上解决 Dubbo 的压测需求问题，可以自己写 Dubbo 客户端，自己统计汇总结果，但总归不够优雅，再加上很多开发同学没有丰富的测试经验，很容易出现一些偏差。说到底，还是压测工具靠谱，于是便引出了本文的主角 —— jmeter-plugins-for-apache-dubbo。这是一款由 Dubbo 社区 Commiter – 凝雨 同学开发的 JMeter 插件，可以非常轻松地对 Dubbo 实现性能测试。","text":"1 前言说道性能测试工具，你会立刻联想到哪一个？ab（ApacheBench）、JMeter、LoadRunner、wrk…可以说市面上的压测工具实在是五花八门。那如果再问一句，对 Dubbo 进行性能压测，你会 pick 哪一个？可能大多数人就懵逼了。可以发现，大多数的压测工具对开放的协议支持地比较好，例如：HTTP 协议，但对于 Dubbo 框架的私有协议：dubbo，它们都显得力不从心了。 如果不从通用的压测工具上解决 Dubbo 的压测需求问题，可以自己写 Dubbo 客户端，自己统计汇总结果，但总归不够优雅，再加上很多开发同学没有丰富的测试经验，很容易出现一些偏差。说到底，还是压测工具靠谱，于是便引出了本文的主角 —— jmeter-plugins-for-apache-dubbo。这是一款由 Dubbo 社区 Commiter – 凝雨 同学开发的 JMeter 插件，可以非常轻松地对 Dubbo 实现性能测试。 2 JMeter 介绍在开始压测 Dubbo 之前，先简单介绍一下这款开源的性能测试工具 —— JMeter。JMeter 是 Apache 组织基于 Java 开发的一款性能测试工具。它最初被设计用于 Web 应用测试，但后来扩展到其他测试领域，并可以在 Windows、Mac、Linux 环境下安装使用。JMeter 还提供了图形界面，这使得编写测试用例变得非常简单，具有易学和易操作的特点。 JMeter 官网：http://jmeter.apache.org/download_jmeter.cgi 2.1 安装 JMeter截止本文发布，官方的最新版本为：apache-jmeter-5.1.1.zip , 下载后直接解压即可。 在 ${JMETER_HOME}/bin 下找到启动脚本，可以打开图形化界面 Mac/Linux 用户可以直接使用 jmeter 可执行文件，或者 jmeter.sh 启动脚本 Windows 用户可以使用 jmeter.bat 启动脚本 2.2 命令行提示信息启动过程中会有一段命令行日志输出： 12345678================================================================================Don't use GUI mode for load testing !, only for Test creation and Test debugging.For load testing, use CLI Mode (was NON GUI): jmeter -n -t [jmx file] -l [results file] -e -o [Path to web report folder]&amp; increase Java Heap to meet your test requirements: Modify current env variable HEAP=\"-Xms1g -Xmx1g -XX:MaxMetaspaceSize=256m\" in the jmeter batch fileCheck : https://jmeter.apache.org/usermanual/best-practices.html================================================================================ 注意到第一行的提示，GUI 仅仅能够用于调试和创建测试计划，实际的性能测试需要使用命令行工具进行。 jmeter -n -t [jmx file] -l [results file] -e -o [Path to web report folder] 【jmx file】：使用 GUI 创建的测试计划文件，后缀名为 .jmx 【results file】：测试结果文本文件输出路径 【Path to web report folder】：测试报告输出路径，JMeter 的强大之处，可以生成图文并茂的测试报告 2.3 GUI 界面展示 上图所示为 JMeter 的主界面。官方提供了国际化支持，通过 【Options】-&gt;【Choose Language】可以将界面语言变更为简体中文。 3 JMeter 压测 HTTP本节以 JMeter 压测 HTTP 为引子，介绍 JMeter 的使用方式，让没有使用过 JMeter 的读者对这款工具有一个较为直观的感受。 3.1 创建线程组在“测试计划”上右键 【添加】–&gt;【线程（用户）】–&gt;【线程组】。 给线程组起一个名字，方便记忆。 线程数：决定了由多少线程并发压测 Ramp-Up：代表了 JMeter 创建所有线程所需要的时间，如图所示则代表每 0.1s 创建一个线程 循环次数：在运行所设置的次数之后，压测将会终止。如果想要运行固定时长的压测，可以设置为：永远，并在下面的调度器中指定持续时间 3.2 增加 HTTP 取样器在刚刚创建的线程组上右键 【添加】–&gt;【取样器】–&gt;【HTTP 请求】。 为 HTTP 取样器配置上压测地址和必要的参数 3.3 添加察看结果树在刚刚创建的线程组上右键 【添加】–&gt;【监听器】–&gt;【察看结果树】。 只有添加了【察看结果树】才能让我们看到 GUI 中测试的结果。 3.4 准备 HTTP Server使用 SpringBoot 可以快速构建一个 RestController，其暴露了 localhost:8080/queryOrder/{orderNo} 做为压测入口 123456789101112@RestControllerpublic class OrderRestController &#123; @Autowired OrderService orderService; @RequestMapping(\"/queryOrder/&#123;orderNo&#125;\") public OrderDTO queryOrder(@PathVariable(\"orderNo\") long orderNo) &#123; return orderService.queryOrder(orderNo); &#125;&#125; 被压测的服务 OrderService ： 1234567891011@Componentpublic class OrderService &#123; public OrderDTO queryOrder(long orderNo) &#123; OrderDTO orderDTO = new OrderDTO(); orderDTO.setOrderNo(orderNo); orderDTO.setTotalPrice(new BigDecimal(ThreadLocalRandom.current().nextDouble(100.0D))); orderDTO.setBody(new byte[1000]); return orderDTO; &#125;&#125; 3.5 验证结果 在刚刚创建的线程组上右键 【验证】，执行单次验证，可以用来测试与服务端的连通性。在【察看结果树】选项卡中可以看到【响应数据】已经正常返回了。 3.6 执行测试计划还记得之前启动 GUI 时控制台曾经提示过我们，GUI 只负责创建测试计划并验证，不能用于执行实际的并发压测。在 GUI 中准备就绪之后，我们可以在【文件】-&gt;【保存测试计划为】中将测试计划另存为 rest-order-thread-group.jmx 测试文件，以便我们在命令行进行压测： 1jmeter -n -t ./rest-order-thread-group.jmx -l ./result.txt -e -o ./webreport 下图展示了最终生成的测试报告，主要汇总了执行次数、响应时间、吞吐量、网络传输速率。 在实际的测试报告中，还有更加详细的维度可以展示，上述只是展示了汇总信息。 4 JMeter 压测 DubboJMeter 默认并不支持私有的 dubbo 协议，但其优秀的扩展机制使得只需要添加插件，就可以完成 Dubbo 压测，这一节也是本文重点介绍的部分。 4.1 安装 jmeter-plugins-for-apache-dubbo 插件地址：https://github.com/thubbo/jmeter-plugins-for-apache-dubbo 目前该插件支持对最新版本的 Dubbo 进行压测，推荐的安装方式： 克隆项目：git clone https://github.com/thubbo/jmeter-plugins-for-apache-dubbo.git 打包项目，构建 JMeter 插件：mvn clean install ，得到：jmeter-plugins-dubbo-2.7.3-jar-with-dependencies.jar 将插件添加到 ${JMETER_HOME}\\lib\\ext 4.2 增加 Dubbo 取样器之前的小结已经介绍了如何添加线程组和 HTTP 取样器，现在想要对 Dubbo 应用进行性能测试，可以直接复用之前的线程组配置，在线程组上右键 【添加】–&gt;【取样器】–&gt;【Dubbo Sample】。 创建 Dubbo 取样器之后，可以对其进行配置 4.3 准备 Dubbo Provider复用 HTTP 取样器时的 OrderService 1234567891011@Servicepublic class OrderDubboProvider implements OrderApi &#123; @Autowired OrderService orderService; @Override public OrderDTO queryOrder(long orderNo) &#123; return orderService.queryOrder(orderNo); &#125;&#125; 配置 application.properties，注册服务到 Zookeeper 注册中心: 1234dubbo.scan.basePackages=com.alibaba.edas.benchmarkdubbo.application.name=dubbo-provider-demodubbo.registry.address=zookeeper://127.0.0.1:2181dubbo.protocol.port=20880 4.4 验证结果在 JMeter 中配置好 Dubbo 服务所连接的注册中心，接着通过 Get Provider List 可以获取到服务提供者列表，以供压测选择。在线程组上右键 【验证】，执行单次验证，可以用来测试与服务端的连通性。在【察看结果树】选项卡中可以看到【响应数据】可以正常执行 Dubbo 调用了。 4.5 执行测试计划可以将 Dubbo 取样器和 HTTP 取样器包含在同一个测试计划中一起执行，同时进行了 Dubbo 接口与 Rest 接口的性能对比。在命令行进行压测： 1jmeter -n -t ./rest-order-thread-group.jmx -l ./result.txt -e -o ./webreport 下图展示了最终生成的测试报告： Dubbo 接口与 Rest 接口所封装的业务接口均为 OrderService，所以压测上的差距直接体现出了 Dubbo 和 Rest 的差距。从报告对比上来看，Dubbo 接口的平均 RT 远低于 Rest 接口。 5 总结本文从零到一介绍了使用 JMeter 压测 HTTP 的方法，让读者熟悉 JMeter 的使用方式，并着重介绍了使用 jmeter-plugins-for-apache-dubbo 插件压测 Dubbo 的方法。 由于 JMeter Plugin 的限制，目前 Dubbo 的压测请求是通过泛化调用进行发送的，会有一定程度的性能下降，所以在实际评估 Dubbo 接口性能时，接口实际性能会比压测结果更加乐观。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"DUBBO","slug":"DUBBO","permalink":"http://lexburner.github.io/tags/DUBBO/"},{"name":"JMeter","slug":"JMeter","permalink":"http://lexburner.github.io/tags/JMeter/"}]},{"title":"华为云 TaurusDB 性能挑战赛赛题总结","slug":"taurusdb-race","date":"2019-09-02T12:19:23.000Z","updated":"2019-09-26T09:45:29.481Z","comments":true,"path":"taurusdb-race/","link":"","permalink":"http://lexburner.github.io/taurusdb-race/","excerpt":"1 前言 回顾第一次参加性能挑战赛 – 第四届阿里中间件性能挑战赛，那时候真的是什么都不会，只有一腔热情，借着比赛学会了 Netty、学会了文件 IO 的最佳实践，到了这次华为云举办的 TaurusDB 性能挑战赛，已经是第三次参加比赛了，同时也是最“坎坷”的一次比赛。经过我和某位不愿意透露姓名的 96 年小迷妹的不懈努力，最终跑分排名为第 3 名。","text":"1 前言 回顾第一次参加性能挑战赛 – 第四届阿里中间件性能挑战赛，那时候真的是什么都不会，只有一腔热情，借着比赛学会了 Netty、学会了文件 IO 的最佳实践，到了这次华为云举办的 TaurusDB 性能挑战赛，已经是第三次参加比赛了，同时也是最“坎坷”的一次比赛。经过我和某位不愿意透露姓名的 96 年小迷妹的不懈努力，最终跑分排名为第 3 名。 如果要挑选一个词来概括这次比赛的核心内容，那非”计算存储分离“莫属了，通过这次比赛，自己也对计算存储分离架构有了比较直观的感受。为了比较直观的体现计算存储分离的优势，以看电影来举个例子：若干年前，我总是常备一块大容量的硬盘存储小电影，但自从家里带宽升级到 100mpbs 之后，我从来不保存电影了，要看直接下载 / 缓冲，基本几分钟就好了。这在几年前还不可想象，如今是触手可及的事实，归根到底是随着互联网的发展，网络 IO 已经不再是瓶颈了。 计算存储分离架构相比传统本地存储架构而言，具有更加灵活、成本更低等特性，但架构的复杂性也会更高，也会更加考验选手的综合能力。 计算存储分离架构的含义： 存储端有状态，只存储数据，不处理业务逻辑。 计算端无状态，只处理逻辑，不持久化存储数据。 2 赛题概览比赛整体分成了初赛和复赛两个部分，初赛要求实现一个简化、高效的本地 kv 存储引擎，复赛在初赛的基础上增加了计算存储分离的架构，计算节点需要通过网络传输将数据递交给存储节点存储。 12345678public interface KVStoreRace &#123; public boolean init(final String dir, final int thread_num) throws KVSException; public long set(final String key, final byte[] value) throws KVSException; public long get(final String key, final Ref&lt;byte[]&gt; val) throws KVSException;&#125; 计算节点和存储节点共用上述的接口，评测程序分为 2 个阶段： 正确性评测 此阶段评测程序会并发写入随机数据（key 8B、value 4KB），写入数据过程中进行任意次进程意外退出测试，引擎需要保证异常中止不影响已经写入的数据正确性。异常中止后，重启引擎，验证已经写入数据正确性和完整性，并继续写入数据，重复此过程直至数据写入完毕。只有通过此阶段测试才会进入下一阶段测试。 性能评测 随机写入：16 个线程并发随机写入，每个线程使用 Set 各写 400 万次随机数据（key 8B、value 4KB）顺序读取：16 个线程并发按照写入顺序逐一读取，每个线程各使用 Get 读取 400 万次随机数据热点读取：16 个线程并发读取，每个线程按照写入顺序热点分区，随机读取 400 万次数据，读取范围覆盖全部写入数据。热点的逻辑为：按照数据的写入顺序按 10MB 数据粒度分区，分区逆序推进，在每个 10MB 数据分区内随机读取。随机读取次数会增加约 10%。 语言限定 CPP &amp; Java，一起排名 3 赛题剖析看过我之前《PolarDB 数据库性能大赛 Java 选手分享》的朋友应该对题目不会感到陌生，基本可以看做是在 PolarDB 数据库性能挑战赛上增加一个网络通信的部分，所以重头戏基本是在复赛网络通信的比拼上。初赛主要是文件 IO 和存储架构的设计，如果对文件 IO 常识不太了解，可以先行阅读 《文件 IO 操作的一些最佳实践》。 3.1 架构设计计算节点只负责生成数据，在实际生产中计算节点还承担额外的计算开销，由于计算节点是无状态的，所以不能够聚合数据写入、落盘等操作，但可以在 Get 触发网络 IO 时一次读取大块数据用作缓存，减少网络 IO 次数。 存储节点负责存储数据，考验了选手对磁盘 IO 和缓存的设计，可以一次使用缓存写入 / 读取大块数据，减少磁盘 IO 次数。 所以选手们将会围绕网络 IO、磁盘 IO 和缓存设计来设计整体架构。 3.2 正确性检测赛题明确表示会进行 kill -9 并验证数据的一致性，正确性检测主要影响的是写入阶段。 存储节点负责存储数据，需要保证 kill -9 不丢失数据，但并不要求断电不丢失，这间接地阐释了一点：我们可以使用 PageCache 来做写入缓存；正确性检测对于计算节点与存储节点之间通信影响便是：每次写入操作都必须 ack，所以选手必须保证同步通信，类似于 ping/pong 模型。 3.3 性能评测性能评测由随机写、顺序读、热点读（随机读取热点数据）三部分构成。 随机写阶段与 PolarDB 的评测不同，TaurusDB 随机写入 key 的 16 个线程是隔离的，即 A 线程写入的数据只会由 A 线程读出，可以认为是彼此独立的 16 个实例在执行评测，这大大简化了我们的架构。 顺序读阶段的描述也很容易理解，需要注意的是这里的顺序是按照写入顺序，而不是 Key 的字典序，所以随机写可以转化为顺序写，也方便了选手去设计顺序读的架构。 热点读阶段有点故弄玄虚了，其实就是按照 10M 数据为一个分区进行逆序读，同时在 10M 数据范围内掺杂一些随机读，由于操作系统的预读机制只会顺序预读，无法逆序预读，PageCache 将会在这个环节会失效，考验了选手自己设计磁盘 IO 缓存的能力。 4 架构详解4.1 全局架构 计算存储分离架构自然会分成计算节点和存储节点两部分来介绍。计算节点会在内存维护数据的索引表；存储节点负责存储持久化数据，包括索引文件和数据文件；计算节点与存储节点之间的读写都会经过网络 IO。 4.2 随机写架构 随机写阶段，评测程序调用计算节点的 set 接口，发起网络 IO，存储节点接受到数据后不会立刻落盘，针对 data 和 index 的处理也会不同。针对 data 部分，会使用一块缓冲区（如图：Mmap Merge IO）承接数据，由于 Mmap 的特性，会形成 Merge File 文件，一个数据缓冲区可以聚合 16 个数据，当缓冲区满后，将缓冲区的数据追加到数据文件后，并清空 Merge File；针对 index 部分，使用 Mmap 直接追加到索引文件中。 F: 1. data 部分为什么搞这么复杂，需要聚合 16 个数据再刷盘？ Q: 针对此次比赛的数据盘，实测下来 16 个数据刷盘可以打满 IO。 F: 2. 为什么使用 Mmap Merge IO 而不直接使用内存 Merge IO？ Q: 正确性检测阶段，存储节点可能会被随机 kill，Mmap 做缓存的好处是操作系统会帮我们落盘，不会丢失数据 F: 3. 为什么 index 部分直接使用 Mmap，而不和 data 部分一样处理？ Q: 这需要追溯到 Mmap 的特点，Mmap 适合直接写索引这种小数据，所以不需要聚合。 4.3 热点读 &amp; 顺序读架构 热点读取阶段 &amp; 顺序读取阶段 ，这两个阶段其实可以认为是一种策略，只不过一个正序，一个逆序，这里以热点读为例介绍。我们采取了贪心的思想，一次读取操作本应该只会返回 4kb 的数据，但为了做预读缓存，我们决定会存储节点返回 10M 的数据，并缓存在计算节点中，模拟了一个操作系统预读的机制，同时为了能够让计算节点精确知道缓存是否命中，会同时返回索引数据，并在计算节点的内存中维护索引表，这样便减少了成吨的网络 IO 次数。 4.4 存储设计 站在每个线程的视角，可以发现在我们的架构中，每个线程都是独立的。评测程序会对每个线程写入 400w 数据，最终形成 16 16G 的数据文件和 16 32M 左右的索引文件。 数据文件不停追加 MergeFile，相当于一次落盘单位是 64K（16 个数据），由于自行聚合了数据，所以可以采用 Direct IO，减少操作系统的 overhead。 索引文件由小数据构成，所以采用 Mmap 方式直接追加写 计算节点由于无状态的特性，只能在内存中维护索引结构。 4.5 网络通信设计 我们都知道 Java 中有 BIO（阻塞 IO）和 NIO（非阻塞 IO）之分，并且大多数人可能会下意识觉得：NIO 就是比 BIO 快。而这次比赛恰恰是要告诉大家，这两种 IO 方式没有绝对的快慢之分，只有在合适的场景中选择合适的 IO 方式才能发挥出最佳性能。 稍微分析下这次比赛的通信模型，写入阶段由于需要保证每次 set 不受 kill 的影响，所以需要等到同步返回后才能进行下一次 set，而 get 本身依赖于返回值进行数据校验，所以从通信模型上看只能是同步 ping/pong 模型；从线程数上来看，只有固定的 16 个线程进行收发消息。以上两个因素暗示了 BIO 将会非常契合这次比赛。 在很多人的刻板印象中，阻塞就意味着慢，非阻塞就意味着快，这种理解是完全错误的，快慢取决于通信模型、系统架构、带宽、网卡等因素。我测试了 NIO + CountDownLatch 和 BIO 的差距，前者会比后者整体慢 100s ~ 130s。 5 细节优化点5.1 最大化磁盘吞吐量但凡是涉及到磁盘 IO 的比赛，首先需要测试便是在 Direct IO 下，一次读写多大的块能够打满 IO，在此基础上，才能进行写入缓冲设计和读取缓存设计，否则在这种争分夺秒的性能挑战赛中不可能取得较好的名次。测试方法也很简单，如果能够买到对应的机器，直接使用 iostat 观察不同刷盘大小下的 iops 即可，如果比赛没有机器，只能祭出调参大法，不停提交了，这次 TaurusDB 的盘实测下来 64k、128K 都可以获得最大的吞吐量。 5.2 批量回传数据计算节点设计缓存是一个比较容易想到的优化点，按照常规的思路，索引应该是维护在存储节点，但这样做的话，计算节点在 get 数据时就无法判断是否命中缓存，所以在前文的架构介绍中，我们将索引维护在了计算节点之上，在第一次 get 时，顺便恢复索引。批量返回数据的优势在于增加了缓存命中率、降低总网络 IO 次数、减少上行网络 IO 数据量，是整个比赛中分量较重的一个优化点。 5.3 流控 在比赛中容易出现的一个问题，在批量返回 10M 数据时经常会出现网络卡死的情况，一时间无法定位到问题，以为是代码 BUG，但有时候又能跑出分数，不得以尝试过一次返回较少的数据量，就不会报错。最后还是机智的小迷妹定位到问题是 CPU 和 IO 速率不均等导致的，解决方案便是在一次 pong 共计返回 10M 的基础上，将报文拆分成 64k 的小块，中间插入额外的 CPU 操作，最终保证了程序稳定性的同时，也保障了最佳性能。 额外的 CPU 操作例如：for(int i=0;i&lt;700;i++)，不要小看这个微不足道的一个 for 循环哦。 流控其实也是计算存储分离架构一个常见设计点，存储节点与计算节点的写入速度需要做一个平衡，避免直接打垮存储节点，也有一种”滑动窗口“机制专门应对这种问题，不在此赘述了。 5.4 预分配文件在 Cpp 中可以使用 fallocate 预先分配好文件大小，会使得写入速度提升 2s。在 Java 中没有 fallocate 机制，但是可以利用评测程序的漏洞，在 static 块中事先写好 16 * 16G 的文件，同样可以获得 fallocate 的效果。 5.5 合理设计索引结构get 时需要根据 key 查询到文件偏移量，这显示是一个 Map 结构，在这个 Map 上也有几个点需要注意。以 Java 为例，使用 HashMap 是否可行呢？当然可以，但是缺点也很明显，其会占用比较大的内存，而且存取性能不好，可以使用 LongIntHashMap 来代替，看过我之前文章的朋友应该不会对这个数据结构感到陌生，它是专门为基础数据类型设计的 Map 容器。 每个线程 400w 数据，每个线程独享一个索引 Map，为了避免出现扩容，需要合理的设置扩容引子和初始化容量：new LongIntHashMap(410_0000, 0.99); 5.6 Direct IO最终进入决赛的，有三支 Java 队伍，相比较 Cpp 得天独厚的对操作系统的灵活控制性，Java 选手更像是带着镣铐在舞蹈，幸好有了上次 PolarDB 比赛的经验，我提前封装好了 Java 的 Direct IO 类库：https://github.com/lexburner/kdio，相比 FileChannel，它能够使得磁盘 IO 效率更高。得知有 Java 选手真的在比赛中使用了我的 Direct IO 类库，也是比赛中实实切切的乐趣之一。 6 失败的优化点6.1 预读线程先行考虑到网络 IO 还是比本地磁盘 IO 要慢的，一个本以为可行的方案是单独使用预读线程进行存储节点的磁盘 IO，设计一个 RingBuffer，不断往前预读，直到环满，计算阶段 get 时会消费 RingBuffer 的一格缓存，从而使得网络 IO 和磁盘 IO 不会相互等待。实际测试下来，发现瓶颈主要还是在于网络 IO，这样的优化徒增了不少代码，不利于进行其他的优化尝试，最终放弃。 6.2 计算节点聚合写入缓冲既然在 get 阶段时存储节点批量返回数据给计算节点可以提升性能，那 set 阶段聚合批量的数据再发送给存储节点按理来说也能提升性能吧？的确如此，如果不考虑正确性检测，这的确是一个不错的优化点，但由于 kill 的特性使得我们不得不每一次 set 都进行 ACK。但是！可以对将 4/8/16 个线程编为一组进行聚合呀！通过调整参数来确定该方案是否可行。 然后事与愿违，该方案并没有取得成效。 7 聊聊比赛吧之前此类工程性质的性能挑战赛只有阿里一家互联网公司承办过，作为热衷于中间件性能优化的参赛选手而言，非常高兴华为也能够举办这样性质的比赛。虽然比赛中出现了诸多的幺蛾子，但毕竟是第一次承办比赛，我也就不表了。 如果你同样也是性能挑战赛的爱好者，想要在下一次中间件性能挑战赛中有一群小伙伴一起解题、组队，体验冲分的乐趣，欢迎关注我的微信公众号：【Kirito 的技术分享】，也欢迎加入微信技术交流群进行交流 ~","categories":[{"name":"性能挑战赛","slug":"性能挑战赛","permalink":"http://lexburner.github.io/categories/性能挑战赛/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://lexburner.github.io/tags/数据库/"}]},{"title":"日本东京游记 || 内含秋叶原、动漫打卡地攻略","slug":"tokyo-travel","date":"2019-09-02T12:19:23.000Z","updated":"2019-09-26T09:45:31.509Z","comments":true,"path":"tokyo-travel/","link":"","permalink":"http://lexburner.github.io/tokyo-travel/","excerpt":"由于表弟是个狂热的二次元爱好者，受我小姨之托，带他去日本游玩了一趟。趁着这个机会，打算给大家分享一下日本旅游的一些攻略，以祭奠我逝去的年假。这是我第二次去日本了，上一次还是大二时跟我初中舍友一起去的，所以这次去已经有了一些经验了，很多朋友表示想去日本，期待我能写一篇攻略，所以这篇攻略将会偏小白向，如果你是第一次去日本，那这篇攻略想必不会让你失望。","text":"由于表弟是个狂热的二次元爱好者，受我小姨之托，带他去日本游玩了一趟。趁着这个机会，打算给大家分享一下日本旅游的一些攻略，以祭奠我逝去的年假。这是我第二次去日本了，上一次还是大二时跟我初中舍友一起去的，所以这次去已经有了一些经验了，很多朋友表示想去日本，期待我能写一篇攻略，所以这篇攻略将会偏小白向，如果你是第一次去日本，那这篇攻略想必不会让你失望。 出行准备护照 / 签证出国旅游前需要准备两样最基础的东西：护照和签证。 护照 。申请护照一般是由本人到户籍所在地的公安局出入境管理处办理，办理时长一般在 15 个工作日左右。因为我 4 年前去过日本，那时候已经办理了护照，一般护照有效期是 10 年左右，所以这次只需要办理签证就行了。 签证 。日本现在有 单次旅游 /3 年多次往返 /5 年多次往返 三种签证。一般来讲，个人旅游办理的都是单次旅游，条件限制比较低，多次往返签证则相对要求较高。因为领区的不同，具体地区送签材料要求大家可以自己再去咨询。普通送签的话机票酒店信息，银行流水，在职在读等等都需要准备，需要的材料很多，选择跟团的话就可以省去很多麻烦事，旅行社办理签证可以节省下不少准备材料。 这次跟我表弟去日本，由于我在杭州工作，江浙沪属于上海领区，而他在广州，属于广州领区，所有即使是跟团游，我也只能找到旅行社单独办理个签。另外有一点值得注意的是，日本签证要求提供的个人照片尺寸为 4.5cm x 4.5cm，不太符合常规的中国制式，一般各个国家的签证照片都有各自的规定，准备时可以稍微留意下。 行程安排关于行程安排，每个人自然有自己的想法，东京、北海道、大阪、京都都有各自吸引游客的景点。 有的人选择跟团，也有的人选择自由行，也有跟团和自由行的组合半自由行。我们这次选择的就是半自由行，旅行社会负责包揽机票、住宿和固定景点等事宜，也会有 2 天时间供我们在东京自由行，没有自由活动的日本之行是没有灵魂的！ 赴日旅游的游客，我个人还是挺推荐这种 半自由行 的。旅行社会有包车穿梭于各个景点之间，酒店机票等事宜也不用自己操心，可以为前期攻略省下不少时间。提到自由行，虽然我不会日语，但是日本的中国人挺多的，并且所看到的大部分汉字基本都能看懂，服务中心一般用英语也可以沟通，自由行的时候也不用太过于担心。 现金置换 这次去日本算是体会到了日本的进步，在上次去日本时，主要还是通过现金、银联卡两种方式支付，而 2019 年的今天再去东京，大到商场百货，小到街边的拉面店，都已经支持了支付宝、微信这两种中国本土的快捷支付方式。 虽然刷卡、快捷支付很方便，但仍然还是有不少地方只支持现金的，例如日本的电车，所以出行前建议置换好足量的现金，我这次准备了 4000 人民币合 6w 日元的现金。价值较高的商品可以选择使用银联卡或者快捷支付这两种方式。 在国内置换日元。可以选择在银行柜台置换，也可以选择在机场置换。选择在机场置换大概率比银行置换要亏，需要交纳 50 块的手续费，而且汇率也不同，具体没有太多研究，但推荐大家在银行置换好日元。 在日本置换日元。在日本街头的 ATM 使用银联卡就可以取出日元了，当然也可以在到达机场兑换，另外值得一提的是日本的 711 和全家等便利连锁店都设有 ATM，秋叶原等外国游客较多的地方也设有外汇置换点，但是价格较贵。 小 tips：￥是人民币（CNY）和日元（JPY）的货币符号。这两种货币的单位都是元，在日本可不要被高额的标价吓到哦，那是日元，不是人民币。 流量 &amp; 网络在日本，没有开通国际漫游的用户是没法使用手机的，建议赴日旅游前一定要提前准备好随身 wifi 或者开通国际流量包，两者价格都很实惠，推荐后者，毕竟随身 wifi 占据了一定的空间还需要一天充一次电。 由于我的手机卡不支持国际流量包，所以在淘宝提前租好了随身 wifi，一天只需要 9~13 块，网速还可以。如果想要租借随身 wifi，一定要记得在出发前提前 2 天下单，一般店铺都支持在机场自行取货。 小 tips：随身 wifi 不能托运。 APP 推荐谷歌地图 自由行期间必备的 APP，基本走到哪儿都靠他了。可能会有朋友会问，为什么不推荐百度地图？实际上两个地图我这次都用到了，但总体感受是谷歌地图体验更好。 换乘案内 换乘案内 是在日本查询坐车信息的一个软件，功能跟谷歌相似，但比谷歌更详细，也更加准确，但是没有导航功能。在这个软件输入始发站以及到达站就会出来所有的乘坐信息，价格，速度，换乘。 因为日本的公共交通系统极为复杂，光东京一个地方就有 JR/ 都营 /Metro/ 京急 / 小田急等，类似于国内的 1 号线、2 号线，不同的线路分属于不同的铁道公司。例如 JR(Japan Railway) 线，就是其中最大规模的铁道路线。也是游客利用最多的线路之一。 在日本坐车需要注意以下几点： 不同入口可能对应不同的线路，所以不要以为很近的两个入口都可以到达目的地，很有可能是不同线路的入口。 同一个站台，可能会有去往 不同方向 的电车，要注意看站台提示牌上显示的下一辆车的目的地。 同一个站台，同一个线路，会有 特急 、 急行 、 快速 、 准急 、 普通 等种类的电车，例如特急电车在很多站台就不会停靠，所有得严格按照软件的提示来乘坐。 大众点评 大众点评 这款软件即使在日本也可以用于搜索附近的美食、游玩地点！在成田车站附近时，我发现有比较多的拉面店、居酒屋，实在不知道该如何选择，就是通过大众点评来查看的评价和价钱，再做判断，比较实用。 极简汇率汇率换算软件。大多数情况下，记住汇率可以大致算出对应的人民币价钱，但在帮朋友代购或者比价时，就得精准地按汇率计算了，这款小巧的软件可以解决这个问题。 小 tips：日本商品会直接包含 8% 的税率，有一部分商场面向外国游客，标记的是退税之后的价格，注意区分。 百度翻译 虽然很多人说日本人英语不好，但东京作为一个国际大都市，给我的感觉是懂英语的人还是很多的，记得在秋叶原的电器小店中一位日本老爷爷，都可以跟我使用简单的英语词汇进行沟通。不过，也有秋叶原街头也有完全听不懂英语的女仆小姐姐，所以这个时候想要体验到日本的服务，一个翻译软件就显得非常重要了。 东京购物东京有一些著名的商区，例如新宿、池袋、涩谷，也有二次元圣地秋叶原、世界三大奢侈品购物街银座。 tips：购物时一定要随身携带护照，这是退税的证明，商品超过 500 元左右就可以使用护照来退税。 新宿 LUMINE：属于日本年轻潮流百货，拥有许多日系少女风服装，日本的本土时尚品牌也非常齐全，并且价格比国内专柜要便宜。LUMINE 分 1、2 和 EST 三个馆。EST 偏平价一些，1 的品牌价格较 EST 来说贵一点，LUMINE 2 价格最高。 小田急百货 ：是非常推荐购物的一家商场，貌似只有新宿 / 町田 / 藤泽有店。可以在大黑屋或者 Access Ticket 购买 300 日元一张的小田急 9 折折扣券，9 折＋免税几乎在这家百货店的所有柜台都可以使用。新宿因为位于热门商业区，因此可能会出现一些热门产品的断货可能，因此如果想要安静购物且货物相对比较全的可以选择町田或者藤泽的店，游客相对较少。 伊势丹百货 ：日本的高档百货店，有众多品牌 京王百货店 ：同样汇集了众多知名品牌，同样是购物的好去处 大黑屋 ：日本中古店，可以去淘一些 Big Camera：大型购物中心，以售卖电器为主，但是也有各类生活用品以及药妆（注意：这家店 93 折的券是购买除药妆以及部分电器产品以外的才可以使用，药妆折扣是 95 折，部分电器比如 switch 不参加折扣。 如果是准备在东京购物的话，个人还是十分推荐在新宿的 。新宿是各大百货店云集的地方，并且价格平价到高端的都有，适合各种人群，能够满足各种购物需求 ~ 基本你想要的在这里都能找到。因为每家百货店都有其特色，所以如果在新宿购物的话，还是可以考虑一下多分给新宿一些时间的，因为新宿一天真的逛不完。 池袋在池袋同样有几家百货店很推荐去，比如 东武百货店，西武百货，LUMINE，还有就是 0101 丸井百货 ，这是一家面向年轻人的综合百货店，也值得一逛。 另外池袋有一个叫 Sunshine City，这是一个大型综合商业设施，休闲购物观光餐饮都有。在这里可以俯瞰东京全景，如果大家想要去看整个东京的话这也是一个不错的选择 ~ 池袋是除了秋叶原以外另一个动漫爱好者的圣地了，比较有名的有 周刊 JUMP 主题乐园 ，另一个则是神奇宝贝迷的天堂， 超级宝可梦中心 。如果是喜好二次元的小伙伴们可以做一下功课去池袋转一转哦 我们这一回在池袋的地铁站买到了超人气泡芙 CHOUXCREAM CHOUXCRI，在日本非常的有名，泡芙很好吃。喜欢甜食的小伙伴一定要去池袋打卡这家店哦 ~ 涩谷涩谷是日本众多潮流的发源地，有很多潮牌以及首饰专卖店，算是年轻的潮流街区。涩谷站周边有很多百货商场，以及著名的忠犬八公像。 涩谷 109：是涩谷的标志性建筑，巨大的 109 标志在街道上一目了然。里面有很多日系的少女品牌，非常推荐大家去这里购物，以销售少女平价潮流服饰而闻名。 西武百货 ：大牌比较齐全，游客也相对较少，日本有连锁。 东急百货店 ：涩谷店是日本的总店，品牌比较多，非常值得一逛。 LOFT：日本是一个以文具著名的国家。LOFT 是文具控们必去的一家啦，其中最全的一家就位于涩谷，想要带些文具走的小伙伴们一定要去逛一逛啊。 银座 银座是世界三大繁华购物街之一 ，很多高端品牌的旗舰店都坐落于银座，这里同样也是百货商场云集的地方，可以供大家选择的购物场所非常的多。同样的这次，虽然这次我们的行程里面没有安排银座，但是以下的商场都是来自于油皮朋友的推荐 三越百货： 日本一家老牌顶级百货商场了，历史非常悠久，这家商场品牌非常的全，购物服务非常的好。（如果来这家百货店，那么你名下有黑卡或者白金信用卡的话就可以去游客中心换一张 95 折的会员卡） 松屋银座百货： 算是银座的地标性建筑之一，LV 的店面引人注目 银座 SIX： 同样是一家购物环境非常不错的百货店，值得一提的是这家店有 1860 年创立的辻利茶铺。喜欢抹茶甜品的小伙伴可以在购物的间隙来这里歇歇脚，品尝下日本百年抹茶老店的味道 银座 DSM： 是川久保玲开的一家买手店，东京这家非常的大，一共有 7 层。是高端潮流品牌和奢侈品品牌并存的店。店铺的设计还有售卖的单品都有主理人川久保玲的色彩在里面。不过里面从平价到贵价的商品都有，喜欢潮流的小伙伴可以来这里看一看。 伊东屋： 这家店也是文具控必去的一家店铺 ~ 一共有 12 层，每层售卖的东西都不一样。 银座的旗舰店和百货商场非常多，但是总的来说是属于消费水平整体非常高的街区，所以大家可以根据自己的情况选择适合自己的商区 ~ 秋叶原 秋叶原作为日本最出名的二次元朝圣地，同时还有一个电器街的身份，可以说技术宅的天堂了。 这次的行程中，花了一天半在秋叶原，可以说非常尽兴了。如果你乘坐大巴，不用问司机、不用看地图就可以清晰地辨认出你来到了秋叶原，整个街道的风格弥漫在二次元之中，在这里有鳞次栉比的手办店，日本特色的影像店，也有动次打次的电玩店，卡哇伊的女仆店。 游玩攻略镰仓 神奈川县镰仓，小小的街道，没有太多人。战神源义经的子孙在这里创立了大名鼎鼎的镰仓幕府；几乎笼罩了所有 80 后童年的灌篮高手片头曲里，樱木花道对赤木晴子挥手的地方就取景于镰仓高校前站；倒数第二次恋爱中千明深夜从东京回来居住的小城也是这里。作为继京都、奈良后日本第三座知名的古都，这里的人流量比起其他两座城市要小很多。但就是因为这样，当你坐车江之电瞎转或是慢悠悠散布在海岸上的时候，能发现很多有爱的小细节，请用随意的慢节奏去体会这座海边的古都。 在镰仓不能错过的是乘坐著名的绿皮电车江之电电车，电车穿梭于一排排日本民宿之中，驰行一段时间后，还可以看到海边，迎着和煦并带着一丝湿意的海风，再过一段会经过镰仓高校前站，正好看到放学的高中生，一切都充满了青春的气息。遗憾的是中途路过著名的护栏景点，只可远观，没能下车打卡。 江之岛 从镰仓乘坐江之电到江之岛站便可以到达江之岛，江之电之所叫这个名字，最大的原因就是为了服务这里最著名的景点江之岛。 江之岛是湘南海岸的代表景点，也是神奈川县指定史迹名胜。江之岛是一个陆系岛，通过一道沙洲与大陆相连。岛上有几处观光景点。包括神社、公园、展望台和和岩洞。岛上有三处神社统称江之岛神社，可以参拜弁天，以求财富与好运。通往神社的一条商业街，街两旁都是各种小玩意和小吃，推荐一家当地的网红小吃：虾饼。 刚到达岛上就有一个中文非常棒的日本志愿者大妈在发放着岛上的地图，据说 2020 东京奥运会会有项目在此举办。 秋叶原在购物篇提到了秋叶原，但秋叶原游玩的地方肯定比购物的地方要多的多，并且还有很多日本“特色”的游玩场所。 两次来日本都逛了秋叶原，但这次有一个独特的经历便是在深夜の巡礼。原本以为秋叶原街头只有 1~2 家女仆咖啡馆、女仆餐厅，夜晚来到里街才看到街边站着一排排女仆小姐姐，在招揽着 master。大多数店铺会派出 1 个女仆到街边拉客，在店里提供的大多数是爱心蛋包饭、咖啡等轻食，并且会有很多互动的小游戏，如果不会日语，就比较吃亏了，不过只要脸皮厚加上翻译软件的帮助，即使女仆小姐姐不会英语，也可以让你感受到这源自于大和民族独特的宅文化。 除了声名远扬的女仆店，秋叶原还有遍地的各种类型的新奇店铺： 电玩店，最出名的非 Sega 莫属了，里面充斥着各种年龄段的人群，跟国内大多数人童年印象中的游戏厅不同，这里的电玩店主要以 Galgame、小钢珠、音游为主（还有一些看都看不大懂的游戏），由于自己是个电玩小白，只能感受个氛围，凑个热闹。 写真店，我也是来了日本才知道，竟然东京街头还有专门卖女子偶像写真营生的店铺，以 AKB48 为首。 AKB48 主题餐厅、高达主题餐厅，这两个餐厅可以说是秋叶原的地标了，第二次来日本，竟然店铺还换了个位置，不过牌子倒是还在。 手办店。关于日本的手办店，去逛的时候一定要做好心理预期，因为那些没有包装盒的手办基本都是二手的，所以看起来很精致，而且价格也不是很贵，普通的手办只需要 200-400 人民币就可以拿下；很多低于 1000 元的手办其实都有着 made in China 的说明，有人会觉得大老远跑到日本买个中国制造不是有猫病吗，其实不建议这么想，因为日本的人工费很高，所以大多数手办都是日本出图纸，转到中国制造，最后根据成品质量来决定价格。 歌舞伎町 歌舞伎町说白了就是中国的风月场所，位于新宿的歌舞伎町有两条街：一番街和二番街，仅仅走马观花地看了一遍街道布局，但并不推荐大家体验。由于笔者是一个非常纯洁的人，不太了解这里，所以选取了知乎的一些介绍： 「就在这个夜里各种外围女陪酒男出没的地区，拿到执照可以与从业人员发生关系的店面，其实仅有 5 家。而其他上千家的店面，客人任何试图发生性行为的举动，店家都会强制报警以猥亵罪起诉你，或者向你索取高额的封口费，这个数字从几千人民币到几万不等。 那些其他的店面，虽然也属于风月场所，但接客内容分为两类：一种是按摩、SPA 类型的内容，同样，一旦有猥亵店员的行为，请参照上面说明。 但话说回来，这些店里的最大问题是收费：一瓶市场价 1600 人民币左右的唐培里侬香槟，在店里至少会收 1 万人民币一瓶… 而如果想跟哪个姑娘熟络起来，至少得去个 3-4 次，每次不开个香槟、红酒什么的，基本别想了（看过日剧《黑色皮革手册》之类的朋友，肯定有心理准备）。 当然，借着酒劲占女孩子便宜的客人不是没有，但你得明白，这些店基本上跟当地的黑社会的关系是非常近的。我曾经亲眼见过被从店面后门拖出来，两眼像熊猫的客人。」 旨在打破那些去日本游玩的朋友在异国他乡发生一段奇妙旅程的幻想。 新宿御苑 新宿御苑是跨新宿与涩谷的一个庭园，也是新海诚的《言叶之庭》的灵感发源地。公园位于市中心，乘坐 JR 线在御苑前站下站，走两步就可以直接到达了，距离之前提到的购物圣地 LUMINE 也只有 10 分钟的步程。绿荫环绕的和式庭院与周围的摩天大楼形成绝妙的反差，非常适合高强度逛街过后来放松一下。 这里四季都有不一样的美，特别推荐在在樱花盛开的季节来赏樱。可惜的是，我冬天来了一次，夏天来了一次，都没能见到樱花盛开， 须贺神社日本人的宗教信仰主要以佛教和神道教为主，寺庙之于佛教相当于神社之于神道教。佛教自不必多介绍，神道教是什么来历呢？日本有八百万神明之说，上至神话传说中的神灵，中到历史上名人伟人，下至自然界的大小万物都会成为供奉的对象，每个神社主管的范围内都不一样。比如说稻荷神社是供奉主管农业和商业的稻荷诸神的（不是供奉狐狸的，狐狸是稻荷神的使者）；天满宫是供奉学问之神菅原道真的（这位是历史名人）；以神宫为名的通常都是供奉某位天皇或者皇室成员的；还有些比较有趣的，比如奈良的冰室神社，是管冷冻的，所以很多奉纳的都是制冷、冰库、冷藏物流的企业… 按照导游的介绍，区分神社和寺庙实际上非常简单，神社门口大多会有一个红色的鸟居，参拜的地方（拜殿）会有稻草编制的注连绳，进入神社前会有用于清洁的手水舍。 既然神社这么多，那么自然得推荐大家去看点有意义的神社，例如新海诚导演的《你的名字》就是以须贺神社作为的取经地。须贺神社可以乘坐 JR 线在六本木四丁目站下站之后步行不到 10 分钟就可到达，片中男主与女主最后见面的阶梯就位于须贺神社旁。 当天玩的太晚，到达神社时已经是夜晚了，人烟也很稀少，相比繁华的东京，这里更加的幽静。喜欢动漫的读者可以将这里作为一个不错的打卡地点。片中还有不少景点，例如天桥取景自 JR 信浓町站旁边，港区的东京塔，涩谷区地标建筑 NTT DoCoMo 代代木大厦等等。 国立新美术馆 同样是《你的名字》中的取景地，片中泷被三叶套路后，与奥寺前辈第一次约会时吃中餐时的咖啡店，位于六本木的国立新美术馆。这家美术馆是世界著名设计师同时也是日本建筑界三杰之一的黑川纪章所设计的最后一件作品，是现在日本楼板面积最大的美术馆，并且也拥有日本国内最大的展示空间。喜欢文艺范的游客可以考虑来此地观光。 一般参观美术馆以及很多的展览都是免费的，这次我们就参观了书法展以及画展。馆内除了艺术展览还有设餐厅、咖啡厅、以及博物馆商店。馆内的设计非常好看，两个倒锥体的设计很抢眼。 温泉这次跟团有一晚是在富士山脚下的温泉酒店住宿。说到富士山，这次实在是有点气，第一是因为这次的温泉酒店实在令人失望，其次是由于天气原因，没办法看到富士山的全貌，只能看到山脚。 泡温泉的最佳时间和地点我可以说是相当有感触，上次来日本最深刻的印象便是在冬天在北海道，那时候外面飘着鹅毛大雪，远处是高山，在一处露天温泉，头顶着一条毛巾，特别惬意。虽然是东京旅游攻略，但有了这次的对比，还是推荐大家有机会一定要在冬天去一次北海道，别有一番风味。 日本见闻街道东京这个城市，抬头看到的是高楼大厦，低头看到的便是街道了，日本的街道很容易给来日本旅游的人以深刻的印象，因为太干净了。在街道上，很少看到垃圾桶，所以日本人会有随身携带垃圾袋的习惯。 除了干净还有一个印象便是安静，在车水马龙的街道上，几乎没有车辆会按喇叭，但我的旅途上发生了一个小插曲，导游刚介绍完日本的司机基本不会按喇叭，我们旅游大巴的喇叭就不争气的坏了，导致一路上总是会自己发出声响，打的一手好脸。 楼梯在商场、地铁等会出现手扶梯的地方，可以看到一个独特的风景，虽然大多数楼梯都是双行道，但所有人都会靠左站立，把右侧留出来给急着赶路的人。 据导游介绍，关东的东京无论是楼梯、扶梯、街道通行都会习惯靠左，而关西的大阪则是与其相反 —— 靠右。 吃喝日本的食物偏生冷，新鲜是新鲜，但是种类实在太少，相比之下，让我更加感慨中华美食的魅力。日本街头遍历都是拉面店、寿司店，当年看火影忍者时就对片中的一乐拉面饱含期待，在日本领略过当地的拉面后，并没有感到失望，日本拉面店会习惯配上冰水，这个让我感到一本满足。 要说日本远超预期的美食，非和牛饭莫属了，肉质非常鲜嫩，让人流连忘返。 而傍晚直至深夜，居酒屋这样的场所会涌入一批批上班族，这是日本特有的文化，社长会带着社员一天会轮流去好几个居酒屋，含蓄的日本人只有借助酒意，才敢向领导吐露心声。 穿着 在日本街头随处可见身着浴衣、脚蹬木屐的女子，日本人真的是把传统服饰融入到了生活之中。 除此之外，第一次来日本时同样是在东京街头，让我感到惊讶的是，日本的女孩子在寒冷的冬天依旧穿着短裙，上身则穿着毛衣。 出行在之前 【APP 推荐】中介绍换乘案内时，就介绍了日本出行的主要方式了——电车。电车作为日本人最主要的出行方式，主要的原因是，打车实在是太贵了！比国内贵的多的多，所以国内能够随地打车真的是一件非常幸福的事情。日本的出租车司机很有范，个个西装笔挺的打扮，带着白手套；公交车司机给我留下的印象则是年纪偏大，日本是个老龄化严重的国家，所以这些老年人通常退休的时间也会比国内要晚。说道老龄化的对策，最近安倍政府刚推行了一项政策，在九年义务教育的基础上，推行了 3-5 岁幼儿教育费全免的政策，凡是日本国籍或者在日打工的外籍纳税人都可以享受这份政策，从而拯救佛系的日本青年们。 乘坐电车时，除了之前提到的坐错车的问题，还需要有不少其他注意事项。日本人是一个秉承着尽量不去打扰别人理念的民族，所以在车厢内或者餐厅都尽量保持安静。在日本的地铁或者电车上有些会贴有将手机调成震动的提醒，大家可以注意一下。日本的电车设有女性车厢，以防止电车之狼，在限定时间段内男性最好还是不要去乘坐的好，要注意电车上贴的标志，不然一群女性投来的目光也会挺尴尬的。 住宿由于是旅行社负责了全部的住宿问题，所以没有太关注如何订房这件事。对于想要完全自由行的朋友，可以通过非常多的 app 来预定酒店以及机票，比如飞猪 / 携程 / 途牛等等。 日本的住宿费用相对是国内一线城市的水准，并不便宜。想要省钱的话，可以选择民宿，一些性价比高的酒店则需要提前很早预定。有一些住宿的地方会提供榻榻米，不过个人不太感冒，睡地板实在不太习惯。住宿 check out 的时候要注意退宿须知，有的地方会有叠好被单、整理褥子之类的要求，特别是民宿需要格外留意。 尾记以上就是本次东京游玩的全部攻略啦，其实自己对日本也不是特别了解，只能凭借零散的记忆组织起来这篇攻略，期间也参考了不少大牛的攻略文章，想要了解更多攻略的同学可以在 B 站搜搜看相关的视频，很多有用的建议，国庆也快到了，祝有个愉快的旅程 ~","categories":[{"name":"随笔","slug":"随笔","permalink":"http://lexburner.github.io/categories/随笔/"}],"tags":[{"name":"日本旅游攻略","slug":"日本旅游攻略","permalink":"http://lexburner.github.io/tags/日本旅游攻略/"}]},{"title":"Dubbo 中的 http 协议","slug":"dubbo-http-protocol","date":"2019-07-16T11:13:06.000Z","updated":"2019-09-26T09:45:30.214Z","comments":true,"path":"dubbo-http-protocol/","link":"","permalink":"http://lexburner.github.io/dubbo-http-protocol/","excerpt":"太阳红彤彤，花儿五颜六色，各位读者朋友好，又来到了分享 Dubbo 知识点的时候了。说到 Dubbo 框架支持的协议，你的第一反应是什么？大概会有 Dubbo 默认支持的 dubbo 协议，以及老生常谈的由当当贡献给 Dubbo 的 rest 协议，或者是今天的主角 http。截止到目前，Dubbo 最新版本演进到了 2.7.3，已经支持了：dubbo，hessain，http，injvm，jsonrpc，memcached，native-thrift，thrift，redis，rest，rmi，webservice，xml 等协议，有些协议的使用方式还没有补全到官方文档中。原来 Dubbo 支持这么多协议，是不是有点出乎你的意料呢？ 这么多 RPC 协议，可能有人会产生如下的疑问：rest，jsonrpc，webservice 不都是依靠 http 通信吗？为什么还单独有一个 http 协议？先不急着回答这个问题，而是引出今天的话题，先来介绍下 Dubbo 框架中所谓的 http 协议。","text":"太阳红彤彤，花儿五颜六色，各位读者朋友好，又来到了分享 Dubbo 知识点的时候了。说到 Dubbo 框架支持的协议，你的第一反应是什么？大概会有 Dubbo 默认支持的 dubbo 协议，以及老生常谈的由当当贡献给 Dubbo 的 rest 协议，或者是今天的主角 http。截止到目前，Dubbo 最新版本演进到了 2.7.3，已经支持了：dubbo，hessain，http，injvm，jsonrpc，memcached，native-thrift，thrift，redis，rest，rmi，webservice，xml 等协议，有些协议的使用方式还没有补全到官方文档中。原来 Dubbo 支持这么多协议，是不是有点出乎你的意料呢？ 这么多 RPC 协议，可能有人会产生如下的疑问：rest，jsonrpc，webservice 不都是依靠 http 通信吗？为什么还单独有一个 http 协议？先不急着回答这个问题，而是引出今天的话题，先来介绍下 Dubbo 框架中所谓的 http 协议。 Dubbo 中的 http 协议在 Dubbo 使用 http 协议和其他协议基本一样，只需要指定 protocol 即可。 1&lt;dubbo:protocol name=\"http\" port=\"8080\" server=\"jetty\" /&gt; server 属性可选值：jetty，tomcat，servlet。 配置过后，当服务消费者向服务提供者发起调用，底层便会使用标准的 http 协议进行通信。可以直接在 https://github.com/apache/dubbo-samples 中找到官方示例，其中的子模块：dubbo-samples-http 构建了一个 http 协议调用的例子。 为避免大家误解，特在此声明：本文中，所有的 http 协议特指的是 dubbo 中的 http 协议，并非那个大家耳熟能详的通用的 http 协议。 http 协议的底层原理从默认的 dubbo 协议改为 http 协议是非常简单的一件事，上面便是使用者视角所看到的全部的内容了，接下来我们将会探讨其底层实现原理。 翻看 Dubbo 的源码，找到 HttpProtocol 的实现，你可能会吃惊，基本就依靠 HttpProtocol 一个类，就实现了 http 协议 要知道实现自定义的 dubbo 协议，有近 30 个类！http 协议实现的如此简单，背后主要原因有两点： remoting 层使用 http 通信，不需要自定义编解码 借助了 Spring 提供的 HttpInvoker 封装了 refer 和 exporter 的逻辑 Spring 提供的 HttpInvoker 是何方神圣呢？的确是一个比较生僻的概念，但并不复杂，简单来说，就是使用 Java 序列化将对象转换成字节，通过 http 发送出去，在 server 端，Spring 能根据 url 映射，找到容器中对应的 Bean 反射调用的过程，没见识过它也不要紧，可以通过下面的示例快速掌握这一概念。 Spring HttpInvoker 本节内容可参见 Spring 文档：https://docs.spring.io/spring/docs/4.3.24.RELEASE/spring-framework-reference/htmlsingle/#remoting-httpinvoker-server 下面的示例将会展示如何使用 Spring 原生的 HttpInvoker 实现远程调用。 创建服务提供者1234567public class AccountServiceImpl implements AccountService &#123; @Override public Account findById(int id) &#123; Account account = new Account(id, new Date().toString()); return account; &#125;&#125; 123456789101112@BeanAccountService accountService()&#123; return new AccountServiceImpl();&#125;@Bean(\"/AccountService\")public HttpInvokerServiceExporter accountServiceExporter(AccountService accountService)&#123; HttpInvokerServiceExporter exporter = new HttpInvokerServiceExporter(); exporter.setService(accountService); exporter.setServiceInterface(AccountService.class); return exporter;&#125; 暴露服务的代码相当简单，需要注意两点： org.springframework.remoting.httpinvoker.HttpInvokerServiceExporter 是 Spring 封装的一个服务暴露器，它会以 serviceInterface 为公共接口，以 service 为实现类向外提供服务。 @Bean(“/AccountService”) 不仅仅指定了 IOC 容器中 bean 的名字，还充当了路径映射的功能，如果本地服务器暴露在 8080 端口，则示例服务的访问路径为 http://localhost:8080/AccountService 创建服务消费者12345678910@Configurationpublic class HttpProxyConfig &#123; @Bean(\"accountServiceProxy\") public HttpInvokerProxyFactoryBean accountServiceProxy()&#123; HttpInvokerProxyFactoryBean accountService = new HttpInvokerProxyFactoryBean(); accountService.setServiceInterface(AccountService.class); accountService.setServiceUrl(\"http://localhost:8080/AccountService\"); return accountService; &#125;&#125; 12345678@SpringBootApplicationpublic class HttpClientApp &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(HttpClientApp.class, args); AccountService accountService = applicationContext.getBean(AccountService.class); System.out.println(accountService.findById(10086)); &#125;&#125; 消费者端引用服务同样有两个注意点： org.springframework.remoting.httpinvoker.HttpInvokerProxyFactoryBean 是 Spring 封装的一个服务引用器，serviceInterface 指定了生成代理的接口，serviceUrl 指定了服务所在的地址，与之前配置的服务暴露者的路径需要对应。 HttpInvokerProxyFactoryBean 注册到容器之中时，会同时生成一个 AccountService 接口的代理类，由 Spring 封装远程调用的逻辑。 调用细节分析对于 Spring HttpInvoker 的底层实现，就没必要深究了，但大家肯定还是会好奇一些细节：dubbo 中的 http 报文体是怎么组织的？如何序列化对象的？ 我们使用 wireshark 可以抓取到客户端发送的请求以及服务端响应的报文。 追踪报文流，可以看到详细的请求和响应内容 从 ContentType: application/x-java-serialized-object 和报文 Body 部分的 ASCII 码可以看出，使用的是 Java Serialize 序列化。我们将 Body 部分导出成文件，使用 Java Serialize 反序列化响应，来验证一下它的庐山真面目： 使用 Java Serialize 可以正常反序列化报文，得到结果是 Spring 内置的包装类 RemoteInvocationResult，里面装饰着实际的业务返回结果。 http 协议的意义Dubbo 提供的众多协议有各自适用的场景，例如 dubbo://，dubbo 协议是默认的协议，自定义二进制协议；单个长连接节省资源；基于 tcp，架构于 netty 之上，性能还算可以；协议设计上没有足够的前瞻性，不适合做 service-mesh 谈不上多么优雅，但是好歹风风雨雨用了这么多年，周边也有不少配套组件例如 dubbo2.js, dubbo-go, dubbo-cpp，一定程度解决了多语言的问题。 webservice://,hession://,thrift:// 等协议，基本是为了适配已有协议的服务端 / 客户端，借助于 dubbo 框架的 api，可以使用其功能特性，意义不是特别大。 redis://,memcached:// 等协议，并非是暴露给用户配置的协议，一般是 dubbo 自用，在注册中心模块中会使用到相应的扩展 所有协议的具体使用场景和其特性，我可能会单独写文章来分析，而如今我们要思考的是 dubbo 提供 http 协议到底解决什么问题，什么场景下用户会考虑使用 dubbo 的 http 协议。 我个人认为 dubbo 现如今的 http 协议比较鸡肋，原生 http 通信的优势在于其通用性，基本所有语言都有配套的 http 客户端和服务端支持，但是 dubbo 的 http 协议却使用了 application/x-java-serialized-object 的格式来做为默认的 payload，使得其丧失了跨语言的优势。可能有读者会反驳：HttpInvoker 支持配置序列化格式，不能这么草率的诟病它。但其实我们所关注的恰恰是默认实现，正如 dubbo:// 协议也可以配置 fastjson 作为序列化方案，但是我们同样不认为 dubbo:// 协议是一个优秀的跨语言方案，理由是一样的。当然，评价一个应用层协议是否是优秀的，是否适合做 mesh 等等，需要多种方向去分析，这些我不在本文去分析。 说到底，本文花了一定的篇幅向大家介绍了 dubbo 的 http 协议，到头来却是想告诉你：这是一个比较鸡肋的协议，是不是有些失望呢？不要失望，dubbo 可能在 2.7.4 版本废弃现有的 http 协议，转而使用 jsonrpc 协议替代，其实也就是将 jsonrpc 协议换了个名字而已，而关于 jsonrpc 的细节，我将会在下一篇文章中介绍，届时，我也会分析，为什么 jsonrpc 比现有的 http 协议更适合戴上 http 协议的帽子，至于现有的 http 协议，我更倾向于称之为：spring-httpinvoker 协议。 总结，dubbo 现有 http 协议的意义是什么？如果你习惯于使用 Spring HttpInvoker，那或许现有的 http 协议还有一定的用处，但从 dubbo 交流群和 Spring 文档介绍其所花费的篇幅来看，它还是非常小众的。同时也可以让我们更好地认识协议发展的历史，知道一个协议为什么存在，为什么会被淘汰。 当然，我说了不算，最终还是要看 dubbo 社区的决策，如果你对这个迁移方案感兴趣，想要参与讨论，欢迎大家在 dubbo 社区的邮件列表中发表你的见解 Topic：[Proposal] replace the protocol=”http” with protocol=”jsonrpc” 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"}]},{"title":"IDEA 插件推荐：Cloud Toolkit 测评","slug":"cloud-toolkit-benchmark","date":"2019-06-27T11:19:41.000Z","updated":"2019-09-26T09:45:31.575Z","comments":true,"path":"cloud-toolkit-benchmark/","link":"","permalink":"http://lexburner.github.io/cloud-toolkit-benchmark/","excerpt":"产品介绍Cloud Toolkit 是一款 IDE 插件，帮助开发者更高效地开发、测试、诊断并部署应用。开发者能够方便地将本地应用一键部署到任意机器，或 ECS、EDAS、Kubernetes；并内置 Arthas 诊断、高效执行终端命令和 SQL 等。 对这款产品最直观的感受：这是一款发布工具，帮助用户在 IDE 中直接打包应用并部署到各种终端。原本看到其产品介绍位于阿里云的页面中，以为是一款和阿里云服务强绑定的产品，但试用过后发现，即使对于普通的云主机，其也非常适用，可以解决很多开发运维的痛点，非阿里云用户可以放心使用。","text":"产品介绍Cloud Toolkit 是一款 IDE 插件，帮助开发者更高效地开发、测试、诊断并部署应用。开发者能够方便地将本地应用一键部署到任意机器，或 ECS、EDAS、Kubernetes；并内置 Arthas 诊断、高效执行终端命令和 SQL 等。 对这款产品最直观的感受：这是一款发布工具，帮助用户在 IDE 中直接打包应用并部署到各种终端。原本看到其产品介绍位于阿里云的页面中，以为是一款和阿里云服务强绑定的产品，但试用过后发现，即使对于普通的云主机，其也非常适用，可以解决很多开发运维的痛点，非阿里云用户可以放心使用。 在 Cloud Toolkit 出现之前作为一个 Java 程序员，我们现在大多数都会在 Intellij IDEA 中基于 SpringBoot 来开发 WEB 应用，所以本文中的测评将会基于如下架构 开发环境：IDEA 项目组织方式：Maven 开发框架：SpringBoot 来构建。在接触 Cloud Toolkit 之前，可以怎么部署一个 SpringBoot 应用呢？作为一个偏正经的测评人员，我不会为了凸显出 Cloud Toolkit 的强大而去翻出一些上古的部署工具来做对比，而是直接使用 Intellij IDEA 的内置功能与之对比。 第一步：配置服务器信息在 Tools -&gt; Deployment 中可以找到 IDEA 对项目部署支持的内置插件 我们可以在其中进行服务器信息的配置，包括服务器地址和权限认证，并且在 Mapping 选项卡中完成本地工程与服务器路径的映射。 第二步：配置 Maven 打包插件12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 由于是 SpringBoot 应用，配置专用的打包插件后，可以将整个工程打成一个 fatjar，示例工程非常简单： 123456789101112@SpringBootApplication@RestControllerpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @RequestMapping(\"/hello\") public String hello() &#123; return \"hello world~~~~~~~~~~~~~~~~\"; &#125;&#125; 之后，只要执行 install，即可得到一个可运行的 jar 包： 第三步：部署 jar 包 由于我们在第一步已经配置过项目路径与服务器路径的映射，可以选择直接对 fatjar 右键，upload 到远程服务器上。 第四步：启动应用 上图中展示的是 IDEA 中两个非常棒的内置功能，可以在 Tools -&gt; Start SSH session 中开启远程服务器的终端，在 IDEA 下方可以执行远程指令；也可以在 Tools -&gt; Deployment -&gt;Browse Remote Host 中展开如图右侧的结构，可视化地浏览服务器上的文件列表，检查应用是否部署成功。 在远程终端中，找到对应的 fatjar，执行 java -jar spring-demo-1.0-SNAPSHOT.jar 便完成了整个部署流程。 IDEA 内置插件总结IDEA 内置插件已经提供了相当强大的能力，整个部署过程我们完全没有离开 IDEA！避免了频繁切换窗口，装各种部署工具，可以说已经很方便了，Cloud Toolkit 必须要比这个部署过程做的更加强大才行，那下面就让我们来体验下 Cloud Toolkit 是怎么优化的吧。 Cloud Toolkit 初体验我们不急着用 Cloud Toolkit 来部署应用。虽然笔者是一位开发，但还是从产品的角度来研究下它的菜单项，看看它的产品定位。IDEA 安装插件的过程省略，详情可以参考 《Intellij IDEA 安装 Cloud Toolkit 教程》。 其他菜单项暂且抛到一边，这 5 个核心能力应该就是 Cloud Toolkit 的核心了。 即使作为一个插件小白，应该也能够望名知意，猜到这几个菜单对应的功能： Deploy to Host：部署到任意服务器。这一个功能决定了 Cloud Toolkit 强大的功能可以使得每个开发者受益，它其实并不是和阿里云厂商强绑定的。在下文也会重点测评下这个功能。 Deploy to ECS：这里的 ECS 指的阿里云的 ECS，如果你的服务部署在阿里云 ECS 上，可以选择使用这个功能，获得比 Deploy to Host 更加丰富的功能。在下文我也会简单测评下这个功能。 Deploy to EDAS，Deploy to EDAS Serverless：EDAS &amp; EDAS Serverless 是阿里云上提供的分布式服务治理服务，可以理解为商业版的 Dubbo，具有强大的服务治理、服务调度能力，Cloud Toolkit 对 EDAS 做了个性化的部署支持，使得使用者无需登录控制台，在 IDEA 中即可完成 EDAS 的部署。 Deploy to CS K8S：云原生时代很多应用使用容器化的方式进行部署，Cloud Toolkit 这一点做的还是不错的，已经具备了容器化部署的能力，具有一定的前瞻性。 其实从简单的功能介绍就可以看出，Cloud Toolkit 相比 IDEA 内置的部署能力的确是高出一大截了，甚至可以说，Deploy to Host 这一能力完全就可以覆盖 IDEA 插件的所有能力，并且对流程还进行了一些简化。下面我重点测评下 Deploy to Host 这一能力，与之前的部署流程进行一个对比。 使用 Cloud Toolkit 部署应用到任意服务器 上图展示的 Deploy to Host 功能的配置项，实际上涵盖了 远程服务器配置 部署方式：Maven 构建，直接上传文件（目前还不支持 Gradle 构建，可能在后续的版本会支持） 本地文件与服务器路径的映射配置 启动脚本的集成 账号管理SSH 登录账户可以在 Preferences -&gt; Alibaba Cloud Toolkit -&gt; SSH Profile 中管理，找不到也没关系，需要设置的时候一般都会有超链接跳转，这点做得很人性化。 主机管理服务信息可以在 Tools -&gt; Alibaba Cloud -&gt;Alibaba Cloud View 中展开，如下图所示 Deploy to Host配置完账号信息和主机信息，然后只需要右键项目选择 Alibaba Cloud -&gt; Deploy to Host-&gt; Run ，一切就搞定了。这个过程相比之前变得非常简易 不需要自己打包。Cloud Toolkit 集成了 Maven 插件。 不需要登录远程终端去执行脚本启动服务。Cloud Toolkit 提供了应用部署生命周期必要的钩子，只需要设置好启动脚本即可。 修改完本地代码，点击下 Deploy to Host，即可完成改动代码的部署。 经过如上的测评过程，相信即使没有使用过 Cloud Toolkit 的用户，也可以直观体会到这是怎么样一款插件了，并且它的功能是多么的实用。 使用 Cloud Toolkit 部署应用到 ECS从产品设计的角度来分析，Cloud Toolkit 提供如此众多的部署能力，可以想到是其直接预设了使用人群。例如一个阿里云的 ECS 用户，在选择部署方式时，既可以使用 Deploy to Host 也可以使用 Deploy to ECS；例如一个 EDAS 用户，在选择部署方式时，既可以使用 Deploy to Host、Deploy to ECS，也可以使用 Deploy to EDAS（EDAS 可以理解为一个定制化的 ECS）。从产品的角度，越定制化的功能服务的人群越少，同时功能更强大；从用户体验的角度，其实也透露了云服务的一个特点，云厂商正在为其所提供的云服务提供更好的用户体验，借助于此类插件，可以降低使用者的开发运维门槛。 可以预见的一件事是，对于非阿里云用户来说，Deploy to Host 是使用 Cloud Toolkit 最大的诱惑了。作为一个测评文章，除了 Deploy to Host 之外，我还选择了 Deploy to ECS 这一功能来进行测评。为此我购买了一台阿里云的 ECS 来部署与上文相同的应用。 在阿里云控制台可以获取到账号的 Access Key/Access Key Secret，在 IDEA 中的 Preferences -&gt; Alibaba Cloud Toolkit -&gt; Accounts 中可以设置账号。 在账号设置完毕后，Cloud Toolkit 看起来是通过内置的 API 直接关联到了我的 ECS 实例，在选择部署时，可以直接根据 region 选择实例列表中的机器进行部署。 其余的部署流程和 Deploy to Host 相差无几。也就是说，Deploy to ECS 更多的其实完成了权限管理和主机管理，ECS 用户使用这个功能就显得非常高效了。 Cloud Toolkit 的亮点功能Cloud Toolkit 除了主打的部署能力，还提供了不少亮点功能，我选择了其中的 3 个功能：上传文件，远程 Terminal，内置应用诊断功能来进行评测。 上传文件 有些脚本我们希望在本地编辑之后上传到服务器上，Cloud Toolkit 对每一个主机都提供了一个 Upload 操作，可以将本地的文件上传到远程主机上，并且还可以触发一个 commond，这个功能也是很人性化的，因为上传脚本后，往往需要运行一次，避免了我们再登录到远程主机上执行一次运行操作。 远程 Terminal特别是在 Mac 中，我一直苦恼的一件事便是如何管理众多的远程机器，我需要偶尔去搭建了博客的主机上查看下个人博客为什么挂了，偶尔又要去看看我的 VPN 主机排查下为什么无法转发流量了，在开发测试阶段，又要经常去测试主机上简单的执行一些命令。所有这一切通过 ssh 工具去完成都不麻烦，但所有的麻烦事集合到一起时往往会让我变得焦头烂额，这一点，Cloud Toolkit 简直是一个 Life Saver。 事实上，在前面的测评中我们已经了解到 IDEA 内置了远程 Terminal 这个功能，Cloud Toolkit 是进一步优化了它的体验，用户可以直接在可视化的页面选择想要远程登录的主机，在对主机加了 Tag 之后，这个过程会更加直观。 内置应用诊断功能在测评体验过程中，意外地发现了 Cloud Toolkit 的一个功能支持，就是前面的截图有显示，但我未提到的 Diagnostic （诊断）功能。Cloud Toolkit 集成了阿里巴巴开源的一款应用诊断框架 – Arthas。 对于本地主机，可以直接通过 Tools -&gt; Alibaba Cloud -&gt; Diagnostic Tools 开启诊断。 对于远程主机，可以通过主机管理中的 Diagnostic 选项卡，开启远程诊断。 在过去，我们想要进行诊断，必须要手动在服务器上安装 Arthas，Cloud Toolkit 借助于 Remote Terminal 和 Arthas 的集成，让这一切都可以在 IDEA 中完成，似乎是想要贯彻：彻底杜绝第三方工具，一切都用插件完成。 当你遇到以下类似问题而束手无策时，Arthas 可以帮助你解决： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到 JVM 的实时运行状态？ 作为一个偏正经的评测，我们试用一下远程诊断的功能，选取比较直观的 trace 命令来进行评测 如上图所示，我们构造了一个慢请求，其中 invokeServiceA_B() 相对于其他方法十分耗时，我们希望通过 Cloud Toolkit 定位到慢调用的源头，找出 invokeServiceA_B 这个罪魁祸首。 点击 IDEA 中对应部署服务器的 Diagnostic 菜单项，就会出现如上图所示的一个 Arthas 诊断页面，它会自动关联到用户的 Java 进程，用户只需要选择相应诊断的进程即可。 在关联到相应的进程之后，我们执行 trace 指令 trace moe.cnkirito.demo.Application * -j 这个指令的含义是当 moe.cnkirito.demo.Application 中的任意方法被触发调用后，会打印出相应的调用栈，并计算耗时，-j 的含义是过滤掉 JDK 内置的类，简化堆栈。正如上图所示，我们定位到是 invokeServiceA 的 invokeServiceA_B 最为耗时。用户可以自行监控对应的方法，把 * 替换为想要监控的方式即可。更多的监控指令可以参考：Arthas 文档 测评中发现的不足是软件就必然有 bug，或者是用户体验不好的地方，花费了一个下午进行测评，简单罗列下我认为的缺陷。 远程连接容易出现异常这个问题不是特别容易复现，表现是长时间运行项目后，再部署，会提示远程连接失败，在重启 IDEA 之后可以解决这个问题，原因未知。在后面想要复现时一直无法复现，但的确耗费了我很长的时间，不知道有没有其他的用户遇到同样的问题。 文件浏览器过于简陋 当尝试配置 SSH 公私钥以实现免密登录时，发现 Browse 打开的文件浏览器无法正常显示 Mac 中的 .ssh 隐藏文件夹，大多数情况下用户会将 SSH 公私钥存放在 ~/.ssh 中，这个用户体验不是很好，或许有办法在这个文件浏览器中访问到隐藏文件夹，但至少我还没找到方法。 缺少远程主机的可视化功能IDEA 的默认插件支持 Remote Host 这个可以提升用户体验，Cloud Toolkit 提供了远程主机的管理，额外实现一个 ftp 协议可能会更方便用户查看自己的部署结果。从连接协议的选择上也可以发现，Cloud Toolkit 目前只支持 sftp 协议，而 IDEA 内置的 Deployment 插件还支持 ftp、ftps 等方式。 产品定位 &amp; 评价 &amp; 竞品其实本文基本是围绕 IDEA 的内置 Deployment 顺带着 Cloud Toolkit 的测评一起进行的。实际上我并不觉得 Cloud Toolkit 存在什么竞品 xftp 或者 xshell 吗？它们只是一款 ssh 工具罢了，人家压根没想着跟你竞争。 jenkins 吗？jenkins 有自己的 devops 流程，侧重在持续集成，而 Cloud Toolkit 定位是在日常开发中完成部署验证等行为。 在我的测评过程中，能够感受到这款产品的匠心，几乎为所有用户可能遇到的问题都做配备了文档：不知道启动脚本怎么写？链接了常用的 Java 应用启动脚本；不清楚该使用哪种部署方式？每种方式都有完整的部署文档；多语言？同时提供了 Go、NodeJS 的部署案例… 同时还支持了一些赠品功能：查看实时日志，文件上传，SQL 执行等。 以个人愚见，聊聊这款产品的定位，一方面是云厂商无关的特性，Cloud Toolkit 提供了 Deploy to Host、内置 Arthas 诊断等功能，造福了广大的开发者，另一方面是阿里云服务绑定的一些功能，Cloud Toolkit 为 ECS、EDAS 用户带来了福音，可以享受比普通应用部署更加便捷的操作。前者为 Cloud Toolkit 积累了业界口碑，后者为阿里云付费用户增加了信心，同时也为潜在的阿里云用户埋下了种子。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"Cloud Toolkit","slug":"Cloud-Toolkit","permalink":"http://lexburner.github.io/tags/Cloud-Toolkit/"}]},{"title":"研究网卡地址注册时的一点思考","slug":"network-interfaces","date":"2019-04-29T11:09:53.000Z","updated":"2019-09-26T09:45:29.822Z","comments":true,"path":"network-interfaces/","link":"","permalink":"http://lexburner.github.io/network-interfaces/","excerpt":"我曾经写过一篇和本文标题类似的文章《研究优雅停机时的一点思考》，上文和本文都有一个共同点：网卡地址注册和优雅停机都是一个很小的知识点，但是背后牵扯到的知识点却是庞大的体系，我在写这类文章前基本也和大多数读者一样，处于“知道有这么个东西，但不了解细节”的阶段，但一旦深挖，会感受到其中的奇妙，并有机会接触到很多平时不太关注的知识点。 另外，我还想介绍一个叫做”元阅读“的技巧，可能这个词是我自己造的，也有人称之为”超视角阅读“。其内涵指的是，普通读者从我的文章中学到的是某个知识点，而元阅读者从我的文章中可能会额外关注，我是如何掌握某个知识点的，在一个知识点的学习过程中我关注了哪些相关的知识点，又是如何将它们联系在一起，最终形成一个体系的。这篇文章就是一个典型的例子，我会对一些点进行发散，大家可以尝试着跟我一起来思考”网卡地址注册“这个问题。","text":"我曾经写过一篇和本文标题类似的文章《研究优雅停机时的一点思考》，上文和本文都有一个共同点：网卡地址注册和优雅停机都是一个很小的知识点，但是背后牵扯到的知识点却是庞大的体系，我在写这类文章前基本也和大多数读者一样，处于“知道有这么个东西，但不了解细节”的阶段，但一旦深挖，会感受到其中的奇妙，并有机会接触到很多平时不太关注的知识点。 另外，我还想介绍一个叫做”元阅读“的技巧，可能这个词是我自己造的，也有人称之为”超视角阅读“。其内涵指的是，普通读者从我的文章中学到的是某个知识点，而元阅读者从我的文章中可能会额外关注，我是如何掌握某个知识点的，在一个知识点的学习过程中我关注了哪些相关的知识点，又是如何将它们联系在一起，最终形成一个体系的。这篇文章就是一个典型的例子，我会对一些点进行发散，大家可以尝试着跟我一起来思考”网卡地址注册“这个问题。 1 如何选择合适的网卡地址可能相当一部分人还不知道我这篇文章到底要讲什么，我说个场景，大家应该就明晰了。在分布式服务调用过程中，以 Dubbo 为例，服务提供者往往需要将自身的 IP 地址上报给注册中心，供消费者去发现。在大多数情况下 Dubbo 都可以正常工作，但如果你留意过 Dubbo 的 github issue，其实有不少人反馈：Dubbo Provider 注册了错误的 IP。如果你能立刻联想到：多网卡、内外网地址共存、VPN、虚拟网卡等关键词，那我建议你一定要继续将本文看下去，因为我也想到了这些，它们都是本文所要探讨的东西！那么“如何选择合适的网卡地址”呢，Dubbo 现有的逻辑到底算不算完备？我们不急着回答它，而是带着这些问题一起进行研究，相信到文末，其中答案，各位看官自有评说。 2 Dubbo 是怎么做的Dubbo 获取网卡地址的逻辑在各个版本中也是千回百转，走过弯路，也做过优化，我们用最新的 2.7.2-SNAPSHOT 版本来介绍，在看以下源码时，大家可以怀着质疑的心态去阅读，在 dubbo github 的 master 分支可以获取源码。获取 localhost 的逻辑位于 org.apache.dubbo.common.utils.NetUtils#getLocalAddress0() 之中 123456789101112131415161718192021222324252627private static InetAddress getLocalAddress0() &#123; InetAddress localAddress = null; // 首先尝试获取 /etc/hosts 中 hostname 对应的 IP localAddress = InetAddress.getLocalHost(); Optional&lt;InetAddress&gt; addressOp = toValidAddress(localAddress); if (addressOp.isPresent()) &#123; return addressOp.get(); &#125; // 没有找到适合注册的 IP，则开始轮询网卡 Enumeration&lt;NetworkInterface&gt; interfaces = NetworkInterface.getNetworkInterfaces(); if (null == interfaces) &#123; return localAddress; &#125; while (interfaces.hasMoreElements()) &#123; NetworkInterface network = interfaces.nextElement(); Enumeration&lt;InetAddress&gt; addresses = network.getInetAddresses(); while (addresses.hasMoreElements()) &#123; // 返回第一个匹配的适合注册的 IP Optional&lt;InetAddress&gt; addressOp = toValidAddress(addresses.nextElement()); if (addressOp.isPresent()) &#123; return addressOp.get(); &#125; &#125; &#125; return localAddress;&#125; Dubbo 这段选取本地地址的逻辑大致分成了两步 先去 /etc/hosts 文件中找 hostname 对应的 IP 地址，找到则返回；找不到则转 2 轮询网卡，寻找合适的 IP 地址，找到则返回；找不到返回 null，再 getLocalAddress0 外侧还有一段逻辑，如果返回 null，则注册 127.0.0.1 这个本地回环地址 首先强调下，这段逻辑并没有太大的问题，先别急着挑刺，让我们来分析下其中的一些细节，并进行验证。 2.1 尝试获取 hostname 映射 IPDubbo 首先选取的是 hostname 对应的 IP，在源码中对应的 InetAddress.getLocalHost(); 在 *nix 系统实际部署 Dubbo 应用时，可以首先使用 hostname 命令获取主机名 12xujingfengdeMacBook-Pro:~ xujingfeng$ hostnamexujingfengdeMacBook-Pro.local 紧接着在 /etc/hosts 配置 IP 映射，为了验证 Dubbo 的机制，我们随意为 hostname 配置一个 IP 地址 12127.0.0.1 localhost1.2.3.4 xujingfengdeMacBook-Pro.local 接着调用 NetUtils.getLocalAddress0() 进行验证，控制台打印如下： 1xujingfengdeMacBook-Pro.local/1.2.3.4 2.2 判定有效的 IP 地址在 toValidAddress 逻辑中，Dubbo 存在以下逻辑判定一个 IP 地址是否有效 123456789101112private static Optional&lt;InetAddress&gt; toValidAddress(InetAddress address) &#123; if (address instanceof Inet6Address) &#123; Inet6Address v6Address = (Inet6Address) address; if (isValidV6Address(v6Address)) &#123; return Optional.ofNullable(normalizeV6Address(v6Address)); &#125; &#125; if (isValidV4Address(address)) &#123; return Optional.of(address); &#125; return Optional.empty();&#125; 依次校验其符合 Ipv6 或者 Ipv4 的 IP 规范，对于 Ipv6 的地址，见如下代码： 123456789101112static boolean isValidV6Address(Inet6Address address) &#123; boolean preferIpv6 = Boolean.getBoolean(\"java.net.preferIPv6Addresses\"); if (!preferIpv6) &#123; return false; &#125; try &#123; return address.isReachable(100); &#125; catch (IOException e) &#123; // ignore &#125; return false;&#125; 首先获取 java.net.preferIPv6Addresses 参数，其默认值为 false，鉴于大多数应用并没有使用 Ipv6 地址作为理想的注册 IP，这问题不大，紧接着通过 isReachable 判断网卡的连通性。例如一些网卡可能是 VPN/ 虚拟网卡的地址，如果没有配置路由表，往往无法连通，可以将之过滤。 对于 Ipv4 的地址，见如下代码： 1234567891011static boolean isValidV4Address(InetAddress address) &#123; if (address == null || address.isLoopbackAddress()) &#123; return false; &#125; String name = address.getHostAddress(); boolean result = (name != null &amp;&amp; IP_PATTERN.matcher(name).matches() &amp;&amp; !Constants.ANYHOST_VALUE.equals(name) &amp;&amp; !Constants.LOCALHOST_VALUE.equals(name)); return result;&#125; 对比 Ipv6 的判断，这里我们已经发现前后不对称的情况了 Ipv4 相比 Ipv6 的逻辑多了 Ipv4 格式的正则校验、本地回环地址校验、ANYHOST 校验 Ipv4 相比 Ipv6 的逻辑少了网卡连通性的校验 大家都知道，Ipv4 将 127.0.0.1 定为本地回环地址， Ipv6 也存在回环地址：0:0:0:0:0:0:0:1 或者表示为 ::1。改进建议也很明显，我们放到文末统一总结。 2.3 轮询网卡如果上述地址获取为 null 则进入轮询网卡的逻辑（例如 hosts 未指定 hostname 的映射或者 hostname 配置成了 127.0.0.1 之类的地址便会导致获取到空的网卡地址），轮询网卡对应的源码是 NetworkInterface.getNetworkInterfaces() ，这里面涉及的知识点就比较多了，支撑起了我写这篇文章的素材，Dubbo 的逻辑并不复杂，进行简单的校验，返回第一个可用的 IP 即可。 性子急的读者可能忍不住了，多网卡！合适的网卡可能不止一个，Dubbo 怎么应对呢？按道理说，我们也替 Dubbo 说句公道话，客官要不你自己指定下？我们首先得对多网卡的场景达成一致看法，才能继续把这篇文章完成下去：我们只能 尽可能 过滤那些“ 不对 ”的网卡。Dubbo 看样子对所有网卡是一视同仁了，那么是不是可以尝试优化一下其中的逻辑呢？ 许多开源的服务治理框架在 stackoverflow 或者其 issue 中，注册错 IP 相关的问题都十分高频，大多数都是轮询网卡出了问题。既然事情发展到这儿，势必需要了解一些网络、网卡的知识，我们才能过滤掉那些明显不适合 RPC 服务注册的 IP 地址了。 3 Ifconfig 介绍我并没有想要让大家对后续的内容望而却步，特地选择了这个大家最熟悉的 Linux 命令！对于那些吐槽：“天呐，都 2019 年了，你怎么还在用 net-tools/ifconfig，iproute2/ip 了解一下”的言论，请大家视而不见。无论你使用的是 mac，还是 linux，都可以使用它去 CRUD 你的网卡配置。 3.1 常用指令 启动关闭指定网卡： 12ifconfig eth0 upifconfig eth0 down ifconfig eth0 up 为启动网卡 eth0，ifconfig eth0 down 为关闭网卡 eth0。ssh 登陆 linux 服务器操作的用户要小心执行这个操作了，千万不要蠢哭自己。不然你下一步就需要去 google：“禁用 eth0 网卡后如何远程连接 Linux 服务器” 了。 为网卡配置和删除 IPv6 地址： 12ifconfig eth0 add 33ffe:3240:800:1005::2/64 #为网卡 eth0 配置 IPv6 地址ifconfig eth0 del 33ffe:3240:800:1005::2/64 #为网卡 eth0 删除 IPv6 地址 用 ifconfig 修改 MAC 地址： 1ifconfig eth0 hw ether 00:AA:BB:CC:dd:EE 配置 IP 地址： 123[root@localhost ~]# ifconfig eth0 192.168.2.10[root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0[root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 启用和关闭 arp 协议： 12ifconfig eth0 arp #开启网卡 eth0 的 arp 协议ifconfig eth0 -arp #关闭网卡 eth0 的 arp 协议 设置最大传输单元： 1ifconfig eth0 mtu 1500 #设置能通过的最大数据包大小为 1500 bytes 3.2 查看网卡信息在一台 ubuntu 上执行 ifconfig -a 12345678910111213141516171819202122232425262728293031ubuntu@VM-30-130-ubuntu:~$ ifconfig -aeth0 Link encap:Ethernet HWaddr 52:54:00:a9:5f:ae inet addr:10.154.30.130 Bcast:10.154.63.255 Mask:255.255.192.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:149673 errors:0 dropped:0 overruns:0 frame:0 TX packets:152271 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:15205083 (15.2 MB) TX bytes:21386362 (21.3 MB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) docker0 Link encap:Ethernet HWaddr 02:42:58:45:c1:15 inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)tun0 Link encap:UNSPEC HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 UP POINTOPOINT NOARP MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 为了防止黑客对我的 Linux 发起攻击，我还是偷偷对 IP 做了一点“改造”，请不要为难一个趁着打折 + 组团购买廉价云服务器的小伙子。对于部门网卡的详细解读: eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址 (MAC 地址）是 02:42:38:52:70:54 inet addr 用来表示网卡的 IP 地址，此网卡的 IP 地址是 10.154.30.130，广播地址， Bcast: 172.18.255.255，掩码地址 Mask:255.255.0.0 lo 是表示主机的回环地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD 服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架 WEB 网站了。但只是你能看得到，局域网的其它主机或用户无从知晓。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件 mac 地址） 第二行：网卡的 IP 地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500 字节（ipconfig 不加 -a 则无法看到 DOWN 的网卡） 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 紧接着的两个网卡 docker0，tun0 是怎么出来的呢？我在我的 ubuntu 上装了 docker 和 openvpn。这两个东西应该是日常干扰我们做服务注册时的罪魁祸首了，当然，也有可能存在 eth1 这样的第二块网卡。ifconfig -a 看到的东西就对应了 JDK 的 api ：NetworkInterface.getNetworkInterfaces() 。我们简单做个总结，大致有三个干扰因素 以 docker 网桥为首的虚拟网卡地址，毕竟这东西这么火，怎么也得单独列出来吧？ 以 TUN/TAP 为代表的虚拟网卡地址，多为 VPN 场景 以 eth1 为代表的多网卡场景，有钱就可以装多网卡了！ 我们后续的篇幅将针对这些场景做分别的介绍，力求让大家没吃过猪肉，起码看下猪怎么跑的。 4 干扰因素一：Docker 网桥熟悉 docker 的朋友应该知道 docker 会默认创建一个 docker0 的网桥，供容器实例连接。如果嫌默认的网桥不够直观，我们可以使用 bridge 模式自定义创建一个新的网桥： 12345678910ubuntu@VM-30-130-ubuntu:~$ docker network create kirito-bridgea38696dbbe58aa916894c674052c4aa6ab32266dcf6d8111fb794b8a344aa0d9ubuntu@VM-30-130-ubuntu:~$ ifconfig -abr-a38696dbbe58 Link encap:Ethernet HWaddr 02:42:6e:aa:fd:0c inet addr:172.19.0.1 Bcast:172.19.255.255 Mask:255.255.0.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 使用 docker network 指令创建网桥之后，自动创建了对应的网卡，我只给出了 ifconfig -a 的增量返回部分，可以看出多了一个 br-a38696dbbe58 的网卡。 我有意区分了“网桥”和“网卡”，可以使用 bridge-utils/brctl 来查看网桥信息： 1234ubuntu@VM-30-130-ubuntu:~$ sudo brctl showbridge name bridge id STP enabled interfacesbr-a38696dbbe58 8000.02426eaafd0c nodocker0 8000.02425845c215 no 网桥是一个虚拟设备，这个设备只有 brctl show 能看到，网桥创建之后，会自动创建一个同名的网卡，并将这个网卡加入网桥。 5 干扰因素二：TUN/TAP 虚拟网络设备平时我们所说的虚拟网卡、虚拟机，大致都跟 TUN/TAP 有关。我的读者大多数是 Java 从业者，相信我下面的内容并没有太超纲，不要被陌生的名词唬住。对于被唬住的读者，也可以直接跳过 5.1~5.3，直接看 5.4 的实战。 5.1 真实网卡工作原理 上图中的 eth0 表示我们主机已有的真实的网卡接口 (interface)。 网卡接口 eth0 所代表的真实网卡通过网线 (wire) 和外部网络相连，该物理网卡收到的数据包会经由接口 eth0 传递给内核的网络协议栈(Network Stack)。然后协议栈对这些数据包进行进一步的处理。 对于一些错误的数据包, 协议栈可以选择丢弃；对于不属于本机的数据包，协议栈可以选择转发；而对于确实是传递给本机的数据包, 而且该数据包确实被上层的应用所需要，协议栈会通过 Socket API 告知上层正在等待的应用程序。 5.2 TUN 工作原理 我们知道，普通的网卡是通过网线来收发数据包的话，而 TUN 设备比较特殊，它通过一个文件收发数据包。 如上图所示，tunX 和上面的 eth0 在逻辑上面是等价的， tunX 也代表了一个网络接口, 虽然这个接口是系统通过软件所模拟出来的. 网卡接口 tunX 所代表的虚拟网卡通过文件 /dev/tunX 与我们的应用程序 (App) 相连，应用程序每次使用 write 之类的系统调用将数据写入该文件，这些数据会以网络层数据包的形式，通过该虚拟网卡，经由网络接口 tunX 传递给网络协议栈，同时该应用程序也可以通过 read 之类的系统调用，经由文件 /dev/tunX 读取到协议栈向 tunX 传递的 所有 数据包。 此外，协议栈可以像操纵普通网卡一样来操纵 tunX 所代表的虚拟网卡。比如说，给 tunX 设定 IP 地址，设置路由，总之，在协议栈看来，tunX 所代表的网卡和其他普通的网卡区别不大，当然，硬要说区别，那还是有的, 那就是 tunX 设备不存在 MAC 地址，这个很好理解，tunX 只模拟到了网络层，要 MAC 地址没有任何意义。当然，如果是 tapX 的话，在协议栈的眼中，tapX 和真实网卡没有任何区别。 是不是有些懵了？我是谁，为什么我要在这篇文章里面学习 TUN！因为我们常用的 VPN 基本就是基于 TUN/TAP 搭建的，如果我们使用 TUN 设备搭建一个基于 UDP 的 VPN ，那么整个处理过程可能是这幅样子： 5.3 TAP 工作原理TAP 设备与 TUN 设备工作方式完全相同，区别在于： TUN 设备是一个三层设备，它只模拟到了 IP 层，即网络层 我们可以通过 /dev/tunX 文件收发 IP 层数据包，它无法与物理网卡做 bridge，但是可以通过三层交换（如 ip_forward）与物理网卡连通。可以使用 ifconfig 之类的命令给该设备设定 IP 地址。 TAP 设备是一个二层设备，它比 TUN 更加深入，通过 /dev/tapX 文件可以收发 MAC 层数据包，即数据链路层，拥有 MAC 层功能，可以与物理网卡做 bridge，支持 MAC 层广播。同样的，我们也可以通过 ifconfig 之类的命令给该设备设定 IP 地址，你如果愿意，我们可以给它设定 MAC 地址。 关于文章中出现的二层，三层，我这里说明一下，第一层是物理层，第二层是数据链路层，第三层是网络层，第四层是传输层。 5.4 openvpn 实战openvpn 是 Linux 上一款开源的 vpn 工具，我们通过它来复现出影响我们做网卡选择的场景。 安装 openvpn 1sudo apt-get install openvpn 安装一个 TUN 设备： 123ubuntu@VM-30-130-ubuntu:~$ sudo openvpn --mktun --dev tun0Mon Apr 29 22:23:31 2019 TUN/TAP device tun0 openedMon Apr 29 22:23:31 2019 Persist state set to: ON 安装一个 TAP 设备： 123ubuntu@VM-30-130-ubuntu:~$ sudo openvpn --mktun --dev tap0Mon Apr 29 22:24:36 2019 TUN/TAP device tap0 openedMon Apr 29 22:24:36 2019 Persist state set to: ON 执行 ifconfig -a 查看网卡，只给出增量的部分： 1234567891011121314tap0 Link encap:Ethernet HWaddr 7a:a2:a8:f1:6b:df BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)tun0 Link encap:UNSPEC HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 inet addr:10.154.30.131 P-t-P:10.154.30.131 Mask:255.255.255.255 UP POINTOPOINT NOARP MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 这样就解释了文章一开始为什么会有 tun0 这样的网卡了。这里读者可能会有疑惑，使用 ifconfig 不是也可以创建 tap 和 tun 网卡吗？当然啦，openvpn 是一个 vpn 工具，只能创建名为 tunX/tapX 的网卡，其遵守着一定的规范，ifconfig 可以随意创建，但没人认那些随意创建的网卡。 6 干扰因素三：多网卡 这个没有太多好说的，有多张真实的网卡，从普哥那儿搞到如上的 IP 信息。 7 MAC 下的差异虽然 ifconfig 等指令是 *nux 通用的，但是其展示信息，网卡相关的属性和命名都有较大的差异。例如这是我 MAC 下执行 ifconfig -a 的返回： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859xujingfengdeMacBook-Pro:dubbo-in-action xujingfeng$ ifconfig -alo0: flags=8049&lt;UP,LOOPBACK,RUNNING,MULTICAST&gt; mtu 16384 options=1203&lt;RXCSUM,TXCSUM,TXSTATUS,SW_TIMESTAMP&gt; inet 127.0.0.1 netmask 0xff000000 inet6 ::1 prefixlen 128 inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1 nd6 options=201&lt;PERFORMNUD,DAD&gt;gif0: flags=8010&lt;POINTOPOINT,MULTICAST&gt; mtu 1280stf0: flags=0&lt;&gt; mtu 1280XHC0: flags=0&lt;&gt; mtu 0XHC20: flags=0&lt;&gt; mtu 0en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 ether 88:e9:fe:88:a0:76 inet6 fe80::1cab:f689:60d1:bacb%en0 prefixlen 64 secured scopeid 0x6 inet 30.130.11.242 netmask 0xffffff80 broadcast 30.130.11.255 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activep2p0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 2304 ether 0a:e9:fe:88:a0:76 media: autoselect status: inactiveawdl0: flags=8943&lt;UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1484 ether 66:d2:8c:8c:dd:85 inet6 fe80::64d2:8cff:fe8c:dd85%awdl0 prefixlen 64 scopeid 0x8 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: activeen1: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether aa:00:d0:13:0e:01 media: autoselect &lt;full-duplex&gt; status: inactiveen2: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500 options=60&lt;TSO4,TSO6&gt; ether aa:00:d0:13:0e:00 media: autoselect &lt;full-duplex&gt; status: inactivebridge0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=63&lt;RXCSUM,TXCSUM,TSO4,TSO6&gt; ether aa:00:d0:13:0e:01 Configuration: id 0:0:0:0:0:0 priority 0 hellotime 0 fwddelay 0 maxage 0 holdcnt 0 proto stp maxaddr 100 timeout 1200 root id 0:0:0:0:0:0 priority 0 ifcost 0 port 0 ipfilter disabled flags 0x2 member: en1 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 9 priority 0 path cost 0 member: en2 flags=3&lt;LEARNING,DISCOVER&gt; ifmaxaddr 0 port 10 priority 0 path cost 0 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: &lt;unknown type&gt; status: inactiveutun0: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 2000 inet6 fe80::3fe0:3e8b:384:9968%utun0 prefixlen 64 scopeid 0xc nd6 options=201&lt;PERFORMNUD,DAD&gt;utun1: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380 inet6 fe80::7894:3abc:5abd:457d%utun1 prefixlen 64 scopeid 0xd nd6 options=201&lt;PERFORMNUD,DAD&gt; 内容很多，我挑几点差异简述下： 内容展示形式不一样，没有 Linux 下的接收、发送数据字节数等统计信息 真实网卡的命名不一样：eth0 -&gt; en0 虚拟网卡的命名格式不一样：tun/tap -&gt; utun 对于这些常见网卡命名的解读，我摘抄一部分来自 stackoverflow 的回答： In arbitrary order of my familarity / widespread relevance: lo0 is loopback. en0 at one point “ethernet”, now is WiFi (and I have no idea what extra en1 or en2 are used for). fw0 is the FireWire network interface. stf0 is an IPv6 to IPv4 tunnel interface) to support the transition from IPv4 to the IPv6 standard. gif0 is a more generic tunneling interface) [46]-to-[46]. awdl0 is Apple Wireless Direct Link p2p0 is related to AWDL features. Either as an old version, or virtual interface with different semantics than awdl. the “Network” panel in System Preferences to see what network devices “exist” or “can exist” with current configuration. many VPNs will add additional devices, often “utun#” or “utap#” following TUN/TAP (L3/L2)virtual networking devices. use netstat -nr to see how traffic is currently routed via network devices according to destination. interface naming conventions started in BSD were retained in OS X / macOS, and now there also additions. 8 Dubbo 改进建议我们进行了以上探索，算是对网卡有一点了解了。回过头来看看 Dubbo 获取网卡的逻辑，是否可以做出改进呢？ Dubbo Action 1: 保持 Ipv4 和 Ipv6 的一致性校验。为 Ipv4 增加连通性校验；为 Ipv6 增加 LoopBack 和 ANYHOST 等校验。 Dubbo Action 2: 1234NetworkInterface network = interfaces.nextElement();if (network.isLoopback() || network.isVirtual()|| !network.isUp()) &#123; continue;&#125; JDK 提供了以上的 API，我们可以利用起来，过滤一部分一定不正确的网卡。 Dubbo Action 3: 我们本文花了较多的篇幅介绍了 docker 和 TUN/TAP 两种场景导致的虚拟网卡的问题，算是较为常见的一个影响因素，虽然他们的命名具有固定性，如 docker0、tunX、tapX，但我觉得通过网卡名称的判断方式去过滤注册 IP 有一些 hack，所以不建议 dubbo contributor 提出相应的 pr 去增加这些 hack 判断，尽管可能会对判断有所帮助。 对于真实多网卡、内外网 IP 共存的场景，不能仅仅是框架侧在做努力，用户也需要做一些事，就像爱情一样，我可以主动一点，但你也得反馈，才能发展出故事。 Dubbo User Action 1: 可以配置 /etc/hosts 文件，将 hostname 对应的 IP 显示配置进去。 Dubbo User Action 2: 可以使用启动参数去显示指定注册的 IP： 1-DDUBBO_IP_TO_REGISTRY=1.2.3.4 也可以指定 Dubbo 服务绑定在哪块网卡上： 1-DDUBBO_IP_TO_BIND=1.2.3.4 9 参考文章TUN/TAP 设备浅析 what-are-en0-en1-p2p-and-so-on-that-are-displayed-after-executing-ifconfig 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"},{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"},{"name":"网卡","slug":"网卡","permalink":"http://lexburner.github.io/tags/网卡/"}]},{"title":"【Dubbo3.0 新特性】集成 RSocket, 新增响应式支持","slug":"dubbo-rsocket","date":"2019-04-11T11:19:41.000Z","updated":"2019-09-26T09:45:31.122Z","comments":true,"path":"dubbo-rsocket/","link":"","permalink":"http://lexburner.github.io/dubbo-rsocket/","excerpt":"响应式编程响应式编程现在是现在一个很热的话题。响应式编程让开发者更方便地编写高性能的异步代码，关于响应式编程更详细的信息可以参考 http://reactivex.io/ 。很可惜，在之前很长一段时间里，Dubbo 并不支持响应式编程，简单来说，Dubbo 不支持在 rpc 调用时，使用 Mono/Flux 这种流对象（reactive-stream 中流的概念 )，给用户使用带来了不便。 RSocket 是一个支持 reactive-stream 语义的开源网络通信协议，它将 reactive 语义的复杂逻辑封装了起来，使得上层可以方便实现网络程序。RSocket 详细资料：http://rsocket.io/。 Dubbo 在 3.0.0-SNAPSHOT 版本里基于 RSocket 对响应式编程提供了支持，用户可以在请求参数和返回值里使用 Mono 和 Flux 类型的对象。下面我们给出使用范例，源码可以在文末获取。","text":"响应式编程响应式编程现在是现在一个很热的话题。响应式编程让开发者更方便地编写高性能的异步代码，关于响应式编程更详细的信息可以参考 http://reactivex.io/ 。很可惜，在之前很长一段时间里，Dubbo 并不支持响应式编程，简单来说，Dubbo 不支持在 rpc 调用时，使用 Mono/Flux 这种流对象（reactive-stream 中流的概念 )，给用户使用带来了不便。 RSocket 是一个支持 reactive-stream 语义的开源网络通信协议，它将 reactive 语义的复杂逻辑封装了起来，使得上层可以方便实现网络程序。RSocket 详细资料：http://rsocket.io/。 Dubbo 在 3.0.0-SNAPSHOT 版本里基于 RSocket 对响应式编程提供了支持，用户可以在请求参数和返回值里使用 Mono 和 Flux 类型的对象。下面我们给出使用范例，源码可以在文末获取。 Dubbo RSocket 初体验服务接口1234public interface DemoService &#123; Mono&lt;String&gt; requestMonoWithMonoArg(Mono&lt;String&gt; m1, Mono&lt;String&gt; m2); Flux&lt;String&gt; requestFluxWithFluxArg(Flux&lt;String&gt; f1, Flux&lt;String&gt; f2);&#125; 12345&lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-core&lt;/artifactId&gt; &lt;version&gt;3.2.3-RELEASE&lt;/version&gt;&lt;/dependency&gt; 在服务定义层，引入了 Mono，Flux 等 reactor 的概念，所以需要添加 reactor-core 的依赖。 服务提供者123456789101112131415161718192021public class DemoServiceImpl implements DemoService &#123; @Override public Mono&lt;String&gt; requestMonoWithMonoArg(Mono&lt;String&gt; m1, Mono&lt;String&gt; m2) &#123; return m1.zipWith(m2, new BiFunction&lt;String, String, String&gt;() &#123; @Override public String apply(String s, String s2) &#123; return s+\" \"+s2; &#125; &#125;); &#125; @Override public Flux&lt;String&gt; requestFluxWithFluxArg(Flux&lt;String&gt; f1, Flux&lt;String&gt; f2) &#123; return f1.zipWith(f2, new BiFunction&lt;String, String, String&gt;() &#123; @Override public String apply(String s, String s2) &#123; return s+\" \"+s2; &#125; &#125;); &#125;&#125; 除了常规的 Dubbo 必须依赖之外，还需要添加 dubbo-rsocket 的扩展 12345//... other dubbo moudle&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-rpc-rsocket&lt;/artifactId&gt;&lt;/dependency&gt; 配置并启动服务端，注意协议名字填写 rsocket： 12345678910111213141516171819202122&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://dubbo.apache.org/schema/Dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- provider's application name, used for tracing dependency relationship --&gt; &lt;dubbo:application name=\"demo-provider\"/&gt; &lt;!-- use registry center to export service --&gt; &lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt; &lt;!-- use Dubbo protocol to export service on port 20890 --&gt; &lt;dubbo:protocol name=\"rsocket\" port=\"20890\"/&gt; &lt;!-- service implementation, as same as regular local bean --&gt; &lt;bean id=\"demoService\" class=\"org.apache.dubbo.samples.basic.impl.DemoServiceImpl\"/&gt; &lt;!-- declare the service interface to be exported --&gt; &lt;dubbo:service interface=\"org.apache.dubbo.samples.basic.api.DemoService\" ref=\"demoService\"/&gt;&lt;/beans&gt; 服务提供者的 bootstrap： 123456789public class RsocketProvider &#123; public static void main(String[] args) throws Exception &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;\"spring/rsocket-provider.xml\"&#125;); context.start(); System.in.read(); // press any key to exit &#125;&#125; 服务消费者然后配置并启动消费者消费者如下, 注意协议名填写 rsocket： 123456789101112131415161718&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/Dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- consumer's application name, used for tracing dependency relationship (not a matching criterion), don't set it same as provider --&gt; &lt;dubbo:application name=\"demo-consumer\"/&gt; &lt;!-- use registry center to discover service --&gt; &lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt; &lt;!-- generate proxy for the remote service, then demoService can be used in the same way as the local regular interface --&gt; &lt;dubbo:reference id=\"demoService\" check=\"true\" interface=\"org.apache.dubbo.samples.basic.api.DemoService\"/&gt;&lt;/beans&gt; 12345678910111213141516171819202122232425262728293031public class RsocketConsumer &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;\"spring/rsocket-consumer.xml\"&#125;); context.start(); DemoService demoService = (DemoService) context.getBean(\"demoService\"); // get remote service proxy while (true) &#123; try &#123; Mono&lt;String&gt; monoResult = demoService.requestMonoWithMonoArg(Mono.just(\"A\"), Mono.just(\"B\")); monoResult.doOnNext(new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;).block(); Flux&lt;String&gt; fluxResult = demoService.requestFluxWithFluxArg(Flux.just(\"A\",\"B\",\"C\"), Flux.just(\"1\",\"2\",\"3\")); fluxResult.doOnNext(new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;).blockLast(); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; &#125; &#125;&#125; 可以看到配置上除了协议名使用 rsocket 以外其他并没有特殊之处。 实现原理以前用户并不能在参数或者返回值里使用 Mono/Flux 这种流对象（reactive-stream 里的流的概念）。因为流对象自带异步属性，当业务把流对象作为参数或者返回值传递给框架之后，框架并不能将流对象正确的进行序列化。 Dubbo 基于 RSocket 提供了 reactive 支持。RSocket 将 reactive 语义的复杂逻辑封装起来了，给上层提供了简洁的抽象如下：1234567Mono&lt;Void&gt; fireAndForget(Payload payload);Mono&lt;Payload&gt; requestResponse(Payload payload);Flux&lt;Payload&gt; requestStream(Payload payload);Flux&lt;Payload&gt; requestChannel(Publisher&lt;Payload&gt; payloads); 从客户端视角看，框架建立连接之后，只需要将请求信息编码到 Payload 里，然后通过 requestStream 方法即可向服务端发起请求。 从服务端视角看，RSocket 收到请求之后，会调用我们实现的 requestStream 方法，我们从 Payload 里解码得到请求信息之后，调用业务方法，然后拿到 Flux 类型的返回值即可。 需要注意的是业务返回值一般是 Flux&lt;BizDO&gt;，而 RSocket 要求的是 Flux&lt;Payload&gt;，所以我们需要通过 map operator 拦截业务数据，将 BizDO 编码为 Payload 才可以递交给 RSocket。而 RSocket 会负责数据的传输和 reactive 语义的实现。 结语Dubbo 2.7 相比 Dubbo 2.6 提供了 CompletableFuture 的异步化支持，在 Dubbo 3.0 又继续拥抱了 Reactive，不断对新特性的探索，无疑是增加了使用者的信心。RSocket 这一框架 / 协议，如今在国内外也是比较火的一个概念，它提供了丰富的 Reactive 语义以及多语言的支持，使得服务治理框架可以很快地借助它实现 Reactive 语义。有了响应式编程支持，业务可以更加方便的实现异步逻辑。 本篇文章对 Dubbo RSocket 进行了一个简单的介绍，对 Reactive、RSocket 感兴趣的同学也可以浏览下 Dubbo 3.0 源码对 RSocket 的封装。 相关链接： [1] 文中源码：https://github.com/apache/incubator-dubbo-samples/tree/3.x/dubbo-samples-rsocket [2] Dubbo 3.x 开发分支：https://github.com/apache/incubator-Dubbo/tree/3.x-dev","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"}]},{"title":"Dubbo2.7 三大新特性详解","slug":"dubbo27-features","date":"2019-03-21T06:12:40.000Z","updated":"2019-09-26T09:45:30.083Z","comments":true,"path":"dubbo27-features/","link":"","permalink":"http://lexburner.github.io/dubbo27-features/","excerpt":"1 背景介绍自 2017 年 7 月阿里重启 Dubbo 开源，到目前为止 github star 数，contributor 数都有了非常大的提升。2018 年 2 月 9 日阿里决定将 Dubbo 项目贡献给 Apache，经过一周的投票，顺利成为了 Apache 的孵化项目，也就是大家现在看到的 Incubator Dubbo。预计在 2019 年 4 月，Dubbo 可以达成毕业，成为 Apache 的顶级项目。","text":"1 背景介绍自 2017 年 7 月阿里重启 Dubbo 开源，到目前为止 github star 数，contributor 数都有了非常大的提升。2018 年 2 月 9 日阿里决定将 Dubbo 项目贡献给 Apache，经过一周的投票，顺利成为了 Apache 的孵化项目，也就是大家现在看到的 Incubator Dubbo。预计在 2019 年 4 月，Dubbo 可以达成毕业，成为 Apache 的顶级项目。 2 分支介绍 Dubbo 目前有如图所示的 5 个分支，其中 2.7.1-release 只是一个临时分支，忽略不计，对其他 4 个分支进行介绍。 2.5.x 近期已经通过投票，Dubbo 社区即将停止对其的维护。 2.6.x 为长期支持的版本，也是 Dubbo 贡献给 Apache 之前的版本，其包名前缀为：com.alibaba，JDK 版本对应 1.6。 3.x-dev 是前瞻性的版本，对 Dubbo 进行一些高级特性的补充，如支持 rx 特性。 master 为长期支持的版本，版本号为 2.7.x，也是 Dubbo 贡献给 Apache 的开发版本，其包名前缀为：org.apache，JDK 版本对应 1.8。 如果想要研究 Dubbo 的源码，建议直接浏览 master 分支。 3 Dubbo 2.7 新特性Dubbo 2.7.x 作为 Apache 的孵化版本，除了代码优化之外，还新增了许多重磅的新特性，本文将会介绍其中最典型的三个新特性： 异步化改造 三大中心改造 服务治理增强 4 异步化改造4.1 几种调用方式 在远程方法调用中，大致可以分为这 4 种调用方式。oneway 指的是客户端发送消息后，不需要接受响应。对于那些不关心服务端响应的请求，比较适合使用 oneway 通信。 注意，void hello() 方法在远程方法调用中，不属于 oneway 调用，虽然 void 方法表达了不关心返回值的语义，但在 RPC 层面，仍然需要做通信层的响应。 sync 是最常用的通信方式，也是默认的通信方法。 future 和 callback 都属于异步调用的范畴，他们的区别是：在接收响应时，future.get() 会导致线程的阻塞;callback 通常会设置一个回调线程，当接收到响应时，自动执行，不会对当前线程造成阻塞。 4.2 Dubbo 2.6 异步化异步化的优势在于客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小。介绍 2.7 中的异步化改造之前，先回顾一下如何在 2.6 中使用 Dubbo 异步化的能力。 将同步接口声明成 async=true 1&lt;dubbo:reference id=\"asyncService\" interface=\"org.apache.dubbo.demo.api.AsyncService\" async=\"true\"/&gt; 123public interface AsyncService &#123; String sayHello(String name);&#125; 通过上下文类获取 future 123AsyncService.sayHello(\"Han Meimei\");Future&lt;String&gt; fooFuture = RpcContext.getContext().getFuture();fooFuture.get(); 可以看出，这样的使用方式，不太符合异步编程的习惯，竟然需要从一个上下文类中获取到 Future。如果同时进行多个异步调用，使用不当很容易造成上下文污染。而且，Future 并不支持 callback 的调用方式。这些弊端在 Dubbo 2.7 中得到了改进。 4.3 Dubbo 2.7 异步化 无需配置中特殊声明，显示声明异步接口即可 123456public interface AsyncService &#123; String sayHello(String name); default CompletableFuture&lt;String&gt; sayHiAsync(String name) &#123; return CompletableFuture.completedFuture(sayHello(name)); &#125;&#125; 使用 callback 方式处理返回值 12345678CompletableFuture&lt;String&gt; future = asyncService.sayHiAsync(\"Han MeiMei\");future.whenComplete((retValue, exception) -&gt; &#123; if (exception == null) &#123; System.out.println(retValue); &#125; else &#123; exception.printStackTrace(); &#125;&#125;); Dubbo 2.7 中使用了 JDK1.8 提供的 CompletableFuture 原生接口对自身的异步化做了改进。CompletableFuture 可以支持 future 和 callback 两种调用方式，用户可以根据自己的喜好和场景选择使用，非常灵活。 4.4 异步化设计 FAQQ：如果 RPC 接口只定义了同步接口，有办法使用异步调用吗？ A：2.6 中的异步调用唯一的优势在于，不需要在接口层面做改造，又可以进行异步调用，这种方式仍然在 2.7 中保留；使用 Dubbo 官方提供的 compiler hacker，编译期自动重写同步方法，请 在此 讨论和跟进具体进展。 Q：关于异步接口的设计问题，为何不提供编译插件，根据原接口，自动编译出一个 XxxAsync 接口？ A：Dubbo 2.7 采用采用过这种设计，但接口的膨胀会导致服务类的增量发布，而且接口名的变化会影响服务治理的一些相关逻辑，改为方法添加 Async 后缀相对影响范围较小。 Q：Dubbo 分为了客户端异步和服务端异步，刚刚你介绍的是客户端异步，为什么不提服务端异步呢？ A：Dubbo 2.7 新增了服务端异步的支持，但实际上，Dubbo 的业务线程池模型，本身就可以理解为异步调用，个人认为服务端异步的特性较为鸡肋。 5 三大中心改造三大中心指的：注册中心，元数据中心，配置中心。 在 2.7 之前的版本，Dubbo 只配备了注册中心，主流使用的注册中心为 zookeeper。新增加了元数据中心和配置中心，自然是为了解决对应的痛点，下面我们来详细阐释三大中心改造的原因。 5.1 元数据改造元数据是什么？元数据定义为描述数据的数据，在服务治理中，例如服务接口名，重试次数，版本号等等都可以理解为元数据。在 2.7 之前，元数据一股脑丢在了注册中心之中，这造成了一系列的问题： 推送量大 -&gt; 存储数据量大 -&gt; 网络传输量大 -&gt; 延迟严重 生产者端注册 30+ 参数，有接近一半是不需要作为注册中心进行传递；消费者端注册 25+ 参数，只有个别需要传递给注册中心。有了以上的理论分析，Dubbo 2.7 进行了大刀阔斧的改动，只将真正属于服务治理的数据发布到注册中心之中，大大降低了注册中心的负荷。 同时，将全量的元数据发布到另外的组件中：元数据中心。元数据中心目前支持 redis（推荐），zookeeper。这也为 Dubbo 2.7 全新的 Dubbo Admin 做了准备，关于新版的 Dubbo Admin，我将会后续准备一篇独立的文章进行介绍。 示例：使用 zookeeper 作为元数据中心 1&lt;dubbo:metadata-report address=\"zookeeper://127.0.0.1:2181\"/&gt; 5.2 Dubbo 2.6 元数据1234567891011121314dubbo://30.5.120.185:20880/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello&amp;bean.name=com.alibaba.dubbo.demo.DemoService&amp;dubbo=2.0.2&amp;executes=4500&amp;generic=false&amp;owner=kirito&amp;pid=84228&amp;retries=7&amp;side=provider&amp;timestamp=1552965771067 从本地的 zookeeper 中取出一条服务数据，通过解码之后，可以看出，的确有很多参数是不必要。 5.3 Dubbo 2.7 元数据在 2.7 中，如果不进行额外的配置，zookeeper 中的数据格式仍然会和 Dubbo 2.6 保持一致，这主要是为了保证兼容性，让 Dubbo 2.6 的客户端可以调用 Dubbo 2.7 的服务端。如果整体迁移到 2.7，则可以为注册中心开启简化配置的参数： 1&lt;dubbo:registry address=“zookeeper://127.0.0.1:2181” simplified=\"true\"/&gt; Dubbo 将会只上传那些必要的服务治理数据，一个简化过后的数据如下所示： 12345dubbo://30.5.120.185:20880/org.apache.dubbo.demo.api.DemoService?application=demo-provider&amp;dubbo=2.0.2&amp;release=2.7.0&amp;timestamp=1552975501873 对于那些非必要的服务信息，仍然全量存储在元数据中心之中： 元数据中心的数据可以被用于服务测试，服务 MOCK 等功能。目前注册中心配置中 simplified 的默认值为 false，因为考虑到了迁移的兼容问题，在后续迭代中，默认值将会改为 true。 5.4 配置中心支持衡量配置中心的必要性往往从三个角度出发： 分布式配置统一管理 动态变更推送 安全性 Spring Cloud Config, Apollo, Nacos 等分布式配置中心组件都对上述功能有不同程度的支持。在 2.7 之前的版本中，在 zookeeper 中设置了部分节点：configurators，routers，用于管理部分配置和路由信息，它们可以理解为 Dubbo 配置中心的雏形。在 2.7 中，Dubbo 正式支持了配置中心，目前支持的几种注册中心 Zookeeper，Apollo，Nacos（2.7.1-release 支持）。 在 Dubbo 中，配置中心主要承担了两个作用 外部化配置。启动配置的集中式存储 服务治理。服务治理规则的存储与通知 示例：使用 Zookeeper 作为配置中心 1&lt;dubbo:config-center address=\"zookeeper://127.0.0.1:2181\"/&gt; 引入配置中心后，需要注意配置项的覆盖问题，优先级如图所示 6 服务治理增强我更倾向于将 Dubbo 当做一个服务治理框架，而不仅仅是一个 RPC 框架。在 2.7 中，Dubbo 对其服务治理能力进行了增强，增加了标签路由的能力，并抽象出了应用路由和服务路由的概念。在最后一个特性介绍中，着重对标签路由 TagRouter 进行探讨。 在服务治理中，路由层和负载均衡层的对比。区别 1，Router：m 选 n，LoadBalance：n 选 1；区别 2，路由往往是叠加使用的，负载均衡只能配置一种。 在很长的一段时间内，Dubbo 社区经常有人提的一个问题是：Dubbo 如何实现流量隔离和灰度发布，直到 2.7 提供了标签路由，用户可以使用这个功能，来实现上述的需求。 标签路由提供了这样一个能力，当调用链路为 A -&gt; B -&gt; C -&gt; D 时，用户给请求打标，最典型的打标方式可以借助 attachment（他可以在分布式调用中传递下去），调用会优先请求那些匹配的服务端，如 A -&gt; B，C -&gt; D，由于集群中未部署 C 节点，则会降级到普通节点。 打标方式会收到集成系统差异的影响，从而导致很大的差异，所以 Dubbo 只提供了 RpcContext.getContext().setAttachment() 这样的基础接口，用户可以使用 SPI 扩展，或者 server filter 的扩展，对测试流量进行打标，引导进入隔离环境 / 灰度环境。 新版的 Dubbo Admin 提供了标签路由的配置项： Dubbo 用户可以在自己系统的基础上对标签路由进行二次扩展，或者借鉴标签路由的设计，实现自己系统的流量隔离，灰度发布。 7 总结本文介绍了 Dubbo 2.7 比较重要的三大新特性：异步化改造，三大中心改造，服务治理增强。Dubbo 2.7 还包含了很多功能优化、特性升级，可以在项目源码的 CHANGES.md 中浏览全部的改动点。最后提供一份 Dubbo 2.7 的升级文档：2.7 迁移文档，欢迎体验。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"}]},{"title":"一文探讨堆外内存的监控与回收","slug":"nio-buffer-recycle","date":"2019-03-17T06:12:40.000Z","updated":"2019-09-26T09:45:30.702Z","comments":true,"path":"nio-buffer-recycle/","link":"","permalink":"http://lexburner.github.io/nio-buffer-recycle/","excerpt":"引子记得那是一个风和日丽的周末，太阳红彤彤，花儿五颜六色，96 年的普哥微信找到我，描述了一个诡异的线上问题：线上程序使用了 NIO FileChannel 的 堆内内存（HeapByteBuffer）作为缓冲区，读写文件，逻辑可以说相当简单，但根据监控，却发现堆外内存（DirectByteBuffer）飙升，导致了 OutOfMemeory 的异常。 由这个线上问题，引出了这篇文章的主题，主要包括：FileChannel 源码分析，堆外内存监控，堆外内存回收。","text":"引子记得那是一个风和日丽的周末，太阳红彤彤，花儿五颜六色，96 年的普哥微信找到我，描述了一个诡异的线上问题：线上程序使用了 NIO FileChannel 的 堆内内存（HeapByteBuffer）作为缓冲区，读写文件，逻辑可以说相当简单，但根据监控，却发现堆外内存（DirectByteBuffer）飙升，导致了 OutOfMemeory 的异常。 由这个线上问题，引出了这篇文章的主题，主要包括：FileChannel 源码分析，堆外内存监控，堆外内存回收。 问题分析 &amp; 源码分析根据异常日志的定位，发现的确使用的是 HeapByteBuffer 来进行读写，但却导致堆外内存飙升，随即翻了 FileChannel 的源码，来一探究竟。 FileChannel 使用的是 IOUtil 进行读写操作（本文只分析读的逻辑，写和读的代码逻辑一致，不做重复分析） 12345678910111213141516171819202122//sun.nio.ch.IOUtil#readstatic int read(FileDescriptor var0, ByteBuffer var1, long var2, NativeDispatcher var4) throws IOException &#123; if (var1.isReadOnly()) &#123; throw new IllegalArgumentException(\"Read-only buffer\"); &#125; else if (var1 instanceof DirectBuffer) &#123; return readIntoNativeBuffer(var0, var1, var2, var4); &#125; else &#123; ByteBuffer var5 = Util.getTemporaryDirectBuffer(var1.remaining()); int var7; try &#123; int var6 = readIntoNativeBuffer(var0, var5, var2, var4); var5.flip(); if (var6 &gt; 0) &#123; var1.put(var5); &#125; var7 = var6; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(var5); &#125; return var7; &#125;&#125; 可以发现当使用 HeapByteBuffer 时，会走到下面这行看似有点疑问的代码分支： 1Util.getTemporaryDirectBuffer(var1.remaining()); 这个 Util 封装了更为底层的一些 IO 逻辑 123456789101112131415161718192021222324package sun.nio.ch;public class Util &#123; private static ThreadLocal&lt;Util.BufferCache&gt; bufferCache; public static ByteBuffer getTemporaryDirectBuffer(int var0) &#123; if (isBufferTooLarge(var0)) &#123; return ByteBuffer.allocateDirect(var0); &#125; else &#123; // FOUCS ON THIS LINE Util.BufferCache var1 = (Util.BufferCache)bufferCache.get(); ByteBuffer var2 = var1.get(var0); if (var2 != null) &#123; return var2; &#125; else &#123; if (!var1.isEmpty()) &#123; var2 = var1.removeFirst(); free(var2); &#125; return ByteBuffer.allocateDirect(var0); &#125; &#125; &#125;&#125; isBufferTooLarge 这个方法会根据传入 Buffer 的大小决定如何分配堆外内存，如果过大，直接分配大缓冲区；如果不是太大，会使用 bufferCache 这个 ThreadLocal 变量来进行缓存，从而复用（实际上这个数值非常大，几乎不会走进直接分配堆外内存这个分支）。这么看来似乎发现了两个不得了的结论： 使用 HeapByteBuffer 读写都会经过 DirectByteBuffer，写入数据的流转方式其实是：HeapByteBuffer -&gt; DirectByteBuffer -&gt; PageCache -&gt; Disk，读取数据的流转方式正好相反。 使用 HeapByteBuffer 读写会申请一块跟线程绑定的 DirectByteBuffer。这意味着，线程越多，临时 DirectByteBuffer 就越会占用越多的空间。 看到这儿，线上的问题似乎有了一点眉目：很有可能是多线程使用 HeapByteBuffer 写入文件，而额外分配的这块 DirectByteBuffer 导致了内存溢出。在验证这个猜测之前，我们最好能直观地监控到堆外内存的使用量，这才能增加我们定位问题的信心。 实现堆外内存的监控JDK 提供了一个非常好用的监控工具 —— Java VisualVM。我们只需要为它安装一个插件，即可很方便地实现堆外内存的监控。 进入本地 JDK 的可执行目录（在我本地是：/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/bin），找到 jvisualvm 命令，双击打开一个可视化的界面 左侧树状目录可以选择需要监控的 Java 进程，右侧是监控的维度信息，除了 CPU、线程、堆、类等信息，还可以通过上方的【工具 (T)】 安装插件，增加 MBeans、Buffer Pools 等维度的监控。 Buffer Pools 插件可以监控堆外内存（包含 DirectByteBuffer 和 MappedByteBuffer），如下图所示： 左侧对应 DirectByteBuffer，右侧对应 MappedByteBuffer。 复现问题为了复现线上的问题，我们使用一个程序，不断开启线程使用堆内内存作为缓冲区进行文件的读取操作，并监控该进程的堆外内存使用情况。 123456789101112131415161718192021public class ReadByHeapByteBufferTest &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; File data = new File(\"/tmp/data.txt\"); FileChannel fileChannel = new RandomAccessFile(data, \"rw\").getChannel(); ByteBuffer buffer = ByteBuffer.allocate(4 * 1024 * 1024); for (int i = 0; i &lt; 1000; i++) &#123; Thread.sleep(1000); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; fileChannel.read(buffer); buffer.clear(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125;&#125; 运行一段时间后，我们观察下堆外内存的使用情况 如上图左所示，堆外内存的确开始疯涨了，的确符合我们的预期，堆外缓存和线程绑定，当线程非常多时，即使只使用了 4M 的堆内内存，也可能会造成极大的堆外内存膨胀，在中间发生了一次断崖，推测是线程执行完毕 or GC，导致了内存的释放。 知晓了这一点，相信大家今后使用堆内内存时可能就会更加注意了，我总结了两个注意点： 使用 HeapByteBuffer 还需要经过一次 DirectByteBuffer 的拷贝，在追求极致性能的场景下是可以通过直接复用堆外内存来避免的。 多线程下使用 HeapByteBuffer 进行文件读写，要注意 ThreadLocal&lt;Util.BufferCache&gt; bufferCache 导致的堆外内存膨胀的问题。 问题深究那大家有没有想过，为什么 JDK 要如此设计？为什么不直接使用堆内内存写入 PageCache 进而落盘呢？为什么一定要经过 DirectByteBuffer 的拷贝呢？ 在知乎的相关问题中，R 大和 曾泽堂 两位同学进行了解答，是我比较认同的解释： 作者：RednaxelaFX 链接：https://www.zhihu.com/question/57374068/answer/152691891 来源：知乎 这里其实是在迁就 OpenJDK 里的 HotSpot VM 的一点实现细节。 HotSpot VM 里的 GC 除了 CMS 之外都是要移动对象的，是所谓“compacting GC”。 如果要把一个 Java 里的 byte[] 对象的引用传给 native 代码，让 native 代码直接访问数组的内容的话，就必须要保证 native 代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。 可惜 HotSpot VM 出于一些取舍而决定不实现单个对象层面的 object pinning，要 pin 的话就得暂时禁用 GC——也就等于把整个 Java 堆都给 pin 住。 所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的 I/O 可能是一个很慢的操作。 于是它就先把 HeapByteBuffer 背后的 byte[] 的内容拷贝到一个 DirectByteBuffer 背后的 native memory 去，这个拷贝会涉及 sun.misc.Unsafe.copyMemory() 的调用，背后是类似 memcpy() 的实现。这个操作本质上是会在整个拷贝过程中暂时不允许发生 GC 的。 然后数据被拷贝到 native memory 之后就好办了，就去做真正的 I/O，把 DirectByteBuffer 背后的 native memory 地址传给真正做 I/O 的函数。这边就不需要再去访问 Java 对象去读写要做 I/O 的数据了。 总结一下就是： 为了方便 GC 的实现，DirectByteBuffer 指向的 native memory 是不受 GC 管辖的 HeapByteBuffer 背后使用的是 byte 数组，其占用的内存不一定是连续的，不太方便 JNI 方法的调用 数组实现在不同 JVM 中可能会不同 堆外内存的回收继续深究下一个话题，也是我的微信交流群中曾经有人提出过的一个疑问，到底该如何回收 DirectByteBuffer？既然可以监控堆外内存，那验证堆外内存的回收就变得很容易实现了。 CASE 1：分配 1G 的 DirectByteBuffer，等待用户输入后，复制为 null，之后阻塞持续观察堆外内存变化 12345678public class WriteByDirectByteBufferTest &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; ByteBuffer buffer = ByteBuffer.allocateDirect(1024 * 1024 * 1024); System.in.read(); buffer = null; new CountDownLatch(1).await(); &#125;&#125; 结论：变量虽然置为了 null，但内存依旧持续占用。 CASE 2：分配 1G DirectByteBuffer，等待用户输入后，复制为 null，手动触发 GC，之后阻塞持续观察堆外内存变化 123456789public class WriteByDirectByteBufferTest &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; ByteBuffer buffer = ByteBuffer.allocateDirect(1024 * 1024 * 1024); System.in.read(); buffer = null; System.gc(); new CountDownLatch(1).await(); &#125;&#125; 结论：GC 时会触发堆外空闲内存的回收。 CASE 3：分配 1G DirectByteBuffer，等待用户输入后，手动回收堆外内存，之后阻塞持续观察堆外内存变化 12345678public class WriteByDirectByteBufferTest &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; ByteBuffer buffer = ByteBuffer.allocateDirect(1024 * 1024 * 1024); System.in.read(); ((DirectBuffer) buffer).cleaner().clean(); new CountDownLatch(1).await(); &#125;&#125; 结论：手动回收可以立刻释放堆外内存，不需要等待到 GC 的发生。 对于 MappedByteBuffer 这个有点神秘的类，它的回收机制大概和 DirectByteBuffer 类似，体现在右边的 Mapped 之中，我们就不重复 CASE1 和 CASE2 的测试了，直接给出结论，在 GC 发生或者操作系统主动清理时 MappedByteBuffer 会被回收。但也不是不进行测试，我们会对 MappedByteBuffer 进行更有意思的研究。 CASE 4：手动回收 MappedByteBuffer。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class MmapUtil &#123; public static void clean(MappedByteBuffer mappedByteBuffer) &#123; ByteBuffer buffer = mappedByteBuffer; if (buffer == null || !buffer.isDirect() || buffer.capacity()== 0) return; invoke(invoke(viewed(buffer), \"cleaner\"), \"clean\"); &#125; private static Object invoke(final Object target, final String methodName, final Class&lt;?&gt;... args) &#123; return AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; public Object run() &#123; try &#123; Method method = method(target, methodName, args); method.setAccessible(true); return method.invoke(target); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; &#125;); &#125; private static Method method(Object target, String methodName, Class&lt;?&gt;[] args) throws NoSuchMethodException &#123; try &#123; return target.getClass().getMethod(methodName, args); &#125; catch (NoSuchMethodException e) &#123; return target.getClass().getDeclaredMethod(methodName, args); &#125; &#125; private static ByteBuffer viewed(ByteBuffer buffer) &#123; String methodName = \"viewedBuffer\"; Method[] methods = buffer.getClass().getMethods(); for (int i = 0; i &lt; methods.length; i++) &#123; if (methods[i].getName().equals(\"attachment\")) &#123; methodName = \"attachment\"; break; &#125; &#125; ByteBuffer viewedBuffer = (ByteBuffer) invoke(buffer, methodName); if (viewedBuffer == null) return buffer; else return viewed(viewedBuffer); &#125;&#125; 这个类曾经在我的《文件 IO 的一些最佳实践》中有所介绍，在这里我们将验证它的作用。编写测试类： 1234567891011public class WriteByMappedByteBufferTest &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; File data = new File(\"/tmp/data.txt\"); data.createNewFile(); FileChannel fileChannel = new RandomAccessFile(data, \"rw\").getChannel(); MappedByteBuffer map = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 1024L * 1024 * 1024); System.in.read(); MmapUtil.clean(map); new CountDownLatch(1).await(); &#125;&#125; 结论：通过一顿复杂的反射操作，成功地手动回收了 Mmap 的内存映射。 CASE 5：测试 Mmap 的内存占用 123456789101112public class WriteByMappedByteBufferTest &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; File data = new File(\"/tmp/data.txt\"); data.createNewFile(); FileChannel fileChannel = new RandomAccessFile(data, \"rw\").getChannel(); for (int i = 0; i &lt; 1000; i++) &#123; fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 1024L * 1024 * 1024); &#125; System.out.println(\"map finish\"); new CountDownLatch(1).await(); &#125;&#125; 我尝试映射了 1000G 的内存，我的电脑显然没有 1000G 这么大内存，那么监控是如何反馈的呢？ 几乎在瞬间，控制台打印出了 map finish 的日志，也意味着 1000G 的内存映射几乎是不耗费时间的，为什么要做这个测试？就是为了解释内存映射并不等于内存占用，很多文章认为内存映射这种方式可以大幅度提升文件的读写速度，并宣称“写 MappedByteBuffer 就等于写内存”，实际是非常错误的认知。通过控制面板可以查看到该 Java 进程（pid 39040）实际占用的内存，仅仅不到 100M。(关于 Mmap 的使用场景和方式可以参考我之前的文章) 结论：MappedByteBuffer 映射出一片文件内容之后，不会全部加载到内存中，而是会进行一部分的预读（体现在占用的那 100M 上），MappedByteBuffer 不是文件读写的银弹，它仍然依赖于 PageCache 异步刷盘的机制。 通过 Java VisualVM 可以监控到 mmap 总映射的大小，但并不是实际占用的内存量 。 总结本文借助一个线上问题，分析了使用堆内内存仍然会导致堆外内存分析的现象以及背后 JDK 如此设计的原因，并借助安装了插件之后的 Java VisualVM 工具进行了堆外内存的监控，进而讨论了如何正确的回收堆外内存，以及纠正了一个关于 MappedByteBuffer 的错误认知。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://lexburner.github.io/categories/数据库/"}],"tags":[{"name":"文件 IO","slug":"文件-IO","permalink":"http://lexburner.github.io/tags/文件-IO/"}]},{"title":"Dubbo 的前世今生 & Dubbo Meetup 南京","slug":"dubbo-meetup-nj","date":"2019-03-08T06:12:40.000Z","updated":"2019-09-26T09:45:30.305Z","comments":true,"path":"dubbo-meetup-nj/","link":"","permalink":"http://lexburner.github.io/dubbo-meetup-nj/","excerpt":"Dubbo 的前世今生2011 年 10 月 27 日，阿里巴巴开源了自己的 SOA 服务化治理方案的核心框架 Dubbo，服务治理和 SOA 的设计理念开始逐渐在国内软件行业中落地，并被广泛应用。自开源后，许多非阿里系公司选择使用 Dubbo，其中既有当当网、网易考拉等互联网公司，也有中国人寿、青岛海尔等传统企业。","text":"Dubbo 的前世今生2011 年 10 月 27 日，阿里巴巴开源了自己的 SOA 服务化治理方案的核心框架 Dubbo，服务治理和 SOA 的设计理念开始逐渐在国内软件行业中落地，并被广泛应用。自开源后，许多非阿里系公司选择使用 Dubbo，其中既有当当网、网易考拉等互联网公司，也有中国人寿、青岛海尔等传统企业。 2012 年 10 月 23 日 Dubbo 2.5.3 发布后，在 Dubbo 开源将满一周年之际，阿里基本停止了对 Dubbo 的主要升级。 2013 年，2014 年，更新了 2 次 Dubbo 2.4 的维护版本，然后停止了所有维护工作。至此，Dubbo 对 Srping 的支持也停留在了 Spring 2.5.6 版本上。 阿里停止维护和升级 Dubbo 期间，当当网开始维护自己的 Dubbo 分支版本 Dubbox，新增支持了新版本的 Spring，支持了 Rest 协议等，并对外开源了 Dubbox。同时，网易考拉也维护了自己的独立分支 Dubbok，可惜并未对外开源。 2017 年 9 月 7 日，Dubbo 悄悄在 GitHub 发布了 2.5.4 版本。随后，又迅速发布了 2.5.5、2.5.6、2.5.7 等版本。在 10 月举行的云栖大会上，阿里宣布 Dubbo 被列入集团重点维护开源项目，这也就意味着 Dubbo 起死回生，开始重新进入快车道。 2018 年 1 月 8 日，Dubbo 2.6.0 版本发布，新版本将之前当当网开源的 Dubbox 进行了合并，实现了 Dubbo 版本的统一整合。 2018 年 2 月 9 日，Apache 基金会的邮件列表上发起了讨论是否接纳阿里的 Dubbo 项目进入 Apache 孵化器的投票。经过一周的投票，邮件列表显示，Dubbo 获得了 14 张赞成票，在无弃权和反对票的情况下，正式通过投票，顺利成为 Apache 基金会孵化项目。 自此，Dubbo 开始了两个长期维护的版本，Dubbo 2.6.x （包名：com.alibaba）稳定维护版本和 Dubbo 2.7.x （包名：org.apache）apache 孵化版本。 2018 ~ 2019 年，在此期间，Dubbo 发布了 4、5 个版本，并发布了 nodejs，python，go 等多语言的客户端。在此期间，Dubbo 社区相继在北京、上海、深圳、成都、杭州等地举办了开发者沙龙。 2019 年 1 月，2.7.0 release 版本发布，这个即将毕业的 apache 版本支持了丰富的新特性，全新的 Dubbo Ops 控制台。 报名 | Dubbo Meetup 南京 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"}]},{"title":"Java 文件 IO 操作之 DirectIO","slug":"direct-io","date":"2019-03-02T07:45:13.000Z","updated":"2019-09-26T09:46:40.510Z","comments":true,"path":"direct-io/","link":"","permalink":"http://lexburner.github.io/direct-io/","excerpt":"在前文《文件 IO 操作的一些最佳实践》中，我介绍了一些 Java 中常见的文件操作的接口，并且就 PageCache 和 DIrect IO 进行了探讨，最近我自己封装了一个 Direct IO 的库，趁着这个机会，本文重点谈谈 Java 中 Direct IO 的意义，以及简单介绍下我自己的轮子。","text":"在前文《文件 IO 操作的一些最佳实践》中，我介绍了一些 Java 中常见的文件操作的接口，并且就 PageCache 和 DIrect IO 进行了探讨，最近我自己封装了一个 Direct IO 的库，趁着这个机会，本文重点谈谈 Java 中 Direct IO 的意义，以及简单介绍下我自己的轮子。 Java 中的 Direct IO如果你阅读过我之前的文章，应该已经了解 Java 中常用的文件操作接口为：FileChannel，并且没有直接操作 Direct IO 的接口。这也就意味着 Java 无法绕开 PageCache 直接对存储设备进行读写，但对于使用 Java 语言来编写的数据库，消息队列等产品而言，的确存在绕开 PageCache 的需求： PageCache 属于操作系统层面的概念，用户层面很难干预，User BufferCache 显然比 Kernel PageCache 要可控 现代操作系统会使用尽可能多的空闲内存来充当 PageCache，当操作系统回收 PageCache 内存的速度低于应用写缓存的速度时，会影响磁盘写入的速率，直接表现为写入 RT 增大，这被称之为“毛刺现象” PageCache 可能会好心办坏事，采用 Direct IO + 自定义内存管理机制会使得产品更加的可控，高性能。 Direct IO 的限制在 Java 中使用 Direct IO 最终需要调用到 c 语言的 pwrite 接口，并设置 O_DIRECT flag，使用 O_DIRECT 存在不少限制 操作系统限制：Linux 操作系统在 2.4.10 及以后的版本中支持 O_DIRECT flag，老版本会忽略该 Flag；Mac OS 也有类似于 O_DIRECT 的机制 用于传递数据的缓冲区，其内存边界必须对齐为 blockSize 的整数倍 用于传递数据的缓冲区，其传递数据的大小必须是 blockSize 的整数倍。 数据传输的开始点，即文件和设备的偏移量，必须是 blockSize 的整数倍 查看系统 blockSize 大小的方式：stat /boot/|grep “IO Block” ubuntu@VM-30-130-ubuntu:~$ stat /boot/|grep “IO Block” Size: 4096 Blocks: 8 IO Block: 4096 directory 通常为 4kb Java 使用 Direct IO项目地址https://github.com/lexburner/kdio 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;moe.cnkirito.kdio&lt;/groupId&gt; &lt;artifactId&gt;kdio-core&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 注意事项12345// file path should be specific since the different file path determine whether your system support direct iopublic static DirectIOLib directIOLib = DirectIOLib.getLibForPath(\"/\");// you should always write into your disk the Integer-Multiple of block size through direct io.// in most system, the block size is 4kbprivate static final int BLOCK_SIZE = 4 * 1024; Direct IO 写12345678910111213private static void write() throws IOException &#123; if (DirectIOLib.binit) &#123; ByteBuffer byteBuffer = DirectIOUtils.allocateForDirectIO(directIOLib, 4 * BLOCK_SIZE); for (int i = 0; i &lt; BLOCK_SIZE; i++) &#123; byteBuffer.putInt(i); &#125; byteBuffer.flip(); DirectRandomAccessFile directRandomAccessFile = new DirectRandomAccessFile(new File(\"./database.data\"), \"rw\"); directRandomAccessFile.write(byteBuffer, 0); &#125; else &#123; throw new RuntimeException(\"your system do not support direct io\"); &#125;&#125; Direct IO 读12345678910111213public static void read() throws IOException &#123; if (DirectIOLib.binit) &#123; ByteBuffer byteBuffer = DirectIOUtils.allocateForDirectIO(directIOLib, 4 * BLOCK_SIZE); DirectRandomAccessFile directRandomAccessFile = new DirectRandomAccessFile(new File(\"./database.data\"), \"rw\"); directRandomAccessFile.read(byteBuffer, 0); byteBuffer.flip(); for (int i = 0; i &lt; BLOCK_SIZE; i++) &#123; System.out.print(byteBuffer.getInt() + \" \"); &#125; &#125; else &#123; throw new RuntimeException(\"your system do not support direct io\"); &#125;&#125; 主要 API DirectIOLib.java 提供 Native 的 pwrite 和 pread DirectIOUtils.java 提供工具类方法，比如分配 Block 对齐的 ByteBuffer DirectChannel/DirectChannelImpl.java 提供对 fd 的 Direct 包装，提供类似 FileChannel 的读写 API。 DirectRandomAccessFile.java 通过 DIO 的方式打开文件，并暴露 IO 接口。 总结这个简单的 Direct IO 框架参考了 smacke/jaydio，这个库自己搞了一套 Buffer 接口跟 JDK 的类库不兼容，且读写实现里面加了一块 Buffer 用于缓存内容至 Block 对齐有点破坏 Direct IO 的语义。同时，感谢尘央同学的指导，这个小轮子的代码量并不多，初始代码引用自他的一个小 demo（已获得本人授权）。为什么需要这么一个库？主要是考虑后续会出现像「中间件性能挑战赛」和「PolarDB 性能挑战赛」这样的比赛，Java 本身的 API 可能不足以发挥其优势，如果有一个库可以屏蔽掉 Java 和 CPP 选手的差距，岂不是美哉？我也将这个库发到了中央仓库，方便大家在自己的代码中引用。 后续会视需求，会这个小小的轮子增加注入 fadvise，mmap 等系统调用的映射，也欢迎对文件操作感兴趣的同学一起参与进来，pull request &amp; issue are welcome！ 扩展阅读《文件 IO 操作的一些最佳实践》 《PolarDB 数据库性能大赛 Java 选手分享》 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://lexburner.github.io/categories/数据库/"}],"tags":[{"name":"DirectIO","slug":"DirectIO","permalink":"http://lexburner.github.io/tags/DirectIO/"},{"name":"JNA","slug":"JNA","permalink":"http://lexburner.github.io/tags/JNA/"}]},{"title":"一致性哈希负载均衡算法的探讨","slug":"consistent-hash-lb","date":"2019-02-15T07:45:13.000Z","updated":"2019-09-26T09:45:30.947Z","comments":true,"path":"consistent-hash-lb/","link":"","permalink":"http://lexburner.github.io/consistent-hash-lb/","excerpt":"前言一致性哈希算法在很多领域有应用，例如分布式缓存领域的 MemCache，Redis，负载均衡领域的 Nginx，各类 RPC 框架。不同领域场景不同，需要顾及的因素也有所差异，本文主要讨论在 负载均衡 中一致性哈希算法的设计。 在介绍一致性哈希算法之前，我将会介绍一些哈希算法，讨论它们的区别和使用场景。也会给出一致性哈希算法的 Java 通用实现，可以直接引用，文末会给出 github 地址。 友情提示：阅读本文前，最好对一致性哈希算法有所了解，例如你最好听过一致性哈希环这个概念，我会在基本概念上缩短篇幅。","text":"前言一致性哈希算法在很多领域有应用，例如分布式缓存领域的 MemCache，Redis，负载均衡领域的 Nginx，各类 RPC 框架。不同领域场景不同，需要顾及的因素也有所差异，本文主要讨论在 负载均衡 中一致性哈希算法的设计。 在介绍一致性哈希算法之前，我将会介绍一些哈希算法，讨论它们的区别和使用场景。也会给出一致性哈希算法的 Java 通用实现，可以直接引用，文末会给出 github 地址。 友情提示：阅读本文前，最好对一致性哈希算法有所了解，例如你最好听过一致性哈希环这个概念，我会在基本概念上缩短篇幅。 一致性哈希负载均衡介绍负载均衡这个概念可以抽象为：从 n 个候选服务器中选择一个进行通信的过程。负载均衡算法有多种多样的实现方式：随机、轮询、最小负载优先等，其中也包括了今天的主角：一致性哈希负载均衡。一致性哈希负载均衡需要保证的是“相同的请求尽可能落到同一个服务器上”，注意这短短的一句描述，却包含了相当大的信息量。“相同的请求” — 什么是相同的请求？一般在使用一致性哈希负载均衡时，需要指定一个 key 用于 hash 计算，可能是： 请求方 IP 请求服务名称，参数列表构成的串 用户 ID “尽可能” —为什么不是一定？因为服务器可能发生上下线，所以少数服务器的变化不应该影响大多数的请求。这也呼应了算法名称中的“一致性”。 同时，一个优秀的负载均衡算法还有一个隐性要求：流量尽可能均匀分布。 综上所述，我们可以概括出一致性哈希负载均衡算法的设计思路。 尽可能保证每个服务器节点均匀的分摊流量 尽可能保证服务器节点的上下线不影响流量的变更 哈希算法介绍哈希算法是一致性哈希算法中重要的一个组成部分，你可以借助 Java 中的 int hashCode() 去理解它。 说到哈希算法，你想到了什么？Jdk 中的 hashCode、SHA-1、MD5，除了这些耳熟能详的哈希算法，还存在很多其他实现，详见 HASH 算法一览。可以将他们分成三代： 第一代：SHA-1（1993），MD5（1992），CRC（1975），Lookup3（2006） 第二代：MurmurHash（2008） 第三代：CityHash， SpookyHash（2011） 这些都可以认为是广义上的哈希算法，你可以在 wiki 百科 中查看所有的哈希算法。当然还有一些哈希算法如：Ketama，专门为一致性哈希算法而设计。 既然有这么多哈希算法，那必然会有人问：当我们在讨论哈希算法时，我们再考虑哪些东西？我大概总结下有以下四点： 实现复杂程度 分布均匀程度 哈希碰撞概率 性能 先聊聊性能，是不是性能越高就越好呢？你如果有看过我曾经的文章 《该如何设计你的 PasswordEncoder?》 ，应该能了解到，在设计加密器这个场景下，慢 hash 算法反而有优势；而在负载均衡这个场景下，安全性不是需要考虑的因素，所以性能自然是越高越好。 优秀的算法通常比较复杂，但不足以构成评价标准，有点黑猫白猫论，所以 2，3 两点：分布均匀程度，哈希碰撞概率成了主要考虑的因素。 我挑选了几个值得介绍的哈希算法，重点介绍下。 MurmurHash 算法：高运算性能，低碰撞率，由 Austin Appleby 创建于 2008 年，现已应用到 Hadoop、libstdc++、nginx、libmemcached 等开源系统。2011 年 Appleby 被 Google 雇佣，随后 Google 推出其变种的 CityHash 算法。官方只提供了 C 语言的实现版本。 Java 界中 Redis，Memcached，Cassandra，HBase，Lucene 都在使用它。 在 Java 的实现，Guava 的 Hashing 类里有，上面提到的 Jedis，Cassandra 里都有相关的 Util 类。 FNV 算法：全名为 Fowler-Noll-Vo 算法，是以三位发明人 Glenn Fowler，Landon Curt Noll，Phong Vo 的名字来命名的，最早在 1991 年提出。 特点和用途：FNV 能快速 hash 大量数据并保持较小的冲突率，它的高度分散使它适用于 hash 一些非常相近的字符串，比如 URL，hostname，文件名，text，IP 地址等。 Ketama 算法：将它称之为哈希算法其实不太准确，称之为一致性哈希算法可能更为合适，其他的哈希算法有通用的一致性哈希算法实现，只不过是替换了哈希方式而已，但 Ketama 是一整套的流程，我们将在后面介绍。 以上三者都是最合适的一致性哈希算法的强力争夺者。 一致性哈希算法实现 一致性哈希的概念我不做赘述，简单介绍下这个负载均衡中的一致性哈希环。首先将服务器（ip+ 端口号）进行哈希，映射成环上的一个节点，在请求到来时，根据指定的 hash key 同样映射到环上，并顺时针选取最近的一个服务器节点进行请求（在本图中，使用的是 userId 作为 hash key）。 当环上的服务器较少时，即使哈希算法选择得当，依旧会遇到大量请求落到同一个节点的问题，为避免这样的问题，大多数一致性哈希算法的实现度引入了虚拟节点的概念。 在上图中，只有两台物理服务器节点：11.1.121.1 和 11.1.121.2，我们通过添加后缀的方式，克隆出了另外三份节点，使得环上的节点分布的均匀。一般来说，物理节点越多，所需的虚拟节点就越少。 介绍完了一致性哈希换，我们便可以对负载均衡进行建模了： 123public interface LoadBalancer &#123; Server select(List&lt;Server&gt; servers, Invocation invocation);&#125; 下面直接给出通用的算法实现： 12345678910111213141516171819202122232425262728293031323334353637public class ConsistentHashLoadBalancer implements LoadBalancer&#123; private HashStrategy hashStrategy = new JdkHashCodeStrategy(); private final static int VIRTUAL_NODE_SIZE = 10; private final static String VIRTUAL_NODE_SUFFIX = \"&amp;&amp;\"; @Override public Server select(List&lt;Server&gt; servers, Invocation invocation) &#123; int invocationHashCode = hashStrategy.getHashCode(invocation.getHashKey()); TreeMap&lt;Integer, Server&gt; ring = buildConsistentHashRing(servers); Server server = locate(ring, invocationHashCode); return server; &#125; private Server locate(TreeMap&lt;Integer, Server&gt; ring, int invocationHashCode) &#123; // 向右找到第一个 key Map.Entry&lt;Integer, Server&gt; locateEntry = ring.ceilingEntry(invocationHashCode); if (locateEntry == null) &#123; // 想象成一个环，超过尾部则取第一个 key locateEntry = ring.firstEntry(); &#125; return locateEntry.getValue(); &#125; private TreeMap&lt;Integer, Server&gt; buildConsistentHashRing(List&lt;Server&gt; servers) &#123; TreeMap&lt;Integer, Server&gt; virtualNodeRing = new TreeMap&lt;&gt;(); for (Server server : servers) &#123; for (int i = 0; i &lt; VIRTUAL_NODE_SIZE; i++) &#123; // 新增虚拟节点的方式如果有影响，也可以抽象出一个由物理节点扩展虚拟节点的类 virtualNodeRing.put(hashStrategy.getHashCode(server.getUrl() + VIRTUAL_NODE_SUFFIX + i), server); &#125; &#125; return virtualNodeRing; &#125;&#125; 对上述的程序做简单的解读： Server 是对服务器的抽象，一般是 ip+port 的形式。 123public class Server &#123; private String url;&#125; Invocation 是对请求的抽象，包含一个用于 hash 的 key。 123public class Invocation &#123; private String hashKey;&#125; 使用 TreeMap 作为一致性哈希环的数据结构，ring.ceilingEntry 可以获取环上最近的一个节点。在 buildConsistentHashRing 之中包含了构建一致性哈希环的过程，默认加入了 10 个虚拟节点。 计算方差，标准差的公式： 123456789101112131415161718192021222324252627282930313233public class StatisticsUtil &#123; // 方差 s^2=[(x1-x)^2 +...(xn-x)^2]/n public static double variance(Long[] x) &#123; int m = x.length; double sum = 0; for (int i = 0; i &lt; m; i++) &#123;// 求和 sum += x[i]; &#125; double dAve = sum / m;// 求平均值 double dVar = 0; for (int i = 0; i &lt; m; i++) &#123;// 求方差 dVar += (x[i] - dAve)* (x[i] - dAve); &#125; return dVar / m; &#125; // 标准差σ=sqrt(s^2) public static double standardDeviation(Long[] x) &#123; int m = x.length; double sum = 0; for (int i = 0; i &lt; m; i++) &#123;// 求和 sum += x[i]; &#125; double dAve = sum / m;// 求平均值 double dVar = 0; for (int i = 0; i &lt; m; i++) &#123;// 求方差 dVar += (x[i] - dAve)* (x[i] - dAve); &#125; return Math.sqrt(dVar / m); &#125;&#125; 其中，HashStrategy 是下文中重点讨论的一个内容，他是对 hash 算法的抽象，我们将会着重对比各种 hash 算法给测评结果带来的差异性。 123public interface HashStrategy &#123; int getHashCode(String origin);&#125; 测评程序前面我们已经明确了一个优秀的一致性哈希算法的设计思路。这一节我们给出实际的量化指标：假设 m 次请求打到 n 个候选服务器上 统计每个服务节点收到的流量，计算方差、标准差。测量流量分布均匀情况，我们可以模拟 10000 个随机请求，打到 100 个指定服务器，测试最后个节点的方差，标准差。 记录 m 次请求落到的服务器节点，下线 20% 的服务器，重放流量，统计 m 次请求中落到跟原先相同服务器的概率。测量节点上下线的情况，我们可以模拟 10000 个随机请求，打到 100 个指定服务器，之后下线 20 个服务器并重放流量，统计请求到相同服务器的比例。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class LoadBalanceTest &#123; static String[] ips = &#123;...&#125;; // 100 台随机 ip /** * 测试分布的离散情况 */ @Test public void testDistribution() &#123; List&lt;Server&gt; servers = new ArrayList&lt;&gt;(); for (String ip : ips) &#123; servers.add(new Server(ip+\":8080\")); &#125; LoadBalancer chloadBalance = new ConsistentHashLoadBalancer(); // 构造 10000 随机请求 List&lt;Invocation&gt; invocations = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10000; i++) &#123; invocations.add(new Invocation(UUID.randomUUID().toString())); &#125; // 统计分布 AtomicLongMap&lt;Server&gt; atomicLongMap = AtomicLongMap.create(); for (Server server : servers) &#123; atomicLongMap.put(server, 0); &#125; for (Invocation invocation : invocations) &#123; Server selectedServer = chloadBalance.select(servers, invocation); atomicLongMap.getAndIncrement(selectedServer); &#125; System.out.println(StatisticsUtil.variance(atomicLongMap.asMap().values().toArray(new Long[]&#123;&#125;))); System.out.println(StatisticsUtil.standardDeviation(atomicLongMap.asMap().values().toArray(new Long[]&#123;&#125;))); &#125; /** * 测试节点新增删除后的变化程度 */ @Test public void testNodeAddAndRemove() &#123; List&lt;Server&gt; servers = new ArrayList&lt;&gt;(); for (String ip : ips) &#123; servers.add(new Server(ip)); &#125; List&lt;Server&gt; serverChanged = servers.subList(0, 80); ConsistentHashLoadBalancer chloadBalance = new ConsistentHashLoadBalancer(); // 构造 10000 随机请求 List&lt;Invocation&gt; invocations = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10000; i++) &#123; invocations.add(new Invocation(UUID.randomUUID().toString())); &#125; int count = 0; for (Invocation invocation : invocations) &#123; Server origin = chloadBalance.select(servers, invocation); Server changed = chloadBalance.select(serverChanged, invocation); if (origin.getUrl().equals(changed.getUrl())) count++; &#125; System.out.println(count / 10000D); &#125; 不同哈希算法的实现及测评最简单、经典的 hashCode 实现： 123456public class JdkHashCodeStrategy implements HashStrategy &#123; @Override public int getHashCode(String origin) &#123; return origin.hashCode(); &#125;&#125; FNV1_32_HASH 算法实现： 1234567891011121314151617181920public class FnvHashStrategy implements HashStrategy &#123; private static final long FNV_32_INIT = 2166136261L; private static final int FNV_32_PRIME = 16777619; @Override public int getHashCode(String origin) &#123; final int p = FNV_32_PRIME; int hash = (int) FNV_32_INIT; for (int i = 0; i &lt; origin.length(); i++) hash = (hash ^ origin.charAt(i)) * p; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; hash = Math.abs(hash); return hash; &#125;&#125; CRC 算法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class CRCHashStrategy implements HashStrategy &#123; private static final int LOOKUP_TABLE[] = &#123;0x0000, 0x1021, 0x2042, 0x3063, 0x4084, 0x50A5, 0x60C6, 0x70E7, 0x8108, 0x9129, 0xA14A, 0xB16B, 0xC18C, 0xD1AD, 0xE1CE, 0xF1EF, 0x1231, 0x0210, 0x3273, 0x2252, 0x52B5, 0x4294, 0x72F7, 0x62D6, 0x9339, 0x8318, 0xB37B, 0xA35A, 0xD3BD, 0xC39C, 0xF3FF, 0xE3DE, 0x2462, 0x3443, 0x0420, 0x1401, 0x64E6, 0x74C7, 0x44A4, 0x5485, 0xA56A, 0xB54B, 0x8528, 0x9509, 0xE5EE, 0xF5CF, 0xC5AC, 0xD58D, 0x3653, 0x2672, 0x1611, 0x0630, 0x76D7, 0x66F6, 0x5695, 0x46B4, 0xB75B, 0xA77A, 0x9719, 0x8738, 0xF7DF, 0xE7FE, 0xD79D, 0xC7BC, 0x48C4, 0x58E5, 0x6886, 0x78A7, 0x0840, 0x1861, 0x2802, 0x3823, 0xC9CC, 0xD9ED, 0xE98E, 0xF9AF, 0x8948, 0x9969, 0xA90A, 0xB92B, 0x5AF5, 0x4AD4, 0x7AB7, 0x6A96, 0x1A71, 0x0A50, 0x3A33, 0x2A12, 0xDBFD, 0xCBDC, 0xFBBF, 0xEB9E, 0x9B79, 0x8B58, 0xBB3B, 0xAB1A, 0x6CA6, 0x7C87, 0x4CE4, 0x5CC5, 0x2C22, 0x3C03, 0x0C60, 0x1C41, 0xEDAE, 0xFD8F, 0xCDEC, 0xDDCD, 0xAD2A, 0xBD0B, 0x8D68, 0x9D49, 0x7E97, 0x6EB6, 0x5ED5, 0x4EF4, 0x3E13, 0x2E32, 0x1E51, 0x0E70, 0xFF9F, 0xEFBE, 0xDFDD, 0xCFFC, 0xBF1B, 0xAF3A, 0x9F59, 0x8F78, 0x9188, 0x81A9, 0xB1CA, 0xA1EB, 0xD10C, 0xC12D, 0xF14E, 0xE16F, 0x1080, 0x00A1, 0x30C2, 0x20E3, 0x5004, 0x4025, 0x7046, 0x6067, 0x83B9, 0x9398, 0xA3FB, 0xB3DA, 0xC33D, 0xD31C, 0xE37F, 0xF35E, 0x02B1, 0x1290, 0x22F3, 0x32D2, 0x4235, 0x5214, 0x6277, 0x7256, 0xB5EA, 0xA5CB, 0x95A8, 0x8589, 0xF56E, 0xE54F, 0xD52C, 0xC50D, 0x34E2, 0x24C3, 0x14A0, 0x0481, 0x7466, 0x6447, 0x5424, 0x4405, 0xA7DB, 0xB7FA, 0x8799, 0x97B8, 0xE75F, 0xF77E, 0xC71D, 0xD73C, 0x26D3, 0x36F2, 0x0691, 0x16B0, 0x6657, 0x7676, 0x4615, 0x5634, 0xD94C, 0xC96D, 0xF90E, 0xE92F, 0x99C8, 0x89E9, 0xB98A, 0xA9AB, 0x5844, 0x4865, 0x7806, 0x6827, 0x18C0, 0x08E1, 0x3882, 0x28A3, 0xCB7D, 0xDB5C, 0xEB3F, 0xFB1E, 0x8BF9, 0x9BD8, 0xABBB, 0xBB9A, 0x4A75, 0x5A54, 0x6A37, 0x7A16, 0x0AF1, 0x1AD0, 0x2AB3, 0x3A92, 0xFD2E, 0xED0F, 0xDD6C, 0xCD4D, 0xBDAA, 0xAD8B, 0x9DE8, 0x8DC9, 0x7C26, 0x6C07, 0x5C64, 0x4C45, 0x3CA2, 0x2C83, 0x1CE0, 0x0CC1, 0xEF1F, 0xFF3E, 0xCF5D, 0xDF7C, 0xAF9B, 0xBFBA, 0x8FD9, 0x9FF8, 0x6E17, 0x7E36, 0x4E55, 0x5E74, 0x2E93, 0x3EB2, 0x0ED1, 0x1EF0,&#125;; /** * Create a CRC16 checksum from the bytes. implementation is from * mp911de/lettuce, modified with some more optimizations * * @param bytes * @return CRC16 as integer value */ public static int getCRC16(byte[] bytes) &#123; int crc = 0x0000; for (byte b : bytes) &#123; crc = ((crc &lt;&lt; 8) ^ LOOKUP_TABLE[((crc &gt;&gt;&gt; 8) ^ (b &amp; 0xFF)) &amp; 0xFF]); &#125; return crc &amp; 0xFFFF; &#125; public static int getCRC16(String key) &#123; return getCRC16(key.getBytes(Charset.forName(\"UTF-8\"))); &#125; @Override public int getHashCode(String origin) &#123; // optimization with modulo operator with power of 2 // equivalent to getCRC16(key) % 16384 return getCRC16(origin) &amp; (16384 - 1); &#125;&#125; Ketama 算法： 123456789101112131415161718192021222324252627282930313233343536public class KetamaHashStrategy implements HashStrategy &#123; private static MessageDigest md5Digest; static &#123; try &#123; md5Digest = MessageDigest.getInstance(\"MD5\"); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException(\"MD5 not supported\", e); &#125; &#125; @Override public int getHashCode(String origin) &#123; byte[] bKey = computeMd5(origin); long rv = ((long) (bKey[3] &amp; 0xFF)&lt;&lt; 24) | ((long) (bKey[2] &amp; 0xFF)&lt;&lt; 16) | ((long) (bKey[1] &amp; 0xFF)&lt;&lt; 8) | (bKey[0] &amp; 0xFF); return (int) (rv &amp; 0xffffffffL); &#125; /** * Get the md5 of the given key. */ public static byte[] computeMd5(String k) &#123; MessageDigest md5; try &#123; md5 = (MessageDigest) md5Digest.clone(); &#125; catch (CloneNotSupportedException e) &#123; throw new RuntimeException(\"clone of MD5 not supported\", e); &#125; md5.update(k.getBytes()); return md5.digest(); &#125;&#125; MurmurHash 算法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class MurmurHashStrategy implements HashStrategy &#123; @Override public int getHashCode(String origin) &#123; ByteBuffer buf = ByteBuffer.wrap(origin.getBytes()); int seed = 0x1234ABCD; ByteOrder byteOrder = buf.order(); buf.order(ByteOrder.LITTLE_ENDIAN); long m = 0xc6a4a7935bd1e995L; int r = 47; long h = seed ^ (buf.remaining() * m); long k; while (buf.remaining() &gt;= 8) &#123; k = buf.getLong(); k *= m; k ^= k &gt;&gt;&gt; r; k *= m; h ^= k; h *= m; &#125; if (buf.remaining() &gt; 0) &#123; ByteBuffer finish = ByteBuffer.allocate(8).order( ByteOrder.LITTLE_ENDIAN); // for big-endian version, do this first: // finish.position(8-buf.remaining()); finish.put(buf).rewind(); h ^= finish.getLong(); h *= m; &#125; h ^= h &gt;&gt;&gt; r; h *= m; h ^= h &gt;&gt;&gt; r; buf.order(byteOrder); return (int) (h &amp; 0xffffffffL); &#125;&#125; 测评结果： 方差 标准差 不变流量比例 JdkHashCodeStrategy 29574.08 171.97 0.6784 CRCHashStrategy 3013.02 54.89 0.7604 FnvHashStrategy 961.64 31.01 0.7892 KetamaHashStrategy 1254.64 35.42 0.7986 MurmurHashStrategy 815.72 28.56 0.7971 其中方差和标准差反映了均匀情况，越低越好，可以发现 MurmurHashStrategy，KetamaHashStrategy，FnvHashStrategy 都表现的不错。 不变流量比例体现了服务器上下线对原有请求的影响程度，不变流量比例越高越高，可以发现 KetamaHashStrategy 和 MurmurHashStrategy 表现最为优秀。 我并没有对小集群，小流量进行测试，样本偏差性较大，仅从这个常见场景来看，MurmurHashStrategy 是一个不错的选择，多次测试后发现 FnvHashStrategy，KetamaHashStrategy，MurmurHashStrategy 差距不是很大。 至于性能测试，MurmurHash 也十分的高性能，我并没有做测试（感兴趣的同学可以对几种 strategy 用 JMH 测评一下）, 这里我贴一下 MurmurHash 官方的测评数据： OneAtATime - 354.163715 mb/sec FNV - 443.668038 mb/sec SuperFastHash - 985.335173 mb/sec lookup3 - 988.080652 mb/sec MurmurHash 1.0 - 1363.293480 mb/sec MurmurHash 2.0 - 2056.885653 mb/sec 扩大虚拟节点可以明显降低方差和标准差，但虚拟节点的增加会加大内存占用量以及计算量 Ketama 一致性哈希算法实现Ketama 算法有其专门的配套实现方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class KetamaConsistentHashLoadBalancer implements LoadBalancer &#123; private static MessageDigest md5Digest; static &#123; try &#123; md5Digest = MessageDigest.getInstance(\"MD5\"); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException(\"MD5 not supported\", e); &#125; &#125; private final static int VIRTUAL_NODE_SIZE = 12; private final static String VIRTUAL_NODE_SUFFIX = \"-\"; @Override public Server select(List&lt;Server&gt; servers, Invocation invocation) &#123; long invocationHashCode = getHashCode(invocation.getHashKey()); TreeMap&lt;Long, Server&gt; ring = buildConsistentHashRing(servers); Server server = locate(ring, invocationHashCode); return server; &#125; private Server locate(TreeMap&lt;Long, Server&gt; ring, Long invocationHashCode) &#123; // 向右找到第一个 key Map.Entry&lt;Long, Server&gt; locateEntry = ring.ceilingEntry(invocationHashCode); if (locateEntry == null) &#123; // 想象成一个环，超过尾部则取第一个 key locateEntry = ring.firstEntry(); &#125; return locateEntry.getValue(); &#125; private TreeMap&lt;Long, Server&gt; buildConsistentHashRing(List&lt;Server&gt; servers) &#123; TreeMap&lt;Long, Server&gt; virtualNodeRing = new TreeMap&lt;&gt;(); for (Server server : servers) &#123; for (int i = 0; i &lt; VIRTUAL_NODE_SIZE / 4; i++) &#123; byte[] digest = computeMd5(server.getUrl() + VIRTUAL_NODE_SUFFIX + i); for (int h = 0; h &lt; 4; h++) &#123; Long k = ((long) (digest[3 + h * 4] &amp; 0xFF)&lt;&lt; 24) | ((long) (digest[2 + h * 4] &amp; 0xFF)&lt;&lt; 16) | ((long) (digest[1 + h * 4] &amp; 0xFF)&lt;&lt; 8) | (digest[h * 4] &amp; 0xFF); virtualNodeRing.put(k, server); &#125; &#125; &#125; return virtualNodeRing; &#125; private long getHashCode(String origin) &#123; byte[] bKey = computeMd5(origin); long rv = ((long) (bKey[3] &amp; 0xFF)&lt;&lt; 24) | ((long) (bKey[2] &amp; 0xFF)&lt;&lt; 16) | ((long) (bKey[1] &amp; 0xFF)&lt;&lt; 8) | (bKey[0] &amp; 0xFF); return rv; &#125; private static byte[] computeMd5(String k) &#123; MessageDigest md5; try &#123; md5 = (MessageDigest) md5Digest.clone(); &#125; catch (CloneNotSupportedException e) &#123; throw new RuntimeException(\"clone of MD5 not supported\", e); &#125; md5.update(k.getBytes()); return md5.digest(); &#125;&#125; 稍微不同的地方便在于：Ketama 将四个节点标为一组进行了虚拟节点的设置。 方差 标准差 不变流量比例 KetamaConsistentHashLoadBalancer 911.08 30.18 0.7936 实际结果并没有太大的提升，可能和测试数据的样本规模有关。 总结优秀的哈希算法和一致性哈希算法可以帮助我们在大多数场景下应用的高性能，高稳定性，但在实际使用一致性哈希负载均衡的场景中，最好针对实际的集群规模和请求哈希方式进行压测，力保流量均匀打到所有的机器上，这才是王道。 不仅仅是分布式缓存，负载均衡等等有限的场景，一致性哈希算法、哈希算法，尤其是后者，是一个用处很广泛的常见算法，了解它的经典实现是很有必要的，例如 MurmurHash，在 guava 中就有其 Java 实现，当需要高性能，分布均匀，碰撞概率小的哈希算法时，可以考虑使用它。 本文代码的 github 地址：https://github.com/lexburner/consistent-hash-algorithm 扩展阅读深入理解 RPC 之集群篇 《该如何设计你的 PasswordEncoder?》 参考文章MurmurHash memcached Java 客户端 spymemcached 的一致性 Hash 算法","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"定时器的几种实现方式","slug":"timer","date":"2019-01-24T10:47:55.000Z","updated":"2019-09-26T09:45:31.563Z","comments":true,"path":"timer/","link":"","permalink":"http://lexburner.github.io/timer/","excerpt":"1 前言在开始正题之前，先闲聊几句。有人说，计算机科学这个学科，软件方向研究到头就是数学，硬件方向研究到头就是物理，最轻松的是中间这批使用者，可以不太懂物理，不太懂数学，依旧可以使用计算机作为自己谋生的工具。这个规律具有普适应，看看“定时器”这个例子，往应用层研究，有 Quartz，Spring Schedule 等框架；往分布式研究，又有 SchedulerX，ElasticJob 等分布式任务调度；往底层实现看，又有多种定时器实现方案的原理、工作效率、数据结构可以深究…简单上手使用一个框架，并不能体现出个人的水平，如何与他人构成区分度？我觉得至少要在某一个方向有所建树： 深入研究某个现有框架的实现原理，例如：读源码 将一个传统技术在分布式领域很好地延伸，很多成熟的传统技术可能在单机 work well，但分布式场景需要很多额外的考虑。 站在设计者的角度，如果从零开始设计一个轮子，怎么利用合适的算法、数据结构，去实现它。 回到这篇文章的主题，我首先会围绕第三个话题讨论：设计实现一个定时器，可以使用什么算法，采用什么数据结构。接着再聊聊第一个话题：探讨一些优秀的定时器实现方案。","text":"1 前言在开始正题之前，先闲聊几句。有人说，计算机科学这个学科，软件方向研究到头就是数学，硬件方向研究到头就是物理，最轻松的是中间这批使用者，可以不太懂物理，不太懂数学，依旧可以使用计算机作为自己谋生的工具。这个规律具有普适应，看看“定时器”这个例子，往应用层研究，有 Quartz，Spring Schedule 等框架；往分布式研究，又有 SchedulerX，ElasticJob 等分布式任务调度；往底层实现看，又有多种定时器实现方案的原理、工作效率、数据结构可以深究…简单上手使用一个框架，并不能体现出个人的水平，如何与他人构成区分度？我觉得至少要在某一个方向有所建树： 深入研究某个现有框架的实现原理，例如：读源码 将一个传统技术在分布式领域很好地延伸，很多成熟的传统技术可能在单机 work well，但分布式场景需要很多额外的考虑。 站在设计者的角度，如果从零开始设计一个轮子，怎么利用合适的算法、数据结构，去实现它。 回到这篇文章的主题，我首先会围绕第三个话题讨论：设计实现一个定时器，可以使用什么算法，采用什么数据结构。接着再聊聊第一个话题：探讨一些优秀的定时器实现方案。 2 理解定时器很多场景会用到定时器，例如 使用 TCP 长连接时，客户端需要定时向服务端发送心跳请求。 财务系统每个月的月末定时生成对账单。 双 11 的 0 点，定时开启秒杀开关。 定时器像水和空气一般，普遍存在于各个场景中，一般定时任务的形式表现为：经过固定时间后触发、按照固定频率周期性触发、在某个时刻触发。定时器是什么？可以理解为这样一个数据结构： 存储一系列的任务集合，并且 Deadline 越接近的任务，拥有越高的执行优先级在用户视角支持以下几种操作：NewTask：将新任务加入任务集合Cancel：取消某个任务在任务调度的视角还要支持：Run：执行一个到期的定时任务 判断一个任务是否到期，基本会采用轮询的方式， 每隔一个时间片 去检查 最近的任务 是否到期，并且，在 NewTask 和 Cancel 的行为发生之后，任务调度策略也会出现调整。 说到底，定时器还是靠线程轮询实现的。 3 数据结构我们主要衡量 NewTask（新增任务），Cancel（取消任务），Run（执行到期的定时任务）这三个指标，分析他们使用不同数据结构的时间 / 空间复杂度。 3.1 双向有序链表在 Java 中，LinkedList 是一个天然的双向链表 NewTask：O(N)Cancel：O(1)Run：O(1)N：任务数 NewTask O(N) 很容易理解，按照 expireTime 查找合适的位置即可；Cancel O(1) ，任务在 Cancel 时，会持有自己节点的引用，所以不需要查找其在链表中所在的位置，即可实现当前节点的删除，这也是为什么我们使用双向链表而不是普通链表的原因是 ；Run O(1)，由于整个双向链表是基于 expireTime 有序的，所以调度器只需要轮询第一个任务即可。 3.2 堆在 Java 中，PriorityQueue 是一个天然的堆，可以利用传入的 Comparator 来决定其中元素的优先级。 NewTask：O(logN)Cancel：O(logN)Run：O(1)N：任务数 expireTime 是 Comparator 的对比参数。NewTask O(logN) 和 Cancel O(logN) 分别对应堆插入和删除元素的时间复杂度 ；Run O(1)，由 expireTime 形成的小根堆，我们总能在堆顶找到最快的即将过期的任务。 堆与双向有序链表相比，NewTask 和 Cancel 形成了 trade off，但考虑到现实中，定时任务取消的场景并不是很多，所以堆实现的定时器要比双向有序链表优秀。 3.3 时间轮Netty 针对 I/O 超时调度的场景进行了优化，实现了 HashedWheelTimer 时间轮算法。 HashedWheelTimer 是一个环形结构，可以用时钟来类比，钟面上有很多 bucket ，每一个 bucket 上可以存放多个任务，使用一个 List 保存该时刻到期的所有任务，同时一个指针随着时间流逝一格一格转动，并执行对应 bucket 上所有到期的任务。任务通过 取模 决定应该放入哪个 bucket 。和 HashMap 的原理类似，newTask 对应 put，使用 List 来解决 Hash 冲突。 以上图为例，假设一个 bucket 是 1 秒，则指针转动一轮表示的时间段为 8s，假设当前指针指向 0，此时需要调度一个 3s 后执行的任务，显然应该加入到 (0+3=3) 的方格中，指针再走 3 次就可以执行了；如果任务要在 10s 后执行，应该等指针走完一轮零 2 格再执行，因此应放入 2，同时将 round（1）保存到任务中。检查到期任务时只执行 round 为 0 的， bucket 上其他任务的 round 减 1。 再看图中的 bucket5，我们可以知道在 $18+5=13s$ 后，有两个任务需要执行，在 $28+5=21s$ 后有一个任务需要执行。 NewTask：O(1)Cancel：O(1)Run：O(M)Tick：O(1)M： bucket ，M ~ N/C ，其中 C 为单轮 bucket 数，Netty 中默认为 512 时间轮算法的复杂度可能表达有误，比较难算，仅供参考。另外，其复杂度还受到多个任务分配到同一个 bucket 的影响。并且多了一个转动指针的开销。 传统定时器是面向任务的，时间轮定时器是面向 bucket 的。 构造 Netty 的 HashedWheelTimer 时有两个重要的参数：tickDuration 和 ticksPerWheel。 tickDuration：即一个 bucket 代表的时间，默认为 100ms，Netty 认为大多数场景下不需要修改这个参数； ticksPerWheel：一轮含有多少个 bucket ，默认为 512 个，如果任务较多可以增大这个参数，降低任务分配到同一个 bucket 的概率。 3.4 层级时间轮Kafka 针对时间轮算法进行了优化，实现了层级时间轮 TimingWheel 如果任务的时间跨度很大，数量也多，传统的 HashedWheelTimer 会造成任务的 round 很大，单个 bucket 的任务 List 很长，并会维持很长一段时间。这时可将轮盘按时间粒度分级： 现在，每个任务除了要维护在当前轮盘的 round，还要计算在所有下级轮盘的 round。当本层的 round 为 0 时，任务按下级 round 值被下放到下级轮子，最终在最底层的轮盘得到执行。 NewTask：O(H)Cancel：O(H)Run：O(M)Tick：O(1)H：层级数量 设想一下一个定时了 3 天，10 小时，50 分，30 秒的定时任务，在 tickDuration = 1s 的单层时间轮中，需要经过：$3246060+106060+5060+30$ 次指针的拨动才能被执行。但在 wheel1 tickDuration = 1 天，wheel2 tickDuration = 1 小时，wheel3 tickDuration = 1 分，wheel4 tickDuration = 1 秒 的四层时间轮中，只需要经过 $3+10+50+30$ 次指针的拨动！ 相比单层时间轮，层级时间轮在时间跨度较大时存在明显的优势。 4 常见实现4.1 TimerJDK 中的 Timer 是非常早期的实现，在现在看来，它并不是一个好的设计。 12345678// 运行一个一秒后执行的定时任务Timer timer = new Timer();timer.schedule(new TimerTask() &#123; @Override public void run() &#123; // do sth &#125;&#125;, 1000); 使用 Timer 实现任务调度的核心是 Timer 和 TimerTask。其中 Timer 负责设定 TimerTask 的起始与间隔执行时间。使用者只需要创建一个 TimerTask 的继承类，实现自己的 run 方法，然后将其丢给 Timer 去执行即可。 1234public class Timer &#123; private final TaskQueue queue = new TaskQueue(); private final TimerThread thread = new TimerThread(queue);&#125; 其中 TaskQueue 是使用数组实现的一个简易的堆。另外一个值得注意的属性是 TimerThread，Timer 使用唯一的线程负责轮询并执行任务。Timer 的优点在于简单易用，但也因为所有任务都是由同一个线程来调度，因此整个过程是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务。 轮询时如果发现 currentTime &lt; heapFirst.executionTime，可以 wait(executionTime - currentTime) 来减少不必要的轮询时间。这是普遍被使用的一个优化。 Timer 只能被单线程调度 TimerTask 中出现的异常会影响到 Timer 的执行。 由于这两个缺陷，JDK 1.5 支持了新的定时器方案 ScheduledExecutorService。 4.2 ScheduledExecutorService12345678// 运行一个一秒后执行的定时任务ScheduledExecutorService service = Executors.newScheduledThreadPool(10);service.scheduleA(new Runnable() &#123; @Override public void run() &#123; //do sth &#125;&#125;, 1, TimeUnit.SECONDS); 相比 Timer，ScheduledExecutorService 解决了同一个定时器调度多个任务的阻塞问题，并且任务异常不会中断 ScheduledExecutorService。 ScheduledExecutorService 提供了两种常用的周期调度方法 ScheduleAtFixedRate 和 ScheduleWithFixedDelay。 ScheduleAtFixedRate 每次执行时间为上一次任务开始起向后推一个时间间隔，即每次执行时间为 : $initialDelay$, $initialDelay+period$, $initialDelay+2*period$, … ScheduleWithFixedDelay 每次执行时间为上一次任务结束起向后推一个时间间隔，即每次执行时间为：$initialDelay$, $initialDelay+executeTime+delay$, $initialDelay+2executeTime+2delay$, … 由此可见，ScheduleAtFixedRate 是基于固定时间间隔进行任务调度，ScheduleWithFixedDelay 取决于每次任务执行的时间长短，是基于不固定时间间隔的任务调度。 ScheduledExecutorService 底层使用的数据结构为 PriorityQueue，任务调度方式较为常规，不做特别介绍。 4.3 HashedWheelTimer12345678Timer timer = new HashedWheelTimer();// 等价于 Timer timer = new HashedWheelTimer(100, TimeUnit.MILLISECONDS, 512);timer.newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; //do sth &#125;&#125;, 1, TimeUnit.SECONDS); 前面已经介绍过了 Netty 中 HashedWheelTimer 内部的数据结构，默认构造器会配置轮询周期为 100ms，bucket 数量为 512。其使用方法和 JDK 的 Timer 十分相似。 12private final Worker worker = new Worker();// Runnableprivate final Thread workerThread;// Thread 由于篇幅限制，我并不打算做详细的源码分析，但上述两行来自 HashedWheelTimer 的代码阐释了一个事实：HashedWheelTimer 内部也同样是使用单个线程进行任务调度。与 JDK 的 Timer 一样，存在”前一个任务执行时间过长，影响后续定时任务执行“的问题。 理解 HashedWheelTimer 中的 ticksPerWheel，tickDuration，对二者进行合理的配置，可以使得用户在合适的场景得到最佳的性能。 5 最佳实践5.1 选择合适的定时器毋庸置疑，JDK 的 Timer 使用的场景是最窄的，完全可以被后两者取代。如何在 ScheduledExecutorService 和 HashedWheelTimer 之间如何做选择，需要区分场景，做一个简单的对比： ScheduledExecutorService 是面向任务的，当任务数非常大时，使用堆 (PriorityQueue) 维护任务的新增、删除会导致性能下降，而 HashedWheelTimer 面向 bucket，设置合理的 ticksPerWheel，tickDuration ，可以不受任务量的限制。所以在任务非常多时，HashedWheelTimer 可以表现出它的优势。 相反，如果任务量少，HashedWheelTimer 内部的 Worker 线程依旧会不停的拨动指针，虽然不是特别消耗性能，但至少不能说：HashedWheelTimer 一定比 ScheduledExecutorService 优秀。 HashedWheelTimer 由于开辟了一个 bucket 数组，占用的内存会稍大。 上述的对比，让我们得到了一个最佳实践：在任务非常多时，使用 HashedWheelTimer 可以获得性能的提升。例如服务治理框架中的心跳定时任务，服务实例非常多时，每一个客户端都需要定时发送心跳，每一个服务端都需要定时检测连接状态，这是一个非常适合使用 HashedWheelTimer 的场景。 5.2 单线程与业务线程池我们需要注意 HashedWheelTimer 使用单线程来调度任务，如果任务比较耗时，应当设置一个业务线程池，将 HashedWheelTimer 当做一个定时触发器，任务的实际执行，交给业务线程池。 如果所有的任务都满足： taskNStartTime - taskN-1StartTime &gt; taskN-1CostTime，即任意两个任务的间隔时间小于先执行任务的执行时间，则无需担心这个问题。 5.3 全局定时器实际使用 HashedWheelTimer 时， 应当将其当做一个全局的任务调度器，例如设计成 static 。时刻谨记一点：HashedWheelTimer 对应一个线程，如果每次实例化 HashedWheelTimer，首先是线程会很多，其次是时间轮算法将会完全失去意义。 5.4 为 HashedWheelTimer 设置合理的参数ticksPerWheel，tickDuration 这两个参数尤为重要，ticksPerWheel 控制了时间轮中 bucket 的数量，决定了冲突发生的概率，tickDuration 决定了指针拨动的频率，一方面会影响定时的精度，一方面决定 CPU 的消耗量。当任务数量非常大时，考虑增大 ticksPerWheel；当时间精度要求不高时，可以适当加大 tickDuration，不过大多数情况下，不需要 care 这个参数。 5.5 什么时候使用层级时间轮当时间跨度很大时，提升单层时间轮的 tickDuration 可以减少空转次数，但会导致时间精度变低，层级时间轮既可以避免精度降低，又避免了指针空转的次数。如果有时间跨度较长的定时任务，则可以交给层级时间轮去调度。此外，也可以按照定时精度实例化多个不同作用的单层时间轮，dayHashedWheelTimer、hourHashedWheelTimer、minHashedWheelTimer，配置不同的 tickDuration，此法虽 low，但不失为一个解决方案。Netty 设计的 HashedWheelTimer 是专门用来优化 I/O 调度的，场景较为局限，所以并没有实现层级时间轮；而在 Kafka 中定时器的适用范围则较广，所以其实现了层级时间轮，以应对更为复杂的场景。 6 参考资料[1] https://www.ibm.com/developerworks/cn/java/j-lo-taskschedule/index.html [2] http://novoland.github.io/ 并发 /2014/07/26/ 定时器（Timer）的实现.html [3] http://www.cs.columbia.edu/~nahum/w6998/papers/sosp87-timing-wheels.pdf 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"提问前，请先让自己成为值得被教的人","slug":"thinging-in-ask","date":"2019-01-21T18:18:51.000Z","updated":"2019-09-26T09:45:29.551Z","comments":true,"path":"thinging-in-ask/","link":"","permalink":"http://lexburner.github.io/thinging-in-ask/","excerpt":"每一个不恰当的提问都在消耗别人对你的耐心，程序员届早已经有了诸如《提问的智慧》之类的经典文章介绍了什么是蠢问题，如何避免问蠢问题。然而，常年混迹于十几个技术交流微信群的我，发现很多小白程序员并不懂得这一点，为改善微信群的技术交流氛围，转此文，意图是让大家在担任提问者的角色时，尽可能提高提问的素质，让自己成为值得被教的人。 原文出处：https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way","text":"每一个不恰当的提问都在消耗别人对你的耐心，程序员届早已经有了诸如《提问的智慧》之类的经典文章介绍了什么是蠢问题，如何避免问蠢问题。然而，常年混迹于十几个技术交流微信群的我，发现很多小白程序员并不懂得这一点，为改善微信群的技术交流氛围，转此文，意图是让大家在担任提问者的角色时，尽可能提高提问的素质，让自己成为值得被教的人。 原文出处：https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way 用清晰、正确、精准并语法正确的语句我们从经验中发现，粗心的提问者通常也会粗心的写程序与思考（我敢打包票）。回答粗心大意者的问题很不值得，我们宁愿把时间耗在别处。 正确的拼字、标点符号和大小写是很重要的。一般来说，如果你觉得这样做很麻烦，不想在乎这些，那我们也觉得麻烦，不想在乎你的提问。花点额外的精力斟酌一下字句，用不着太僵硬与正式。 更白话地说，如果你写得像是个小白，那多半得不到理睬。 如果在使用非母语的论坛提问，你可以犯点拼写和语法上的小错，但决不能在思考上马虎（没错，我们通常能弄清两者的分别）。同时，除非你知道回复者使用的语言，否则请使用英语书写。繁忙的程序员一般会直接删除用他们看不懂语言写的消息。在网络上英语是通用语言，用英语书写可以将你的问题在尚未被阅读就被直接删除的可能性降到最低。 如果英文是你的外语（Second language），提示潜在回复者你有潜在的语言困难是很好的： [译注：以下附上原文以供使用] English is not my native language; please excuse typing errors. 英文不是我的母语，请原谅我的错字或语法 If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question. 如果你说 某语言 ，请寄信 / 私讯给我；我需要有人协助我翻译我的问题 I am familiar with the technical terms, but some slang expressions and idioms are difficult for me. 我对技术名词很熟悉，但对于俗语或是特别用法比较不甚了解。 I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other. 我把我的问题用 某语言 和英文写出来，如果你只用一种语言回答，我会乐意将其翻译成另一种。 精确的描述问题并言之有物 仔细、清楚地描述你的问题或 Bug 的症状。 描述问题发生的环境（机器配置、操作系统、应用程序、以及相关的信息），提供经销商的发行版和版本号（如：Fedora Core 4、Slackware 9.1 等）。 描述在提问前你是怎样去研究和理解这个问题的。 描述在提问前为确定问题而采取的诊断步骤。 描述最近做过什么可能相关的硬件或软件变更。 尽可能的提供一个可以 重现这个问题的可控环境 的方法。 尽量去揣测一个程序员会怎样反问你，在你提问之前预先将程序员们可能遇到的问题回答一遍。 以上几点中，当你报告的是你认为可能在代码中的问题时，给程序员一个可以重现你的问题的环境尤其重要。当你这么做时，你得到有效的回答的机会和速度都会大大的提升。 Simon Tatham 写过一篇名为《如何有效的报告 Bug》的出色文章。强力推荐你也读一读。 话不在多而在精你需要提供精确有内容的信息。这并不是要求你简单的把成堆的出错代码或者资料完全转录到你的提问中。如果你有庞大而复杂的测试样例能重现程序挂掉的情境，尽量将它剪裁得越小越好。 这样做的用处至少有三点。 第一，表现出你为简化问题付出了努力，这可以使你得到回答的机会增加； 第二，简化问题使你更有可能得到 有用 的答案； 第三，在精炼你的 bug 报告的过程中，你很可能就自己找到了解决方法或权宜之计。 别动辄声称找到 Bug当你在使用软件中遇到问题，除非你非常、 非常 的有根据，不要动辄声称找到了 Bug。提示：除非你能提供解决问题的源代码补丁，或者提供回归测试来表明前一版本中行为不正确，否则你都多半不够完全确信。这同样适用在网页和文件，如果你（声称）发现了文件的 Bug，你应该能提供相应位置的修正或替代文件。 请记得，还有许多其它使用者没遇到你发现的问题，否则你在阅读文件或搜索网页时就应该发现了（你在抱怨前 已经做了这些，是吧？）。这也意味着很有可能是你弄错了而不是软件本身有问题。 编写软件的人总是非常辛苦地使它尽可能完美。如果你声称找到了 Bug，也就是在质疑他们的能力，即使你是对的，也有可能会冒犯到其中某部分人。当你在标题中嚷嚷着有 Bug 时，这尤其严重。 提问时，即使你私下非常确信已经发现一个真正的 Bug，最好写得像是 你 做错了什么。如果真的有 Bug，你会在回复中看到这点。这样做的话，如果真有 Bug，维护者就会向你道歉，这总比你惹恼别人然后欠别人一个道歉要好一点。 低声下气不能代替你的功课有些人明白他们不该粗鲁或傲慢的提问并要求得到答复，但他们选择另一个极端 – 低声下气：我知道我只是个可悲的新手，一个撸瑟，但...。这既使人困扰，也没有用，尤其是伴随着与实际问题含糊不清的描述时更令人反感。 别用原始灵长类动物的把戏来浪费你我的时间。取而代之的是，尽可能清楚地描述背景条件和你的问题情况。这比低声下气更好地定位了你的位置。 有时网页论坛会设有专为新手提问的版面，如果你真的认为遇到了初学者的问题，到那去就是了，但一样别那么低声下气。 描述问题症状而非你的猜测告诉程序员们你认为问题是怎样造成的并没什么帮助。（如果你的推断如此有效，还用向别人求助吗？），因此要确信你原原本本告诉了他们问题的症状，而不是你的解释和理论；让程序员们来推测和诊断。如果你认为陈述自己的猜测很重要，清楚地说明这只是你的猜测，并描述为什么它们不起作用。 蠢问题 我在编译内核时接连遇到 SIG11 错误， 我怀疑某条飞线搭在主板的走线上了，这种情况应该怎样检查最好？ 聪明问题 我的组装电脑是 FIC-PA2007 主机板搭载 AMD K6/233 CPU（威盛 Apollo VP2 芯片组）， 256MB Corsair PC133 SDRAM 内存，在编译内核时，从开机 20 分钟以后就频频产生 SIG11 错误， 但是在头 20 分钟内从没发生过相同的问题。重新启动也没有用，但是关机一晚上就又能工作 20 分钟。 所有内存都换过了，没有效果。相关部分的标准编译记录如下…。 由于以上这点似乎让许多人觉得难以配合，这里有句话可以提醒你：所有的诊断专家都来自密苏里州。 美国国务院的官方座右铭则是：让我看看（出自国会议员 Willard D. Vandiver 在 1899 年时的讲话：我来自一个出产玉米，棉花，牛蒡和民主党人的国家，滔滔雄辩既不能说服我，也不会让我满意。我来自密苏里州，你必须让我看看。） 针对诊断者而言，这并不是一种怀疑，而只是一种真实而有用的需求，以便让他们看到的是与你看到的原始证据尽可能一致的东西，而不是你的猜测与归纳的结论。所以，大方的展示给我们看吧！ 按发生时间先后列出问题症状问题发生前的一系列操作，往往就是对找出问题最有帮助的线索。因此，你的说明里应该包含你的操作步骤，以及机器和软件的反应，直到问题发生。在命令行处理的情况下，提供一段操作记录（例如运行脚本工具所生成的），并引用相关的若干行（如 20 行）记录会非常有帮助。 如果挂掉的程序有诊断选项（如 -v 的详述开关），试着选择这些能在记录中增加调试信息的选项。记住，多 不等于 好。试着选取适当的调试级别以便提供有用的信息而不是让读者淹没在垃圾中。 如果你的说明很长（如超过四个段落），在开头简述问题，接下来再按时间顺序详述会有所帮助。这样程序员们在读你的记录时就知道该注意哪些内容了。 描述目标而不是过程如果你想弄清楚如何做某事（而不是报告一个 Bug），在开头就描述你的目标，然后才陈述重现你所卡住的特定步骤。 经常寻求技术帮助的人在心中有个更高层次的目标，而他们在自以为能达到目标的特定道路上被卡住了，然后跑来问该怎么走，但没有意识到这条路本身就有问题。结果要费很大的劲才能搞定。 蠢问题 我怎样才能从某绘图程序的颜色选择器中取得十六进制的的 RGB 值？ 聪明问题 我正试着用替换一幅图片的色码（color table）成自己选定的色码，我现在知道的唯一方法是编辑每个色码区块（table slot）， 但却无法从某绘图程序的颜色选择器取得十六进制的的 RGB 值。 第二种提问法比较聪明，你可能得到像是 建议采用另一个更合适的工具 的回复。 清楚明确的表达你的问题以及需求漫无边际的提问是近乎无休无止的时间黑洞。最有可能给你有用答案的人通常也正是最忙的人（他们忙是因为要亲自完成大部分工作）。这样的人对无节制的时间黑洞相当厌恶，所以他们也倾向于厌恶那些漫无边际的提问。 如果你明确表述需要回答者做什么（如提供指点、发送一段代码、检查你的补丁、或是其他等等），就最有可能得到有用的答案。因为这会定出一个时间和精力的上限，便于回答者能集中精力来帮你。这么做很棒。 要理解专家们所处的世界，请把专业技能想像为充裕的资源，而回复的时间则是稀缺的资源。你要求他们奉献的时间越少，你越有可能从真正专业而且很忙的专家那里得到解答。 所以，界定一下你的问题，使专家花在辨识你的问题和回答所需要付出的时间减到最少，这技巧对你有用答案相当有帮助 – 但这技巧通常和简化问题有所区别。因此，问 我想更好的理解 X，可否指点一下哪有好一点说明？ 通常比问 你能解释一下 X 吗？ 更好。如果你的代码不能运作，通常请别人看看哪里有问题，比要求别人替你改正要明智得多。 询问有关代码的问题时别要求他人帮你调试有问题的代码，不提示一下应该从何入手。张贴几百行的代码，然后说一声：它不能工作 会让你完全被忽略。只贴几十行代码，然后说一句：在第七行以后，我期待它显示 &lt;x&gt;，但实际出现的是 &lt;y&gt; 比较有可能让你得到回应。 最有效描述程序问题的方法是提供最精简的 Bug 展示测试用例（bug-demonstrating test case）。什么是最精简的测试用例？那是问题的缩影；一小个程序片段能 刚好 展示出程序的异常行为，而不包含其他令人分散注意力的内容。怎么制作最精简的测试用例？如果你知道哪一行或哪一段代码会造成异常的行为，复制下来并加入足够重现这个状况的代码（例如，足以让这段代码能被编译 / 直译 / 被应用程序处理）。如果你无法将问题缩减到一个特定区块，就复制一份代码并移除不影响产生问题行为的部分。总之，测试用例越小越好。 一般而言，要得到一段相当精简的测试用例并不太容易，但永远先尝试这样做的是种好习惯。这种方式可以帮助你了解如何自行解决这个问题 —- 而且即使你的尝试不成功，程序员们也会看到你在尝试取得答案的过程中付出了努力，这可以让他们更愿意与你合作。 如果你只是想让别人帮忙审查（Review）一下代码，在信的开头就要说出来，并且一定要提到你认为哪一部分特别需要关注以及为什么。 别把自己家庭作业的问题贴上来程序员们很擅长分辨哪些问题是家庭作业式的问题；因为我们中的大多数都曾自己解决这类问题。同样，这些问题得由 你 来搞定，你会从中学到东西。你可以要求给点提示，但别要求得到完整的解决方案。 如果你怀疑自己碰到了一个家庭作业式的问题，但仍然无法解决，试试在使用者群组，论坛或（最后一招）在项目的 使用者 邮件列表或论坛中提问。尽管程序员们 会 看出来，但一些有经验的使用者也许仍会给你一些提示。 去掉无意义的提问句避免用无意义的话结束提问，例如 有人能帮我吗？ 或者 这有答案吗？。 首先：如果你对问题的描述不是很好，这样问更是画蛇添足。 其次：由于这样问是画蛇添足，程序员们会很厌烦你 – 而且通常会用逻辑上正确，但毫无意义的回答来表示他们的蔑视， 例如：没错，有人能帮你 或者 不，没答案。 一般来说，避免用 是或否、对或错、有或没有 类型的问句，除非你想得到 是或否类型的回答。 礼多人不怪，而且有时还很有帮助彬彬有礼，多用 请 和 谢谢您的关注，或 谢谢你的关照。让大家都知道你对他们花时间免费提供帮助心存感激。 坦白说，这一点并没有比清晰、正确、精准并合法语法和避免使用专用格式重要（也不能取而代之）。程序员们一般宁可读有点唐突但技术上鲜明的 Bug 报告，而不是那种有礼但含糊的报告。（如果这点让你不解，记住我们是按问题能教给我们什么来评价问题的价值的） 然而，如果你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。 （我们注意到，自从本指南发布后，从资深程序员那里得到的唯一严重缺陷反馈，就是对预先道谢这一条。一些程序员觉得 先谢了 意味着事后就不用再感谢任何人的暗示。我们的建议是要么先说 先谢了， 然后 事后再对回复者表示感谢，或者换种方式表达感激，譬如用 谢谢你的关注 或 谢谢你的关照。） 问题解决后，加个简短的补充说明问题解决后，向所有帮助过你的人发个说明，让他们知道问题是怎样解决的，并再一次向他们表示感谢。如果问题在新闻组或者邮件列表中引起了广泛关注，应该在那里贴一个说明比较恰当。 最理想的方式是向最初提问的话题回复此消息，并在标题中包含 已修正，已解决 或其它同等含义的明显标记。在人来人往的邮件列表里，一个看见讨论串 问题 X 和 问题 X - 已解决 的潜在回复者就明白不用再浪费时间了（除非他个人觉得 问题 X 的有趣），因此可以利用此时间去解决其它问题。 补充说明不必很长或是很深入；简单的一句 你好，原来是网线出了问题！谢谢大家 – Bill 比什么也不说要来的好。事实上，除非结论真的很有技术含量，否则简短可爱的小结比长篇大论更好。说明问题是怎样解决的，但大可不必将解决问题的过程复述一遍。 对于有深度的问题，张贴调试记录的摘要是有帮助的。描述问题的最终状态，说明是什么解决了问题，在此 之后 才指明可以避免的盲点。避免盲点的部分应放在正确的解决方案和其它总结材料之后，而不要将此信息搞成侦探推理小说。列出那些帮助过你的名字，会让你交到更多朋友。 除了有礼貌和有内涵以外，这种类型的补充也有助于他人在邮件列表 / 新闻群组 / 论坛中搜索到真正解决你问题的方案，让他们也从中受益。 至少，这种补充有助于让每位参与协助的人因问题的解决而从中得到满足感。如果你自己不是技术专家或者程序员，那就相信我们，这种感觉对于那些你向他们求助的大师或者专家而言，是非常重要的。问题悬而未决会让人灰心；程序员们渴望看到问题被解决。好人有好报，满足他们的渴望，你会在下次提问时尝到甜头。 思考一下怎样才能避免他人将来也遇到类似的问题，自问写一份文件或加个常见问题（FAQ）会不会有帮助。如果是的话就将它们发给维护者。 在程序员中，这种良好的后继行动实际上比传统的礼节更为重要，也是你如何透过善待他人而赢得声誉的方式，这是非常有价值的资产。 如何解读答案RTFM 和 STFW：如何知道你已完全搞砸了有一个古老而神圣的传统：如果你收到 RTFM （Read The Fucking Manual） 的回应，回答者认为你 应该去读他妈的手册 。当然，基本上他是对的，你应该去读一读。 RTFM 有一个年轻的亲戚。如果你收到 STFW（Search The Fucking Web） 的回应，回答者认为你 应该到他妈的网上搜索 过了。那人多半也是对的，去搜索一下吧。（更温和一点的说法是 Google 是你的朋友 ！） 在论坛，你也可能被要求去爬爬论坛的旧文。事实上，有人甚至可能热心地为你提供以前解决此问题的讨论串。但不要依赖这种关照，提问前应该先搜索一下旧文。 通常，用这两句之一回答你的人会给你一份包含你需要内容的手册或者一个网址，而且他们打这些字的时候也正在读着。这些答复意味着回答者认为 你需要的信息非常容易获得 ； 你自己去搜索这些信息比灌给你，能让你学到更多 。 你不应该因此不爽； 依照程序员的标准，他已经表示了对你一定程度的关注，而没有对你的要求视而不见 。你应该对他祖母般的慈祥表示感谢。 如果还是搞不懂如果你看不懂回应，别立刻要求对方解释。像你以前试着自己解决问题时那样（利用手册，FAQ，网络，身边的高手），先试着去搞懂他的回应。如果你真的需要对方解释，记得表现出你已经从中学到了点什么。 比方说，如果我回答你：看来似乎是 zentry 卡住了；你应该先清除它。，然后，这是一个 很糟的 后续问题回应：zentry 是什么？ 好 的问法应该是这样：哦 ~~~ 我看过说明了但是只有 -z 和 -p 两个参数中提到了 zentries，而且还都没有清楚的解释如何清除它。你是指这两个中的哪一个吗？还是我看漏了什么？ 处理无礼的回应很多程序员圈子中看似无礼的行为并不是存心冒犯。相反，它是直接了当，一针见血式的交流风格，这种风格更注重解决问题，而不是使人感觉舒服而却模模糊糊。 如果你觉得被冒犯了，试着平静地反应。如果有人真的做了出格的事，邮件列表、新闻群组或论坛中的前辈多半会招呼他。如果这 没有 发生而你却发火了，那么你发火对象的言语可能在程序员社区中看起来是正常的，而 你 将被视为有错的一方，这将伤害到你获取信息或帮助的机会。 另一方面，你偶而真的会碰到无礼和无聊的言行。与上述相反，对真正的冒犯者狠狠地打击，用犀利的语言将其驳得体无完肤都是可以接受的。然而，在行事之前一定要非常非常的有根据。纠正无礼的言论与开始一场毫无意义的口水战仅一线之隔，程序员们自己莽撞地越线的情况并不鲜见。如果你是新手或外人，避开这种莽撞的机会并不高。如果你想得到的是信息而不是消磨时光，这时最好不要把手放在键盘上以免冒险。 （有些人断言很多程序员都有轻度的自闭症或亚斯伯格综合症，缺少用于润滑人类社会 正常 交往所需的神经。这既可能是真也可能是假的。如果你自己不是程序员，兴许你认为我们脑袋有问题还能帮助你应付我们的古怪行为。只管这么干好了，我们不在乎。我们 喜欢 我们现在这个样子，并且通常对病患标记都有站得住脚的怀疑。） Jeff Bigler 的观察总结和这个相关也值得一读 (tact filters)。 在下一节，我们会谈到另一个问题，当 你 行为不当时所会受到的 冒犯。 如何避免扮演失败者在程序员社区的论坛中有那么几次你可能会搞砸 – 以本指南所描述到的或类似的方式。而你会在公开场合中被告知你是如何搞砸的，也许攻击的言语中还会带点夹七夹八的颜色。 这种事发生以后，你能做的最糟糕的事莫过于哀嚎你的遭遇、宣称被口头攻击、要求道歉、高声尖叫、憋闷气、威胁诉诸法律、向其雇主报怨、忘了关马桶盖等等。相反地，你该这么做： 熬过去，这很正常。事实上，它是有益健康且合理的。 社区的标准不会自行维持，它们是通过参与者积极而 公开地 执行来维持的。不要哭嚎所有的批评都应该通过私下的邮件传送，它不是这样运作的。当有人评论你的一个说法有误或者提出不同看法时，坚持声称受到个人攻击也毫无益处，这些都是失败者的态度。 也有其它的程序员论坛，受过高礼节要求的误导，禁止参与者张贴任何对别人帖子挑毛病的消息，并声称 如果你不想帮助用户就闭嘴。 结果造成有想法的参与者纷纷离开，这么做只会使它们沦为毫无意义的唠叨与无用的技术论坛。 夸张的讲法是：你要的是 友善 （以上述方式）还是有用？两个里面挑一个。 记着：当程序员说你搞砸了，并且（无论多么刺耳）告诉你别再这样做时，他正在为关心 你 和 他的社区 而行动。对他而言，不理你并将你从他的生活中滤掉更简单。如果你无法做到感谢，至少要表现得有点尊严，别大声哀嚎，也别因为自己是个有戏剧性超级敏感的灵魂和自以为有资格的新来者，就指望别人像对待脆弱的洋娃娃那样对你。 有时候，即使你没有搞砸（或者只是在他的想像中你搞砸了），有些人也会无缘无故地攻击你本人。在这种情况下，抱怨倒是 真的 会把问题搞砸。 这些来找麻烦的人要么是毫无办法但自以为是专家的不中用家伙，要么就是测试你是否真会搞砸的心理专家。其它读者要么不理睬，要么用自己的方式对付他们。这些来找麻烦的人在给他们自己找麻烦，这点你不用操心。 也别让自己卷入口水战，最好不要理睬大多数的口水战 – 当然，这是在你检验它们只是口水战，并且未指出你有搞砸的地方，同时也没有巧妙地将问题真正的答案藏于其后（这也是有可能的）。 不该问的问题以下是几个经典蠢问题，以及程序员没回答时心中所想的： 问题：我能在哪找到 X 程序或 X 资源？ 问题：我怎样用 X 做 Y？ 问题：如何设定我的 shell 提示？ 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？ 问题：我的程序 / 设定 /SQL 语句没有用 问题：我的 Windows 电脑有问题，你能帮我吗？ 问题：我的程序不会动了，我认为系统工具 X 有问题 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？ 问题：我怎么才能破解 root 帐号 / 窃取 OP 特权 / 读别人的邮件呢？ 问题：我能在哪找到 X 程序或 X 资源？ 回答：就在我找到它的地方啊，白痴 – 搜索引擎的那一头。天哪！难道还有人不会用 Google 吗？ 问题：我怎样用 X 做 Y？ 回答：如果你想解决的是 Y ，提问时别给出可能并不恰当的方法。这种问题说明提问者不但对 X 完全无知，也对 Y 要解决的问题糊涂，还被特定形势禁锢了思维。最好忽略这种人，等他们把问题搞清楚了再说。 问题：如何设定我的 shell 提示？？ 回答：如果你有足够的智慧提这个问题，你也该有足够的智慧去 RTFM，然后自己去找出来。 问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？ 回答：试试看就知道了。如果你试过，你既知道了答案，就不用浪费我的时间了。 问题：我的 {程序 / 设定 /SQL 语句} 不工作 回答：这不算是问题吧，我对要我问你二十个问题才找得出你真正问题的问题没兴趣 – 我有更有意思的事要做呢。在看到这类问题的时候，我的反应通常不外如下三种 你还有什么要补充的吗？ 真糟糕，希望你能搞定。 这关我有什么屁事？ 问题：我的 Windows 电脑有问题，你能帮我吗？ 回答：能啊，扔掉微软的垃圾，换个像 Linux 或 BSD 的开放源代码操作系统吧。 注意：如果程序有官方版 Windows 或者与 Windows 有互动（如 Samba），你 可以 问与 Windows 相关的问题， 只是别对问题是由 Windows 操作系统而不是程序本身造成的回复感到惊讶， 因为 Windows 一般来说实在太烂，这种说法通常都是对的。 问题：我的程序不会动了，我认为系统工具 X 有问题 回答：你完全有可能是第一个注意到被成千上万用户反复使用的系统调用与函数库档案有明显缺陷的人，更有可能的是你完全没有根据。不同凡响的说法需要不同凡响的证据，当你这样声称时，你必须有清楚而详尽的缺陷说明文件作后盾。 问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？ 回答：不能，我只有亲自在你的电脑上动手才能找到毛病。还是去找你当地的 Linux 使用群组者寻求实际的指导吧（你能在 这儿 找到使用者群组的清单）。 注意：如果安装问题与某 Linux 的发行版有关，在它的邮件列表、论坛或本地使用者群组中提问也许是恰当的。此时，应描述问题的准确细节。在此之前，先用 Linux 和 所有 被怀疑的硬件作关键词仔细搜索。 问题：我怎么才能破解 root 帐号 / 窃取 OP 特权 / 读别人的邮件呢？ 回答：想要这样做，说明了你是个卑鄙小人；想找个程序员帮你，说明你是个白痴！ 好问题与蠢问题最后，我将透过举一些例子，来说明怎样聪明的提问；同一个问题的两种问法被放在一起，一种是愚蠢的，另一种才是明智的。 蠢问题 ： 我可以在哪儿找到关于 Foonly Flurbamatic 的资料？ 这种问法无非想得到 STFW 这样的回答。 聪明问题 ： 我用 Google 搜索过 “Foonly Flurbamatic 2600”，但是没找到有用的结果。谁知道上哪儿去找对这种设备编程的资料？ 这个问题已经 STFW 过了，看起来他真的遇到了麻烦。 蠢问题 我从 foo 项目找来的源码没法编译。它怎么这么烂？ 他觉得都是别人的错，这个傲慢自大的提问者。 聪明问题 foo 项目代码在 Nulix 6.2 版下无法编译通过。我读过了 FAQ，但里面没有提到跟 Nulix 有关的问题。这是我编译过程的记录，我有什么做的不对的地方吗？ 提问者已经指明了环境，也读过了 FAQ，还列出了错误，并且他没有把问题的责任推到别人头上，他的问题值得被关注。 蠢问题 我的主机板有问题了，谁来帮我？ 某程序员对这类问题的回答通常是：好的，还要帮你拍拍背和换尿布吗？，然后按下删除键。 聪明问题 我在 S2464 主机板上试过了 X 、 Y 和 Z ，但没什么作用，我又试了 A 、 B 和 C 。请注意当我尝试 C 时的奇怪现象。显然 florbish 正在 grommicking，但结果出人意料。通常在 Athlon MP 主机板上引起 grommicking 的原因是什么？有谁知道接下来我该做些什么测试才能找出问题？ 这个家伙，从另一个角度来看，值得去回答他。他表现出了解决问题的能力，而不是坐等天上掉答案。 在最后一个问题中，注意 告诉我答案 和 给我启示，指出我还应该做什么诊断工作 之间微妙而又重要的区别。 事实上，后一个问题源自于 2001 年 8 月在 Linux 内核邮件列表（lkml）上的一个真实的提问。我（Eric）就是那个提出问题的人。我在 Tyan S2464 主板上观察到了这种无法解释的锁定现象，列表成员们提供了解决这一问题的重要信息。 通过我的提问方法，我给了别人可以咀嚼玩味的东西；我设法让人们很容易参与并且被吸引进来。我显示了自己具备和他们同等的能力，并邀请他们与我共同探讨。通过告诉他们我所走过的弯路，以避免他们再浪费时间，我也表明了对他们宝贵时间的尊重。 事后，当我向每个人表示感谢，并且赞赏这次良好的讨论经历的时候， 一个 Linux 内核邮件列表的成员表示，他觉得我的问题得到解决并非由于我是这个列表中的 名人 ，而是因为我用了正确的方式来提问。 程序员从某种角度来说是拥有丰富知识但缺乏人情味的家伙；我相信他是对的，如果我 像 个乞讨者那样提问，不论我是谁，一定会惹恼某些人或者被他们忽视。他建议我记下这件事，这直接导致了本指南的出现。 如果得不到回答如果仍得不到回答，请不要以为我们觉得无法帮助你。有时只是看到你问题的人不知道答案罢了。没有回应不代表你被忽视，虽然不可否认这种差别很难区分。 总的来说，简单的重复张贴问题是个很糟的点子。这将被视为无意义的喧闹。有点耐心，知道你问题答案的人可能生活在不同的时区，可能正在睡觉，也有可能你的问题一开始就没有组织好。 你可以通过其他渠道获得帮助，这些渠道通常更适合初学者的需要。 有许多网上的以及本地的使用者群组，由热情的软件爱好者（即使他们可能从没亲自写过任何软件）组成。通常人们组建这样的团体来互相帮助并帮助新手。 另外，你可以向很多商业公司寻求帮助，不论公司大还是小。别为要付费才能获得帮助而感到沮丧！毕竟，假使你的汽车发动机汽缸密封圈爆掉了 – 完全可能如此 – 你还得把它送到修车铺，并且为维修付费。就算软件没花费你一分钱，你也不能强求技术支持总是免费的。 对像是 Linux 这种大众化的软件，每个开发者至少会对应到上万名使用者。根本不可能由一个人来处理来自上万名使用者的求助电话。要知道，即使你要为这些协助付费，和你所购买的同类软件相比，你所付出的也是微不足道的（通常封闭源代码软件的技术支持费用比开放源代码软件的要高得多，且内容也没那么丰富）。 如何更好地回答问题 态度和善一点 。问题带来的压力常使人显得无礼或愚蠢，其实并不是这样。 对初犯者私下回复 。对那些坦诚犯错之人没有必要当众羞辱，一个真正的新手也许连怎么搜索或在哪找常见问题都不知道。 如果你不确定，一定要说出来 ！一个听起来权威的错误回复比没有还要糟，别因为听起来像个专家很好玩，就给别人乱指路。要谦虚和诚实，给提问者与同行都树个好榜样。 如果帮不了忙，也别妨碍他 。不要在实际步骤上开玩笑，那样也许会毁了使用者的设置 – 有些可怜的呆瓜会把它当成真的指令。 试探性的反问以引出更多的细节 。如果你做得好，提问者可以学到点东西 – 你也可以。试试将蠢问题转变成好问题，别忘了我们都曾是新手。 尽管对那些懒虫抱怨一声 RTFM 是正当的，能指出文件的位置（即使只是建议个 Google 搜索关键词）会更好。 如果你决定回答，就请给出好的答案 。当别人正在用错误的工具或方法时别建议笨拙的权宜之计（wordaround），应推荐更好的工具，重新界定问题。 正面的回答问题 ！如果这个提问者已经很深入的研究而且也表明已经试过 X 、 Y 、 Z 、 A 、 B 、 C 但没得到结果，回答 试试看 A 或是 B 或者 试试 X 、 Y 、 Z 、 A 、 B 、 C 并附上一个链接一点用都没有。 帮助你的社区从问题中学习 。当回复一个好问题时，问问自己 如何修改相关文件或常见问题文件以免再次解答同样的问题？，接着再向文件维护者发一份补丁。 如果你是在研究一番后才做出的回答， 展现你的技巧而不是直接端出结果 。毕竟 授人以鱼不如授人以渔。 tips：还有一点博主我觉得挺重要的：如果有妹子私聊你请教问题，请务必不要介意本文介绍的反例。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"}]},{"title":"一种心跳，两种设计","slug":"heartbeat-design","date":"2019-01-11T22:24:09.000Z","updated":"2019-09-26T09:45:29.612Z","comments":true,"path":"heartbeat-design/","link":"","permalink":"http://lexburner.github.io/heartbeat-design/","excerpt":"1 前言在前一篇文章 《聊聊 TCP 长连接和心跳那些事》 中，我们已经聊过了 TCP 中的 KeepAlive，以及在应用层设计心跳的意义，但却对长连接心跳的设计方案没有做详细地介绍。事实上，设计一个好的心跳机制并不是一件容易的事，就我所熟知的几个 RPC 框架，它们的心跳机制可以说大相径庭，这篇文章我将探讨一下 如何设计一个优雅的心跳机制，主要从 Dubbo 的现有方案以及一个改进方案来做分析 。","text":"1 前言在前一篇文章 《聊聊 TCP 长连接和心跳那些事》 中，我们已经聊过了 TCP 中的 KeepAlive，以及在应用层设计心跳的意义，但却对长连接心跳的设计方案没有做详细地介绍。事实上，设计一个好的心跳机制并不是一件容易的事，就我所熟知的几个 RPC 框架，它们的心跳机制可以说大相径庭，这篇文章我将探讨一下 如何设计一个优雅的心跳机制，主要从 Dubbo 的现有方案以及一个改进方案来做分析 。 2 预备知识因为后续我们将从源码层面来进行介绍，所以一些服务治理框架的细节还需要提前交代一下，方便大家理解。 2.1 客户端如何得知请求失败了？高性能的 RPC 框架几乎都会选择使用 Netty 来作为通信层的组件，非阻塞式通信的高效不需要我做过多的介绍。但也由于非阻塞的特性，导致其发送数据和接收数据是一个异步的过程，所以当存在服务端异常、网络问题时，客户端接是接收不到响应的，那我们如何判断一次 RPC 调用是失败的呢？ 误区一：Dubbo 调用不是默认同步的吗？ Dubbo 在通信层是异步的，呈现给使用者同步的错觉是因为内部做了阻塞等待，实现了异步转同步。 误区二： Channel.writeAndFlush 会返回一个 channelFuture，我只需要判断 channelFuture.isSuccess 就可以判断请求是否成功了。 注意，writeAndFlush 成功并不代表对端接受到了请求，返回值为 true 只能保证写入网络缓冲区成功，并不代表发送成功。 避开上述两个误区，我们再来回到本小节的标题：客户端如何得知请求失败？ 正确的逻辑应当是以客户端接收到失败响应为判断依据 。等等，前面不还在说在失败的场景中，服务端是不会返回响应的吗？没错，既然服务端不会返回，那就只能客户端自己造了。 一个常见的设计是：客户端发起一个 RPC 请求，会设置一个超时时间 client_timeout，发起调用的同时，客户端会开启一个延迟 client_timeout 的定时器 接收到正常响应时，移除该定时器。 定时器倒计时完毕，还没有被移除，则认为请求超时，构造一个失败的响应传递给客户端。 Dubbo 中的超时判定逻辑： 1234567891011121314151617181920212223242526272829public static DefaultFuture newFuture(Channel channel, Request request, int timeout) &#123; final DefaultFuture future = new DefaultFuture(channel, request, timeout); // timeout check timeoutCheck(future); return future;&#125;private static void timeoutCheck(DefaultFuture future) &#123; TimeoutCheckTask task = new TimeoutCheckTask(future); TIME_OUT_TIMER.newTimeout(task, future.getTimeout(), TimeUnit.MILLISECONDS);&#125;private static class TimeoutCheckTask implements TimerTask &#123; private DefaultFuture future; TimeoutCheckTask(DefaultFuture future) &#123; this.future = future; &#125; @Override public void run(Timeout timeout) &#123; if (future == null || future.isDone()) &#123; return; &#125; // create exception response. Response timeoutResponse = new Response(future.getId()); // set timeout status. timeoutResponse.setStatus(future.isSent() ? Response.SERVER_TIMEOUT : Response.CLIENT_TIMEOUT); timeoutResponse.setErrorMessage(future.getTimeoutMessage(true)); // handle response. DefaultFuture.received(future.getChannel(), timeoutResponse); &#125;&#125; 主要逻辑涉及的类：DubboInvoker，HeaderExchangeChannel，DefaultFuture ，通过上述代码，我们可以得知一个细节，无论是何种调用，都会经过这个定时器的检测， 超时即调用失败，一次 RPC 调用的失败，必须以客户端收到失败响应为准 。 2.2 心跳检测需要容错网络通信永远要考虑到最坏的情况，一次心跳失败，不能认定为连接不通，多次心跳失败，才能采取相应的措施。 2.3 心跳检测不需要忙检测忙检测的对立面是空闲检测，我们做心跳的初衷，是为了保证连接的可用性，以保证及时采取断连，重连等措施。如果一条通道上有频繁的 RPC 调用正在进行，我们不应该为通道增加负担去发送心跳包。 心跳扮演的角色应当是晴天收伞，雨天送伞。 3 Dubbo 现有方案 本文的源码对应 Dubbo 2.7.x 版本，在 apache 孵化的该版本中，心跳机制得到了增强。 介绍完了一些基础的概念，我们再来看看 Dubbo 是如何设计应用层心跳的。Dubbo 的心跳是双向心跳，客户端会给服务端发送心跳，反之，服务端也会向客户端发送心跳。 3.1 连接建立时创建定时器1234567891011121314151617public class HeaderExchangeClient implements ExchangeClient &#123; private int heartbeat; private int heartbeatTimeout; private HashedWheelTimer heartbeatTimer; public HeaderExchangeClient(Client client, boolean needHeartbeat) &#123; this.client = client; this.channel = new HeaderExchangeChannel(client); this.heartbeat = client.getUrl().getParameter(Constants.HEARTBEAT_KEY, dubbo != null &amp;&amp; dubbo.startsWith(\"1.0.\") ? Constants.DEFAULT_HEARTBEAT : 0); this.heartbeatTimeout = client.getUrl().getParameter(Constants.HEARTBEAT_TIMEOUT_KEY, heartbeat * 3); if (needHeartbeat) &#123; &lt;1&gt; long tickDuration = calculateLeastDuration(heartbeat); heartbeatTimer = new HashedWheelTimer(new NamedThreadFactory(\"dubbo-client-heartbeat\", true), tickDuration, TimeUnit.MILLISECONDS, Constants.TICKS_PER_WHEEL); &lt;2&gt; startHeartbeatTimer(); &#125; &#125; &#125; 默认开启心跳检测的定时器 创建了一个 HashedWheelTimer 开启心跳检测 ，这是 Netty 所提供的一个经典的时间轮定时器实现，至于它和 jdk 的实现有何不同，不了解的同学也可以关注下，我就不拓展了。 不仅 HeaderExchangeClient 客户端开起了定时器，HeaderExchangeServer 服务端同样开起了定时器，由于服务端的逻辑和客户端几乎一致，所以后续我并不会重复粘贴服务端的代码。 Dubbo 在早期版本版本中使用的是 schedule 方案，在 2.7.x 中替换成了 HashWheelTimer。 3.2 开启两个定时任务123456789private void startHeartbeatTimer() &#123; long heartbeatTick = calculateLeastDuration(heartbeat); long heartbeatTimeoutTick = calculateLeastDuration(heartbeatTimeout); HeartbeatTimerTask heartBeatTimerTask = new HeartbeatTimerTask(cp, heartbeatTick, heartbeat); &lt;1&gt; ReconnectTimerTask reconnectTimerTask = new ReconnectTimerTask(cp, heartbeatTimeoutTick, heartbeatTimeout); &lt;2&gt; heartbeatTimer.newTimeout(heartBeatTimerTask, heartbeatTick, TimeUnit.MILLISECONDS); heartbeatTimer.newTimeout(reconnectTimerTask, heartbeatTimeoutTick, TimeUnit.MILLISECONDS);&#125; Dubbo 在 startHeartbeatTimer 方法中主要开启了两个定时器： HeartbeatTimerTask，ReconnectTimerTask HeartbeatTimerTask 主要用于定时发送心跳请求 ReconnectTimerTask 主要用于心跳失败之后处理重连，断连的逻辑 至于方法中的其他代码，其实也是本文的重要分析内容，先容我卖个关子，后面再来看追溯。 3.3 定时任务一：发送心跳请求详细解析下心跳检测定时任务的逻辑 HeartbeatTimerTask#doTask： 12345678910111213protected void doTask(Channel channel) &#123; Long lastRead = lastRead(channel); Long lastWrite = lastWrite(channel); if ((lastRead != null &amp;&amp; now() - lastRead &gt; heartbeat) || (lastWrite != null &amp;&amp; now() - lastWrite &gt; heartbeat)) &#123; Request req = new Request(); req.setVersion(Version.getProtocolVersion()); req.setTwoWay(true); req.setEvent(Request.HEARTBEAT_EVENT); channel.send(req); &#125; &#125;&#125; 前面已经介绍过，Dubbo 采取的是是双向心跳设计 ，即服务端会向客户端发送心跳，客户端也会向服务端发送心跳，接收的一方更新 lastRead 字段，发送的一方更新 lastWrite 字段，超过心跳间隙的时间，便发送心跳请求给对端。这里的 lastRead/lastWrite 同样会被同一个通道上的普通调用更新，通过更新这两个字段，实现了只在连接空闲时才会真正发送空闲报文的机制，符合我们一开始科普的做法。 注意：不仅仅心跳请求会更新 lastRead 和 lastWrite，普通请求也会。这对应了我们预备知识中的空闲检测机制。 3.4 定时任务二：处理重连和断连继续研究下重连和断连定时器都实现了什么 ReconnectTimerTask#doTask。 1234567891011protected void doTask(Channel channel) &#123; Long lastRead = lastRead(channel); Long now = now(); if (lastRead != null &amp;&amp; now - lastRead &gt; heartbeatTimeout) &#123; if (channel instanceof Client) &#123; ((Client) channel).reconnect(); &#125; else &#123; channel.close(); &#125; &#125;&#125; 第二个定时器则负责根据客户端、服务端类型来对连接做不同的处理，当超过设置的心跳总时间之后，客户端选择的是重新连接，服务端则是选择直接断开连接。这样的考虑是合理的，客户端调用是强依赖可用连接的，而服务端可以等待客户端重新建立连接。 细心的朋友会发现，这个类被命名为 ReconnectTimerTask 是不太准确的，因为它处理的是重连和断连两个逻辑。 3.5 定时不精确的问题在 Dubbo 的 issue 中曾经有人反馈过定时不精确的问题，我们来看看是怎么一回事。 Dubbo 中默认的心跳周期是 60s，设想如下的时序： 第 0 秒，心跳检测发现连接活跃 第 1 秒，连接实际断开 第 60 秒，心跳检测发现连接不活跃 由于 时间窗口的问题，死链不能够被及时检测出来，最坏情况为一个心跳周期 。 为了解决上述问题，我们再倒回去看一下上面的 startHeartbeatTimer() 方法 12long heartbeatTick = calculateLeastDuration(heartbeat); long heartbeatTimeoutTick = calculateLeastDuration(heartbeatTimeout); 其中 calculateLeastDuration 根据心跳时间和超时时间分别计算出了一个 tick 时间，实际上就是将两个变量除以了 3，使得他们的值缩小，并传入了 HashedWheelTimer 的第二个参数之中 12heartbeatTimer.newTimeout(heartBeatTimerTask, heartbeatTick, TimeUnit.MILLISECONDS);heartbeatTimer.newTimeout(reconnectTimerTask, heartbeatTimeoutTick, TimeUnit.MILLISECONDS); tick 的含义便是定时任务执行的频率。这样，通过减少检测间隔时间，增大了及时发现死链的概率，原先的最坏情况是 60s，如今变成了 20s。这个频率依旧可以加快，但需要考虑资源消耗的问题。 定时不准确的问题出现在 Dubbo 的两个定时任务之中，所以都做了 tick 操作。事实上，所有的定时检测的逻辑都存在类似的问题。 3.6 Dubbo 心跳总结Dubbo 对于建立的每一个连接，同时在客户端和服务端开启了 2 个定时器，一个用于定时发送心跳，一个用于定时重连、断连，执行的频率均为各自检测周期的 1/3。定时发送心跳的任务负责在连接空闲时，向对端发送心跳包。定时重连、断连的任务负责检测 lastRead 是否在超时周期内仍未被更新，如果判定为超时，客户端处理的逻辑是重连，服务端则采取断连的措施。 先不急着判断这个方案好不好，再来看看改进方案是怎么设计的。 4 Dubbo 改进方案实际上我们可以更优雅地实现心跳机制，本小节开始，我将介绍一个新的心跳机制。 4.1 IdleStateHandler 介绍Netty 对空闲连接的检测提供了天然的支持，使用 IdleStateHandler 可以很方便的实现空闲检测逻辑。 123public IdleStateHandler( long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit)&#123;&#125; readerIdleTime：读超时时间 writerIdleTime：写超时时间 allIdleTime：所有类型的超时时间 IdleStateHandler 这个类会根据设置的超时参数，循环检测 channelRead 和 write 方法多久没有被调用。当在 pipeline 中加入 IdleSateHandler 之后，可以在此 pipeline 的任意 Handler 的 userEventTriggered 方法之中检测 IdleStateEvent 事件， 1234567@Overridepublic void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent) &#123; //do something &#125; ctx.fireUserEventTriggered(evt);&#125; 为什么需要介绍 IdleStateHandler 呢？其实提到它的空闲检测 + 定时的时候，大家应该能够想到了，这不天然是给心跳机制服务的吗？很多服务治理框架都选择了借助 IdleStateHandler 来实现心跳。 IdleStateHandler 内部使用了 eventLoop.schedule(task) 的方式来实现定时任务，使用 eventLoop 线程的好处是还同时保证了 线程安全 ，这里是一个小细节。 4.2 客户端和服务端配置首先是将 IdleStateHandler 加入 pipeline 中。 客户端： 123456bootstrap.handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline().addLast(\"clientIdleHandler\", new IdleStateHandler(60, 0, 0)); &#125;&#125;); 服务端： 123456serverBootstrap.childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline().addLast(\"serverIdleHandler\",new IdleStateHandler(0, 0, 200)); &#125;&#125; 客户端配置了 read 超时为 60s，服务端配置了 write/read 超时为 200s，先在此埋下两个伏笔： 为什么客户端和服务端配置的超时时间不一致？ 为什么客户端检测的是读超时，而服务端检测的是读写超时？ 4.3 空闲超时逻辑 — 客户端对于空闲超时的处理逻辑，客户端和服务端是不同的。首先来看客户端 123456789@Overridepublic void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent) &#123; // send heartbeat sendHeartBeat(); &#125; else &#123; super.userEventTriggered(ctx, evt); &#125;&#125; 检测到空闲超时之后，采取的行为是向服务端发送心跳包，具体是如何发送，以及处理响应的呢？伪代码如下 12345678910111213141516171819public void sendHeartBeat() &#123; Invocation invocation = new Invocation(); invocation.setInvocationType(InvocationType.HEART_BEAT); channel.writeAndFlush(invocation).addListener(new CallbackFuture() &#123; @Override public void callback(Future future) &#123; RPCResult result = future.get(); // 超时 或者 写失败 if (result.isError()) &#123; channel.addFailedHeartBeatTimes(); if (channel.getFailedHeartBeatTimes() &gt;= channel.getMaxHeartBeatFailedTimes()) &#123; channel.reconnect(); &#125; &#125; else &#123; channel.clearHeartBeatFailedTimes(); &#125; &#125; &#125;);&#125; 行为并不复杂，构造一个心跳包发送到服务端，接受响应结果 响应成功，清空请求失败标记 响应失败，心跳失败标记 +1，如果超过配置的失败次数，则重新连接 不仅仅是心跳，普通请求返回成功响应时也会清空标记 4.4 空闲超时逻辑 — 服务端12345678@Overridepublic void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent) &#123; channel.close(); &#125; else &#123; super.userEventTriggered(ctx, evt); &#125;&#125; 服务端处理空闲连接的方式非常简单粗暴，直接关闭连接。 4.5 改进方案心跳总结 为什么客户端和服务端配置的超时时间不一致？ 因为客户端有重试逻辑，不断发送心跳失败 n 次之后，才认为是连接断开；而服务端是直接断开，留给服务端时间得长一点。60 * 3 &lt; 200 还说明了一个问题，双方都拥有断开连接的能力，但连接的创建是由客户端主动发起的，那么客户端也更有权利去主动断开连接。 为什么客户端检测的是读超时，而服务端检测的是读写超时？ 这其实是一个心跳的共识了，仔细思考一下，定时逻辑是由客户端发起的，所以整个链路中不通的情况只有可能是：服务端接收，服务端发送，客户端接收。也就是说，只有客户端的 pong，服务端的 ping，pong 的检测是有意义的。 主动追求别人的是你，主动说分手的也是你。 利用 IdleStateHandler 实现心跳机制可以说是十分优雅的，借助 Netty 提供的空闲检测机制，利用客户端维护单向心跳，在收到 3 次心跳失败响应之后，客户端断开连接，交由异步线程重连，本质还是表现为客户端重连。服务端在连接空闲较长时间后，主动断开连接，以避免无谓的资源浪费。 5 心跳设计方案对比 Dubbo 现有方案 Dubbo 改进方案 主体设计 开启两个定时器 借助 IdleStateHandler，底层使用 schedule 心跳方向 双向 单向（客户端 -&gt; 服务端） 心跳失败判定方式 心跳成功更新标记，借助定时器定时扫描标记，如果超过心跳超时周期未更新标记，认为心跳失败。 通过判断心跳响应是否失败，超过失败次数，认为心跳失败 扩展性 Dubbo 存在 mina，grizzy 等其他通信层实现，自定义定时器很容易适配多种扩展 多通信层各自实现心跳，不做心跳的抽象 设计性 编码复杂度高，代码量大，方案复杂，不易维护 编码量小，可维护性强 私下请教过 美团点评的长连接负责人：俞超（闪电侠），美点使用的心跳方案和 Dubbo 改进方案几乎一致，可以说该方案是标准实现了。 6 Dubbo 实际改动点建议鉴于 Dubbo 存在一些其他通信层的实现，所以可以保留现有的定时发送心跳的逻辑。 建议改动点一： 双向心跳的设计是不必要的，兼容现有的逻辑，可以让客户端在连接空闲时发送单向心跳，服务端定时检测连接可用性。定时时间尽量保证：客户端超时时间 * 3 ≈ 服务端超时时间 建议改动点二： 去除处理重连和断连的定时任务，Dubbo 可以判断心跳请求是否响应失败，可以借鉴改进方案的设计，在连接级别维护一个心跳失败次数的标记，任意响应成功，清除标记；连续心跳失败 n 次，客户端发起重连。这样可以减少一个不必要的定时器，任何轮询的方式，都是不优雅的。 最后再聊聊可扩展性这个话题。其实我是建议把定时器交给更加底层的 Netty 去做，也就是完全使用 IdleStateHandler ，其他通信层组件各自实现自己的空闲检测逻辑，但是 Dubbo 中 mina，grizzy 的兼容问题囿住了我的拳脚，但试问一下，如今的 2019 年，又有多少人在使用 mina 和 grizzy？因为一些不太可能用的特性，而限制了主流用法的优化，这肯定不是什么好事。抽象，功能，可扩展性并不是越多越好，开源产品的人力资源是有限的，框架使用者的理解能力也是有限的，能解决大多数人问题的设计，才是好的设计。哎，谁让我不会 mina，grizzy，还懒得去学呢 [摊手]。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://lexburner.github.io/tags/TCP/"},{"name":"心跳","slug":"心跳","permalink":"http://lexburner.github.io/tags/心跳/"}]},{"title":"聊聊 TCP 长连接和心跳那些事","slug":"tcp-talk","date":"2019-01-06T10:24:09.000Z","updated":"2019-09-26T09:45:29.692Z","comments":true,"path":"tcp-talk/","link":"","permalink":"http://lexburner.github.io/tcp-talk/","excerpt":"前言可能很多 Java 程序员对 TCP 的理解只有一个三次握手，四次握手的认识，我觉得这样的原因主要在于 TCP 协议本身稍微有点抽象（相比较于应用层的 HTTP 协议）；其次，非框架开发者不太需要接触到 TCP 的一些细节。其实我个人对 TCP 的很多细节也并没有完全理解，这篇文章主要针对微信交流群里有人提出的长连接，心跳问题，做一个统一的整理。 在 Java 中，使用 TCP 通信，大概率会涉及到 Socket、Netty，本文将借用它们的一些 API 和设置参数来辅助介绍。","text":"前言可能很多 Java 程序员对 TCP 的理解只有一个三次握手，四次握手的认识，我觉得这样的原因主要在于 TCP 协议本身稍微有点抽象（相比较于应用层的 HTTP 协议）；其次，非框架开发者不太需要接触到 TCP 的一些细节。其实我个人对 TCP 的很多细节也并没有完全理解，这篇文章主要针对微信交流群里有人提出的长连接，心跳问题，做一个统一的整理。 在 Java 中，使用 TCP 通信，大概率会涉及到 Socket、Netty，本文将借用它们的一些 API 和设置参数来辅助介绍。 长连接与短连接TCP 本身并没有长短连接的区别 ，长短与否，完全取决于我们怎么用它。 短连接：每次通信时，创建 Socket；一次通信结束，调用 socket.close()。这就是一般意义上的短连接，短连接的好处是管理起来比较简单，存在的连接都是可用的连接，不需要额外的控制手段。 长连接：每次通信完毕后，不会关闭连接，这样可以做到连接的复用。 长连接的好处是省去了创建连接的耗时。 短连接和长连接的优势，分别是对方的劣势。想要图简单，不追求高性能，使用短连接合适，这样我们就不需要操心连接状态的管理；想要追求性能，使用长连接，我们就需要担心各种问题：比如 端对端连接的维护，连接的保活 。 长连接还常常被用来做数据的推送，我们大多数时候对通信的认知还是 request/response 模型，但 TCP 双工通信的性质决定了它还可以被用来做双向通信。在长连接之下，可以很方便的实现 push 模型，长连接的这一特性在本文并不会进行探讨，有兴趣的同学可以专门去搜索相关的文章。 短连接没有太多东西可以讲，所以下文我们将目光聚焦在长连接的一些问题上。纯讲理论未免有些过于单调，所以下文我借助一些 RPC 框架的实践来展开 TCP 的相关讨论。 服务治理框架中的长连接前面已经提到过，追求性能时，必然会选择使用长连接，所以借助 Dubbo 可以很好的来理解 TCP。我们开启两个 Dubbo 应用，一个 server 负责监听本地 20880 端口（众所周知，这是 Dubbo 协议默认的端口），一个 client 负责循环发送请求。执行 lsof -i:20880 命令可以查看端口的相关使用情况： *:20880 (LISTEN) 说明了 Dubbo 正在监听本地的 20880 端口，处理发送到本地 20880 端口的请求 后两条信息说明请求的发送情况，验证了 TCP 是一个双向的通信过程，由于我是在同一个机器开启了两个 Dubbo 应用，所以你能够看到是本地的 53078 端口与 20880 端口在通信。我们并没有手动设置 53078 这个客户端端口，它是随机的。通过这两条信息，阐释了一个事实： 即使是发送请求的一方，也需要占用一个端口 。 稍微说一下 FD 这个参数，他代表了 文件句柄 ，每新增一条连接都会占用新的文件句柄，如果你在使用 TCP 通信的过程中出现了 open too many files 的异常，那就应该检查一下，你是不是创建了太多连接，而没有关闭。细心的读者也会联想到长连接的另一个好处，那就是会占用较少的文件句柄。 长连接的维护因为客户端请求的服务可能分布在多个服务器上，客户端自然需要跟对端创建多条长连接，我们遇到的第一个问题就是如何维护长连接。 123456789// 客户端public class NettyHandler extends SimpleChannelHandler &#123; private final Map&lt;String, Channel&gt; channels = new ConcurrentHashMap&lt;String, Channel&gt;(); // &lt;ip:port, channel&gt;&#125;// 服务端public class NettyServer extends AbstractServer implements Server &#123; private Map&lt;String, Channel&gt; channels; // &lt;ip:port, channel&gt;&#125; 在 Dubbo 中，客户端和服务端都使用 ip:port 维护了端对端的长连接，Channel 便是对连接的抽象。我们主要关注 NettyHandler 中的长连接，服务端同时维护一个长连接的集合是 Dubbo 的额外设计，我们将在后面提到。 这里插一句，解释下为什么我认为客户端的连接集合要重要一点。TCP 是一个双向通信的协议，任一方都可以是发送者，接受者，那为什么还抽象了 Client 和 Server 呢？因为 建立连接这件事就跟谈念爱一样，必须要有主动的一方，你主动我们就会有故事 。Client 可以理解为主动建立连接的一方，实际上两端的地位可以理解为是对等的。 连接的保活这个话题就有的聊了，会牵扯到比较多的知识点。首先需要明确一点，为什么需要连接的保活？当双方已经建立了连接，但因为网络问题，链路不通，这样长连接就不能使用了。需要明确的一点是，通过 netstat，lsof 等指令查看到连接的状态处于 ESTABLISHED 状态并不是一件非常靠谱的事，因为连接可能已死，但没有被系统感知到，更不用提假死这种疑难杂症了。如果保证长连接可用是一件技术活。 连接的保活：KeepAlive首先想到的是 TCP 中的 KeepAlive 机制。KeepAlive 并不是 TCP 协议的一部分，但是大多数操作系统都实现了这个机制（所以需要在操作系统层面设置 KeepAlive 的相关参数）。KeepAlive 机制开启后，在一定时间内（一般时间为 7200s，参数 tcp_keepalive_time）在链路上没有数据传送的情况下，TCP 层将发送相应的 KeepAlive 探针以确定连接可用性，探测失败后重试 10（参数 tcp_keepalive_probes）次，每次间隔时间 75s（参数 tcp_keepalive_intvl），所有探测失败后，才认为当前连接已经不可用。 在 Netty 中开启 KeepAlive： 1bootstrap.option(ChannelOption.SO_KEEPALIVE, true) Linux 操作系统中设置 KeepAlive 相关参数，修改 /etc/sysctl.conf 文件： 123net.ipv4.tcp_keepalive_time=90net.ipv4.tcp_keepalive_intvl=15net.ipv4.tcp_keepalive_probes=2 KeepAlive 机制是在网络层面保证了连接的可用性 ，但站在应用框架层面我们认为这还不够。主要体现在三个方面： KeepAlive 的开关是在应用层开启的，但是具体参数（如重试测试，重试间隔时间）的设置却是操作系统级别的，位于操作系统的 /etc/sysctl.conf 配置中，这对于应用来说不够灵活。 KeepAlive 的保活机制只在链路空闲的情况下才会起到作用，假如此时有数据发送，且物理链路已经不通，操作系统这边的链路状态还是 ESTABLISHED，这时会发生什么？自然会走 TCP 重传机制，要知道默认的 TCP 超时重传，指数退避算法也是一个相当长的过程。 KeepAlive 本身是面向网络的，并不面向于应用，当连接不可用，可能是由于应用本身的 GC 频繁，系统 load 高等情况，但网络仍然是通的，此时，应用已经失去了活性，连接应该被认为是不可用的。 我们已经为应用层面的连接保活做了足够的铺垫，下面就来一起看看，怎么在应用层做连接保活。 连接的保活：应用层心跳终于点题了，文题中提到的 心跳 便是一个本文想要重点强调的另一个重要的知识点。上一节我们已经解释过了，网络层面的 KeepAlive 不足以支撑应用级别的连接可用性，本节就来聊聊应用层的心跳机制是实现连接保活的。 如何理解应用层的心跳？简单来说，就是客户端会开启一个定时任务，定时对已经建立连接的对端应用发送请求（这里的请求是特殊的心跳请求），服务端则需要特殊处理该请求，返回响应。如果心跳持续多次没有收到响应，客户端会认为连接不可用，主动断开连接。不同的服务治理框架对心跳，建连，断连，拉黑的机制有不同的策略，但大多数的服务治理框架都会在应用层做心跳，Dubbo/HSF 也不例外。 应用层心跳的设计细节以 Dubbo 为例，支持应用层的心跳，客户端和服务端都会开启一个 HeartBeatTask，客户端在 HeaderExchangeClient 中开启，服务端将在 HeaderExchangeServer 开启。文章开头埋了一个坑：Dubbo 为什么在服务端同时维护 Map&lt;String,Channel&gt; 呢？主要就是为了给心跳做贡献，心跳定时任务在发现连接不可用时，会根据当前是客户端还是服务端走不同的分支，客户端发现不可用，是重连；服务端发现不可用，是直接 close。 123456// HeartBeatTaskif (channel instanceof Client) &#123; ((Client) channel).reconnect();&#125; else &#123; channel.close();&#125; Dubbo 2.7.x 相比 2.6.x 做了定时心跳的优化，使用 HashedWheelTimer 更加精准的控制了只在连接闲置时发送心跳。 再看看 HSF 的实现，并没有设置应用层的心跳，准确的说，是在 HSF2.2 之后，使用 Netty 提供的 IdleStateHandler 更加优雅的实现了应用的心跳。 12ch.pipeline() .addLast(\"clientIdleHandler\", new IdleStateHandler(getHbSentInterval(), 0, 0)); 处理 userEventTriggered 中的 IdleStateEvent 事件 12345678@Overridepublic void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent) &#123; callConnectionIdleListeners(client, (ClientStream) StreamUtils.streamOfChannel(ctx.channel())); &#125; else &#123; super.userEventTriggered(ctx, evt); &#125;&#125; 对于客户端，HSF 使用 SendHeartbeat 来进行心跳，每次失败累加心跳失败的耗时，当超过最大限制时断开乱接；对于服务端 HSF 使用 CloseIdle 来处理闲置连接，直接关闭连接。一般来说，服务端的闲置时间会设置的稍长。 熟悉其他 RPC 框架的同学会发现，不同框架的心跳机制真的是差距非常大。心跳设计还跟连接创建，重连机制，黑名单连接相关，还需要具体框架具体分析。 除了定时任务的设计，还需要在协议层面支持心跳。最简单的例子可以参考 nginx 的健康检查，而针对 Dubbo 协议，自然也需要做心跳的支持，如果将心跳请求识别为正常流量，会造成服务端的压力问题，干扰限流等诸多问题。 其中 Flag 代表了 Dubbo 协议的标志位，一共 8 个地址位。低四位用来表示消息体数据用的序列化工具的类型（默认 hessian），高四位中，第一位为 1 表示是 request 请求，第二位为 1 表示双向传输（即有返回 response）， 第三位为 1 表示是心跳事件 。 心跳请求应当和普通请求区别对待。 注意和 HTTP 的 KeepAlive 区别对待 HTTP 协议的 KeepAlive 意图在于连接复用，同一个连接上串行方式传递请求 - 响应数据 TCP 的 KeepAlive 机制意图在于保活、心跳，检测连接错误。 这压根是两个概念。 KeepAlive 常见错误启用 TCP KeepAlive 的应用程序，一般可以捕获到下面几种类型错误 ETIMEOUT 超时错误，在发送一个探测保护包经过 (tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes) 时间后仍然没有接收到 ACK 确认情况下触发的异常，套接字被关闭 1java.io.IOException: Connection timed out EHOSTUNREACH host unreachable(主机不可达) 错误，这个应该是 ICMP 汇报给上层应用的。 1java.io.IOException: No route to host 链接被重置，终端可能崩溃死机重启之后，接收到来自服务器的报文，然物是人非，前朝往事，只能报以无奈重置宣告之。 1java.io.IOException: Connection reset by peer 总结有三种使用 KeepAlive 的实践方案： 默认情况下使用 KeepAlive 周期为 2 个小时，如不选择更改，属于误用范畴，造成资源浪费：内核会为每一个连接都打开一个保活计时器，N 个连接会打开 N 个保活计时器。 优势很明显： TCP 协议层面保活探测机制，系统内核完全替上层应用自动给做好了 内核层面计时器相比上层应用，更为高效 上层应用只需要处理数据收发、连接异常通知即可 数据包将更为紧凑 关闭 TCP 的 KeepAlive，完全使用应用层心跳保活机制。由应用掌管心跳，更灵活可控，比如可以在应用级别设置心跳周期，适配私有协议。 业务心跳 + TCP KeepAlive 一起使用，互相作为补充，但 TCP 保活探测周期和应用的心跳周期要协调，以互补方可，不能够差距过大，否则将达不到设想的效果。 各个框架的设计都有所不同，例如 Dubbo 使用的是方案三，但阿里内部的 HSF 框架则没有设置 TCP 的 KeepAlive，仅仅由应用心跳保活。和心跳策略一样，这和框架整体的设计相关。 欢迎关注我的微信公众号：「Kirito 的技术分享」","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://lexburner.github.io/tags/TCP/"}]},{"title":"Dubbo 中的 URL 统一模型","slug":"dubbo-url","date":"2018-12-25T02:24:09.000Z","updated":"2019-09-26T09:45:31.376Z","comments":true,"path":"dubbo-url/","link":"","permalink":"http://lexburner.github.io/dubbo-url/","excerpt":"定义在不谈及 dubbo 时，我们大多数人对 URL 这个概念并不会感到陌生。统一资源定位器 (RFC1738――Uniform Resource Locators (URL)）应该是最广为人知的一个 RFC 规范，它的定义也非常简单 因特网上的可用资源可以用简单字符串来表示，该文档就是描述了这种字符串的语法和语义。而这些字符串则被称为：“统一资源定位器”（URL） 一个标准的 URL 格式 至多可以包含如下的几个部分 1protocol://username:password@host:port/path?key=value&amp;key=value","text":"定义在不谈及 dubbo 时，我们大多数人对 URL 这个概念并不会感到陌生。统一资源定位器 (RFC1738――Uniform Resource Locators (URL)）应该是最广为人知的一个 RFC 规范，它的定义也非常简单 因特网上的可用资源可以用简单字符串来表示，该文档就是描述了这种字符串的语法和语义。而这些字符串则被称为：“统一资源定位器”（URL） 一个标准的 URL 格式 至多可以包含如下的几个部分 1protocol://username:password@host:port/path?key=value&amp;key=value 一些典型 URL 123http://www.facebook.com/friends?param1=value1&amp;amp;param2=value2https://username:password@10.20.130.230:8080/list?version=1.0.0ftp://username:password@192.168.1.7:21/1/read.txt 当然，也有一些 不太符合常规的 URL，也被归类到了 URL 之中 1234567891011121314151617181920192.168.1.3:20880url protocol = null, url host = 192.168.1.3, port = 20880, url path = nullfile:///home/user1/router.js?type=scripturl protocol = file, url host = null, url path = home/user1/router.jsfile://home/user1/router.js?type=script&lt;br&gt;url protocol = file, url host = home, url path = user1/router.jsfile:///D:/1/router.js?type=scripturl protocol = file, url host = null, url path = D:/1/router.jsfile:/D:/1/router.js?type=script同上 file:///D:/1/router.js?type=script/home/user1/router.js?type=scripturl protocol = null, url host = null, url path = home/user1/router.jshome/user1/router.js?type=scripturl protocol = null, url host = home, url path = user1/router.js Dubbo 中的 URL在 dubbo 中，也使用了类似的 URL，主要用于在各个扩展点之间传递数据，组成此 URL 对象的具体参数如下: protocol：一般是 dubbo 中的各种协议 如：dubbo thrift http zk username/password：用户名 / 密码 host/port：主机 / 端口 path：接口名称 parameters：参数键值对 12345678910111213141516171819202122public URL(String protocol, String username, String password, String host, int port, String path, Map&lt;String, String&gt; parameters) &#123; if ((username == null || username.length() == 0) &amp;&amp; password != null &amp;&amp; password.length()&gt; 0) &#123; throw new IllegalArgumentException(\"Invalid url, password without username!\"); &#125; this.protocol = protocol; this.username = username; this.password = password; this.host = host; this.port = (port &lt; 0 ? 0 : port); this.path = path; // trim the beginning \"/\" while(path != null &amp;&amp; path.startsWith(\"/\")) &#123; path = path.substring(1); &#125; if (parameters == null) &#123; parameters = new HashMap&lt;String, String&gt;(); &#125; else &#123; parameters = new HashMap&lt;String, String&gt;(parameters); &#125; this.parameters = Collections.unmodifiableMap(parameters);&#125; 可以看出，dubbo 认为 protocol，username，passwored，host，port，path 是主要的 URL 参数，其他键值对村房子啊 parameters 之中。 一些典型的 Dubbo URL 12345678dubbo://192.168.1.6:20880/moe.cnkirito.sample.HelloService?timeout=3000描述一个 dubbo 协议的服务zookeeper://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?application=demo-consumer&amp;dubbo=2.0.2&amp;interface=org.apache.dubbo.registry.RegistryService&amp;pid=1214&amp;qos.port=33333&amp;timestamp=1545721981946描述一个 zookeeper 注册中心consumer://30.5.120.217/org.apache.dubbo.demo.DemoService?application=demo-consumer&amp;category=consumers&amp;check=false&amp;dubbo=2.0.2&amp;interface=org.apache.dubbo.demo.DemoService&amp;methods=sayHello&amp;pid=1209&amp;qos.port=33333&amp;side=consumer&amp;timestamp=1545721827784描述一个消费者 可以说，任意的一个领域中的一个实现都可以认为是一类 URL，dubbo 使用 URL 来统一描述了元数据，配置信息，贯穿在整个框架之中。 URL 相关的生命周期解析服务基于 dubbo.jar 内的 META-INF/spring.handlers 配置，Spring 在遇到 dubbo 名称空间时，会回调 DubboNamespaceHandler。 所有 dubbo 的标签，都统一用 DubboBeanDefinitionParser 进行解析，基于一对一属性映射，将 XML 标签解析为 Bean 对象。 在 ServiceConfig.export() 或 ReferenceConfig.get() 初始化时，将 Bean 对象转换 URL 格式，所有 Bean 属性转成 URL 的参数。 然后将 URL 传给协议扩展点，基于扩展点自适应机制，根据 URL 的协议头，进行不同协议的服务暴露或引用。 暴露服务1. 只暴露服务端口： 在没有注册中心，直接暴露提供者的情况下，ServiceConfig 解析出的 URL 的格式为：dubbo://service-host/com.foo.FooService?version=1.0.0。 基于扩展点自适应机制，通过 URL 的 dubbo:// 协议头识别，直接调用 DubboProtocol 的 export() 方法，打开服务端口。 2. 向注册中心暴露服务： 在有注册中心，需要注册提供者地址的情况下，ServiceConfig 解析出的 URL 的格式为: registry://registry-host/org.apache.dubbo.registry.RegistryService?export=URL.encode(&quot;dubbo://service-host/com.foo.FooService?version=1.0.0&quot;)， 基于扩展点自适应机制，通过 URL 的 registry:// 协议头识别，就会调用 RegistryProtocol 的 export() 方法，将 export 参数中的提供者 URL，先注册到注册中心。 再重新传给 Protocol 扩展点进行暴露： dubbo://service-host/com.foo.FooService?version=1.0.0，然后基于扩展点自适应机制，通过提供者 URL 的 dubbo:// 协议头识别，就会调用 DubboProtocol 的 export() 方法，打开服务端口。 引用服务1. 直连引用服务： 在没有注册中心，直连提供者的情况下，ReferenceConfig 解析出的 URL 的格式为：dubbo://service-host/com.foo.FooService?version=1.0.0。 基于扩展点自适应机制，通过 URL 的 dubbo:// 协议头识别，直接调用 DubboProtocol 的 refer() 方法，返回提供者引用。 2. 从注册中心发现引用服务： 在有注册中心，通过注册中心发现提供者地址的情况下，ReferenceConfig 解析出的 URL 的格式为：registry://registry-host/org.apache.dubbo.registry.RegistryService?refer=URL.encode(&quot;consumer://consumer-host/com.foo.FooService?version=1.0.0&quot;)。 基于扩展点自适应机制，通过 URL 的 registry:// 协议头识别，就会调用 RegistryProtocol 的 refer() 方法，基于 refer 参数中的条件，查询提供者 URL，如： dubbo://service-host/com.foo.FooService?version=1.0.0。 基于扩展点自适应机制，通过提供者 URL 的 dubbo:// 协议头识别，就会调用 DubboProtocol 的 refer() 方法，得到提供者引用。 然后 RegistryProtocol 将多个提供者引用，通过 Cluster 扩展点，伪装成单个提供者引用返回。 URL 统一模型的意义对于 dubbo 中的 URL，有人理解为配置总线，有人理解为统一配置模型，说法虽然不同，但都是在表达一个意思，这样的 URL 在 dubbo 中被当做是 公共契约，所有扩展点参数都包含 URL 参数，URL 作为上下文信息贯穿整个扩展点设计体系。 在没有 URL 之前，只能以字符串传递参数，不停的解析和拼装，导致相同类型的接口，参数时而 Map, 时而 Parameters 类包装： 12export(String url) createExporter(String host, int port, Parameters params) 使用 URL 一致性模型： 12export(URL url) createExporter(URL url) 在最新的 dubbo 代码中，我们可以看到大量使用 URL 来进行上下文之间信息的传递，这样的好处是显而易见的： 使得代码编写者和阅读者能够将一系列的参数联系起来，进而形成规范，使得代码易写，易读。 可扩展性强，URL 相当于参数的集合 (相当于一个 Map)，他所表达的含义比单个参数更丰富，当我们在扩展代码时，可以将新的参数追加到 URL 之中，而不需要改变入参，返参的结构。 统一模型，它位于 org.apache.dubbo.common 包中，各个扩展模块都可以使用它作为参数的表达形式，简化了概念，降低了代码的理解成本。 如果你能够理解 final 契约和 restful 契约，那我相信你会很好地理解 URL 契约。契约的好处我还是啰嗦一句：大家都这么做，就形成了默契，沟通是一件很麻烦的事，统一 URL 模型可以省去很多沟通成本，这边是 URL 统一模型存在的意义。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"DUBBO","slug":"DUBBO","permalink":"http://lexburner.github.io/tags/DUBBO/"}]},{"title":"PolarDB 数据库性能大赛 Java 选手分享","slug":"polardb-race","date":"2018-12-10T10:43:56.000Z","updated":"2019-09-26T09:45:31.456Z","comments":true,"path":"polardb-race/","link":"","permalink":"http://lexburner.github.io/polardb-race/","excerpt":"1 前言 国际惯例，先报成绩，熬了无数个夜晚，最后依旧被绝杀出了第一页，最终排名第 21 名。前十名的成绩分布为 413.69~416.94，我最终的耗时是 422.43。成绩虽然不是特别亮眼，但与众多参赛选手使用 C++ 作为参赛语言不同，我使用的是 Java，一方面是我 C++ 的能力早已荒废，另一方面是我想验证一下使用 Java 编写存储引擎是否与 C++ 差距巨大 (当然，主要还是前者 QAQ)。所以在本文中，我除了介绍整体的架构之外，还会着重笔墨来探讨 Java 编写存储类型应用的一些最佳实践，文末会给出 github 的开源地址。","text":"1 前言 国际惯例，先报成绩，熬了无数个夜晚，最后依旧被绝杀出了第一页，最终排名第 21 名。前十名的成绩分布为 413.69~416.94，我最终的耗时是 422.43。成绩虽然不是特别亮眼，但与众多参赛选手使用 C++ 作为参赛语言不同，我使用的是 Java，一方面是我 C++ 的能力早已荒废，另一方面是我想验证一下使用 Java 编写存储引擎是否与 C++ 差距巨大 (当然，主要还是前者 QAQ)。所以在本文中，我除了介绍整体的架构之外，还会着重笔墨来探讨 Java 编写存储类型应用的一些最佳实践，文末会给出 github 的开源地址。 2 赛题概览比赛总体分成了初赛和复赛两个阶段，整体要求实现一个简化、高效的 kv 存储引擎 初赛要求支持 Write、Read 接口。 12public abstract void write(byte[] key, byte[] value);public abstract byte[] read(byte[] key); 复赛在初赛题目基础上，还需要额外实现一个 Range 接口。 1public abstract void range(byte[] lower, byte[] upper, AbstractVisitor visitor); 程序评测逻辑 分为 2 个阶段：1）Recover 正确性评测：此阶段评测程序会并发写入特定数据（key 8B、value 4KB）同时进行任意次 kill -9 来模拟进程意外退出（参赛引擎需要保证进程意外退出时数据持久化不丢失），接着重新打开 DB，调用 Read、Range 接口来进行正确性校验 2）性能评测 随机写入：64 个线程并发随机写入，每个线程使用 Write 各写 100 万次随机数据（key 8B、value 4KB） 随机读取：64 个线程并发随机读取，每个线程各使用 Read 读取 100 万次随机数据 顺序读取：64 个线程并发顺序读取，每个线程各使用 Range 有序（增序）遍历全量数据 2 次注：2.2 阶段会对所有读取的 kv 校验是否匹配，如不通过则终止，评测失败；2.3 阶段除了对迭代出来每条的 kv 校 验是否匹配外，还会额外校验是否严格字典序递增，如不通过则终止，评测失败。 语言限定：C++ &amp; JAVA，一起排名 3 赛题剖析关于文件 IO 操作的一些基本常识，我已经在专题文章中进行了介绍，如果你没有浏览那篇文章，建议先行浏览一下：文件 IO 操作的一些最佳实践。再回归赛题，先对赛题中的几个关键词来进行解读。 3.1 key 8B, value 4kbkey 为固定的 8 字节，因此可使用 long 来表示。 value 为 4kb，这节省了我们很大的工作量，因为 4kb 的整数倍落盘是非常磁盘 IO 友好的。 value 为 4kb 的另一个好处是我们再内存做索引时，可以使用 int 而不是 long，来记录数据的逻辑偏移量：LogicOffset = PhysicalOffset / 4096，可以将 offset 的内存占用量减少一半。 3.2 kill -9 数据不丢失首先赛题明确表示会进行 kill -9 并验证数据的一致性，这加大了我们在内存中做 write buffer 的难度。但它并没有要求断电不丢失，这间接地阐释了一点：我们可以使用 pageCache 来做写入缓存，在具体代码中我使用了 PageCache 来充当数据和索引的写入缓冲（两者策略不同）。同时这点也限制了参赛选手，不能使用 AIO 这样的异步落盘方式。 3.3 分阶段测评赛题分为了随机写，随机读，顺序读三个阶段，每个阶段都会重新 open，且不会发生随机写到一半校验随机读这样的行为，所以我们在随机写阶段不需要在内存维护索引，而是直接落盘。随机读和顺序读阶段，磁盘均存在数据，open 阶段需要恢复索引，可以使用多线程并发恢复。 同时，赛题还有存在一些隐性的测评细节没有披露给大家，但通过测试，我们可以得知这些信息。 3.4 清空 PageCache 的耗时虽然我们可以使用 PageCache，但评测程序在每个阶段之后都使用脚本清空了 PageCache，并且将这部分时间也算进了最终的成绩之中，所以有人感到奇怪：三个阶段的耗时相加比输出出来的成绩要差，其实那几秒便是清空 PageCache 的耗时。 123456#清理 pagecache (页缓存)sysctl -w vm.drop_caches=1#清理 dentries（目录缓存）和 inodessysctl -w vm.drop_caches=2#清理 pagecache、dentries 和 inodessysctl -w vm.drop_caches=3 这一点启发我们，不能毫无节制的使用 PageCache，也正是因为这一点，一定程度上使得 Direct IO 这一操作成了本次竞赛的银弹。 3.5 key 的分布这一个隐性条件可谓是本次比赛的关键，因为它涉及到 Range 部分的架构设计。本次比赛的 key 共计 6400w，但是他们的分布都是 均匀 的，在 《文件 IO 操作的一些最佳实践》 一文中我们已经提到了数据分区的好处，可以大大减少顺序读写的锁冲突，而 key 的分布均匀这一特性，启发我们在做数据分区时，可以按照 key 的搞 n 位来做 hash，从而确保 key 两个分区之间整体有序 (分区内部无序)。实际我尝试了将数据分成 1024、2048 个分区，效果最佳。 3.6 Range 的缓存设计赛题要求 64 个线程 Range 两次全量的数据，限时 1h，这也启发了我们，如果不对数据进行缓存，想要在 1h 内完成比赛是不可能的，所以，我们的架构设计应该尽量以 Range 为核心，兼顾随机写和随机读。Range 部分也是最容易拉开差距的一个环节。 4 架构详解首先需要明确的是，随机写指的是 key 的写入是随机的，但我们可以根据 key hash，将随机写转换为对应分区文件的顺序写。 123456789/** * using high ten bit of the given key to determine which file it hits. */public class HighTenPartitioner implements Partitionable &#123; @Override public int getPartition(byte[] key) &#123; return ((key[0] &amp; 0xff)&lt;&lt; 2) | ((key[1] &amp; 0xff)&gt;&gt; 6); &#125;&#125; 明确了高位分区的前提再来看整体的架构就变得明朗了 全局视角 分区视角 内存视角 内存中仅仅维护有序的 key[1024][625000] 数组和 offset[1024][625000] 数组。 上述两张图对整体的架构进行了一个很好的诠释，利用数据分布均匀的特性，可以将全局数据 hash 成 1024 个分区，在每个分区中存放两类文件：索引文件和数据文件。在随机写入阶段，根据 key 获得该数据对应分区位置，并按照时序，顺序追加到文件末尾，将全局随机写转换为局部顺序写。利用索引和数据一一对应的特性，我们也不需要将 data 的逻辑偏移量落盘，在 recover 阶段可以按照恢复 key 的次序，反推出 value 的逻辑偏移量。 在 range 阶段，由于我们事先按照 key 的高 10 为做了分区，所以我们可以认定一个事实，patition(N) 中的任何一个数据一定大于 partition(N-1) 中的任何一个数据，于是我们可以采用大块读，将一个 partition 整体读进内存，供 64 个 visit 线程消费。到这儿便奠定了整体的基调：读盘线程负责按分区读盘进入内存，64 个 visit 线程负责消费内存，按照 key 的次序随机访问内存，进行 Visitor 的回调。 5 随机写流程介绍完了整体架构，我们分阶段来看一下各个阶段的一些细节优化点，有一些优化在各个环节都会出现，未避免重复，第二次出现的同一优化点我就不赘述了，仅一句带过。 使用 pageCache 实现写入缓冲区主要看数据落盘，后讨论索引落盘。磁盘 IO 类型的比赛，第一步便是测量磁盘的 IOPS 以及多少个线程一次读写多大的缓存能够打满 IO，在固定 64 线程写入的前提下，16kb，64kb 均可以达到最理想 IOPS，所以理所当然的想到，可以为每一个分区分配一个写入缓存，凑齐 4 个 value 落盘。但是此次比赛，要做到 kill -9 不丢失数据，不能简单地在内存中分配一个 ByteBuffer.allocate(4096 * 4);， 而是可以考虑使用 mmap 内存映射出一片写入缓冲，凑齐 4 个刷盘，这样在 kill -9 之后，PageCache 不会丢失。实测 16kb 落盘比 4kb 落盘要快 6s 左右。 索引文件的落盘则没有太大的争议，由于 key 的数据量为固定的 8B，所以 mmap 可以发挥出它写小数据的优势，将 pageCache 利用起来，实测 mmap 相比 filechannel 写索引要快 3s 左右，相信如果把 polardb 这块盘换做其他普通的 ssd，这个数值还要增加。 写入时不维护内存索引，不写入数据偏移一开始审题不清，在随机写之后误以为会立刻随机读，实际上每个阶段都是独立的，所以不需要在写入时维护内存索引；其次，之前的架构图中也已经提及，不需要写入连带 key+offset 一起写入文件，recover 阶段可以按照恢复索引的顺序，反推出 data 的逻辑偏移，因为我们的 key 和 data 在同一个分区内的位置是一一对应的。 6 恢复流程recover 阶段的逻辑实际上包含在程序的 open 接口之中，我们需要再数据库引擎启动时，将索引从数据文件恢复到内存之中，在这之中也存在一些细节优化点。 由于 1024 个分区的存在，我们可以使用 64 个线程 (经验值) 并发地恢复索引，使用快速排序对 key[1024][625000] 数组和 offset[1024][625000] 进行 sort，之后再 compact，对 key 进行去重。需要注意的一点是，不要使用结构体，将 key 和 offset 封装在一起，这会使得排序和之后的二分效率非常低，这之中涉及到 CPU 缓存行的知识点，不了解的读者可以翻阅我之前的博客: 《CPU Cache 与缓存行》 12345// wrongpublic class KeyOffset &#123; long key; int offset;&#125; 整个 recover 阶段耗时为 1s，跟 cpp 选手交流后发现恢复流程比之慢了 600ms，这中间让我觉得比较诡异，加载索引和排序不应该这么慢才对，最终也没有优化成功。 7 随机读流程随机读流程没有太大的优化点，优化空间实在有限，实现思路便是先根据 key 定位到分区，之后在有序的 key 数据中二分查找到 key/offset，拿到 data 的逻辑偏移和分区编号，便可以愉快的随机读了，随机读阶段没有太大的优化点，但仍然比 cpp 选手慢了 2-3s，可能是语言无法越过的差距。 8 顺序读流程Range 环节是整个比赛的大头，也是拉开差距的分水岭。前面我们已经大概提到了 Range 的整体思路是一个生产者消费者模型，n 个生成者负责从磁盘读数据进入内存（n 作为变量，通过 benchmark 来确定多少合适，最终实测 n 为 4 时效果最佳），64 个消费者负责调用 visit 回调，来验证数据，visit 过程就是随机读内存的过程。在 Range 阶段，剩余的内存还有大概 1G 左右，所以我分配了 4 个堆外缓冲，一个 256M，从而可以缓存 4 个分区的数据，并且，我为每一个分区分配了一个读盘线程，负责 load 数据进入缓存，供 64 个消费者消费。 具体的顺序读架构可以参见下图： 大体来看，便是 4 个 fetch 线程负责读盘，fetch thread n 负责 partitionNo % 4 == n 编号的分区，完成后通知 visit 消费。这中间充斥着比较多的互斥等待逻辑，并未在图中体现出来，大体如下： fetch thread 1~4 加载磁盘数据进入缓存是并发的 visit group 1~64 访问同一个 buffer 是并发的 visit group 1~64 访问不同 partition 对应的 buffer 是按照次序来进行的 (打到全局有序) 加载 partitonN 会阻塞 visit bufferN，visit bufferN 会阻塞加载 partitionN+4(相当于复用 4 块缓存) 大块的加载读进缓存，最大程度复用，是 ReadSeq 部分的关键。顺序读两轮的成绩在 196~198s 左右，相比 C++ 又慢了 4s 左右。 9 魔鬼在细节中这儿是个分水岭，介绍完了整体架构和四个阶段的细节实现，下面就是介绍下具体的优化点了。 10 Java 实现 Direct IO由于这次比赛将 drop cache 的时间算进了测评程序之中，所以在不必要的地方应当尽量避免 pageCache，也就是说除了写索引之外，其他阶段不应该出现 pageCache。这对于 Java 选手来说可能是不小的障碍，因为 Java 原生没有提供 Direct IO，需要自己封装一套 JNA 接口，封装这套接口借鉴了开源框架 jaydio 的思路，感谢 @尘央的协助，大家可以在文末的代码中看到实现细节。这一点可以说是拦住了一大票 Java 选手。 Direct IO 需要注意的两个细节： 分配的内存需要对齐，对应 jna 方法：posix_memalign 写入的数据需要对齐通常是 pageSize 的整数倍，实际使用了 pread 的 O_DIRECT 11 直接内存优于堆内内存这一点在《文件 IO 操作的一些最佳实践》中有所提及，堆外内存的两大好处是减少了一份内存拷贝，并且对 gc 友好，在 Direct IO 的实现中，应该配备一套堆外内存的接口，才能发挥出最大的功效。尤其在 Range 阶段，一个缓存区的大小便对应一个 partition 数据分区的大小：256M，大块的内存，更加适合用 DirectByteBuffer 装载。 12 JVM 调优1-server -Xms2560m -Xmx2560m -XX:MaxDirectMemorySize=1024m -XX:NewRatio=4 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:-UseBiasedLocking 众所周知 newRatio 控制的是 young 区和 old 区大小的比例，官方推荐参数为 -XX:NewRatio=1，很多不注意的 Java 选手可能没有意识去修改它，会在无形中被 gc 拖累。经过和 @阿杜的讨论，最终得出的结论： young 区过大，对象在年轻代待得太久，多次拷贝 old 区过小，会频繁触发 old 区的 cms gc 在比赛中这显得尤为重要，-XX:NewRatio=4 放大老年代可以有效的减少 cms gc 的次数，将 126 次 cms gc，下降到最终的 5 次。 13 池化对象无论是 apache 的 ObjectPool 还是 Netty 中的 Recycler，还是 RingBuffer 中预先分配的对象，都在传达一种思想，对于那些反复需要 new 出来的东西，都可以池化，分配内存再回收，这也是一笔不小的开销。在此次比赛的场景下，没必要大费周章地动用对象池，直接一个 ThreadLocal 即可搞定，事实上我对 key/value 的写入和读取都进行了 ThreadLocal 的缓存，做到了永远不再循环中分配对象。 14 减少线程切换无论是网络 IO 还是磁盘 IO，io worker 线程的时间片都显得尤为的可贵，在我的架构中，range 阶段主要分为了两类线程：64 个 visit 线程并发随机读内存，4 个 io 线程并发读磁盘。木桶效应，我们很容易定位到瓶颈在于 4 个 io 线程，在 wait/notify 的模型中，为了尽可能的减少 io 线程的时间片流失，可以考虑使用 while(true) 进行轮询，而 visit 线程则可以 sleep(1us) 避免 cpu 空转带来的整体性能下降，由于评测机拥有 64 core，所以这样的分配算是较为合理的，为此我实现了一个简单粗暴的信号量。 12345678910111213141516171819202122232425262728public class LoopQuerySemaphore &#123; private volatile boolean permit; public LoopQuerySemaphore(boolean permit) &#123; this.permit = permit; &#125; // for 64 visit thread public void acquire() throws InterruptedException &#123; while (!permit) &#123; Thread.sleep(0,1); &#125; permit = false; &#125; // for 4 fetch thread public void acquireNoSleep() throws InterruptedException &#123; while (!permit) &#123; &#125; permit = false; &#125; public void release() &#123; permit = true; &#125;&#125; 正确的在 IO 中 acquireNoSleep，在 Visit 中 acquire，可以让成绩相比使用普通的阻塞 Semaphore 提升 6s 左右。 15 绑核线上机器的抖动在所难免，避免 IO 线程的切换也并不仅仅能够用依靠 while(true) 的轮询，一个 CPU 级别的优化便是腾出 4 个核心专门给 IO 线程使用，完全地避免 IO 线程的时间片争用。在 Java 中这也不难实现，依赖万能的 github，我们可以轻松地实现 Affinity。github 传送门：https://github.com/OpenHFT/Java-Thread-Affinity 使用方式： 123try (final AffinityLock al2 = AffinityLock.acquireLock()) &#123; // do fetch ...&#125; 这个方式可以让你的代码快 1~2 s，并且保持测评的稳定性。 0 聊聊 FileChannel，MMAP，Direct IO，聊聊比赛我在最终版本的代码中，几乎完全抛弃了 FileChannel，事实上，在不 Drop Cache 的场景下，它已经可以发挥出它利用 PageCache 的一些优势，并且优秀的 Java 存储引擎都主要使用了 FileChannel 来进行读写，在少量的场景下，使用了 MMAP 作为辅助，毕竟，MMAP 在写小数据量文件时存在其价值。 另外需要注意的一点，在跟 @96 年的亚普长谈的一个夜晚，发现 FileChannel 中出人意料的一个实现，在分配对内内存时，它仍然会拷贝一份堆外内存，这对于实际使用 FileChannel 的场景需要额外注意，这部分意料之外分配的内存很容易导致线上的问题（实际上已经遇到了，和 glibc 的 malloc 相关，当 buffer 大于 128k 时，会使用 mmap 分配一块内存作为缓存） 说回 FileChannel，MMAP，最容易想到的是 RocketMQ 之中对两者灵活的运用，不知道在其他 Java 实现的存储引擎之中，是不是可以考虑使用 Direct IO 来提升存储引擎的性能呢？我们可以设想一下，利用有限并且少量的 PageCache 来保证一致性，在主流程中使用 Direct IO 配合顺序读写是不是一种可以配套使用的方案，不仅仅 PolarDB，算作是参加本次比赛给予我的一个启发。 虽然无缘决赛，但使用 Java 取得这样的成绩还算不是特别难过，在 6400w 数据随机写，随机读，顺序读的场景下，Java 可以做到仅仅相差 C++ 不到 10s 的 overhead，我倒是觉得完全是可以接受的，哈哈。还有一些小的优化点就不在此赘述了，欢迎留言与我交流优化点和比赛感悟。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"性能挑战赛","slug":"性能挑战赛","permalink":"http://lexburner.github.io/categories/性能挑战赛/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://lexburner.github.io/tags/数据库/"}]},{"title":"文件 IO 操作的一些最佳实践","slug":"file-io-best-practise","date":"2018-11-27T15:22:22.000Z","updated":"2019-09-26T09:45:30.439Z","comments":true,"path":"file-io-best-practise/","link":"","permalink":"http://lexburner.github.io/file-io-best-practise/","excerpt":"背景已经过去的中间件性能挑战赛，和正在进行中的 第一届 PolarDB 数据性能大赛 都涉及到了文件操作，合理地设计架构以及正确地压榨机器的读写性能成了比赛中获取较好成绩的关键。正在参赛的我收到了几位公众号读者朋友的反馈，他们大多表达出了这样的烦恼：“对比赛很感兴趣，但不知道怎么入门”，“能跑出成绩，但相比前排的选手，成绩相差 10 倍有余”…为了能让更多的读者参与到之后相类似的比赛中来，我简单整理一些文件 IO 操作的最佳实践，而不涉及整体系统的架构设计，希望通过这篇文章的介绍，让你能够欢快地参与到之后类似的性能挑战赛之中来。","text":"背景已经过去的中间件性能挑战赛，和正在进行中的 第一届 PolarDB 数据性能大赛 都涉及到了文件操作，合理地设计架构以及正确地压榨机器的读写性能成了比赛中获取较好成绩的关键。正在参赛的我收到了几位公众号读者朋友的反馈，他们大多表达出了这样的烦恼：“对比赛很感兴趣，但不知道怎么入门”，“能跑出成绩，但相比前排的选手，成绩相差 10 倍有余”…为了能让更多的读者参与到之后相类似的比赛中来，我简单整理一些文件 IO 操作的最佳实践，而不涉及整体系统的架构设计，希望通过这篇文章的介绍，让你能够欢快地参与到之后类似的性能挑战赛之中来。 知识点梳理本文主要关注的 Java 相关的文件操作，理解它们需要一些前置条件，比如 PageCache，Mmap(内存映射)，DirectByteBuffer(堆外缓存)，顺序读写，随机读写… 不一定需要完全理解，但至少知道它们是个啥，因为本文将会主要围绕这些知识点来展开描述。 初识 FileChannel 和 MMAP首先，文件 IO 类型的比赛最重要的一点，就是选择好读写文件的方式，那 JAVA 中文件 IO 有多少种呢？原生的读写方式大概可以被分为三种：普通 IO，FileChannel(文件通道)，MMAP(内存映射)。区分他们也很简单，例如 FileWriter,FileReader 存在于 java.io 包中，他们属于普通 IO；FileChannel 存在于 java.nio 包中，属于 NIO 的一种，但是注意 NIO 并不一定意味着非阻塞，这里的 FileChannel 就是阻塞的；较为特殊的是后者 MMAP，它是由 FileChannel 调用 map 方法衍生出来的一种特殊读写文件的方式，被称之为内存映射。 使用 FIleChannel 的方式： 1FileChannel fileChannel = new RandomAccessFile(new File(\"db.data\"), \"rw\").getChannel(); 获取 MMAP 的方式： 1MappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, filechannel.size(); MappedByteBuffer 便是 JAVA 中 MMAP 的操作类。 面向于字节传输的传统 IO 方式遭到了我们的唾弃，我们重点探讨 FileChannel 和 MMAP 这两种读写方式的区别。 FileChannel 读写123456789101112131415// 写byte[] data = new byte[4096];long position = 1024L;// 指定 position 写入 4kb 的数据fileChannel.write(ByteBuffer.wrap(data), position);// 从当前文件指针的位置写入 4kb 的数据fileChannel.write(ByteBuffer.wrap(data));// 读ByteBuffer buffer = ByteBuffer.allocate(4096);long position = 1024L;// 指定 position 读取 4kb 的数据fileChannel.read(buffer,position)；// 从当前文件指针的位置读取 4kb 的数据fileChannel.read(buffer); FileChannel 大多数时候是和 ByteBuffer 这个类打交道，你可以将它理解为一个 byte[] 的封装类，提供了丰富的 API 去操作字节，不了解的同学可以去熟悉下它的 API。值得一提的是，write 和 read 方法均是 线程安全 的，FileChannel 内部通过一把 private final Object positionLock = new Object(); 锁来控制并发。 FileChannel 为什么比普通 IO 要快呢？这么说可能不严谨，因为你要用对它，FileChannel 只有在一次写入 4kb 的整数倍时，才能发挥出实际的性能，这得益于 FileChannel 采用了 ByteBuffer 这样的内存缓冲区，让我们可以非常精准的控制写盘的大小，这是普通 IO 无法实现的。4kb 一定快吗？也不严谨，这主要取决你机器的磁盘结构，并且受到操作系统，文件系统，CPU 的影响，例如中间件性能挑战赛时的那块盘，一次至少写入 64kb 才能发挥出最高的 IOPS。 然而 PolarDB 这块盘就完全不一样了，可谓是异常彪悍，具体是如何的表现由于比赛仍在进行中，不予深究，但凭借着 benchmark everyting 的技巧，我们完全可以测出来。 另外一点，成就了 FileChannel 的高效，介绍这点之前，我想做一个提问：FileChannel 是直接把 ByteBuffer 中的数据写入到磁盘吗？思考几秒…答案是：NO。ByteBuffer 中的数据和磁盘中的数据还隔了一层，这一层便是 PageCache，是用户内存和磁盘之间的一层缓存。我们都知道磁盘 IO 和内存 IO 的速度可是相差了好几个数量级。我们可以认为 filechannel.write 写入 PageCache 便是完成了落盘操作，但实际上，操作系统最终帮我们完成了 PageCache 到磁盘的最终写入，理解了这个概念，你就应该能够理解 FileChannel 为什么提供了一个 force() 方法，用于通知操作系统进行及时的刷盘。 同理，当我们使用 FileChannel 进行读操作时，同样经历了：磁盘 -&gt;PageCache-&gt; 用户内存这三个阶段，对于日常使用者而言，你可以忽略掉 PageCache，但作为挑战者参赛，PageCache 在调优过程中是万万不能忽视的，关于读操作这里不做过多的介绍，我们再下面的小结中还会再次提及，这里当做是引出 PageCache 的概念。 MMAP 读写12345678910111213141516171819// 写byte[] data = new byte[4];int position = 8;// 从当前 mmap 指针的位置写入 4b 的数据mappedByteBuffer.put(data);// 指定 position 写入 4b 的数据MappedByteBuffer subBuffer = mappedByteBuffer.slice();subBuffer.position(position);subBuffer.put(data);// 读byte[] data = new byte[4];int position = 8;// 从当前 mmap 指针的位置读取 4b 的数据mappedByteBuffer.get(data)；// 指定 position 读取 4b 的数据MappedByteBuffer subBuffer = mappedByteBuffer.slice();subBuffer.position(position);subBuffer.get(data); FileChannel 已经足够强大了，MappedByteBuffer 还能玩出什么花来呢？请容许我卖个关子先，先介绍一下 MappedByteBuffer 的使用注意点。 当我们执行 fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 1.5 * 1024 * 1024 * 1024); 之后，观察一下磁盘上的变化，会立刻获得一个 1.5G 的文件，但此时文件的内容全部是 0（字节 0）。这符合 MMAP 的中文描述：内存映射文件，我们之后对内存中 MappedByteBuffer 做的任何操作，都会被最终映射到文件之中， mmap 把文件映射到用户空间里的虚拟内存，省去了从内核缓冲区复制到用户空间的过程，文件中的位置在虚拟内存中有了对应的地址，可以像操作内存一样操作这个文件，相当于已经把整个文件放入内存，但在真正使用到这些数据前却不会消耗物理内存，也不会有读写磁盘的操作，只有真正使用这些数据时，也就是图像准备渲染在屏幕上时，虚拟内存管理系统 VMS 才根据缺页加载的机制从磁盘加载对应的数据块到物理内存进行渲染。这样的文件读写文件方式少了数据从内核缓存到用户空间的拷贝，效率很高 看了稍微官方一点的描述，你可能对 MMAP 有了些许的好奇，有这么厉害的黑科技存在的话，还有 FileChannel 存在的意义吗！并且网上很多文章都在说，MMAP 操作大文件性能比 FileChannel 搞出一个数量级！然而，通过我比赛的认识，MMAP 并非是文件 IO 的银弹，它只有在 一次写入很小量数据的场景 下才能表现出比 FileChannel 稍微优异的性能。紧接着我还要告诉你一些令你沮丧的事，至少在 JAVA 中使用 MappedByteBuffer 是一件非常麻烦并且痛苦的事，主要表现为三点： MMAP 使用时必须实现指定好内存映射的大小，并且一次 map 的大小限制在 1.5G 左右，重复 map 又会带来虚拟内存的回收、重新分配的问题，对于文件不确定大小的情形实在是太不友好了。 MMAP 使用的是虚拟内存，和 PageCache 一样是由操作系统来控制刷盘的，虽然可以通过 force() 来手动控制，但这个时间把握不好，在小内存场景下会很令人头疼。 MMAP 的回收问题，当 MappedByteBuffer 不再需要时，可以手动释放占用的虚拟内存，但…方式非常的诡异。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public static void clean(MappedByteBuffer mappedByteBuffer) &#123; ByteBuffer buffer = mappedByteBuffer; if (buffer == null || !buffer.isDirect() || buffer.capacity()== 0) return; invoke(invoke(viewed(buffer), \"cleaner\"), \"clean\");&#125;private static Object invoke(final Object target, final String methodName, final Class&lt;?&gt;... args) &#123; return AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; public Object run() &#123; try &#123; Method method = method(target, methodName, args); method.setAccessible(true); return method.invoke(target); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; &#125;);&#125;private static Method method(Object target, String methodName, Class&lt;?&gt;[] args) throws NoSuchMethodException &#123; try &#123; return target.getClass().getMethod(methodName, args); &#125; catch (NoSuchMethodException e) &#123; return target.getClass().getDeclaredMethod(methodName, args); &#125;&#125;private static ByteBuffer viewed(ByteBuffer buffer) &#123; String methodName = \"viewedBuffer\"; Method[] methods = buffer.getClass().getMethods(); for (int i = 0; i &lt; methods.length; i++) &#123; if (methods[i].getName().equals(\"attachment\")) &#123; methodName = \"attachment\"; break; &#125; &#125; ByteBuffer viewedBuffer = (ByteBuffer) invoke(buffer, methodName); if (viewedBuffer == null) return buffer; else return viewed(viewedBuffer);&#125; 对的，你没看错，这么长的代码仅仅是为了干回收 MappedByteBuffer 这一件事。 所以我建议，优先使用 FileChannel 去完成初始代码的提交，在必须使用小数据量 (例如几个字节) 刷盘的场景下，再换成 MMAP 的实现，其他场景 FileChannel 完全可以 cover(前提是你理解怎么合理使用 FileChannel)。至于 MMAP 为什么在一次写入少量数据的场景下表现的比 FileChannel 优异，我还没有查到理论根据，如果你有相关的线索，欢迎留言。理论分析下，FileChannel 同样是写入内存，但是在写入小数据量时，MMAP 表现的更加优秀，所以在索引数据落盘时，大多数情况应该选择使用 MMAP。至于 MMAP 分配的虚拟内存是否就是真正的 PageCache 这一点，我觉得可以近似理解成 PageCache。 顺序读比随机读快，顺序写比随机写快无论你是机械硬盘还是 SSD，这个结论都是一定成立的，虽然背后的原因不太一样，我们今天不讨论机械硬盘这种古老的存储介质，重点 foucs 在 SSD 上，来看看在它之上进行的随机读写为什么比顺序读写要慢。即使各个 SSD 和文件系统的构成具有差异性，但我们今天的分析同样具备参考价值。 首先，什么是顺序读，什么是随机读，什么是顺序写，什么是随机写？可能我们刚接触文件 IO 操作时并不会有这样的疑惑，但写着写着，自己都开始怀疑自己的理解了，不知道你有没有经历过这样类似的阶段，反正我有一段时间的确怀疑过。那么，先来看看两段代码： 写入方式一：64 个线程，用户自己使用一个 atomic 变量记录写入指针的位置，并发写入 12345678ExecutorService executor = Executors.newFixedThreadPool(64);AtomicLong wrotePosition = new AtomicLong(0);for(int i=0;i&lt;1024;i++)&#123; final int index = i; executor.execute(()-&gt;&#123; fileChannel.write(ByteBuffer.wrap(new byte[4*1024]),wrote.getAndAdd(4*1024)); &#125;)&#125; 写入方式二：给 write 加了锁，保证了同步。 123456789101112ExecutorService executor = Executors.newFixedThreadPool(64);AtomicLong wrotePosition = new AtomicLong(0);for(int i=0;i&lt;1024;i++)&#123; final int index = i; executor.execute(()-&gt;&#123; write(new byte[4*1024]); &#125;)&#125;public synchronized void write(byte[] data)&#123; fileChannel.write(ByteBuffer.wrap(new byte[4*1024]),wrote.getAndAdd(4*1024));&#125; 答案是方式二才算顺序写，顺序读也是同理。对于文件操作，加锁并不是一件非常可怕的事，不敢同步 write/read 才可怕！有人会问：FileChannel 内部不是已经有 positionLock 保证写入的线程安全了吗，为什么还要自己加同步？为什么这样会快？我用大白话来回答的话就是多线程并发 write 并且不加同步，会导致文件空洞，它的执行次序可能是 时序 1：thread1 write position[0~4096) 时序 2：thread3 write position[8194~12288) 时序 3：thread2 write position[4096~8194) 所以并不是完全的“顺序写”。不过你也别担心加锁会导致性能下降，我们会在下面的小结介绍一个优化：通过文件分片来减少多线程读写时锁的冲突。 在来分析原理，顺序读为什么会比随机读要快？顺序写为什么比随机写要快？这两个对比其实都是一个东西在起作用：PageCache，前面我们已经提到了，它是位于 application buffer(用户内存) 和 disk file(磁盘) 之间的一层缓存。 以顺序读为例，当用户发起一个 fileChannel.read(4kb) 之后，实际发生了两件事 操作系统从磁盘加载了 16kb 进入 PageCache，这被称为预读 操作通从 PageCache 拷贝 4kb 进入用户内存 最终我们在用户内存访问到了 4kb，为什么顺序读快？很容量想到，当用户继续访问接下来的 [4kb,16kb] 的磁盘内容时，便是直接从 PageCache 去访问了。试想一下，当需要访问 16kb 的磁盘内容时，是发生 4 次磁盘 IO 快，还是发生 1 次磁盘 IO+4 次内存 IO 快呢？答案是显而易见的，这一切都是 PageCache 带来的优化。 深度思考：当内存吃紧时，PageCache 的分配会受影响吗？PageCache 的大小如何确定，是固定的 16kb 吗？我可以监控 PageCache 的命中情况吗？ PageCache 会在哪些场景失效，如果失效了，我们又要哪些补救方式呢？ 我进行简单的自问自答，背后的逻辑还需要读者去推敲： 当内存吃紧时，PageCache 的预读会受到影响，实测，并没有搜到到文献支持 PageCache 是动态调整的，可以通过 linux 的系统参数进行调整，默认是占据总内存的 20% https://github.com/brendangregg/perf-tools github 上一款工具可以监控 PageCache 这是很有意思的一个优化点，如果用 PageCache 做缓存不可控，不妨自己做预读如何呢？ 顺序写的原理和顺序读一致，都是收到了 PageCache 的影响，留给读者自己推敲一下。 直接内存 (堆外) VS 堆内内存前面 FileChannel 的示例代码中已经使用到了堆内内存： ByteBuffer.allocate(4 * 1024)，ByteBuffer 提供了另外的方式让我们可以分配堆外内存 ： ByteBuffer.allocateDirect(4 * 1024)。这就引来的一系列的问题，我什么时候应该使用堆内内存，什么时候应该使用直接内存？ 我不花太多笔墨去阐述了，直接上对比： 堆内内存 堆外内存 底层实现 数组，JVM 内存 unsafe.allocateMemory(size) 返回直接内存 分配大小限制 -Xms-Xmx 配置的 JVM 内存相关，并且数组的大小有限制，在做测试时发现，当 JVM free memory 大于 1.5G 时，ByteBuffer.allocate(900M) 时会报错 可以通过 -XX:MaxDirectMemorySize 参数从 JVM 层面去限制，同时受到机器虚拟内存（说物理内存不太准确）的限制 垃圾回收 不必多说 当 DirectByteBuffer 不再被使用时，会出发内部 cleaner 的钩子，保险起见，可以考虑手动回收：((DirectBuffer) buffer).cleaner().clean(); 内存复制 堆内内存 -&gt; 堆外内存 -&gt; pageCache 堆外内存 -&gt; pageCache 关于堆内内存和堆外内存的一些最佳实践： 当需要申请大块的内存时，堆内内存会受到限制，只能分配堆外内存。 堆外内存适用于生命周期中等或较长的对象。(如果是生命周期较短的对象，在 YGC 的时候就被回收了，就不存在大内存且生命周期较长的对象在 FGC 对应用造成的性能影响)。 堆内内存刷盘的过程中，还需要复制一份到堆外内存，这部分内容可以在 FileChannel 的实现源码中看到细节，至于 Jdk 为什么需要这么做，可以参考我的另外一篇文章：《一文探讨堆外内存的监控与回收》 同时，还可以使用池 + 堆外内存 的组合方式，来对生命周期较短，但涉及到 I/O 操作的对象进行堆外内存的再使用 (Netty 中就使用了该方式)。在比赛中，尽量不要出现在频繁 new byte[] ，创建内存区域再回收也是一笔不小的开销，使用 ThreadLocal&lt;ByteBuffer&gt; 和 ThreadLocal&lt;byte[]&gt; 往往会给你带来意外的惊喜 ~ 创建堆外内存的消耗要大于创建堆内内存的消耗，所以当分配了堆外内存之后，尽可能复用它。 黑魔法：UNSAFE123456789101112public class UnsafeUtil &#123; public static final Unsafe UNSAFE; static &#123; try &#123; Field field = Unsafe.class.getDeclaredField(\"theUnsafe\"); field.setAccessible(true); UNSAFE = (Unsafe) field.get(null); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 我们可以使用 UNSAFE 这个黑魔法实现很多无法想象的事，我这里就稍微介绍一两点吧。 实现直接内存与内存的拷贝： 1234ByteBuffer buffer = ByteBuffer.allocateDirect(4 * 1024 * 1024);long addresses = ((DirectBuffer) buffer).address();byte[] data = new byte[4 * 1024 * 1024];UNSAFE.copyMemory(data, 16, null, addresses, 4 * 1024 * 1024); copyMemory 方法可以实现内存之间的拷贝，无论是堆内和堆外，1~2 个参数是 source 方，3~4 是 target 方，第 5 个参数是 copy 的大小。如果是堆内的字节数组，则传递数组的首地址和 16 这个固定的 ARRAY_BYTE_BASE_OFFSET 偏移常量；如果是堆外内存，则传递 null 和直接内存的偏移量，可以通过 ((DirectBuffer) buffer).address() 拿到。为什么不直接拷贝，而要借助 UNSAFE？当然是因为它快啊！少年！另外补充：MappedByteBuffer 也可以使用 UNSAFE 来 copy 从而达到写盘 / 读盘的效果哦。 至于 UNSAFE 还有那些黑科技，可以专门去了解下，我这里就不过多赘述了。 文件分区前面已经提到了顺序读写时我们需要对 write，read 加锁，并且我一再强调的一点是：加锁并不可怕，文件 IO 操作并没有那么依赖多线程。但是加锁之后的顺序读写必然无法打满磁盘 IO，如今系统强劲的 CPU 总不能不压榨吧？我们可以采用文件分区的方式来达到一举两得的效果：既满足了顺序读写，又减少了锁的冲突。 那么问题又来了，分多少合适呢？文件多了，锁冲突变降低了；文件太多了，碎片化太过严重，单个文件的值太少，缓存也就不容易命中，这样的 trade off 如何平衡？没有理论答案，benchmark everything~ Direct IO 最后我们来探讨一下之前从没提到的一种 IO 方式，Direct IO，什么，Java 还有这东西？博主你骗我？之前怎么告诉我只有三种 IO 方式！别急着骂我，严谨来说，这并不是 JAVA 原生支持的方式，但可以通过 JNA/JNI 调用 native 方法做到。从上图我们可以看到 ：Direct IO 绕过了 PageCache，但我们前面说到过，PageCache 可是个好东西啊，干嘛不用他呢？再仔细推敲一下，还真有一些场景下，Direct IO 可以发挥作用，没错，那就是我们前面没怎么提到的： 随机读 。当使用 fileChannel.read() 这类会触发 PageCache 预读的 IO 方式时，我们其实并不希望操作系统帮我们干太多事，除非真的踩了狗屎运，随机读都能命中 PageCache，但几率可想而知。Direct IO 虽然被 Linus 无脑喷过，但在随机读的场景下，依旧存在其价值，减少了 Block IO Layed（近似理解为磁盘） 到 Page Cache 的 overhead。 话说回来，Java 怎么用 Direct IO 呢？有没有什么限制呢？前面说过，Java 目前原生并不支持，但也有好心人封装好了 Java 的 JNA 库，实现了 Java 的 Direct IO，github 地址：https://github.com/smacke/jaydio 12345678int bufferSize = 20 * 1024 * 1024;DirectRandomAccessFile directFile = new DirectRandomAccessFile(new File(\"dio.data\"), \"rw\", bufferSize);for(int i= 0;i&lt; bufferSize / 4096;i++)&#123; byte[] buffer = new byte[4 * 1024]; directFile.read(buffer); directFile.readFully(buffer);&#125;directFile.close(); 但需要注意的是， 只有 Linux 系统才支持 DIO! 所以，少年，是时候上手装一台 linux 了。值得一提的是，据说在 Jdk10 发布之后，Direct IO 将会得到原生的支持，让我们拭目以待吧！ 总结以上均是个人的实践积累而来的经验，有部分结论没有找到文献的支撑，所以如有错误，欢迎指正。关于 PolarDB 数据性能大赛的比赛分析，等复赛结束后我会专门另起一篇文章，分析下具体如何使用这些优化点，当然这些小技巧其实很多人都知道，决定最后成绩的还是整体设计的架构，以及对文件 IO，操作系统，文件系统，CPU 和语言特性的理解。虽然 JAVA 搞这种性能挑战赛并不吃香，但依旧是乐趣无穷，希望这些文件 IO 的知识能够帮助你，等下次比赛时看到你的身影 ~ 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://lexburner.github.io/categories/数据库/"}],"tags":[{"name":"PolarDB 性能挑战赛","slug":"PolarDB-性能挑战赛","permalink":"http://lexburner.github.io/tags/PolarDB-性能挑战赛/"}]},{"title":"八个层面比较 Java 8, RxJava, Reactor","slug":"comparing-rxjava","date":"2018-10-15T17:25:14.000Z","updated":"2019-09-26T09:45:31.052Z","comments":true,"path":"comparing-rxjava/","link":"","permalink":"http://lexburner.github.io/comparing-rxjava/","excerpt":"前言这是一篇译文，原文出处 戳这里。其实很久以前我就看完了这篇文章，只不过个人对响应式编程研究的不够深入，羞于下笔翻译，在加上这类译文加了原创还有争议性，所以一直没有动力。恰逢今天交流群里两个大佬对响应式编程的话题辩得不可开交，趁印象还算深刻，借机把这篇文章翻译一下。说道辩论的点，不妨也在这里抛出来： 响应式编程在单机环境下是否鸡肋？ 结论是：没有结论，我觉得只能抱着怀疑的眼光审视这个问题了。另外还聊到了 RSocket 这个最近在 SpringOne 大会上比较火爆的响应式 “ 新“网络协议，github 地址 戳这里，为什么给”新“字打了个引号，仔细观察下 RSocket 的 commit log，其实三年前就有了。有兴趣的同学自行翻阅，说不定就是今年这最后两三个月的热点技术哦。 Java 圈子有一个怪事，那就是对 RxJava，Reactor，WebFlux 这些响应式编程的名词、框架永远处于渴望了解，感到新鲜，却又不甚了解，使用贫乏的状态。之前转载小马哥的那篇《Reactive Programming 一种技术，各自表述》时，就已经聊过这个关于名词之争的话题了，今天群里的讨论更是加深了我的映像。Java 圈子里面很多朋友一直对响应式编程处于一个了解名词，知道基本原理，而不是深度用户的状态 (我也是之一)。可能真的和圈子有关，按石冲兄的说法，其实 Scala 圈子里面的那帮人，不知道比咱们高到哪里去了（就响应式编程而言）。 实在是好久没发文章了，向大家说声抱歉，以后的更新频率肯定是没有以前那么勤了（说的好像以前很勤快似的），一部分原因是在公司内网写的文章没法贴到公众号中和大家分享讨论，另一部分是目前我也处于学习公司内部框架的阶段，不太方便提炼成文章，最后，最大的一部分原因还是我这段时间需要学 (tou) 习(lan)其 (da) 他(you)东 (xi) 西啦。好了，废话也说完了，下面是译文的正文部分。","text":"前言这是一篇译文，原文出处 戳这里。其实很久以前我就看完了这篇文章，只不过个人对响应式编程研究的不够深入，羞于下笔翻译，在加上这类译文加了原创还有争议性，所以一直没有动力。恰逢今天交流群里两个大佬对响应式编程的话题辩得不可开交，趁印象还算深刻，借机把这篇文章翻译一下。说道辩论的点，不妨也在这里抛出来： 响应式编程在单机环境下是否鸡肋？ 结论是：没有结论，我觉得只能抱着怀疑的眼光审视这个问题了。另外还聊到了 RSocket 这个最近在 SpringOne 大会上比较火爆的响应式 “ 新“网络协议，github 地址 戳这里，为什么给”新“字打了个引号，仔细观察下 RSocket 的 commit log，其实三年前就有了。有兴趣的同学自行翻阅，说不定就是今年这最后两三个月的热点技术哦。 Java 圈子有一个怪事，那就是对 RxJava，Reactor，WebFlux 这些响应式编程的名词、框架永远处于渴望了解，感到新鲜，却又不甚了解，使用贫乏的状态。之前转载小马哥的那篇《Reactive Programming 一种技术，各自表述》时，就已经聊过这个关于名词之争的话题了，今天群里的讨论更是加深了我的映像。Java 圈子里面很多朋友一直对响应式编程处于一个了解名词，知道基本原理，而不是深度用户的状态 (我也是之一)。可能真的和圈子有关，按石冲兄的说法，其实 Scala 圈子里面的那帮人，不知道比咱们高到哪里去了（就响应式编程而言）。 实在是好久没发文章了，向大家说声抱歉，以后的更新频率肯定是没有以前那么勤了（说的好像以前很勤快似的），一部分原因是在公司内网写的文章没法贴到公众号中和大家分享讨论，另一部分是目前我也处于学习公司内部框架的阶段，不太方便提炼成文章，最后，最大的一部分原因还是我这段时间需要学 (tou) 习(lan)其 (da) 他(you)东 (xi) 西啦。好了，废话也说完了，下面是译文的正文部分。 引言关于响应式编程 (Reactive Programming)，你可能有过这样的疑问：我们已经有了 Java8 的 Stream, CompletableFuture, 以及 Optional，为什么还必要存在 RxJava 和 Reactor？ 回答这个问题并不难，如果在响应式编程中处理的问题非常简单，你的确不需要那些第三方类库的支持。 但随着复杂问题的出现，你写出了一堆难看的代码。然后这些代码变得越来越复杂，难以维护，而 RxJava 和 Reactor 具有许多方便的功能，可以解决你当下问题，并保障了未来一些可预见的需求。本文从响应式编程模型中抽象出了 8 个标准，这将有助于我们理解标准特性与这些库之间的区别： Composable（可组合） Lazy（惰性执行） Reusable（可复用） Asynchronous（异步） Cacheable（可缓存） Push or Pull（推拉模型） Backpressure（回压）(译者注：按照石冲老哥的建议，这个词应当翻译成 “回压” 而不是 “背压”) Operator fusion（操作融合） 我们将会对以下这些类进行这些特性的对比： CompletableFuture（Java 8） Stream（Java 8） Optional（Java 8） Observable (RxJava 1) Observable (RxJava 2) Flowable (RxJava 2) Flux (Reactor Core) 让我们开始吧 ~ 1. Composable（可组合）这些类都是支持 Composable 特性的，使得各位使用者很便利地使用函数式编程的思想去思考问题，这也正是我们拥趸它们的原因。 CompletableFuture - 众多的 .then*() 方法使得我们可以构建一个 pipeline, 用以传递空值，单一的值，以及异常. Stream - 提供了许多链式操作的编程接口，支持在各个操作之间传递多个值。 Optional - 提供了一些中间操作 .map(), .flatMap(), .filter(). Observable, Flowable, Flux - 和 Stream 相同 2. Lazy（惰性执行）CompletableFuture - 不具备惰性执行的特性，它本质上只是一个异步结果的容器。这些对象的创建是用来表示对应的工作，CompletableFuture 创建时，对应的工作已经开始执行了。但它并不知道任何工作细节，只关心结果。所以，没有办法从上至下执行整个 pipeline。当结果被设置给 CompletableFuture 时，下一个阶段才开始执行。 Stream - 所有的中间操作都是延迟执行的。所有的终止操作 (terminal operations)，会触发真正的计算 (译者注：如 collect() 就是一个终止操作 )。 Optional - 不具备惰性执行的特性，所有的操作会立刻执行。 Observable, Flowable, Flux - 惰性执行，只有当订阅者出现时才会执行，否则不执行。 3. Reusable（可复用）CompletableFuture - 可以复用，它仅仅是一个实际值的包装类。但需要注意的是，这个包装是可更改的。.obtrude*() 方法会修改它的内容，如果你确定没有人会调用到这类方法，那么重用它还是安全的。 Stream - 不能复用。Java Doc 注释道： A stream should be operated on (invoking an intermediate or terminal stream operation) only once. A stream implementation may throw IllegalStateException if it detects that the stream is being reused. However, since some stream operations may return their receiver rather than a new stream object, it may not be possible to detect reuse in all cases. （译者注：Stream 只能被调用一次。如果被校测到流被重复使用了，它会跑出抛出一个 IllegalStateException 异常。但是某些流操作会返回他们的接受者，而不是一个新的流对象，所以无法在所有情况下检测出是否可以重用） Optional - 完全可重用，因为它是不可变对象，而且所有操作都是立刻执行的。 Observable, Flowable, Flux - 生而重用，专门设计成如此。当存在订阅者时，每一次执行都会从初始点开始完整地执行一边。 4. Asynchronous（异步）CompletableFuture - 这个类的要点在于它异步地把多个操作连接了起来。CompletableFuture 代表一项操作，它会跟一个 Executor 关联起来。如果不明确指定一个 Executor，那么会默认使用公共的 ForkJoinPool 线程池来执行。这个线程池可以用 ForkJoinPool.commonPool() 获取到。默认设置下它会创建系统硬件支持的线程数一样多的线程（通常和 CPU 的核心数相等，如果你的 CPU 支持超线程 (hyperthreading)，那么会设置成两倍的线程数）。不过你也可以使用 JVM 参数指定 ForkJoinPool 线程池的线程数， 1-Djava.util.concurrent.ForkJoinPool.common.parallelism=? 或者在创建 CompletableFuture 时提供一个指定的 Executor。 Stream - 不支持创建异步执行流程，但是可以使用 stream.parallel() 等方式创建并行流。 Optional - 不支持，它只是一个容器。 Observable, Flowable, Flux - 专门设计用以构建异步系统，但默认情况下是同步的。subscribeOn 和 observeOn 允许你来控制订阅以及接收（这个线程会调用 observer 的 onNext / onError / onCompleted 方法）。 subscribeOn 方法使得你可以决定由哪个 Scheduler 来执行 Observable.create 方法。即便你没有调用创建方法，系统内部也会做同样的事情。例如： 12345678910111213Observable .fromCallable(() -&gt; &#123; log.info(\"Reading on thread:\" + currentThread().getName()); return readFile(\"input.txt\"); &#125;) .map(text -&gt; &#123; log.info(\"Map on thread:\" + currentThread().getName()); return text.length(); &#125;) .subscribeOn(Schedulers.io()) // &lt;-- setting scheduler .subscribe(value -&gt; &#123; log.info(\"Result on thread:\" + currentThread().getName()); &#125;); 输出： 123Reading file on thread: RxIoScheduler-2Map on thread: RxIoScheduler-2Result on thread: RxIoScheduler-2 相反的，observeOn() 控制在 observeOn() 之后，用哪个 Scheduler 来运行下游的执行阶段。例如： 1234567891011121314Observable .fromCallable(() -&gt; &#123; log.info(\"Reading on thread:\" + currentThread().getName()); return readFile(\"input.txt\"); &#125;) .observeOn(Schedulers.computation()) // &lt;-- setting scheduler .map(text -&gt; &#123; log.info(\"Map on thread:\" + currentThread().getName()); return text.length(); &#125;) .subscribeOn(Schedulers.io()) // &lt;-- setting scheduler .subscribe(value -&gt; &#123; log.info(\"Result on thread:\" + currentThread().getName()); &#125;); 输出： 123Reading file on thread: RxIoScheduler-2Map on thread: RxComputationScheduler-1Result on thread: RxComputationScheduler-1 5. Cacheable（可缓存）可缓存和可复用之间的区别是什么？假如我们有 pipeline A，重复使用它两次，来创建两个新的 pipeline B = A + X 以及 C = A + Y 如果 B 和 C 都能成功执行，那么这个 A 就是是可重用的。 如果 B 和 C 都能成功执行，并且 A 在这个过程中，整个 pipeline 只执行了一次，那么我们便称 A 是可缓存的。这意味着，可缓存一定代表可重用。 CompletableFuture - 跟可重用的答案一样。 Stream - 不能缓存中间操作的结果，除非调用了终止操作。 Optional - 可缓存，所有操作立刻执行，并且进行了缓存。 Observable, Flowable, Flux - 默认不可缓存的，但是可以调用 .cache() 把这些类变成可缓存的。例如： 123456Observable&lt;Integer&gt; work = Observable.fromCallable(() -&gt; &#123; System.out.println(\"Doing some work\"); return 10;&#125;);work.subscribe(System.out::println);work.map(i -&gt; i * 2).subscribe(System.out::println); 输出： 1234Doing some work10Doing some work20 使用 .cache()： 123456Observable&lt;Integer&gt; work = Observable.fromCallable(() -&gt; &#123; System.out.println(\"Doing some work\"); return 10;&#125;).cache(); // &lt;- apply cachingwork.subscribe(System.out::println);work.map(i -&gt; i * 2).subscribe(System.out::println); 输出： 123Doing some work1020 6. Push or Pull（推拉模型）Stream 和 Optional - 拉模型。调用不同的方法（.get(), .collect() 等）从 pipeline 拉取结果。拉模型通常和阻塞、同步关联，那也是公平的。当调用方法时，线程会一直阻塞，直到有数据到达。 CompletableFuture, Observable, Flowable, Flux - 推模型。当订阅一个 pipeline ，并且某些事件被执行后，你会得到通知。推模型通常和非阻塞、异步这些词关联在一起。当 pipeline 在某个线程上执行时，你可以做任何事情。你已经定义了一段待执行的代码，当通知到达的时候，这段代码就会在下个阶段被执行。 7. Backpressure（回压） 支持回压的前提是 pipeline 必须是推模型。* Backpressure（回压） 描述了 pipeline 中的一种场景：某些异步阶段的处理速度跟不上，需要告诉上游生产者放慢速度。直接失败是不能接受的，这会导致大量数据的丢失。 Stream &amp; Optional - 不支持回压，因为它们是拉模型。 CompletableFuture - 不存在这个问题，因为它只产生 0 个或者 1 个结果。 Observable(RxJava 1), Flowable, Flux - 支持。常用策略如下： Buffering - 缓冲所有的 onNext 的值，直到下游消费它们。 Drop Recent - 如果下游处理速率跟不上，丢弃最近的 onNext 值。 Use Latest - 如果下游处理速率跟不上，只提供最近的 onNext 值，之前的值会被覆盖。 None - onNext 事件直接被触发，不做缓冲和丢弃。 Exception - 如果下游处理跟不上的话，抛出异常。 Observable(RxJava 2) - 不支持。很多 RxJava 1 的使用者用 Observable 来处理不适用回压的事件，或者是使用 Observable 的时候没有配置任何策略，导致了不可预知的异常。所以，RxJava 2 明确地区分两种情况，提供支持回压的 Flowable 和不支持回压的 Observable。 8. Operator fusion（操作融合）操作融合的内涵在于，它使得生命周期的不同点上的执行阶段得以改变，从而消除类库的架构因素所造成的系统开销。所有这些优化都在内部被处理完毕，从而让外部用户觉得这一切都是透明的。 只有 RxJava 2 和 Reactor 支持这个特性，但支持的方式不同。总的来说，有两种类型的优化： Macro-fusion - 用一个操作替换 2 个或更多的相继的操作 Micro-fusion - 一个输出队列的结束操作，和在一个输入队列的开始操作，能够共享一个队列的实例。比如说，与其调用 request(1) 然后处理 onNext()`： 不然让订阅者直接从父 observable 拉取值。 更多信息可以参考 Part1 和 Part2 总结一图胜千言 Stream，CompletableFuture 和 Optional 这些类的创建，都是为了解决特定的问题。 并且他们非常适合用于解决这些问题。 如果它们满足你的需求，你可以立马使用它们。 然而，不同的问题具有不同的复杂度，并且某些问题只有新技术才能很好的解决，新技术的出现也是为了解决那些高复杂度的问题。 RxJava 和 Reactor 是通用的工具，它们帮助你以声明方式来解决问题，而不是使用那些不够专业的工具，生搬硬套的使用其他的工具来解决响应式编程的问题，只会让你的解决方案变成一种 hack 行为。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"响应式编程","slug":"响应式编程","permalink":"http://lexburner.github.io/categories/响应式编程/"}],"tags":[{"name":"RxJava","slug":"RxJava","permalink":"http://lexburner.github.io/tags/RxJava/"},{"name":"Reactor","slug":"Reactor","permalink":"http://lexburner.github.io/tags/Reactor/"}]},{"title":"关于阿里面试、学习路线、公众号的一些想法","slug":"thinking-2","date":"2018-09-27T18:18:51.000Z","updated":"2019-09-26T09:45:31.096Z","comments":true,"path":"thinking-2/","link":"","permalink":"http://lexburner.github.io/thinking-2/","excerpt":"还记得上一篇记录我心情的随笔是写在离开魔都，去往南京的时候，此时的我，又来到了杭州。工作发生了变故，心境也发生了变化，倒是有不少东西想跟各位来聊一聊，择其三汇成此文。","text":"还记得上一篇记录我心情的随笔是写在离开魔都，去往南京的时候，此时的我，又来到了杭州。工作发生了变故，心境也发生了变化，倒是有不少东西想跟各位来聊一聊，择其三汇成此文。 阿里面试入职阿里第一天，我发了一条入职阿里的朋友圈，很多朋友发表了评论：羡慕，恭喜，也有一些前辈给了我忠告，首先在这儿谢谢大家。 微信群中自然有很多人会关注：“阿里面试都面了什么？有什么回答技巧吗？能不能分享下面经？”。但今天想跟大家说的是，我并不觉得分享那些面试题，甚至把答案都告诉你，会对你有多大的帮助。 其一，那是我的面试题，不是你的。每个人的工作经历不一样，合格的面试官必定是针对个人的简历进行提问，而不是地毯式的来一次 mq，redis，rpc，database，spring 的大扫荡。 其二，平时的知识储备，远胜于那些事先准备好答案的面试题。这和学生时代一样，成绩好的学霸即使期末不用复习，依旧可以考出高分；临时抱佛脚的学渣，大概率会在考试中露出马脚。众所周知，微信公众号文章中阅读量最高的往往是面经类文章，我群里有一名程序媛分享了一篇自己「阿里 7 面」的经历，一早上便有了 3000 多的阅读量。这背后很大程度是出于个人的焦虑，若你的知识储备不足，看的面试题越多，你就会越焦虑；反观我了解的那些技术水平不错的朋友，往往都对这些面试题嗤之以鼻。这背后反映出了一些问题，对于一些老生常谈的面试题，诸如“ConcurrentHashMap 的原理”，“ThreadLocal 的原理”，你即使回答的再好，我相信依旧称不上出彩；而对于一些技术的使用场景你能够说出自己的理解，那才是优秀之处，无招胜有招。 总结下这两点，无非就是想告诉那些新手玩家，面试并不存在什么奇技淫巧，那些在实战积累出来的经验，以及你自己探索源码获得的经验才是面试中的金子。如果你非要我说一两个注意点，那我反而觉得应聘部门的 HC 和面试官的心情更重要一些。 你只是个孩子，你根本不晓得你在说什么。 我问你「艺术」，你可能会提出艺术书籍中的粗浅论调，有关米开朗基罗，你知道很多，他的满腔政治热情，他与教皇相交莫逆；但你不知道西斯汀教堂的气味，你从没站在那儿观赏美丽的天花板。 如果我问关于「女人」的事，你八成会说出个人偏好的谬论，你可能上过几次床，但你说不出在女人身旁醒来，那份内心幸福的滋味 当谈论「战争」，你会说出莎士比亚的话，“共赴战场，亲爱的朋友”。但你从未亲临战阵，从没把把挚友的头抱在膝盖里，看着他吸着最后一口气，凝望着你，希望你能够帮到他 我问你「爱情」，你会引述十四行诗，但你从未看过女人的脆弱，她能以双眼击倒你，感觉上帝让天使为你下凡，从地狱中拯救你。 — 心灵捕手 学习路线与技术标签至于群友关于学习路线的建议，我还是打算在这一话题中提供一点我的看法，仅供参考。如果你是我博客的忠实读者，应当能够知道我的学习路线是什么样的。 在初入职场实习时，主要的任务是巩固 Java 基础，那些 J2SE 的基础知识，不至于说精通源码，至少应该能做到侃侃而谈。这个过程，面很重要，所以适合看书，按照章节的梳理，知识点被串联在一起，日后可以将其对号入座。至于推荐书籍，新的旧的，差异不是很大，可以自行翻阅我博客中或者其他大 V 的推荐书单。 有些人觉得看视频很 low，切不要有这样的偏见，我一直觉得好的视频会给人非常直观的学习体验，虽说不如书籍高效，但学习起来十分轻松，我最近看的视频就包括闪电侠的 netty 源码解读以及小马哥的一些公开课视频，受益很多（互联网鄙视培训，但我初学时也看过传智播客和尚硅谷的一些培训视频，的确讲的很好，没什么丢人不丢人的，学到知识就是王道） 官方文档和源码，这是我目前学习新知识最主要的途径，话不多说，不愿意接受如此高效的学习方法的人，大多数是因为懒。 如上可能还算不上学习路线，顶多算作学习方法，可以说是老生常谈的三点了，拿出来权当是强调一次。我理解的路线是一个人掌握了必备的 IT 基础技能之后，发展一到两个自己非常擅长的路线，如果做的足够的好，你的路线会成为你的技术标签，比如我的好友当中就不乏这样具有技术标签的人物，闪电侠的 netty，厮大的 mq，艿艿的源码解析，亚普的 96/ 调色大师 / 系统监控。再回到我自己，短期内，rpc 服务治理可能就是我打算走的路线。 公众号的一些运营想法也是在最近一个月，粉丝数突破了 5000，我也创了自己的技术交流群「Kirito 的技术分享」。我原本并没有创群的打算，一方面担心自己管理不好，另一方面是加入的微信交流群实在是太多，人员也存在很大程度的重叠。促使我创立交流群（或许称之为「小密圈」可能更为合适）的初衷我也给我的读者交代一下 现在各个微信公众号的知识分享处于一种过剩的状态，优质的原创文，不走心的水文，面向于小白的基础文，广告贴，蹭时事热点的贴子…实在是鱼龙混杂，各个群里面铺天盖地的铺天盖地的文章，使得大家应接不暇。所以，我创了自己的交流圈，初衷便是和关注我的读者们安安静静地讨论文章中知识点和观点，我也并不排斥优质的原创文章，群规便有一点比较独特的地方：只建议推广 个人 的 原创 文章。 关于互推和广告贴，我的个人原则是参与，不推广。互推文这种形式是指几个公众号的维护者一起发文，达到互相增粉的效果，由于微信公众号的文章是闭环的，推广的途径有限，而我希望更多的人能够看到我的文章，所以适度地互推是有必要的，我也希望读者能够不要排斥这种行为，一般我的标题就可以让你知道：这篇文章是一篇互推文，而一般互推文需要一定阅读量的支撑，点击阅读 + 关注互推的公众号，都是对我的支持，可以视自己的接受程度来决策。同理，还有广告贴，一般比较浮夸的标题就是广告跑不了了，同样是有阅读量的需求，广告商的经济鼓励会让博主有更大的动力创作优质的原创文章。 写作圈子里面也有一些坏味道，接广告的公众号瞧不起发水文的公众号，发水文的公众号眼红有广告的公众号，还有一些公众号存在刷粉，刷阅读量的行为，也有一些公众号存在不尊重原创的行为，我也聊聊自己的公众号价值观。 水文：不为了发文而发文，宁缺毋滥。拒绝写水文。 原创：转载需要在文首注明出处，第一时间告诉读者这是一篇转载的文章；翻译文章不能标注原创；转载他人博客的文章不得标明原创，他人主动要求除外；不洗文；多个公众号不要过度转载同样的文章，造成信息的过度消费；未经授权不要随意转载他人文章或标明侵删；微信公众号的转载文章可以不贴对方的二维码，因为微信文章下方自带导流链接。 广告：不做误人子弟的广告如 p2p 理财；不做标题党，明确这是一篇广告；适度 互推：确保互推中其他公众号的质量；适度 热点文：确认事实后再发文，不应煽动 毕竟道德、价值观这些个东西只能用来约束自己，不能用来约束别人，我只能向各位读者保证，我公众号运营的信条如上。 感谢各位读者的关注，今后无论多忙，我一定会坚持把博客写下去。 End","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"}]},{"title":"Java 随机数探秘","slug":"java-random","date":"2018-09-12T11:47:28.000Z","updated":"2019-09-26T09:45:31.668Z","comments":true,"path":"java-random/","link":"","permalink":"http://lexburner.github.io/java-random/","excerpt":"","text":"本文的前 3 节参考修改自微信公众号「咖啡拿铁」的文章，感谢李钊同学对这个话题热情的讨论。 1 前言一提到 Java 中的随机数，很多人就会想到 Random，当出现生成随机数这样需求时，大多数人都会选择使用 Random 来生成随机数。Random 类是线程安全的，但其内部使用 CAS 来保证线程安全性，在多线程并发的情况下的时候它的表现是存在优化空间的。在 JDK1.7 之后，Java 提供了更好的解决方案 ThreadLocalRandom，接下来，我们一起探讨下这几个随机数生成器的实现到底有何不同。 2 RandomRandom 这个类是 JDK 提供的用来生成随机数的一个类，这个类并不是真正的随机，而是伪随机，伪随机的意思是生成的随机数其实是有一定规律的，而这个规律出现的周期随着伪随机算法的优劣而不同，一般来说周期比较长，但是可以预测。通过下面的代码我们可以对 Random 进行简单的使用: Random 原理Random 中的方法比较多，这里就针对比较常见的 nextInt()和 nextInt(int bound) 方法进行分析，前者会计算出 int 范围内的随机数，后者如果我们传入 10，那么他会求出 [0,10) 之间的 int 类型的随机数，左闭右开。我们首先看一下 Random() 的构造方法: 可以发现在构造方法当中，根据当前时间的种子生成了一个 AtomicLong 类型的 seed，这也是我们后续的关键所在。 nextInt()nextInt() 的代码如下所示： 这个里面直接调用的是 next() 方法，传入的 32，代指的是 Int 类型的位数。 这里会根据 seed 当前的值，通过一定的规则 (伪随机算法) 算出下一个 seed，然后进行 CAS，如果 CAS 失败则继续循环上面的操作。最后根据我们需要的 bit 位数来进行返回。核心便是 CAS 算法。 nextInt(int bound)nextInt(int bound) 的代码如下所示： 这个流程比 nextInt() 多了几步，具体步骤如下: 首先获取 31 位的随机数，注意这里是 31 位，和上面 32 位不同，因为在 nextInt()方法中可以获取到随机数可能是负数，而 nextInt(int bound) 规定只能获取到 [0,bound) 之前的随机数，也就意味着必须是正数，预留一位符号位，所以只获取了 31 位。(不要想着使用取绝对值这样操作，会导致性能下降) 然后进行取 bound 操作。 如果 bound 是 2 的幂次方，可以直接将第一步获取的值乘以 bound 然后右移 31 位，解释一下: 如果 bound 是 4，那么乘以 4 其实就是左移 2 位，其实就是变成了 33 位，再右移 31 位的话，就又会变成 2 位，最后，2 位 int 的范围其实就是 [0,4) 了。 如果不是 2 的幂，通过模运算进行处理。 并发瓶颈在我之前的文章中就有相关的介绍，一般而言，CAS 相比加锁有一定的优势，但并不一定意味着高效。一个立刻被想到的解决方案是每次使用 Random 时都去 new 一个新的线程私有化的 Random 对象，或者使用 ThreadLocal 来维护线程私有化对象，但除此之外还存在更高效的方案，下面便来介绍本文的主角 ThreadLocalRandom。 3 ThreadLocalRandom在 JDK1.7 之后提供了新的类 ThreadLocalRandom 用来在并发场景下代替 Random。使用方法比较简单: 12ThreadLocalRandom.current().nextInt();ThreadLocalRandom.current().nextInt(10); 在 current 方法中有: 可以看见如果没有初始化会对其进行初始化，而这里我们的 seed 不再是一个全局变量，在我们的 Thread 中有三个变量: threadLocalRandomSeed：ThreadLocalRandom 使用它来控制随机数种子。 threadLocalRandomProbe：ThreadLocalRandom 使用它来控制初始化。 threadLocalRandomSecondarySeed：二级种子。 可以看见所有的变量都加了 @sun.misc.Contended 这个注解，用来处理伪共享问题。 在 nextInt() 方法当中代码如下: 我们的关键代码如下: 1UNSAFE.putLong(t = Thread.currentThread(), SEED,r=UNSAFE.getLong(t, SEED) + GAMMA); 可以看见由于我们每个线程各自都维护了种子，这个时候并不需要 CAS，直接进行 put，在这里利用线程之间隔离，减少了并发冲突；相比较 ThreadLocal&lt;Random&gt;，ThreadLocalRandom 不仅仅减少了对象维护的成本，其内部实现也更轻量级。所以 ThreadLocalRandom 性能很高。 4 性能测试除了文章中详细介绍的 Random，ThreadLocalRandom，我还将 netty4 实现的 ThreadLocalRandom，以及 ThreadLocal&lt;Random&gt; 作为参考对象，一起参与 JMH 测评。 123456789101112131415161718192021222324252627282930313233343536373839404142@BenchmarkMode(&#123;Mode.AverageTime&#125;)@OutputTimeUnit(TimeUnit.NANOSECONDS)@Warmup(iterations = 3, time = 5)@Measurement(iterations = 3, time = 5)@Threads(50)@Fork(1)@State(Scope.Benchmark)public class RandomBenchmark &#123; Random random = new Random(); ThreadLocal&lt;Random&gt; threadLocalRandomHolder = ThreadLocal.withInitial(Random::new); @Benchmark public int random() &#123; return random.nextInt(); &#125; @Benchmark public int threadLocalRandom() &#123; return ThreadLocalRandom.current().nextInt(); &#125; @Benchmark public int threadLocalRandomHolder() &#123; return threadLocalRandomHolder.get().nextInt(); &#125; @Benchmark public int nettyThreadLocalRandom() &#123; return io.netty.util.internal.ThreadLocalRandom.current().nextInt(); &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(RandomBenchmark.class.getSimpleName()) .build(); new Runner(opt).run(); &#125;&#125; 测评结果如下： 12345Benchmark Mode Cnt Score Error UnitsRandomBenchmark.nettyThreadLocalRandom avgt 3 192.202 ± 295.897 ns/opRandomBenchmark.random avgt 3 3197.620 ± 380.981 ns/opRandomBenchmark.threadLocalRandom avgt 3 90.731 ± 39.098 ns/opRandomBenchmark.threadLocalRandomHolder avgt 3 229.502 ± 267.144 ns/op 从上图可以发现，JDK1.7 的 ThreadLocalRandom 取得了最好的成绩，仅仅需要 90 ns 就可以生成一次随机数，netty 实现的 ThreadLocalRandom 以及使用 ThreadLocal 维护 Random 的方式差距不是很大，位列 2、3 位，共享的 Random 变量则效果最差。 可见，在并发场景下，ThreadLocalRandom 可以明显的提升性能。 5 注意点注意，ThreadLocalRandom 切记不要调用 current 方法之后，作为共享变量使用 123456789public class WrongCase &#123; ThreadLocalRandom threadLocalRandom = ThreadLocalRandom.current(); public int concurrentNextInt()&#123; return threadLocalRandom.nextInt(); &#125; &#125; 这是因为 ThreadLocalRandom.current() 会使用初始化它的线程来填充随机种子，这会带来导致多个线程使用相同的 seed。 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; ThreadLocalRandom threadLocalRandom = ThreadLocalRandom.current(); for(int i=0;i&lt;10;i++) new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(threadLocalRandom.nextInt()); &#125; &#125;).start(); &#125;&#125; 输出相同的随机数： 12345678910-1667209487-1667209487-1667209487-1667209487-1667209487-1667209487-1667209487-1667209487-1667209487-1667209487 请在确保不同线程获取不同的 seed，最简单的方式便是每次调用都是使用 current()： 12345public class RightCase &#123; public int concurrentNextInt()&#123; return ThreadLocalRandom.current().nextInt(); &#125;&#125; 彩蛋 1梁飞博客中一句话常常在我脑海中萦绕：魔鬼在细节中。优秀的代码都是一个个小细节堆砌出来，今天介绍的 ThreadLocalRandom 也不例外。 在 incubator-dubbo-2.7.0 中，随机负载均衡器的一个小改动便是将 Random 替换为了 ThreadLocalRandom，用于优化并发性能。 彩蛋 2ThreadLocalRandom 的 nextInt(int bound) 方法中，当 bound 不为 2 的幂次方时，使用了一个循环来修改 r 的值，我认为这可能不必要，你觉得呢？ 123456789101112131415public int nextInt(int bound) &#123; if (bound &lt;= 0) throw new IllegalArgumentException(BadBound); int r = mix32(nextSeed()); int m = bound - 1; if ((bound &amp; m) == 0) // power of two r &amp;= m; else &#123; // reject over-represented candidates for (int u = r &gt;&gt;&gt; 1; u + m - (r = u % bound) &lt; 0; u = mix32(nextSeed()) &gt;&gt;&gt; 1) ; &#125; return r;&#125; 欢迎关注李钊同学的微信公众号：「咖啡拿铁」 当然，也欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JAVA 并发合集","slug":"JAVA-并发合集","permalink":"http://lexburner.github.io/categories/JAVA-并发合集/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"Spring 中的 XML schema 扩展机制","slug":"spring-xsd","date":"2018-09-03T11:47:28.000Z","updated":"2019-09-26T09:45:30.042Z","comments":true,"path":"spring-xsd/","link":"","permalink":"http://lexburner.github.io/spring-xsd/","excerpt":"前言很久没有写关于 Spring 的文章了，最近在系统梳理 Dubbo 代码的过程中发现了 XML schema 这个被遗漏的知识点。由于工作中使用 SpringBoot 比较多的原因，几乎很少接触 XML，此文可以算做是亡羊补牢，另一方面，也为后续的 Dubbo 源码解析做个铺垫。 XML schema 扩展机制是啥？这并不是一块很大的知识点，翻阅一下 Spring 的文档，我甚至没找到一个贯穿上下文的词来描述这个功能，XML Schema Authoring 是文档中对应的标题，简单来说：","text":"前言很久没有写关于 Spring 的文章了，最近在系统梳理 Dubbo 代码的过程中发现了 XML schema 这个被遗漏的知识点。由于工作中使用 SpringBoot 比较多的原因，几乎很少接触 XML，此文可以算做是亡羊补牢，另一方面，也为后续的 Dubbo 源码解析做个铺垫。 XML schema 扩展机制是啥？这并不是一块很大的知识点，翻阅一下 Spring 的文档，我甚至没找到一个贯穿上下文的词来描述这个功能，XML Schema Authoring 是文档中对应的标题，简单来说： Spring 为基于 XML 构建的应用提供了一种扩展机制，用于定义和配置 Bean。 它允许使用者编写自定义的 XML bean 解析器，并将解析器本身以及最终定义的 Bean 集成到 Spring IOC 容器中。 Dubbo 依赖了 Spring，并提供了一套自定义的 XML 标签，&lt;dubbo:application&gt; ,&lt;dubbo:registry&gt; ,&lt;dubbo:protocol&gt;,&lt;dubbo:service&gt;。作为使用者，大多数人只需要关心这些参数如何配置，但不知道有没有人好奇过，它们是如何加载进入 Spring 的 IOC 容器中被其他组件使用的呢？这便牵扯出了今天的主题：Spring 对 XML schema 的扩展支持。 自定义 XML 扩展为了搞懂 Spring 的 XML 扩展机制，最直接的方式便是实现一个自定义的扩展。实现的步骤也非常简单，分为四步： 编写一个 XML schema 文件描述的你节点元素。 编写一个 NamespaceHandler 的实现类 编写一个或者多个 BeanDefinitionParser 的实现 (关键步骤). 注册上述的 schema 和 handler。 我们的目的便是想要实现一个 kirito XML schema，我们的项目中可以自定义 kirito.xml，在其中会以 kirito 为标签来定义不同的类，并在最终的测试代码中验证这些声明在 kirito.xml 的类是否被 Spring 成功加载。大概像这样，是不是和 dubbo.xml 的格式很像呢？ 动手实现有了明确的目标，我们逐步开展自己的工作。 1 编写 kirito.xsdresources/META-INF/kirito.xsd 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;xsd:schema xmlns=\"http://www.cnkirito.moe/schema/kirito\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:beans=\"http://www.springframework.org/schema/beans\" targetNamespace=\"http://www.cnkirito.moe/schema/kirito\"&gt; ① &lt;xsd:import namespace=\"http://www.springframework.org/schema/beans\"/&gt; &lt;xsd:element name=\"application\"&gt; ② &lt;xsd:complexType&gt; &lt;xsd:complexContent&gt; &lt;xsd:extension base=\"beans:identifiedType\"&gt; &lt;xsd:attribute name=\"name\" type=\"xsd:string\" use=\"required\"/&gt; &lt;/xsd:extension&gt; &lt;/xsd:complexContent&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;xsd:element name=\"service\"&gt; ② &lt;xsd:complexType&gt; &lt;xsd:complexContent&gt; &lt;xsd:extension base=\"beans:identifiedType\"&gt; &lt;xsd:attribute name=\"name\" type=\"xsd:string\" use=\"required\"/&gt; &lt;/xsd:extension&gt; &lt;/xsd:complexContent&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt;&lt;/xsd:schema&gt; ① 注意这里的 targetNamespace=&quot;http://www.cnkirito.moe/schema/kirito&quot; 这便是之后 kirito 标签的关键点。 ② kirito.xsd 定义了两个元素： application 和 service，出于简单考虑，都只有一个 name 字段。 schema 的意义在于它可以和 eclipse/IDEA 这样智能化的集成开发环境形成很好的搭配，在编辑 XML 的过程中，用户可以获得告警和提示。 如果配置得当，可以使用自动完成功能让用户在事先定义好的枚举类型中进行选择。 2 编写 KiritoNamespaceHandler123456789public class KiritoNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; super.registerBeanDefinitionParser(\"application\", new KiritoBeanDefinitionParser(ApplicationConfig.class)); super.registerBeanDefinitionParser(\"service\", new KiritoBeanDefinitionParser(ServiceBean.class)); &#125;&#125; 完成 schema 之后，还需要一个 NamespaceHandler 来帮助 Spring 解析 XML 中不同命名空间的各类元素。 123&lt;kirito:application name=\"kirito\"/&gt;&lt;dubbo:application name=\"dubbo\"/&gt;&lt;motan:application name=\"motan\"/&gt; 不同的命名空间需要不同的 NamespaceHandler 来处理，在今天的示例中，我们使用 KiritoNamespaceHandler 来解析 kirito 命名空间。KiritoNamespaceHandler 继承自 NamespaceHandlerSupport 类，并在其 init() 方法中注册了两个 BeanDefinitionParser ，用于解析 kirito 命名空间 /kirito.xsd 约束中定义的两个元素：application，service。BeanDefinitionParser 是下一步的主角，我们暂且跳过，将重心放在父类 NamespaceHandlerSupport 之上。 12345public interface NamespaceHandler &#123; void init(); BeanDefinition parse(Element element, ParserContext parserContext); BeanDefinitionHolder decorate(Node source, BeanDefinitionHolder definition, ParserContext parserContext);&#125; NamespaceHandlerSupport 是 NamespaceHandler 命名空间处理器的抽象实现，我粗略看了 NamespaceHandler 的几个实现类，parse 和 decorate 方法可以完成元素节点的组装并通过 ParserContext 注册到 Ioc 容器中，但实际我们并没有调用这两个方法，而是通过 init() 方法注册 BeanDefinitionParser 来完成解析节点以及注册 Bean 的工作，所以对于 NamespaceHandler，我们主要关心 init 中注册的两个 BeanDefinitionParser 即可。 3 编写 KiritoBeanDefinitionParser在文章开始我们便标记到 BeanDefinitionParser 是最为关键的一环，每一个 BeanDefinitionParser 实现类都负责一个映射，将一个 XML 节点解析成 IOC 容器中的一个实体类。 123456789101112131415161718192021222324public class KiritoBeanDefinitionParser implements BeanDefinitionParser &#123; private final Class&lt;?&gt; beanClass; public KiritoBeanDefinitionParser(Class&lt;?&gt; beanClass) &#123; this.beanClass = beanClass; &#125; private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass) &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(beanClass); beanDefinition.setLazyInit(false); String name = element.getAttribute(\"name\"); beanDefinition.getPropertyValues().addPropertyValue(\"name\", name); parserContext.getRegistry().registerBeanDefinition(name, beanDefinition); return beanDefinition; &#125; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; return parse(element, parserContext, beanClass); &#125;&#125; 由于我们的实体类是非常简单的，所以不存在很复杂的解析代码，而实际项目中，往往需要大量的解析步骤。parse 方法会解析一个个 XML 中的元素，使用 RootBeanDefinition 组装成对象，并最终通过 parserContext 注册到 IOC 容器中。 至此，我们便完成了 XML 文件中定义的对象到 IOC 容器的映射。 4 注册 schema 和 handler最后一步还需要通知 Spring，告知其自定义 schema 的所在之处以及对应的处理器。 resources/META-INF/spring.handlers 1http\\://www.cnkirito.moe/schema/kirito=moe.cnkirito.sample.xsd.KiritoNamespaceHandler resources/META-INF/spring.schemas 1http\\://www.cnkirito.moe/schema/kirito/kirito.xsd=META-INF/kirito.xsd 没有太多可以说的，需要遵守 Spring 的约定。 至此一个自定义的 XML schema 便扩展完成了，随后来验证一下。 验证扩展我们首先定义好 kirito.xml 123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:kirito=\"http://www.cnkirito.moe/schema/kirito\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.cnkirito.moe/schema/kirito http://www.cnkirito.moe/schema/kirito/kirito.xsd\"&gt; &lt;kirito:application name=\"kirito-demo-application\"/&gt; &lt;kirito:service name=\"kirito-demo-service\"/&gt;&lt;/beans&gt; 使用 Spring 去加载它，并验证 IOC 容器中是否存在注册成功的 Bean。 123456789101112@SpringBootApplication@ImportResource(locations = &#123;\"classpath:kirito.xml\"&#125;)public class XmlSchemaAuthoringSampleApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext applicationContext = SpringApplication.run(XmlSchemaAuthoringSampleApplication.class, args); ServiceBean serviceBean = applicationContext.getBean(ServiceBean.class); System.out.println(serviceBean.getName()); ApplicationConfig applicationConfig = applicationContext.getBean(ApplicationConfig.class); System.out.println(applicationConfig.getName()); &#125;&#125; 观察控制台的输出： kirito-demo-servicekirito-demo-application 一个基础的基于 XML schema 的扩展便完成了。 Dubbo 中的 XML schema 扩展最后我们以 Dubbo 为例，看看一个成熟的 XML schema 扩展是如何被应用的。 刚好对应了四个标准的扩展步骤，是不是对 XML 配置下的 Dubbo 应用有了更好的理解了呢？ 顺带一提，仅仅完成 Bean 的注册还是不够的，在“注册”的同时，Dubbo 还进行了一系列其他操作如：暴露端口，开启服务器，完成注册中心的注册，生成代理对象等等行为，由于不在本文的范围内，后续的 Dubbo 专题会专门介绍这些细节，本文便是了解 Dubbo 加载流程的前置文章了。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"XML","slug":"XML","permalink":"http://lexburner.github.io/tags/XML/"}]},{"title":"如何向开源项目做贡献 (以 incubator-dubbo 为例)","slug":"contribute-to-opensource","date":"2018-08-22T11:47:28.000Z","updated":"2019-09-26T09:45:31.399Z","comments":true,"path":"contribute-to-opensource/","link":"","permalink":"http://lexburner.github.io/contribute-to-opensource/","excerpt":"Github 上有众多优秀的开源项目，大多数 IT 从业者将其当做了予取予求的工具库，遇到什么需求，先去 Github 搜一把，但有没有想过有一天自己也可以给开源事业做一些贡献呢？本文将会以 incubator-dubbo 项目为例，向你阐释，给开源项目做贡献并不是一件难事。","text":"Github 上有众多优秀的开源项目，大多数 IT 从业者将其当做了予取予求的工具库，遇到什么需求，先去 Github 搜一把，但有没有想过有一天自己也可以给开源事业做一些贡献呢？本文将会以 incubator-dubbo 项目为例，向你阐释，给开源项目做贡献并不是一件难事。 1 为何要给开源贡献力量为开源项目做贡献得到的收益是多方面的，为了让你有足够的信心加入到开源项目中，我在文章最开始列举出它的诸多好处。 1.1 巩固技能无论你是提交代码，撰写文档，提交 Issue，组织活动，当你切身参与到一个开源项目中，相关的技能都会得到历练，并且在开源项目中找到自己的位置。一方面，日常工作中我们中的大多数人接触到的是业务场景，并没有太多机会接触到基础架构组件，开源项目为我们提供了一个平台，在这里，你可以尽情挑选自己熟悉的项目为它添砖加瓦（以 Dubbo 为例，并不是所有 IT 公司都有能力自研服务治理框架）；另一方面，你所提交的代码，会有管理员协助审核，他们会给出专业的建议，更好的代码规范以及更优的编程思路最终都会变成你的经验。 1.2 结交朋友开源社区为你提供了一个平台，在这里，你可以认识很多纯粹的技术爱好者，开源贡献者是最符合 geek 定义的那群人，你所接触到的往往是某个领域最厉害的那批人。 1.3 建立口碑这是一个很好的展示个人实力的地方，俗话说：talk is cheap，show me the code. 作为技术人员，没有什么比一个漂亮的 Github 主页更有说服力的了。如果你能够为开源项目做出可观的贡献，你也将收获到业界的知名度，此时开源项目的成就和你是密不可分的。 1.4 传承开源精神只有源源不断的贡献者给开源项目添砖加瓦，才可以为 Github 一类的开源社区形成良好的开源风气。否则，只有输出没有输入，开源会失去活力。 1.5 养成习惯相信我，一旦养成了每天提交代码的习惯，就像你不想中断打卡一样，你绝不想中断 commit。不止有英语打卡，健身打卡，还有开源打卡！ 2 贡献代码时的一些疑难杂症如果你是一名开源界的新手，可能会对贡献的流程心生畏惧。比如：我该怎么修改代码并提交？我的代码要是存在 bug 怎么办？我的代码别人会不会很 low？我该如何寻找合适的开源项目？开源社区那么多的工具和词汇都是什么意思？ 文章的第二部分将从一个 小白 的角度，介绍一下开源中的一些常见问题。 2.1 git 常规操作一般而言，我们选择使用 git 来作为版本管理的工具，你不一定要非常熟练的使用它，在我看来掌握 clone，add，commit，pull，push 即可，遇到复杂的场景，你还有谷歌。 fork 与 clone 如果你只是想下载源码，查看他的源码实现，使用 Clone or download 按钮即可。 如果你想要给开源项目做改动，并且最终请求合并，让开源项目存在你贡献的代码，就应该使用 fork。 fork 将会复制一份当前主分支的代码进入到你的仓库中，之后你所有的修改，应当基于自己的仓库进行，在功能开发 /bug 修复之后，可以使用你的仓库向源仓库提交 pull request。只有源仓库的管理员才有权利合并你的请求。 一些可能对你有帮助的高级指令。 1234567# 设置源仓库git remote add upstream https://github.com/apache/incubator-dubbo.git# 拉取源仓库的更新git fetch upstream# 将自己仓库的主分支合并源仓库的更新git checkout mastergit merge upstream/master pull request pull request 经常被缩写为 PR，指的是一次向源仓库请求合并的行为，如上是我 fork 了 incubator-dubbo 的仓库之后才存在的操作按钮。 源仓库视角的 pull request 管理者会对 pull request 涉及的改动进行 review，以确保你的代码是符合规范的，逻辑有没有偏差，以及符合框架的功能需求。 2.2 Travis CI一些自动化的 CI 流程被植入在每一次 pull request 的构建之中，用于给开源仓库去校验提交者的代码是否符合既定的规范，如：是否有编译问题，单元测试是否通过，覆盖率是否达标，代码风格是否合规等等。 一般情况下，必须通过 CI，你的 pull request 才会被管理 review。 2.3 Mailing list每个开源项目都会有自己的贡献规范，可以参考首页的 Contributing，来获取具体的信息。incubator-dubbo 作为一个孵化中的 apache 项目，遵守了 apache 的传统，在 Contributing 中描述道：当你有新特性想要贡献给 Dubbo 时，官方推荐使用 Mailing list 的方式描述一遍你想要做的改动。 Mailing list 简单来说，就是一个邮件通知机制，所有的 Dubbo 开发者都会订阅该邮箱：dev@dubbo.incubator.apache.org。有任何新特性的改动，或者什么建议想要通知其他开发者，都可以通过向该邮箱发送邮件来达到这个目的，相同地，你也会收到其转发的其他开发者的邮件。 或者你是一个 Dubbo 的使用者，你想要得知开发者的改造方向，也可以订阅，这个 指南 可以帮助你订阅 Dubbo 的 Mailing list。 作为一个 modern developer，你可能觉得 mailing list 的交流方式存在滞后性，这样的沟通方式不是特别的高效，但它作为 apache 项目的推荐交流方式存在其特殊的原因，在此不多赘述。总之遵循一个原则：bug fix 或者讨论，可以在 github issue 中进行，影响较大的特性和讨论则推荐在 mailing list 中展开。 3 其他贡献形式不仅仅只有贡献代码，修复 bug 等行为才算作为开源做贡献，以下这些行为也属于主要形式： 3.1 撰写文档 Dubbo 文档 是其开源组成成分的重要一环，其内容源文件位于：https://github.com/apache/incubator-dubbo-website。同样也是一个 Git 仓库，任何你想要对 dubbo 知识点的补充，都可以在这儿提交 pull request，只需要一些 markdown 的语法知识，和一些可有可无的 npm 语法即可。如果你觉得贡献代码对于现在的自己仍然有点难度，不妨从贡献文档开始接触开源。 3.2 ISSUE无论是 Github 中的 Issue 还是 mailing list 中的讨论，无论是提出问题，汇报 bug，还是回答问题（bugfix 则不仅仅需要 Issue 了），协助管理者 review pull request，都是贡献的一种形式，勿以善小而不为。 3.3 其他行为任何你能够想到的，可以帮助开源项目变得更好的的行为，都属于开源贡献。例如，给每个 Issue 打上合适的 tag，关闭重复的 Issue，链接相关联的 Issue，线下组织沙龙，回答 Stack Overflow 上相关的问题，以及文档中一个错别字的修改等等。 4 开源最佳实践4.1 有效沟通无论你处于什么样的目的：仅仅是一次性的贡献，亦或是永久性的加入社区，都的和他人进行沟通和交往，这是你要在开源圈发展必须修炼的技能。 在你开启一个 isse 或 PR 之前，或者是在聊天室问问题之前，请牢记下面所列出的几点建议，会让你的工作更加的高效。 给出上下文 以便于让其他人能够快速的理解。比方说你运行程序时遇到一个错误，要解释你是如何做的，并描述如何才能再现错误现象。又比方说你是提交一个新的想法，要解释你为什么这么想，对于项目有用处吗（不仅仅是只有你！） 😇 “当我做 Y 的时候 X 不能工作” 😢 “X 出问题! 请修复它。” 在进一步行动前，做好准备工作。 不知道没关系，但是要展现你尝试过、努力过。在寻求帮助之前，请确认阅读了项目的 README、文档、问题（开放的和关闭的）、邮件列表，并搜索了网络。当你表现出很强烈的求知欲的时候，人们是非常欣赏这点的，会很乐意的帮助你。 😇 “我不确定 X 是如何实现的，我查阅了相关的帮助文档，然而毫无所获。” 😢 “我该怎么做 X ?” 保持请求内容短小而直接。 正如发送一份邮件，每一次的贡献，无论是多么的简单，都是需要他人去查阅的。很多项目都是请求的人多，提供帮助的人少。相信我，保持简洁，你能得到他人帮助的机会会大大的增加。 😇 “我很乐意写 API 教程。” 😢 ” 有一天我驾驶汽车行驶在高速公路上，在某个加油站加油的时候，突发奇想，我们应该这么做，不过在我进一步解释之前，我先和大家展示一下。。。” 让所有的沟通都是在公开场合下进行。 哪怕是很不起眼的小事，也不要去给维护者发私信，除非是你要分享一些敏感信息（诸如安全问题或严重的过失）。你若能够保持谈话是公开的，很多人可以你们交换的意见中学习和受益。 😇 (评论) “@维护者 你好！我们该如何处理这个 PR？” 😢 (邮件) “你好，非常抱歉给发信，但是我实在很希望你能看一下我提交的 PR。” 大胆的提问（但是要谨慎！）。 每个人参与社区，开始的时候都是新手，哪怕是非常有经验的贡献者也一样，在刚进入一个新的项目的时候，也是新手。出于同样的原因, 甚至长期维护人员并不总是熟悉一个项目的每一部分。给他们同样的耐心, 你也会得到同样的回报。 😇 “感谢查看了这个错误，我按照您的建议做了，这是输出结果。” 😢 “你为什么不修复我的问题？这难道不是你的项目吗？” 尊重社区的决定。 你的想法可能会和社区的优先级、愿景等有差异，他们可能对于你的想法提供了反馈和最后的决定的理由，这时你应该去积极的讨论，并寻求妥协的办法，维护者必须慎重的考虑你的想法。但是如果你实在是不能同意社区的做法，你可以坚持自己！保持自己的分支，或者另起炉灶。 😇 “你不能支持我的用例，我蛮失望，但是你的解释仅仅是对一小部分用户起作用，我理解是为什么。感谢你的耐心倾听。” 😢 “你为什么不支持我的用例？这是不可接受的！” 以上几点，要铭记在心。 开源是由来自世界各地的人们共同协作实现的。面临的问题是跨语言、跨文化、不同的地理为止、不同的时区，另外，撰写文字的沟通更是难上加难，无法传达语气和情绪。请让这些会话都充满善意吧！在以下情形中请保持礼貌：推动一个想法、请求更多的上下文、进一步澄清你的立场。既然你在互联网找到了自己的所需，那么请尝试让它变得更好！ 4.2 创建 issue你应该在遇到下列情况下，去创建一个 issue： 报告你自己无法解决的错误 讨论一个高级主题或想法 期望实现某新的特性，或者其它项目的想法 在 issue 的沟通中几点实用的技巧: 如果你刚好看到一个开放的 issue，恰是你打算解决的， 添加评论，告诉他人你将对此展开工作，并及时响应。这样的话，可以避免他人重复劳动。 如果说某个 issue 已经开放很久了， 这可能是已经有人正在解决中，又或者是早已经解决过了，所以也请添加评论，在打算开始工作之前，最好是确认一下。 如果你创建了一个 issue，但是没多久自己解决了， 也要添加评论，让其他人知道，然后关闭该 issue。记录本身就是对社区的贡献。 4.3 创建 pull request在下面的情形时，请你务必使用 PR： 提交补丁 ( 例如，纠正拼写错误、损坏的链接、或者是其它较明显的错误） 开始一项别人请求的任务，或者是过去在 issue 中早就讨论过的 一个 PR 并不代表着工作已经完成。它通常是尽早的开启一个 PR，是为了其他人可以观看或者给作者反馈意见。只需要在子标题标记为“WIP”（正在进行中）。作者可以在后面添加很多评论。 如果说项目是托管在 GitHub 上的，以下是我们总结出的提交 RP 的建议： Fork 代码仓库 并克隆到本地，在本地的仓库配置“上游”为远端仓库。这样你可以在提交你的 PR 时保持和“上游”同步，会减少很多解决冲突的时间。(更多关于同步的说明，请参考 这里.) 创建一个分支 用于自己编辑。 参考任何相关的 issue 或者在你的 RP 中支持文档 (比如. “Closes #37.”) 包含之前和之后的快照 如果你的改动是包含了不同的 HTML/CSS。在你的 PR 中拖拉相应的图片。 测试你的改动！ 若测试用例存在的话，跑一遍，以覆盖你的更改，若没有的话，则创建相应的用例。无论测试是否存在，一定要确保你的改动不会破坏掉现有的项目。 和项目现有的风格保持一致 尽你最大的努力，这也就是意味着在使用缩进、分号、以及注释很可能和你自己的风格大相径庭，但是为了节省维护者的精力，以及未来他人更好的理解和维护，还请你容忍一下。 5 成为一个开源贡献者如果你有志于参与开源事业，可以尝试从自己最熟悉的项目开始，开源并不是属于高级开发者的专属词汇，它就是由你我这样的人在需求，修复，构建中演进下去的。Let’s try it ! 参考资料 如何为开源做贡献 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://lexburner.github.io/tags/Dubbo/"},{"name":"开源","slug":"开源","permalink":"http://lexburner.github.io/tags/开源/"}]},{"title":"Java 并发计数器探秘","slug":"java-concurrent-counter","date":"2018-08-22T11:47:28.000Z","updated":"2019-09-26T09:45:29.996Z","comments":true,"path":"java-concurrent-counter/","link":"","permalink":"http://lexburner.github.io/java-concurrent-counter/","excerpt":"前言一提到线程安全的并发计数器，AtomicLong 必然是第一个被联想到的工具。Atomic* 一系列的原子类以及它们背后的 CAS 无锁算法，常常是高性能，高并发的代名词。本文将会阐释，在并发场景下，使用 AtomicLong 来充当并发计数器将会是一个糟糕的设计，实际上存在不少 AtomicLong 之外的计数器方案。近期我研究了一些 Jdk1.8 以及 JCTools 的优化方案，并将它们的对比与实现细节整理于此。 相关面试题： 单机场景下，有比 AtomicLong 更高效的并发计数器方案吗？","text":"前言一提到线程安全的并发计数器，AtomicLong 必然是第一个被联想到的工具。Atomic* 一系列的原子类以及它们背后的 CAS 无锁算法，常常是高性能，高并发的代名词。本文将会阐释，在并发场景下，使用 AtomicLong 来充当并发计数器将会是一个糟糕的设计，实际上存在不少 AtomicLong 之外的计数器方案。近期我研究了一些 Jdk1.8 以及 JCTools 的优化方案，并将它们的对比与实现细节整理于此。 相关面试题： 单机场景下，有比 AtomicLong 更高效的并发计数器方案吗？ 阅读本文前本文相关的基准测试代码均可在博主的 github 中找到，测试方式全部采用 JMH，这篇文章可以帮助你 入门 JMH。 AtomicLong 的前世今生在 Java 中，Atomic* 是高效的，这得益于 sun.misc.Unsafe 提供的一系列底层 API，使得 Java 这样的高级语言能够直接和硬件层面的 CPU 指令打交道。并且在 Jdk1.7 中，这样的底层指令可以配合 CAS 操作，达到 Lock-Free。 在 Jdk1.7 中，AtomicLong 的关键代码如下： 123456789101112public final long getAndIncrement() &#123; while (true) &#123; long current = get(); long next = current + 1; if (compareAndSet(current, next)) return current; &#125;&#125;public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update);&#125; get() 方法 volatile 读当前 long 值 自增 自旋判断新值与当前值 自旋成功，返回；否则返回 1 我们特别留意到 Jdk1.7 中 unsafe 使用的方法是 compareAndSwapLong，它与 x86 CPU 上的 LOCK CMPXCHG 指令对应，并且在应用层使用 while(true) 完成自旋，这个细节在 Jdk1.8 中发生了变化。 在 Jdk1.8 中，AtomicLong 的关键代码如下： 123public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L);&#125; Jdk1.7 的 CAS 操作已经不复存在了，转而使用了 getAndAddLong 方法，它与 x86 CPU 上的 LOCK XADD 指令对应，以原子方式返回当前值并递增（fetch and add）。 当问及 Atomic* 高效的原因，回答 CAS 是不够全面且不够严谨的，Jdk1.7 的 unsafe.compareAndSwapLong 以及 Jdk1.8 的 unsafe.getAndAddLong 才是关键，且 Jdk1.8 中不存在 CAS。 Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。 AtomicLong 真的高效吗？无论在 Jdk1.7 还是 Jdk1.8 中，Atomic* 的开销都是很大的，主要体现在： 高并发下，CAS 操作可能会频繁失败，真正更新成功的线程占少数。(Jdk1.7 独有的问题) 我之前的文章中介绍过“伪共享” (false sharing) 问题，但在 CAS 中，问题则表现的更为直接，这是“真共享”，与”伪共享“存在相同的问题：缓存行失效，缓存一致性开销变大。 底层指令的开销不见得很低，无论是 LOCK XADD 还是 LOCK CMPXCHG，想深究的朋友可以参考 instruction_tables ，（这一点可能有点钻牛角尖，但不失为一个角度去分析高并发下可行的优化） Atomic 所做的，比我们的诉求可能更大，有时候我们只需要计数器具备线程安全地递增这样的特性，但 Atomic 的相关操作每一次都伴随着值的返回。他是个带返回值的方法，而不是 void 方法，而多做了活大概率意味着额外的开销。 抛开上述导致 AtomicLong 慢的原因，AtomicLong 仍然具备优势： 上述的第 4 点换一个角度也是 AtomicLong 的有点，相比下面要介绍的其他计数器方案，AtomicLong 能够保证每次操作都精确的返回真实的递增值。你可以借助 AtomicLong 来做并发场景下的递增序列号方案，注意，本文主要讨论的是计数器方案，而不是序列号方案。 实现简单，回到那句话：“简单的架构通常性能不高，高性能的架构通常复杂度很高”，AtomicLong 属于性能相对较高，但实现极其简单的那种方案，因为大部分的复杂性，由 JMM 和 JNI 方法屏蔽了。相比下面要介绍的其他计数器实现，AtomicLong 真的太“简易”了。 看一组 AtomicLong 在不同并发量下的性能表现。 线程数 increment get 1 22.31 ns/op 11.75 ns/op 3 78.80 ns/op 26.58 ns/op 5 132.85 ns/op 38.57 ns/op 10 242.61 ns/op 67.58 ns/op 20 488.74 ns/op 121.22 ns/op 横向对比，写的性能相比读的性能要差很多，在 20 个线程下写性能比读性能差距了 4~5 倍。 纵向对比，主要关注并发写，线程竞争激烈的情况下，单次自增耗时从 22 ns 增长为了 488 ns，有明显的性能下降。 实际场景中，我们需要统计系统的 qps、接口调用次数，都需要使用到计数的功能，写才是关键，并不是每时每刻都需要关注自增后的返回值，而 AtomicLong 恰恰在核心的写性能上有所欠缺。由此引出其他计数器方案。 认识 LongAdderDoug Lea 在 JDK1.8 中找到了一个上述问题的解决方案，他实现了一个 LongAdder 类。 123@since 1.8@author Doug Leapublic class LongAdder extends Striped64 implements Serializable &#123;&#125; LongAdder 的 API 如下 你应当发现，LongAdder 和 AtomicLong 明显的区别在于，increment 是一个 void 方法。直接来看看 LongAdder 的性能表现如何。(LA = LongAdder, AL = AtomicLong, 单位 ns/op) 线程数 LA.incr AL.incr LA.get AL.get 1 25.51 22.31 11.82 11.75 3 14.99 78.80 52.94 26.58 5 30.26 132.85 75.88 38.57 10 44.33 160.61 139.59 67.58 20 77.81 488.74 306.39 121.22 我们从中可以发现一些有意思的现象，网上不少很多文章没有从读写上对比二者，直接宣称 LongAdder 性能优于 AtomicLong，其实不太严谨。在单线程下，并发问题没有暴露，两者没有体现出差距；随着并发量加大，LongAdder 的 increment 操作更加优秀，而 AtomicLong 的 get 操作则更加优秀。鉴于在计数器场景下的特点—写多读少，所以写性能更高的 LongAdder 更加适合。 LongAdder 写速度快的背后网上分析 LongAdder 源码的文章并不少，我不打算详细分析源码，而是挑选了一些必要的细节以及多数文章没有提及但我认为值得分析的内容。 Cell 设计减少并发修改时的冲突 在 LongAdder 的父类 Striped64 中存在一个 volatile Cell[] cells; 数组，其长度是 2 的幂次方，每个 Cell 都填充了一个 @Contended 的 Long 字段，为了避免伪共享问题。 12345@sun.misc.Contended static final class Cell &#123; volatile long value; Cell(long x) &#123;value = x;&#125; // ... ignore&#125; LongAdder 通过一系列算法，将计数结果分散在了多个 Cell 中，Cell 会随着并发量升高时发生扩容，最坏情况下 Cell == CPU core 的数量。Cell 也是 LongAdder 高效的关键，它将计数的总值分散在了各个 Cell 中，例如 5 = 3 + 2，下一刻，某个线程完成了 3 + (2 + 1) = 6 的操作，而不是在 5 的基础上完成直接相加操作。通过 LongAdder 的 sum() 方法可以直观的感受到这一点（LongAdder 不存在 get 方法） 1234567891011public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 这种惰性求值的思想，在 ConcurrentHashMap 中的 size() 中也存在，毕竟他们的作者都是 Doug Lea。 并发场景下高效获取随机数 LongAdder 内部算法需要获取随机数，而 Random 类在并发场景下也是可以优化的。 12ThreadLocalRandom random = ThreadLocalRandom.current();random.nextInt(5); 使用 ThreadLocalRandom 替代 Random，同样出现在了 LongAdder 的代码中。 longAccumulate longAccumulate 方法是 LongAdder 的核心方法，内部存在大量的分支判断。首先和 Jdk1.7 的 AtomicLong 一样，它使用的是 UNSAFE.compareAndSwapLong 来完成自旋，不同之处在于，其在初次 cas 方式失败的情况下 (说明多个线程同时想更新这个值)，尝试将这个值分隔成多个 Cell，让这些竞争的线程只负责更新自己所属的 Cell，这样将竞争压力分散开。 LongAdder 的前世今生其实在 Jdk1.7 时代，LongAdder 还未诞生时，就有一些人想着自己去实现一个高性能的计数器了，比如一款 Java 性能监控框架 dropwizard/metrics 就做了这样事，在早期版本中，其优化手段并没有 Jdk1.8 的 LongAdder 丰富，而在 metrics 的最新版本中，其已经使用 Jdk1.8 的 LongAdder 替换掉了自己的轮子。在最后的测评中，我们将 metrics 版本的 LongAdder 也作为一个参考对象。 JCTools 中的 ConcurrentAutoTable并非只有 LongAdder 考虑到了并发场景下计数器的优化，大名鼎鼎的并发容器框架 JCTool 中也提供了和今天主题相关的实现，虽然其名称和 Counter 看似没有关系，但通过其 Java 文档和 API ，可以发现其设计意图考虑到了计数器的场景。 An auto-resizing table of longs, supporting low-contention CAS operations.Updates are done with CAS’s to no particular table element.The intent is to support highly scalable counters, r/w locks, and other structures where the updates are associative, loss-free (no-brainer), and otherwise happen at such a high volume that the cache contention for CAS’ing a single word is unacceptable. 在最后的测评中，我们将 JCTools 的 ConcurrentAutoTable 也作为一个参考对象。 最终测评Jdk1.7 的 AtomicLong，Jdk1.8 的 AtomicLong，Jdk 1.8 的 LongAdder，Metrics 的 LongAdder，JCTools 的 ConcurrentAutoTable，我对这五种类型的计数器使用 JMH 进行基准测试。 1234public interface Counter &#123; void inc(); long get();&#125; 将 5 个类都适配成 Counter 接口的实现类，采用 @State(Scope.Group)，@Group 将各组测试用例进行隔离，尽可能地排除了互相之间的干扰，由于计数器场景的特性，我安排了 20 个线程进行并发写，1 个线程与之前的写线程共存，进行并发读。Mode=avgt 代表测试的是方法的耗时，越低代表性能越高。 12345678910111213141516Benchmark (counterType) Mode Cnt Score Error UnitsCounterBenchmark.rw Atomic7 avgt 3 1049.906 ± 2146.838 ns/opCounterBenchmark.rw:get Atomic7 avgt 3 143.352 ± 125.388 ns/opCounterBenchmark.rw:inc Atomic7 avgt 3 1095.234 ± 2247.913 ns/opCounterBenchmark.rw Atomic8 avgt 3 441.837 ± 364.270 ns/opCounterBenchmark.rw:get Atomic8 avgt 3 149.817 ± 66.134 ns/opCounterBenchmark.rw:inc Atomic8 avgt 3 456.438 ± 384.646 ns/opCounterBenchmark.rw ConcurrentAutoTable avgt 3 144.490 ± 577.390 ns/opCounterBenchmark.rw:get ConcurrentAutoTable avgt 3 1243.494 ± 14313.764 ns/opCounterBenchmark.rw:inc ConcurrentAutoTable avgt 3 89.540 ± 166.375 ns/opCounterBenchmark.rw LongAdderMetrics avgt 3 105.736 ± 114.330 ns/opCounterBenchmark.rw:get LongAdderMetrics avgt 3 313.087 ± 307.381 ns/opCounterBenchmark.rw:inc LongAdderMetrics avgt 3 95.369 ± 132.379 ns/opCounterBenchmark.rw LongAdder8 avgt 3 98.338 ± 80.112 ns/opCounterBenchmark.rw:get LongAdder8 avgt 3 274.169 ± 113.247 ns/opCounterBenchmark.rw:inc LongAdder8 avgt 3 89.547 ± 78.720 ns/op 如果我们只关注 inc 即写性能，可以发现 jdk1.8 的 LongAdder 表现的最为优秀，ConcurrentAutoTable 以及两个版本的 LongAdder 在一个数量级之上；1.8 的 AtomicLong 相比 1.7 的 AtomicLong 优秀很多，可以得出这样的结论，1.7 的 CAS+LOCK CMPXCHG 方案的确不如 1.8 的 LOCK XADD 来的优秀，但如果与特地优化过的其他计数器方案来进行比较，便相形见绌了。 如果关注 get 性能，虽然这意义不大，但可以见得，AtomicLong 的 get 性能在高并发下表现依旧优秀，而 LongAdder 组合求值的特性，导致其性能必然存在一定下降，位列第二梯队，而 ConcurrentAutoTable 的并发读性能最差。 关注整体性能，CounterBenchmark.rw 是对一组场景的整合打分，可以发现，在我们模拟的高并发计数器场景下，1.8 的 LongAdder 获得整体最低的延迟 98 ns，相比性能最差的 Jdk1.7 AtomicLong 实现，高了整整 10 倍有余，并且，随着并发度提升，这个数值还会增大。 AtomicLong 可以被废弃吗？既然 LongAdder 的性能高出 AtomicLong 这么多，我们还有理由使用 AtomicLong 吗？ 本文重点讨论的角度还是比较局限的：单机场景下并发计数器的高效实现。AtomicLong 依然在很多场景下有其存在的价值，例如一个内存中的序列号生成器，AtomicLong 可以满足每次递增之后都精准的返回其递增值，而 LongAdder 并不具备这样的特性。LongAdder 为了性能而丧失了一部分功能，这体现了计算机的哲学，无处不在的 trade off。 高性能计数器总结 AtomicLong ：并发场景下读性能优秀，写性能急剧下降，不适合作为高性能的计数器方案。内存需求量少。 LongAdder ：并发场景下写性能优秀，读性能由于组合求值的原因，不如直接读值的方案，但由于计数器场景写多读少的缘故，整体性能在几个方案中最优，是高性能计数器的首选方案。由于 Cells 数组以及缓存行填充的缘故，占用内存较大。 ConcurrentAutoTable ：拥有和 LongAdder 相近的写入性能，读性能则更加不如 LongAdder。它的使用需要引入 JCTools 依赖，相比 Jdk 自带的 LongAdder 并没有优势。但额外说明一点，ConcurrentAutoTable 的使用并非局限于计数器场景，其仍然存在很大的价值。 在前面提到的性能监控框架 Metrics，以及著名的熔断框架 Hystrix 中，都存在 LongAdder 的使用场景，有兴趣的朋友快去实践一下 LongAdder 吧。 本文所有的 JMH 测试代码，均可在我的 github 中获得：https://github.com/lexburner/JMH-samples.git 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JAVA 并发合集","slug":"JAVA-并发合集","permalink":"http://lexburner.github.io/categories/JAVA-并发合集/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"JAVA 拾遗 — JMH 与 8 个测试陷阱","slug":"java-jmh","date":"2018-08-13T11:47:28.000Z","updated":"2019-09-26T09:45:31.310Z","comments":true,"path":"java-jmh/","link":"","permalink":"http://lexburner.github.io/java-jmh/","excerpt":"前言JMH 是 Java Microbenchmark Harness（微基准测试）框架的缩写（2013 年首次发布）。与其他众多测试框架相比，其特色优势在于它是由 Oracle 实现 JIT 的相同人员开发的。在此，我想特别提一下 Aleksey Shipilev（JMH 的作者兼布道者）和他优秀的博客文章。笔者花费了一个周末，将 Aleksey 大神的博客，特别是那些和 JMH 相关的文章通读了几遍，外加一部公开课视频 《”The Lesser of Two Evils” Story》 ，将自己的收获归纳在这篇文章中，文中不少图片都来自 Aleksey 公开课视频。","text":"前言JMH 是 Java Microbenchmark Harness（微基准测试）框架的缩写（2013 年首次发布）。与其他众多测试框架相比，其特色优势在于它是由 Oracle 实现 JIT 的相同人员开发的。在此，我想特别提一下 Aleksey Shipilev（JMH 的作者兼布道者）和他优秀的博客文章。笔者花费了一个周末，将 Aleksey 大神的博客，特别是那些和 JMH 相关的文章通读了几遍，外加一部公开课视频 《”The Lesser of Two Evils” Story》 ，将自己的收获归纳在这篇文章中，文中不少图片都来自 Aleksey 公开课视频。 阅读本文前本文没有花费专门的篇幅在文中介绍 JMH 的语法，如果你使用过 JMH，那当然最好，但如果没听过它，也不需要担心（跟我一周前的状态一样）。我会从 Java Developer 角度来谈谈一些常见的代码测试陷阱，分析他们和操作系统底层以及 Java 底层的关联性，并借助 JMH 来帮助大家摆脱这些陷阱。 通读本文，需要一些操作系统相关以及部分 JIT 的基础知识，如果遇到陌生的知识点，可以留意章节中的维基百科链接，以及笔者推荐的博客。 笔者能力有限，未能完全理解 JMH 解决的全部问题，如有错误以及疏漏欢迎留言与我交流。 初识 JMH测试精度 上图给出了不同类型测试的耗时数量级，可以发现 JMH 可以达到 微秒 级别的的精度。 这样几个数量级的测试所面临的挑战也是不同的。 毫秒级别的测试并不是很困难 微秒级别的测试是具备挑战性的，但并非无法完成，JMH 就做到了 纳秒级别的测试，目前还没有办法精准测试 皮秒级别…Holy Shit 图解： Linpack : Linpack benchmark 一类基础测试，度量系统的浮点计算能力 SPEC：Standard Performance Evaluation Corporation 工业界的测试标准组织 pipelining：系统总线通信的耗时 Benchmark 分类测试在不同的维度可以分为很多类：集成测试，单元测试，API 测试，压力测试… 而 Benchmark 通常译为基准测试（性能测试）。你可以在很多开源框架的包层级中发现 Benchmark，用于阐释该框架的基准水平，从而量化其性能。 基准测试又可以细分为 ：Micro benchmark，Kernels，Synthetic benchmark，Application benchmarks.etc. 本文的主角便属于 Benchmark 的 Micro benchmark。基础测试分类详细介绍 here 为什么需要有 Benchmark If you cannot measure it, you cannot improve it. –Lord Kelvin 俗话说，没有实践就没有发言权，Benchmark 为应用提供了数据支持，是评价和比较方法好坏的基准，Benchmark 的准确性，多样性便显得尤为重要。 Benchmark 作为应用框架，产品的基准画像，存在统一的标准，避免了不同测评对象自说自话的尴尬，应用框架各自使用有利于自身场景的测评方式必然不可取，例如 Standard Performance Evaluation Corporation (SPEC) 即上文“测试精度”提到的词便是工业界的标准组织之一，JMH 的作者 Aleksey 也是其中的成员。 JMH 长这样1234@Benchmarkpublic void measure() &#123; // this method was intentionally left blank.&#125; 使用起来和单元测试一样的简单 它的测评结果 12Benchmark Mode Cnt Score Error UnitsJMHSample_HelloWorld.measure thrpt 5 3126699413.430 ± 179167212.838 ops/s 为什么需要 JMH 测试你可能会想，我用下面的方式来测试有什么不好？ 123long start = System.currentTimeMillis();measure();System.out.println(System.currentTimeMillis()-start); 难道 JMH 不是这么测试的吗？ 123@Benchmarkpublic void measure() &#123;&#125; 事实上，这是本文的核心问题，建议在阅读时时刻带着这样的疑问，为什么不使用第一种方式来测试。 在下面的章节中，我将列举诸多的测试陷阱，他们都会为这个问题提供论据，这些陷阱会启发那些对“测试”不感冒的开发者。。 预热在初识 JMH 小节的最后，花少量的篇幅来给 JMH 涉及的知识点开个头，介绍一个 Java 测试中比较老生常谈的话题 — 预热 (warm up)，它存在于下面所有的测试中。 «Warmup» = waiting for the transient responses to settle down 特别是在编写 Java 测试程序时，预热从来都是不可或缺的一环，它使得结果更加真实可信。 上图展示了一个样例测评程序随着迭代次数增多执行耗时变化的曲线，可以发现在 120 次迭代之后，性能才趋于最终稳定，这意味着：预热阶段需要有至少 120 次迭代，才能得到准确的基础测试报告。（JVM 初始化时的一些准备工作以及 JIT 优化是主要原因，但不是唯一原因）。需要被说明的事，JMH 的运行相对耗时，因为，预热被前置在每一个测评任务之前。 使用 JMH 解决 12 个测试陷阱陷阱 1：死码消除 measureWrong 方法想要测试 Math.log 的性能，得到的结果和空方法 baseline 一致，而 measureRight 相比 measureWrong 多了一个 return，正确的得到了测试结果。 这是由于 JIT 擅长删除“无效”的代码，这给我们的测试带来了一些意外，当你意识到 DCE 现象后，应当有意识的去消费掉这些孤立的代码，例如 return。JMH 不会自动实施对冗余代码的消除。 死码消除 这个概念很多人其实并不陌生，注释的代码，不可达的代码块，可达但不被使用的代码等等，我这里补充一些 Aleksey 提到的概念，用以阐释为何一般测试方法难以避免引用对象发生死码消除现象： Fast object combinator. Need to escape object to limit thread-local optimizations. Publishing the object ⇒ reference heap write ⇒ store barrier. 很绝望，个人水平有限，我没能 get 到这些点，只能原封不动地贴给大家看了。 JMH 提供了专门的 API — Blockhole 来避免死码消除问题。 1234@Benchmarkpublic void measureRight(Blackhole bh) &#123; bh.consume(Math.log(PI));&#125; 陷阱 2：常量折叠与常量传播常量折叠 (Constant folding) 是一个在编译时期简化常数的一个过程，常数在表示式中仅仅代表一个简单的数值，就像是整数 2，若是一个变数从未被修改也可作为常数，或者直接将一个变数被明确地被标注为常数，例如下面的描述： 1i = 320 * 200 * 32; 多数的现代编译器不会真的产生两个乘法的指令再将结果储存下来，取而代之的，他们会辨识出语句的结构，并在编译时期将数值计算出来（在这个例子，结果为 2,048,000）。 有些编译器，常数折叠会在初期就处理完，例如 Java 中的 final 关键字修饰的变量就会被特殊处理。而将常数折叠放在较后期的阶段的编译器，也相当常见。 1234567891011121314151617181920212223242526private double x = Math.PI;// 编译器会对 final 变量特殊处理 private final double wrongX = Math.PI;@Benchmarkpublic double baseline() &#123; // 2.220 ± 0.352 ns/op return Math.PI;&#125;@Benchmarkpublic double measureWrong_1() &#123; // 2.220 ± 0.352 ns/op // 错误，结果可以被预测，会发生常量折叠 return Math.log(Math.PI);&#125;@Benchmarkpublic double measureWrong_2() &#123; // 2.220 ± 0.352 ns/op // 错误，结果可以被预测，会发生常量折叠 return Math.log(wrongX);&#125;@Benchmarkpublic double measureRight() &#123; // 22.590 ± 2.636 ns/op return Math.log(x);&#125; 经过 JMH 可以验证这一点：只有最后的 measureRight 正确测试出了 Math.log 的性能，measureWrong_1，measureWrong_2 都受到了常量折叠的影响。 常数传播 (Constant propagation) 是一个替代表示式中已知常数的过程，也是在编译时期进行，包含前述所定义，内建函数也适用于常数，以下列描述为例： 123int x = 14;int y = 7 - x / 2;return y * (28 / x + 2); 传播可以理解变量的替换，如果进行持续传播，上式会变成： 123int x = 14;int y = 0;return 0; 陷阱 3：永远不要在测试中写循环这个陷阱对我们做日常测试时的影响也是巨大的，所以我直接将他作为了标题：永远不要在测试中写循环！ 本节设计不少知识点，循环展开(loop unrolling)，JIT &amp; OSR 对循环的优化。对于前者循环展开的定义，建议读者直接查看 wiki 的定义，而对于后者 JIT &amp; OSR 对循环的优化，推荐两篇 R 大的知乎回答： 循环长度的相同、循环体代码相同的两次 for 循环的执行时间相差了 100 倍? OSR（On-Stack Replacement）是怎样的机制？ 对于第一个回答，建议不要看问题，直接看答案；第二个回答，阐释了 OSR 都对循环做了哪些手脚。 测试一个耗时较短的方法，入门级程序员（不了解动态编译的同学）会这样写，通过循环放大，再求均值。 12345678910public class BadMicrobenchmark &#123; public static void main(String[] args) &#123; long startTime = System.nanoTime(); for (int i = 0; i &lt; 10_000_000; i++) &#123; reps(); &#125; long endTime = System.nanoTime(); System.out.println(\"ns/op :\" + (endTime - startTime)); &#125;&#125; 实际上，这段代码的结果是不可预测的，太多影响因子会干扰结果。原理暂时不表，通过 JMH 来看看几个测试方法，下面的 Benchmark 尝试对 reps 方法迭代不同的次数，想从中获得 reps 真实的性能。（注意，在 JMH 中使用循环也是不可取的，除非你是 Benchmark 方面的专家，否则在任何时候，你都不应该写循环） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051int x = 1;int y = 2;@Benchmarkpublic int measureRight() &#123; return (x + y);&#125;private int reps(int reps) &#123; int s = 0; for (int i = 0; i &lt; reps; i++) &#123; s += (x + y); &#125; return s;&#125;@Benchmark@OperationsPerInvocation(1)public int measureWrong_1() &#123; return reps(1);&#125;@Benchmark@OperationsPerInvocation(10)public int measureWrong_10() &#123; return reps(10);&#125;@Benchmark@OperationsPerInvocation(100)public int measureWrong_100() &#123; return reps(100);&#125;@Benchmark@OperationsPerInvocation(1000)public int measureWrong_1000() &#123; return reps(1000);&#125;@Benchmark@OperationsPerInvocation(10000)public int measureWrong_10000() &#123; return reps(10000);&#125;@Benchmark@OperationsPerInvocation(100000)public int measureWrong_100000() &#123; return reps(100000);&#125; 结果如下： 12345678Benchmark Mode Cnt Score Error UnitsJMHSample_11_Loops.measureRight avgt 5 2.343 ± 0.199 ns/opJMHSample_11_Loops.measureWrong_1 avgt 5 2.358 ± 0.166 ns/opJMHSample_11_Loops.measureWrong_10 avgt 5 0.326 ± 0.354 ns/opJMHSample_11_Loops.measureWrong_100 avgt 5 0.032 ± 0.011 ns/opJMHSample_11_Loops.measureWrong_1000 avgt 5 0.025 ± 0.002 ns/opJMHSample_11_Loops.measureWrong_10000 avgt 5 0.022 ± 0.005 ns/opJMHSample_11_Loops.measureWrong_100000 avgt 5 0.019 ± 0.001 ns/op 如果不看事先给出的错误和正确的提示，上述的结果，你会选择相信哪一个？实际上跑分耗时从 2.358 随着迭代次数变大，降为了 0.019。手动测试循环的代码 BadMicrobenchmark 也存在同样的问题，实际上它没有做预热，效果只会比 JMH 测试循环更加不可信。 Aleksey 在视频中给出结论：假设单词迭代的耗时是 𝑀 ns. 在 JIT，OSR，循环展开等因素的多重作用下，多次迭代的耗时理论值为 𝛼𝑀 ns, 其中 𝛼 ∈ [0; +∞)。 正确的测试循环的姿势可以看这里：here 陷阱 4：使用 Fork 隔离多个测试方法相信我，这个陷阱中涉及到的例子绝对是 JMH sample 中最诡异的，并且我还没有找到科学的解释（说实话视频中这一段我尝试听了好几遍，没听懂，原谅我的听力） 首先定义一个 Counter 接口，并实现了两份代码完全相同的实现类：Counter1，Counter2 123456789101112131415161718192021public interface Counter &#123; int inc();&#125;public class Counter1 implements Counter &#123; private int x; @Override public int inc() &#123; return x++; &#125;&#125;public class Counter2 implements Counter &#123; private int x; @Override public int inc() &#123; return x++; &#125;&#125; 接着让他们在 同一个 VM 中按照先手顺序进行评测： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public int measure(Counter c) &#123; int s = 0; for (int i = 0; i &lt; 10; i++) &#123; s += c.inc(); &#125; return s;&#125;/* * These are two counters. */Counter c1 = new Counter1();Counter c2 = new Counter2();/* * We first measure the Counter1 alone... * Fork(0) helps to run in the same JVM. */@Benchmark@Fork(0)public int measure_1_c1() &#123; return measure(c1);&#125;/* * Then Counter2... */@Benchmark@Fork(0)public int measure_2_c2() &#123; return measure(c1);&#125;/* * Then Counter1 again... */@Benchmark@Fork(0)public int measure_3_c1_again() &#123; return measure(c1);&#125;@Benchmark@Fork(1)public int measure_4_forked_c1() &#123; return measure(c1);&#125;@Benchmark@Fork(1)public int measure_5_forked_c2() &#123; return measure(c2);&#125; 这一个例子中多了一个 Fork 注解，让我来简单介绍下它。Fork 这个关键字顾名思义，是用来将运行环境复制一份的意思，在我们之前的多个测试中，实际上每次测评都是默认使用了 相互隔离的，完全一致 的测评环境，这得益于 JMH。每个试验运行在单独的 JVM 进程中。也可以指定 (额外的) JVM 参数，例如这里为了演示运行在同一个 JVM 中的弊端，特地做了反面的教材：Fork(0)。试想一下 c1，c2，c1 again 的耗时结果会如何？ 123456Benchmark Mode Cnt Score Error UnitsJMHSample_12_Forking.measure_1_c1 avgt 5 2.518 ± 0.622 ns/opJMHSample_12_Forking.measure_2_c2 avgt 5 14.080 ± 0.283 ns/opJMHSample_12_Forking.measure_3_c1_again avgt 5 13.462 ± 0.164 ns/opJMHSample_12_Forking.measure_4_forked_c1 avgt 5 3.861 ± 0.712 ns/opJMHSample_12_Forking.measure_5_forked_c2 avgt 5 3.574 ± 0.220 ns/op 你会不会感到惊讶，第一次运行的 c1 竟然耗时最低，在我的认知中，JIT 起码会启动预热的作用，无论如何都不可能先运行的方法比之后的方法快这么多！但这个结果也和 Aleksey 视频中介绍的相符。 JMH samples 中的这个示例主要还是想要表达同一个 JVM 中运行的测评代码会互相影响，从结果也可以发现：c1,c2,c1_again 的实现相同，跑分却不同，因为运行在同一个 JVM 中；而 forked_c1 和 forked_c2 则表现出了一致的性能。所以没有特殊原因，Fork 的值一般都需要设置为 &gt;0。 陷阱 5：方法内联熟悉 C/C++ 的朋友不会对方法内联感到陌生，方法内联就是把目标方法的代码“复制”到发起调用的方法之中，避免发生真实的方法调用（减少了操作指令周期）。在 Java 中，无法手动编写内联方法，但 JVM 会自动识别热点方法，并对它们使用方法内联优化。一段代码需要执行多少次才会触发 JIT 优化通常这个值由 -XX:CompileThreshold 参数进行设置： 1、使用 client 编译器时，默认为 1500； 2、使用 server 编译器时，默认为 10000； 但是一个方法就算被 JVM 标注成为热点方法，JVM 仍然不一定会对它做方法内联优化。其中有个比较常见的原因就是这个方法体太大了，分为两种情况。 如果方法是经常执行的，默认情况下，方法大小小于 325 字节的都会进行内联（可以通过 -XX:MaxFreqInlineSize=N 来设置这个大小） 如果方法不是经常执行的，默认情况下，方法大小小于 35 字节才会进行内联（可以通过 -XX:MaxInlineSize=N 来设置这个大小） 我们可以通过增加这个大小，以便更多的方法可以进行内联；但是除非能够显著提升性能，否则不推荐修改这个参数。因为更大的方法体会导致代码内存占用更多，更少的热点方法会被缓存，最终的效果不一定好。 如果想要知道方法被内联的情况，可以使用下面的 JVM 参数来配置 123-XX:+PrintCompilation // 在控制台打印编译过程信息-XX:+UnlockDiagnosticVMOptions // 解锁对 JVM 进行诊断的选项参数。默认是关闭的，开启后支持一些特定参数对 JVM 进行诊断-XX:+PrintInlining // 将内联方法打印出来 方法内联的其他隐含条件 虽然 JIT 号称可以针对代码全局的运行情况而优化，但是 JIT 对一个方法内联之后，还是可能因为方法被继承，导致需要类型检查而没有达到性能的效果 想要对热点的方法使用上内联的优化方法，最好尽量使用 final、private、static 这些修饰符修饰方法，避免方法因为继承，导致需要额外的类型检查，而出现效果不好情况。 方法内联也可能对 Benchmark 产生影响；或者说有时候我们为了优化代码，而故意触发内联，也可以通过 JMH 来和非内联方法进行性能对比: 12345678910111213public void target_blank() &#123; // this method was intentionally left blank&#125;@CompilerControl(CompilerControl.Mode.DONT_INLINE)public void target_dontInline() &#123; // this method was intentionally left blank&#125;@CompilerControl(CompilerControl.Mode.INLINE)public void target_inline() &#123; // this method was intentionally left blank&#125; 1234Benchmark Mode Cnt Score Error UnitsJMHSample_16_CompilerControl.blank avgt 3 0.323 ± 0.544 ns/opJMHSample_16_CompilerControl.dontinline avgt 3 2.099 ± 7.515 ns/opJMHSample_16_CompilerControl.inline avgt 3 0.308 ± 0.264 ns/op 可以发现，内联与不内联的性能差距是巨大的，有一些空间换时间的味道，在 JMH 中使用 CompilerControl.Mode 来控制内联是否开启。 陷阱 6：伪共享与缓存行又遇到了我们的老朋友：CPU Cache 和缓存行填充。这个并发性能杀手，我在之前的文章中专门介绍过，如果你没有看过，可以戳这里：JAVA 拾遗 — CPU Cache 与缓存行。在 Benchmark 中，有时也不能忽视缓存行对测评的影响。 受限于篇幅，在此不展开有关伪共享的陷阱，完整的测评可以戳这里：JMHSample_22_FalseSharing JMH 为解决伪共享问题，提供了 @State 注解，但并不能在单一对象内部对个别的字段增加，如果有必要，可以使用并发包中的 @Contended 注解来处理。 Aleksey 曾为 Java 并发包提供过优化，其中就包括 @Contended 注解。 陷阱 7：分支预测分支预测（Branch Prediction）是这篇文章中介绍的最后一个 Benchmark 中的“捣蛋鬼”。还是从一个具体的 Benchmark 中观察结果。下面的代码尝试遍历了两个长度相等的数组，一个有序，一个无序，并在迭代时加入了一个判断语句，这是分支预测的关键：if(v &gt; 0) 1234567891011121314151617181920212223242526272829303132333435363738private static final int COUNT = 1024 * 1024;private byte[] sorted;private byte[] unsorted;@Setuppublic void setup() &#123; sorted = new byte[COUNT]; unsorted = new byte[COUNT]; Random random = new Random(1234); random.nextBytes(sorted); random.nextBytes(unsorted); Arrays.sort(sorted);&#125;@Benchmark@OperationsPerInvocation(COUNT)public void sorted(Blackhole bh1, Blackhole bh2) &#123; for (byte v : sorted) &#123; if (v &gt; 0) &#123; // 关键 bh1.consume(v); &#125; else &#123; bh2.consume(v); &#125; &#125;&#125;@Benchmark@OperationsPerInvocation(COUNT)public void unsorted(Blackhole bh1, Blackhole bh2) &#123; for (byte v : unsorted) &#123; if (v &gt; 0) &#123; // 关键 bh1.consume(v); &#125; else &#123; bh2.consume(v); &#125; &#125;&#125; 123Benchmark Mode Cnt Score Error UnitsJMHSample_36_BranchPrediction.sorted avgt 25 2.752 ± 0.154 ns/opJMHSample_36_BranchPrediction.unsorted avgt 25 8.175 ± 0.883 ns/op 从结果看，有序数组的遍历比无序数组的遍历快了 2-3 倍。关于这点的介绍，最佳的解释来自于 Stack Overflow 一个 2w 多赞的答案：Why is it faster to process a sorted array than an unsorted array? 假设我们是在 19 世纪，而你负责为火车选择一个方向，那时连电话和手机还没有普及，当火车开来时，你不知道火车往哪个方向开。于是你的做法（算法）是：叫停火车，此时火车停下来，你去问司机，然后你确定了火车往哪个方向开，并把铁轨扳到了对应的轨道。 还有一个需要注意的地方是，火车的惯性是非常大的，所以司机必须在很远的地方就开始减速。当你把铁轨扳正确方向后，火车从启动到加速又要经过很长的时间。 那么是否有更好的方式可以减少火车的等待时间呢？ 有一个非常简单的方式，你提前把轨道扳到某一个方向。那么到底要扳到哪个方向呢，你使用的手段是——“瞎蒙”： 如果蒙对了，火车直接通过，耗时为 0。 如果蒙错了，火车停止，然后倒回去，你将铁轨扳至反方向，火车重新启动，加速，行驶。 如果你很幸运，每次都蒙对了，火车将从不停车，一直前行！如果不幸你蒙错了，那么将浪费很长的时间。 虽然不严谨，但你可以用同样的道理去揣测 CPU 的分支预测，有序数组使得这样的预测大部分情况下是正确的，所以带有判断条件时，有序数组的遍历要比无序数组要快。 这同时也启发我们：在大规模循环逻辑中要尽量避免大量判断（是不是可以抽取到循环外呢？）。 陷阱 8：多线程测试 在 4 核的系统之上运行一个测试方法，得到如上的测试结果， Ops/nsec 代表了单位时间内的运行次数，Scale 代表 2，4 线程相比 1 线程的运行次数倍率。 这个图可供我们提出两个问题： 为什么 2 线程 -&gt; 4 线程几乎没有变化？ 为什么 2 线程相比 1 线程只有 1.87 倍的变化，而不是 2 倍？ 1 电源管理 第一个影响因素便是多线程测试会受到操作系统电源管理（Power Management）的影响，许多系统存在能耗和性能的优化管理。 (Ex: cpufreq, SpeedStep, Cool&amp;Quiet, TurboBoost) 当我们主动对机器进行降频之后，整体性能发生下降，但是 Scale 在线程数 1 -&gt; 2 的过程中变成了严谨的 2 倍。 这样的问题并非无法规避，补救方法便是禁用电源管理, 保证 CPU 的时钟频率 。 JMH 通过长时间运行，保证线程不出现 park(time waiting) 状态，来保证测试的精准性。 2 操作系统调度和分时调用模型 造成多线程测试陷阱的第二个问题，需要从线程调度模型出发来理解：分时调度模型和抢占式调度模型。 分时调度模型是指让所有的线程轮流获得 CPU 的使用权, 并且平均分配每个线程占用的 CPU 的时间片，这个也比较好理解；抢占式调度模型，是指优先让可运行池中优先级高的线程占用 CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用 CPU。处于运行状态的线程会一直运行，直至它不得不放弃 CPU。一个线程会因为以下原因而放弃 CPU。 需要注意的是，线程的调度不是跨平台的，它不仅仅取决于 Java 虚拟机，还依赖于操作系统。在某些操作系统中，只要运行中的线程没有遇到阻塞，就不会放弃 CPU；在某些操作系统中，即使线程没有遇到阻塞，也会运行一段时间后放弃 CPU，给其它线程运行的机会。 无论是那种模型，线程上下文的切换都会造成损耗。到这儿为止，还是只回答了第一个问题：为什么 2 线程相比 1 线程只有 1.87 倍的变化，而不是 2 倍？ 由于上述的两个图我都是从 Aleksey 的视频中抠出来的，并不清楚他的实际测试用例，对于 2 -&gt; 4 线程性能差距并不大只能理解为系统过载，按道理说 4 核的机器，运行 4 个线程应该不至于只比 2 个线程快这么一点。 对于线程分时调用以及线程调度带来的不稳定性，JMH 引入了 bogus iterations 的概念，它保障了在多线程测试过程中，只在线程处于忙碌状态的过程中进行测量。 bogus iterations 这个值得一提，我理解为“伪迭代”，并且也只在 JVM 的注释以及 Aleksey 的几个博客中有介绍，可以理解为 JMH 的内部原理的专用词。 总结本文花了大量的篇幅介绍了 JMH 存在的意义，以及 JMH sample 中提到的诸多陷阱，这些陷阱会非常容易地被那些不规范的测评程序所触发。我觉得作为 Java 语言的使用者，起码有必要了解这些现象的存在，毕竟 JMH 已经帮你解决了诸多问题了，你不用担心预热问题，不用自己写比较 low 的循环去评测，规避这些测试陷阱也变得相对容易。 实际上，本文设计的知识点，仅仅是 Aleksey 博客中的内容、 JMH 的 38 个 sample 的冰山一角，有兴趣的朋友可以戳这里查看所有的 JMH sample 陷阱内心 os：像我这么 diao 的陷阱，还有 30 个！ 例如 Kafka 这样优秀的开源框架，提供了专门的 module 来做 JMH 的基础测试。尝试使用 JMH 作为你的 Benchmark 工具吧。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"JAVA 拾遗 — CPU Cache 与缓存行","slug":"cache-line","date":"2018-07-21T11:47:28.000Z","updated":"2019-09-26T09:45:31.546Z","comments":true,"path":"cache-line/","link":"","permalink":"http://lexburner.github.io/cache-line/","excerpt":"最近的两篇文章，介绍了我参加的中间件比赛中一些相对重要的优化，但实际上还存在很多细节优化，出于篇幅限制并未提及，在最近的博文中，我会将他们整理成独立的知识点，并归类到我的系列文章「JAVA 拾遗」中。","text":"最近的两篇文章，介绍了我参加的中间件比赛中一些相对重要的优化，但实际上还存在很多细节优化，出于篇幅限制并未提及，在最近的博文中，我会将他们整理成独立的知识点，并归类到我的系列文章「JAVA 拾遗」中。 引言123456789101112131415161718192021222324public class Main &#123; static long[][] arr; public static void main(String[] args) &#123; arr = new long[1024 * 1024][8]; // 横向遍历 long marked = System.currentTimeMillis(); for (int i = 0; i &lt; 1024 * 1024; i += 1) &#123; for (int j = 0; j &lt; 8; j++) &#123; sum += arr[i][j]; &#125; &#125; System.out.println(\"Loop times:\" + (System.currentTimeMillis() - marked)+ \"ms\"); marked = System.currentTimeMillis(); // 纵向遍历 for (int i = 0; i &lt; 8; i += 1) &#123; for (int j = 0; j &lt; 1024 * 1024; j++) &#123; sum += arr[j][i]; &#125; &#125; System.out.println(\"Loop times:\" + (System.currentTimeMillis() - marked)+ \"ms\"); &#125;&#125; 如上述代码所示，定义了一个二维数组 long[][] arr 并且使用了横向遍历和纵向遍历两种顺序对这个二位数组进行遍历，遍历总次数相同，只不过循环的方向不同，代码中记录了这两种遍历方式的耗时，不妨先卖个关子，他们的耗时会有区别吗？ 这问题问的和中小学试卷中的：“它们之间有区别吗？如有，请说出区别。”一样没有水准，没区别的话文章到这儿就结束了。事实上，在我的机器上（64 位 mac）多次运行后可以发现：横向遍历的耗时大约为 25 ms，纵向遍历的耗时大约为 60 ms，前者比后者快了 1 倍有余。如果你了解上述现象出现的原因，大概能猜到，今天这篇文章的主角便是他了— CPU Cache&amp;Cache Line。 在学生生涯时，不断收到这样建议：《计算机网络》、《计算机组成原理》、《计算机操作系统》、《数据结构》四门课程是至关重要的，而在我这些年的工作经验中也不断地意识到前辈们如此建议的原因。作为一个 Java 程序员，你可以选择不去理解操作系统，组成原理（相比这二者，网络和数据结构跟日常工作联系得相对紧密），这不会降低你的 KPI，但了解他们可以使你写出更加计算机友好（Mechanical Sympathy）的代码。 下面的章节将会出现不少操作系统相关的术语，我将逐个介绍他们，并最终将他们与 Java 联系在一起。 什么是 CPU 高速缓存？CPU 是计算机的心脏，最终由它来执行所有运算和程序。主内存（RAM）是数据（包括代码行）存放的地方。这两者的定义大家应该不会陌生，那 CPU 高速缓存又是什么呢？ 在 计算机 系统中，CPU 高速缓存 是用于减少处理器访问内存所需平均时间的部件。在金字塔式 存储体系 中它位于自顶向下的第二层，仅次于CPU 寄存器。其容量远小于内存，但速度却可以接近处理器的频率。 当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。 缓存之所以有效，主要是因为程序运行时对内存的访问呈现局部性（Locality）特征。这种局部性既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality）。有效利用这种局部性，缓存可以达到极高的命中率。 在处理器看来，缓存是一个透明部件。因此，程序员通常无法直接干预对缓存的操作。但是， 确实可以根据缓存的特点对程序代码实施特定优化，从而更好地利用缓存 。 — 维基百科 左图为最简单的高速缓存的架构，数据的读取和存储都经过高速缓存，CPU 核心与高速缓存有一条特殊的快速通道；主存与高速缓存都连在系统总线上（BUS），这条总线还用于其他组件的通信。简而言之，CPU 高速缓存就是位于 CPU 操作和主内存之间的一层缓存。 为什么需要有 CPU 高速缓存？随着工艺的提升，最近几十年 CPU 的频率不断提升，而受制于制造工艺和成本限制，目前计算机的内存在访问速度上没有质的突破。因此，CPU 的处理速度和内存的访问速度差距越来越大，甚至可以达到上万倍。这种情况下传统的 CPU 直连内存的方式显然就会因为内存访问的等待，导致计算资源大量闲置，降低 CPU 整体吞吐量。同时又由于内存数据访问的热点集中性，在 CPU 和内存之间用较为快速而成本较高（相对于内存）的介质做一层缓存，就显得性价比极高了。 为什么需要有 CPU 多级缓存？结合 图片 – CPU 缓存架构，再来看一组 CPU 各级缓存存取速度的对比 各种寄存器，用来存储本地变量和函数参数，访问一次需要 1cycle，耗时小于 1ns； L1 Cache，一级缓存，本地 core 的缓存，分成 32K 的数据缓存 L1d 和 32k 指令缓存 L1i，访问 L1 需要 3cycles，耗时大约 1ns； L2 Cache，二级缓存，本地 core 的缓存，被设计为 L1 缓存与共享的 L3 缓存之间的缓冲，大小为 256K，访问 L2 需要 12cycles，耗时大约 3ns； L3 Cache，三级缓存，在同插槽的所有 core 共享 L3 缓存，分为多个 2M 的段，访问 L3 需要 38cycles，耗时大约 12ns； 大致可以得出结论，缓存层级越接近于 CPU core，容量越小，速度越快，同时，没有披露的一点是其造价也更贵。所以为了支撑更多的热点数据，同时追求最高的性价比，多级缓存架构应运而生。 什么是缓存行 (Cache Line)？上面我们介绍了 CPU 多级缓存的概念，而之后的章节我们将尝试忽略“多级”这个特性，将之合并为 CPU 缓存，这对于我们理解 CPU 缓存的工作原理并无大碍。 缓存行 (Cache Line) 便是 CPU Cache 中的最小单位，CPU Cache 由若干缓存行组成，一个缓存行的大小通常是 64 字节（这取决于 CPU），并且它有效地引用主内存中的一块地址。一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。 试想一下你正在遍历一个长度为 16 的 long 数组 data[16]，原始数据自然存在于主内存中，访问过程描述如下 访问 data[0]，CPU core 尝试访问 CPU Cache，未命中。 尝试访问主内存，操作系统一次访问的单位是一个 Cache Line 的大小 — 64 字节，这意味着：既从主内存中获取到了 data[0] 的值，同时将 data[0] ~ data[7] 加入到了 CPU Cache 之中，for free~ 访问 data[1]~data[7]，CPU core 尝试访问 CPU Cache，命中直接返回。 访问 data[8]，CPU core 尝试访问 CPU Cache，未命中。 尝试访问主内存。重复步骤 2 CPU 缓存在顺序访问连续内存数据时挥发出了最大的优势。试想一下上一篇文章中提到的 PageCache，其实发生在磁盘 IO 和内存之间的缓存，是不是有异曲同工之妙？只不过今天的主角— CPU Cache，相比 PageCache 更加的微观。 再回到文章的开头，为何横向遍历 arr = new long[1024 * 1024][8] 要比纵向遍历更快？此处得到了解答，正是更加友好地利用 CPU Cache 带来的优势，甚至有一个专门的词来修饰这种行为 — Mechanical Sympathy。 伪共享通常提到缓存行，大多数文章都会提到伪共享问题（正如提到 CAS 便会提到 ABA 问题一般）。 伪共享指的是多个线程同时读写同一个缓存行的不同变量时导致的 CPU 缓存失效。尽管这些变量之间没有任何关系，但由于在主内存中邻近，存在于同一个缓存行之中，它们的相互覆盖会导致频繁的缓存未命中，引发性能下降。伪共享问题难以被定位，如果系统设计者不理解 CPU 缓存架构，甚至永远无法发现 — 原来我的程序还可以更快。 伪共享 正如图中所述，如果多个线程的变量共享了同一个 CacheLine，任意一方的修改操作都会使得整个 CacheLine 失效（因为 CacheLine 是 CPU 缓存的最小单位），也就意味着，频繁的多线程操作，CPU 缓存将会彻底失效，降级为 CPU core 和主内存的直接交互。 伪共享问题的解决方法便是字节填充。 伪共享 - 字节填充 我们只需要保证不同线程的变量存在于不同的 CacheLine 即可，使用多余的字节来填充可以做点这一点，这样就不会出现伪共享问题。在代码层面如何实现图中的字节填充呢？ Java6 中实现字节填充1234public class PaddingObject&#123; public volatile long value = 0L; // 实际数据 public long p1, p2, p3, p4, p5, p6; // 填充&#125; PaddingObject 类中需要保存一个 long 类型的 value 值，如果多线程操作同一个 CacheLine 中的 PaddingObject 对象，便无法完全发挥出 CPU Cache 的优势（想象一下你定义了一个 PaddingObject[] 数组，数组元素在内存中连续，却由于伪共享导致无法使用 CPU Cache 带来的沮丧）。 不知道你注意到没有，实际数据 value + 用于填充的 p1~p6 总共只占据了 7 * 8 = 56 个字节，而 Cache Line 的大小应当是 64 字节，这是有意而为之，在 Java 中， 对象头还占据了 8 个字节 ，所以一个 PaddingObject 对象可以恰好占据一个 Cache Line。 Java7 中实现字节填充在 Java7 之后，一个 JVM 的优化给字节填充造成了一些影响，上面的代码片段 public long p1, p2, p3, p4, p5, p6; 会被认为是无效代码被优化掉，有回归到了伪共享的窘境之中。 为了避免 JVM 的自动优化，需要使用继承的方式来填充。 1234567abstract class AbstractPaddingObject&#123; protected long p1, p2, p3, p4, p5, p6;// 填充&#125;public class PaddingObject extends AbstractPaddingObject&#123; public volatile long value = 0L; // 实际数据&#125; Tips: 实际上我在本地 mac 下测试过 jdk1.8 下的字节填充，并不会出现无效代码的优化，个人猜测和 jdk 版本有关，不过为了保险起见，还是使用相对稳妥的方式去填充较为合适。 如果你对这个现象感兴趣，测试代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public final class FalseSharing implements Runnable &#123; public final static int NUM_THREADS = 4; // change public final static long ITERATIONS = 500L * 1000L * 1000L; private final int arrayIndex; private static VolatileLong[] longs = new VolatileLong[NUM_THREADS]; static &#123; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new VolatileLong(); &#125; &#125; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; final long start = System.currentTimeMillis(); runTest(); System.out.println(\"duration =\" + (System.currentTimeMillis() - start)); &#125; private static void runTest() throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = i; &#125; &#125; public final static class VolatileLong &#123; public volatile long value = 0L; public long p1, p2, p3, p4, p5, p6; // 填充，可以注释后对比测试 &#125;&#125; Java8 中实现字节填充12345@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.FIELD, ElementType.TYPE&#125;)public @interface Contended &#123; String value() default \"\";&#125; 注意需要同时开启 JVM 参数：-XX:-RestrictContended=false @Contended 注解会增加目标实例大小，要谨慎使用。默认情况下，除了 JDK 内部的类，JVM 会忽略该注解。要应用代码支持的话，要设置 -XX:-RestrictContended=false，它默认为 true（意味仅限 JDK 内部的类使用）。当然，也有个 –XX: EnableContented 的配置参数，来控制开启和关闭该注解的功能，默认是 true，如果改为 false，可以减少 Thread 和 ConcurrentHashMap 类的大小。参加《Java 性能权威指南》210 页。 — @Im 的补充 Java8 中终于提供了字节填充的官方实现，这无疑使得 CPU Cache 更加可控了，无需担心 jdk 的无效字段优化，无需担心 Cache Line 在不同 CPU 下的大小究竟是不是 64 字节。使用 @Contended 注解可以完美的避免伪共享问题。 一些最佳实践可能有读者会问：作为一个普通开发者，需要关心 CPU Cache 和 Cache Line 这些知识点吗？这就跟前几天比较火的话题：「程序员有必要懂 JVM 吗？」一样，仁者见仁了。但确实有不少优秀的源码在关注着这些问题。他们包括： ConcurrentHashMap 面试中问到要吐的 ConcurrentHashMap 中，使用 @sun.misc.Contended 对静态内部类 CounterCell 进行修饰。另外还包括并发容器 Exchanger 也有相同的操作。 12345678910/* ---------------- Counter support -------------- *//** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */@sun.misc.Contended static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123;value = x;&#125;&#125; Thread Thread 线程类的源码中，使用 @sun.misc.Contended 对成员变量进行修饰。 1234567891011121314151617// The following three initially uninitialized fields are exclusively// managed by class java.util.concurrent.ThreadLocalRandom. These// fields are used to build the high-performance PRNGs in the// concurrent code, and we can not risk accidental false sharing.// Hence, the fields are isolated with @Contended./** The current seed for a ThreadLocalRandom */@sun.misc.Contended(\"tlr\")long threadLocalRandomSeed;/** Probe hash value; nonzero if threadLocalRandomSeed initialized */@sun.misc.Contended(\"tlr\")int threadLocalRandomProbe;/** Secondary seed isolated from public ThreadLocalRandom sequence */@sun.misc.Contended(\"tlr\")int threadLocalRandomSecondarySeed; RingBuffer 来源于一款优秀的开源框架 Disruptor 中的一个数据结构 RingBuffer ， 我后续会专门花一篇文章的篇幅来介绍这个数据结构 123456abstract class RingBufferPad&#123; protected long p1, p2, p3, p4, p5, p6, p7;&#125;abstract class RingBufferFields&lt;E&gt; extends RingBufferPad&#123;&#125; 使用字节填充和继承的方式来避免伪共享。 面试题扩展问：说说数组和链表这两种数据结构有什么区别？ 了解了 CPU Cache 和 Cache Line 之后想想可不可以有一些特殊的回答技巧呢？ 参考资料高性能队列——Disruptor 神奇的缓存行填充 伪共享和缓存行填充 关于 CPU Cache – 程序猿需要知道的那些事 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"天池中间件大赛百万队列存储设计总结【复赛】","slug":"mq-million-queue","date":"2018-07-13T11:47:28.000Z","updated":"2019-09-26T09:45:31.340Z","comments":true,"path":"mq-million-queue/","link":"","permalink":"http://lexburner.github.io/mq-million-queue/","excerpt":"维持了 20 天的复赛终于告一段落了，国际惯例先说结果，复赛结果不太理想，一度从第 10 名掉到了最后的第 36 名，主要是写入的优化卡了 5 天，一直没有进展，最终排名也是定格在了排行榜的第二页。痛定思痛，这篇文章将自己复赛中学习的知识，成功的优化，未成功的优化都罗列一下。","text":"维持了 20 天的复赛终于告一段落了，国际惯例先说结果，复赛结果不太理想，一度从第 10 名掉到了最后的第 36 名，主要是写入的优化卡了 5 天，一直没有进展，最终排名也是定格在了排行榜的第二页。痛定思痛，这篇文章将自己复赛中学习的知识，成功的优化，未成功的优化都罗列一下。 赛题介绍题面描述很简单：使用 Java 或者 C++ 实现一个进程内的队列引擎，单机可支持 100 万队列以上。 1234public abstract class QueueStore &#123; abstract void put(String queueName, byte[] message); abstract Collection&lt;byte[]&gt; get(String queueName, long offset, long num);&#125; 编写如上接口的实现。 put 方法将一条消息写入一个队列，这个接口需要是线程安全的，评测程序会并发调用该接口进行 put，每个 queue 中的内容按发送顺序存储消息（可以理解为 Java 中的 List），同时每个消息会有一个索引，索引从 0 开始，不同 queue 中的内容，相互独立，互不影响，queueName 代表队列的名称，message 代表消息的内容，评测时内容会随机产生，大部分长度在 58 字节左右，会有少量消息在 1k 左右。 get 方法从一个队列中读出一批消息，读出的消息要按照发送顺序来，这个接口需要是线程安全的，也即评测程序会并发调用该接口进行 get，返回的 Collection 会被并发读，但不涉及写，因此只需要是线程读安全就可以了，queueName 代表队列的名字，offset 代表消息的在这个队列中的起始索引，num 代表读取的消息的条数，如果消息足够，则返回 num 条，否则只返回已有的消息即可，若消息不足，则返回一个空的集合。 评测程序介绍 发送阶段：消息大小在 58 字节左右，消息条数在 20 亿条左右，即发送总数据在 100G 左右，总队列数 100w 索引校验阶段：会对所有队列的索引进行随机校验；平均每个队列会校验 1~2 次；(随机消费) 顺序消费阶段：挑选 20% 的队列进行 全部 读取和校验； (顺序消费) 发送阶段最大耗时不能超过 1800s；索引校验阶段和顺序消费阶段加在一起，最大耗时也不能超过 1800s；超时会被判断为评测失败。 各个阶段线程数在 20~30 左右 测试环境为 4c8g 的 ECS，限定使用的最大 JVM 大小为 4GB(-Xmx 4g)。带一块 300G 左右大小的 SSD 磁盘。对于 Java 选手而言，可使用的内存可以理解为：堆外 4g 堆内 4g。 赛题剖析首先解析题面，接口描述是非常简单的，只有一个 put 和一个 get 方法。需要注意特别注意下评测程序，发送阶段需要对 100w 队列，每一次发送的量只有 58 字节，最后总数据量是 100g；索引校验和顺序消费阶段都是调用的 get 接口，不同之处在于前者索引校验是随机消费，后者是对 20% 的队列从 0 号索引开始进行全量的顺序消费，评测程序的特性对最终存储设计的影响是至关重要的。 复赛题目的难点之一在于单机百万队列的设计，据查阅的资料显示 Kafka 单机超过 64 个队列 / 分区，Kafka 分区数不宜过多 RocketMQ 单机支持最高 5 万个队列 至于百万队列的使用场景，只能想到 IOT 场景有这样的需求。相较于初赛，复赛的设计更加地具有不确定性，排名靠前的选手可能会选择大相径庭的设计方案。 复赛的考察点主要有以下几个方面：磁盘块读写，读写缓冲，顺序读写与随机读写，pageCache，稀疏索引，队列存储设计等。 由于复赛成绩并不是很理想，优化 put 接口的失败是导致失利的罪魁祸首，最终成绩是 126w TPS，而第一梯队的 TPS 则是到达了 200 w+ 的 TPS。鉴于此，不太想像初赛总结那样，按照优化历程罗列，而是将自己做的方案预研，以及设计思路分享给大家，对文件 IO 不甚了解的读者也可以将此文当做一篇科普向的文章来阅读。 思路详解确定文件读写方式作为忠实的 Java 粉丝，自然选择使用 Java 来作为参赛语言，虽然最终的排名是被 Cpp 大佬所垄断，但着实无奈，毕业后就把 Cpp 丢到一边去了。Java 中的文件读写接口大致可以分为三类： 标准 IO 读写，位于 java.io 包下，相关类：FileInputStream，FileOuputStream NIO 读写，位于 java.nio 包下，相关类：FileChannel，ByteBuffer Mmap 内存映射，位于 java.nio 包下，相关类：FileChannel，MappedByteBuffer 标准 IO 读写不具备调研价值，直接 pass，所以 NIO 和 Mmap 的抉择，成了第一步调研对象。 第一阶段调研了 Mmap。搜索一圈下来发现，几乎所有的文章都一致认为：Mmap 这样的内存映射技术是最快的。很多没有接触过内存映射技术的人可能还不太清楚这是一种什么样的技术，简而言之，Mmap 能够将文件直接映射到用户态的内存地址，使得对文件的操作不再是 write/read, 而转化为直接对内存地址的操作。 1234567891011121314151617public void test1() throws Exception &#123; String dir = \"/Users/kirito/data/\"; ensureDirOK(dir); RandomAccessFile memoryMappedFile; int size = 1 * 1024 * 1024; try &#123; memoryMappedFile = new RandomAccessFile(dir + \"testMmap.txt\", \"rw\"); MappedByteBuffer mappedByteBuffer = memoryMappedFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, size); for (int i = 0; i &lt; 100000; i++) &#123; mappedByteBuffer.position(i * 4); mappedByteBuffer.putInt(i); &#125; memoryMappedFile.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 如上的代码呈现了一个最简单的 Mmap 使用方式，速度也是没话说，一个字：快！我怀着将信将疑的态度去找了更多的佐证，优秀的源码总是第一参考对象，观察下 RocketMQ 的设计，可以发现 NIO 和 Mmap 都出现在了源码中，但更多的读写操作似乎更加青睐 Mmap。RocketMQ 源码 org.apache.rocketmq.store.MappedFile 中两种写方法同时存在，请教 @匠心零度 后大概得出结论：RocketMQ 主要的写是通过 Mmap 来完成。 但是在实际使用 Mmap 来作为写方案时遇到了两大难题，单纯从使用角度来看，暴露出了 Mmap 的局限性： Mmap 在 Java 中一次只能映射 1.5~2G 的文件内存，但实际上我们的数据文件大于 100g，这带来了第一个问题：要么需要对文件做物理拆分，切分成多文件；要么需要对文件映射做逻辑拆分，大文件分段映射。RocketMQ 中限制了单文件大小来避免这个问题。 Mmap 之所以快，是因为借助了内存来加速，mappedByteBuffer 的 put 行为实际是对内存进行的操作，实际的刷盘行为依赖于操作系统的定时刷盘或者手动调用 mappedByteBuffer.force() 接口来刷盘，否则将会导致机器卡死（实测后的结论）。由于复赛的环境下内存十分有限，所以使用 Mmap 存在较难的控制问题。 经过这么一折腾，再加上资料的搜集，最终确定，Mmap 在内存较为富足并且数据量小的场景下存在优势 （大多数文章的结论认为 Mmap 适合大文件的读写，私以为是不严谨的结论）。 第二阶段调研 Nio 的 FileChannel，这也是我最终确定的读写方案。 由于每个消息只有 58 字节左右，直接通过 FileChannel 写入一定会遇到瓶颈，事实上，如果你这么做，复赛连成绩估计都跑不出来。另一个说法是 ssd 最小的写入单位是 4k，如果一次写入低于 4k，实际上耗时和 4k 一样。这里涉及到了赛题的一个重要考点：块读写。 根据阿里云的 ssd 云盘介绍，只有一次写入 16kb ~ 64kb 才能获得理想的 IOPS。文件系统块存储的特性，启发我们需要设置一个内存的写入缓冲区，单个消息写入内存缓冲区，缓冲区满，使用 FileChannel 进行刷盘。经过实践，使用 FileChannel 搭配缓冲区发挥的写入性能和内存充足情况下的 Mmap 并无区别，并且 FileChannel 对文件大小并无限制，控制也相对简单，所以最终确定使用 FileChannel 进行读写。 确定存储结构和索引结构由于赛题的背景是消息队列，评测 2 阶段的随机检测以及 3 阶段的顺序消费一次会读取多条连续的消息，并且 3 阶段的顺序消费是从队列的 0 号索引一直消费到最后一条消息，这些因素都启发我们：应当将同一个队列的消息尽可能的存到一起。前面一节提到了写缓冲区，便和这里的设计非常契合，例如我们可以一个队列设置一个写缓冲区（比赛中 Java 拥有 4g 的堆外内存，100w 队列，一个队列使用 DirectByteBuffer 分配 4k 堆外内存 ，可以保证缓冲区不会爆内存），这样同一个缓冲区的消息一起落盘，就保证了块内消息的顺序性，即做到了”同一个队列的消息尽可能的存到一起“。按块存取消息目前看来有两个优势： 按条读取消息 =&gt; 按块读取消息，发挥块读的优势，减少了 IO 次数 全量索引 =&gt; 稀疏索引。块内数据是连续的，所以只需要记录块的物理文件偏移量 + 块内消息数即可计算出某一条消息的物理位置。这样大大降低了索引的数量，稍微计算一下可以发现，完全可以使用一个 Map 数据结构，Key 为 queueName，Value 为 List 在内存维护队列块的索引。如果按照传统的设计方案：一个 queue 一个索引文件，百万文件必然会超过默认的系统文件句柄上限。索引存储在内存中既规避了文件句柄数的问题，速度也不必多数，文件 IO 和 内存 IO 不是一个量级。 由于赛题规定消息体是非定长的，大多数消息 58 字节，少量消息 1k 字节的数据特性，所以存储消息体时使用 short+byte[] 的结构即可，short 记录消息的实际长度，byte[] 记录完整的消息体。short 比 int 少了 2 个字节，2*20 亿消息，可以减少 4g 的数据量。 稠密索引是对全量的消息进行索引，适用于无序消息，索引量大，数据可以按条存取。 稀疏索引适用于按块存储的消息，块内有序，适用于有序消息，索引量小，数据按照块进行存取。 由于消息队列顺序存储，顺序消费的特性，加上 ssd 云盘最小存取单位为 4k（远大于单条消息）的限制，所以稀疏索引非常适用于这种场景。至于数据文件，可以做成参数，根据实际测试来判断到底是多文件效果好，还是单文件，此方案支持 100g 的单文件。 内存读写缓冲区在稀疏索引的设计中，我们提到了写入缓冲区的概念，根据计算可以发现，100w 队列如果一个队列分配一个写入缓冲区，最多只能分配 4k，这恰好是最小的 ssd 写入块大小（但根据之前 ssd 云盘给出的数据来看，一次写入 64k 才能打满 io）。 一次写入 4k，这导致物理文件中的块大小是 4k，在读取时一次同样读取出 4k。 123456789101112131415// 写缓冲区private ByteBuffer writeBuffer = ByteBuffer.allocateDirect(4 * 1024);// 用 short 记录消息长度private final static int SINGLE_MESSAGE_SIZE = 2;public void put(String queueName,byte[] message)&#123; // 缓冲区满，先落盘 if (SINGLE_MESSAGE_SIZE + message.length &gt; writeBuffer.remaining()) &#123; // 落盘 flush(); &#125; writeBuffer.putInt(SINGLE_MESSAGE_SIZE); writeBuffer.put(message); this.blockLength++;&#125; 不足 4k 的部分可以选择补 0，也可以跳过。评测程序保证了在 queue 级别的写入是同步的，所以对于同一个队列，我们无法担心同步问题。写入搞定之后，同样的逻辑搞定读取，由于 get 操作是并发的，2 阶段和 3 阶段会有 10~30 个线程并发消费同一个队列，所以 get 操作的读缓冲区可以设计成 ThreadLocal&lt;ByteBuffer&gt; ，每次使用时 clear 即可，保证了缓冲区每次读取时都是崭新的，同时减少了读缓冲区的创建，否则会导致频繁的 full gc。读取的伪代码暂时不贴，因为这样的 get 方案不是最终方案。 到这里整体的设计架构已经出来了，写入流程和读取流程的主要逻辑如下： 写入流程： 读取流程： 内存读缓存优化方案设计经过好几次的推翻重来，才算是确定了上述的架构，这样的架构优势在于非常简单明了，实际上我的第一版设计方案的代码量是上述方案代码量的 2~3 倍，但实际效果却不理想。上述架构的跑分成绩大概可以达到 70~80w TPS，只能算作是第三梯队的成绩，在此基础上，进行了读取缓存的优化才达到了 126w 的 TPS。在介绍读取缓存优化之前，先容我介绍下 PageCache 的概念。 Linux 内核会将它最近访问过的文件页面缓存在内存中一段时间，这个文件缓存被称为 PageCache。如上图所示。一般的 read() 操作发生在应用程序提供的缓冲区与 PageCache 之间。而预读算法则负责填充这个 PageCache。应用程序的读缓存一般都比较小，比如文件拷贝命令 cp 的读写粒度就是 4KB；内核的预读算法则会以它认为更合适的大小进行预读 I/O，比如 16-128KB。 所以一般情况下我们认为顺序读比随机读是要快的，PageCache 便是最大的功臣。 回到题目，这简直 nice 啊，因为在磁盘中同一个队列的数据是部分连续（同一个块则连续），实际上一个 4KB 块中大概可以存储 70 多个数据，而在顺序消费阶段，一次的 offset 一般为 10，有了 PageCache 的预读机制，7 次文件 IO 可以减少为 1 次！这可是不得了的优化，但是上述的架构仅仅只有 70~80w 的 TPS，这让我产生了疑惑，经过多番查找资料，最终在 @江学磊 的提醒下，才定位到了问题。 两种可能导致比赛中无法使用 pageCache 来做缓存 由于我使用 FIleChannel 进行读写，NIO 的读写可能走的正是 Direct IO，所以根本不会经过 PageCache 层。 测评环境中内存有限，在 IO 密集的情况下 PageCache 效果微乎其微。 虽然说不确定到底是何种原因导致 PageCache 无法使用，但是我的存储方案仍然满足顺序读取的特性，完全可以自己使用堆外内存自己模拟一个“PageCache”，这样在 3 阶段顺序消费时，TPS 会有非常高的提升。 一个队列一个读缓冲区用于顺序读，又要使得 get 阶段不存在并发问题，所以我选择了复用读缓冲区，并且给 get 操作加上了队列级别的锁，这算是一个小的牺牲，因为 2 阶段不会发生冲突，3 阶段冲突概率也并不大。改造后的读取缓存方案如下： 经过缓存改造之后，使用 Direct IO 也可以实现类似于 PageCache 的优化，并且会更加的可控，不至于造成频繁的缺页中断。经过这个优化，加上一些 gc 的优化，可以达到 126w TPS。整体方案算是介绍完毕。 其他优化还有一些优化对整体流程影响不大，拎出来单独介绍。 2 阶段的随机索引检测和 3 阶段的顺序消费可以采取不同的策略，2 阶段可以直接读取所需要的数据，而不需要进行缓存（因为是随机检测，所以读缓存肯定不会命中）。 将文件数做成参数，调整参数来判断到底是多文件 TPS 高还是单文件，实际上测试后发现，差距并不是很大，单文件效果略好，由于是 ssd 云盘，又不存在磁头，所以真的不太懂原理。 gc 优化，能用数组的地方不要用 List。尽量减少小对象的出现，可以用数组管理基本数据类型，小对象对 gc 非常不友好，无论是初赛还是复赛，Java 比 Cpp 始终差距一个垃圾回收机制。必须保证全程不出现 full gc。 失败的优化与反思本次比赛算是留下了不小的遗憾，因为写入的优化一直没有做好，读取缓存做好之后我 2 阶段和 3 阶段的总耗时相加是 400+s，算是不错的成绩，但是写入耗时在 1300+s。我上述的方案采用的是多线程同步刷盘，但也尝试过如下的写入方案： 异步提交写缓冲区，单线程直接刷盘 异步提交写缓冲区，设置二级缓冲区 64k~64M，单线程使用二级缓冲区刷盘 同步将写缓冲区的数据拷贝至一个 LockFreeQueue，单线程平滑消费，以打满 IOPS 每 16 个队列共享一个写入缓冲区，这样控制写入缓冲区可以达到 64k，在刷盘时进行排序，将同一个 queue 的数据放置在一起。 但都以失败告终，没有 get 到写入优化的要领，算是本次比赛最大的遗憾了。 还有一个失误在于，评测环境使用的云盘 ssd 和我的本地 Mac 下的 ssd 存储结构差距太大，加上 mac os 和 Linux 的一些差距，导致本地成功的优化在线上完全体现不出来，还是租个阿里云环境比较靠谱。 另一方面的反思，则是对存储和 MQ 架构设计的不熟悉，对于 Kafka 和 RocketMQ 所做的一些优化也都是现学现用，不太确定用的对不对，导致走了一些弯路，而比赛中认识的一个 96 年的小伙子王亚普，相比之下对中间件知识理解的深度和广度实在令我钦佩，实在还有很多知识需要学习。 参赛感悟第一感受是累，第二感受是爽。相信很多选手和我一样是工作党，白天工作，只能腾出晚上的时间去搞比赛，对于 966 的我真是太不友好了，初赛时间延长了一次还算给缓了一口气，复赛一眨眼就过去了，想翻盘都没机会，实在是遗憾。爽在于这次比赛真的是汗快淋漓地实践了不少中间件相关的技术，初赛的 Netty，复赛的存储设计，都是难以忘怀的回忆，比赛中也认识了不少朋友，有学生党，有工作党，感谢你们不厌其烦的教导与发人深省的讨论，从不同的人身上是真的可以学到很多自己缺失的知识。 据消息说，阿里中间件大赛很有可能是最后一届，无论是因为什么原因，作为参赛者，我都感到深深的惋惜，希望还能有机会参加下一届的中间件大赛，也期待能看到更多的相同类型的赛事被各大互联网公司举办，和大佬们同台竞技，一边认识更多新朋友的感觉真棒。 虽然最终无缘决赛，但还是期待进入决赛的 11 位选手能带来一场精彩的答辩，也好解答我始终优化失败的写入方案。后续会考虑吸收下前几名 JAVA 的优化思路，整理成最终完善的方案。目前方案的 git 地址，仓库已公开：https://code.aliyun.com/250577914/queuerace2018.git 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"性能挑战赛","slug":"性能挑战赛","permalink":"http://lexburner.github.io/categories/性能挑战赛/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://lexburner.github.io/tags/MQ/"}]},{"title":"选择 Kong 作为你的 API 网关","slug":"kong-introduction","date":"2018-07-12T11:47:28.000Z","updated":"2019-09-26T09:45:30.055Z","comments":true,"path":"kong-introduction/","link":"","permalink":"http://lexburner.github.io/kong-introduction/","excerpt":"Kong（https://github.com/Kong/kong）是一个云原生，高效，可扩展的分布式 API 网关。 自 2015 年在 github 开源后，广泛受到关注，目前已收获 1.68w+ 的 star，其核心价值在于高性能和可扩展性。","text":"Kong（https://github.com/Kong/kong）是一个云原生，高效，可扩展的分布式 API 网关。 自 2015 年在 github 开源后，广泛受到关注，目前已收获 1.68w+ 的 star，其核心价值在于高性能和可扩展性。 为什么需要 API 网关 在微服务架构之下，服务被拆的非常零散，降低了耦合度的同时也给服务的统一管理增加了难度。如上图左所示，在旧的服务治理体系之下，鉴权，限流，日志，监控等通用功能需要在每个服务中单独实现，这使得系统维护者没有一个全局的视图来统一管理这些功能。API 网关致力于解决的问题便是为微服务纳管这些通用的功能，在此基础上提高系统的可扩展性。如右图所示，微服务搭配上 API 网关，可以使得服务本身更专注于自己的领域，很好地对服务调用者和服务提供者做了隔离。 为什么是 KongSpringCloud 玩家肯定都听说过 Zuul 这个路由组件，包括 Zuul2 和 Springcloud Gateway 等框架，在国内的知名度都不低。没错，我称呼这些为组件 Or 框架，而 Kong 则更衬的上产品这个词。在此我们可以简单对比下 Zuul 和 Kong。 举例而言，如果选择使用 Zuul，当需要为应用添加限流功能，由于 Zuul 只提供了基本的路由功能，开发者需要自己研发 Zuul Filter，可能你觉得一个功能还并不麻烦，但如果在此基础上对 Zuul 提出更多的要求，很遗憾，Zuul 使用者需要自行承担这些复杂性。而对于 Kong 来说，限流功能就是一个插件，只需要简单的配置，即可开箱即用。 Kong 的插件机制是其高可扩展性的根源，Kong 可以很方便地为路由和服务提供各种插件，网关所需要的基本特性，Kong 都如数支持： 云原生 : 与平台无关，Kong 可以从裸机运行到 Kubernetes 动态路由 ：Kong 的背后是 OpenResty+Lua，所以从 OpenResty 继承了动态路由的特性 熔断 健康检查 日志 : 可以记录通过 Kong 的 HTTP，TCP，UDP 请求和响应。 鉴权 : 权限控制，IP 黑白名单，同样是 OpenResty 的特性 SSL: Setup a Specific SSL Certificate for an underlying service or API. 监控 : Kong 提供了实时监控插件 认证 : 如数支持 HMAC, JWT, Basic, OAuth2.0 等常用协议 限流 REST API: 通过 Rest API 进行配置管理，从繁琐的配置文件中解放 可用性 : 天然支持分布式 高性能 : 背靠非阻塞通信的 nginx，性能自不用说 插件机制 : 提供众多开箱即用的插件，且有易于扩展的自定义插件接口，用户可以使用 Lua 自行开发插件 上面这些特性中，反复提及了 Kong 背后的 OpenResty，实际上，使用 Kong 之后，Nginx 可以完全摒弃，Kong 的功能是 Nginx 的父集。 而 Zuul 除了基础的路由特性以及其本身和 SpringCloud 结合较为紧密之外，并无任何优势。 Kong 的架构 从技术的角度讲，Kong 可以认为是一个 OpenResty 应用程序。 OpenResty 运行在 Nginx 之上，使用 Lua 扩展了 Nginx。 Lua 是一种非常容易使用的脚本语言，可以让你在 Nginx 中编写一些逻辑操作。之前我们提到过一个概念 Kong = OpenResty + Nginx + Lua，但想要从全局视角了解 Kong 的工作原理，还是直接看源码比较直接。我们定位到本地的 Kong 文件夹，按照上图中的目录层级来识识 Kong 的庐山真面目。 Kong 文件下包含了全部源码和必要组件，分析他们，我们便得到了 Kong 的架构。0.13.x 是目前 Kong 的最新版本。 从 2 号块中可以看到 nginx.conf ，这其实便是一个标准的 Nginx 目录结构，这也揭示了 Kong 其实就是运行在 Nginx 的基础之上，而进行的二次封装。由 share 文件夹向下展开下一次分析。 share 文件夹中包含了 OpenResty 的相关内容，其实背后就是一堆 Lua 脚本，例如 lapis 包含了数据库操作，Nginx 生命周期，缓存控制等必要的 Lua 脚本，logging 包含了日志相关的 Lua 脚本，resty 包含了 dns，健康检查等相关功能的 Lua 脚本…而其中的 kong 目录值得我们重点分析，他包含了 Kong 的核心对象。 api 和 core 文件夹，封装了 Kong 对 service，route，upstream，target 等核心对象的操作代码（这四个核心对象将会在下面的小节重点介绍），而 plugins 文件夹则是 Kong 高可扩展性的根源，存放了 kong 的诸多扩展功能。 plugins 文件夹包含了上一节提到的 Kong 的诸多插件功能，如权限控制插件，跨域插件，jwt 插件，oauth2 插件… 如果需要自定义插件，则需要将代码置于此处。 从上述文件夹浏览下来，大概可以看到它和 Nginx 的相似之处，并在此基础之上借助于 Lua 对自身的功能进行了拓展，除了 nginx.conf 中的配置，和相对固定的文件层级，Kong 还需要连接一个数据库来管理路由配置，服务配置，upstream 配置等信息，是的，由于 Kong 支持动态路由的特性，所以几乎所有动态的配置都不是配置在文件中，而是借助于 Postgres 或者 Cassandra 进行管理。 Kong 对外暴露了 Restful API，最终的配置便是落地在了数据库之中。 Kong 的管理方式通过文件夹结构的分析，以及数据库中的表结构，我们已经对 Kong 的整体架构有了一个基本的认识，但肯定还存在一个疑问：我会配置 Nginx 来控制路由，但这个 Kong 应当怎么配置才能达到相同的目的呢？莫急，下面来看看 Kong 如何管理配置。 Kong 简单易用的背后，便是因为其所有的操作都是基于 HTTP Restful API 来进行的。 其中 8000/8443 分别是 Http 和 Https 的转发端口，等价于 Nginx 默认的 80 端口，而 8001 端口便是默认的管理端口，我们可以通过 HTTP Restful API 来动态管理 Kong 的配置。 一个典型的 Nginx 配置 12345678910upstream helloUpstream &#123; server localhost:3000 weight=100;&#125;server &#123; listen 80; location /hello &#123; proxy_pass http://helloUpstream; &#125;&#125; 如上这个简单的 Nginx 配置，便可以转换为如下的 Http 请求。 对应的 Kong 配置 123456789# 配置 upstreamcurl -X POST http://localhost:8001/upstreams --data \"name=helloUpstream\"# 配置 targetcurl -X POST http://localhost:8001/upstreams/hello/targets --data \"target=localhost:3000\" --data \"weight=100\"# 配置 servicecurl -X POST http://localhost:8001/services --data \"name=hello\" --data \"host=helloUpstream\"# 配置 routecurl -X POST http://localhost:8001/routes --data \"paths[]=/hello\" --data \"service.id=8695cc65-16c1-43b1-95a1-5d30d0a50409\"curl -X POST http://localhost:8001/routes --data \"hosts[]=a.com,b.com,*.abc.com\" --data \"service.id=8695cc65-16c1-43b1-95a1-5d30d0a50409\" 这一切都是动态的，无需手动 reload nginx.conf。 我们为 Kong 新增路由信息时涉及到了 upstream，target，service，route 等概念，他们便是 Kong 最最核心的四个对象。（你可能在其他 Kong 的文章中见到了 api 这个对象，在最新版本 0.13 中已经被弃用，api 已经由 service 和 route 替代） 从上面的配置以及他们的字面含义大概能够推测出他们的职责，upstream 是对上游服务器的抽象；target 代表了一个物理服务，是 ip + port 的抽象；service 是抽象层面的服务，他可以直接映射到一个物理服务 (host 指向 ip + port)，也可以指向一个 upstream 来做到负载均衡；route 是路由的抽象，他负责将实际的 request 映射到 service。 他们的关系如下 upstream 和 target ：1 对 n service 和 upstream ：1 对 1 或 1 对 0 （service 也可以直接指向具体的 target，相当于不做负载均衡） service 和 route：1 对 n 高可扩展性的背后—插件机制Kong 的另一大特色便是其插件机制，这也是我认为的 Kong 最优雅的一个设计。 文章开始时我们便提到一点，微服务架构中，网关应当承担所有服务共同需要的那部分功能，这一节我们便来介绍下，Kong 如何添加 jwt 插件，限流插件。 插件（Plugins）装在哪儿？对于部分插件，可能是全局的，影响范围是整个 Kong 服务；大多数插件都是装在 service 或者 route 之上。这使得插件的影响范围非常灵活，我们可能只需要对核心接口进行限流控制，只需要对部分接口进行权限控制，这时候，对特定的 service 和 route 进行定向的配置即可。 为 hello 服务添加 50 次 / 秒的限流 123curl -X POST http://localhost:8001/services/hello/plugins \\--data \"name=rate-limiting\" \\--data \"config.second=50\" 为 hello 服务添加 jwt 插件 12curl -X POST http://localhost:8001/services/login/plugins \\--data \"name=jwt\" 同理，插件也可以安装在 route 之上 123456curl -X POST http://localhost:8001/routes/&#123;routeId&#125;/plugins \\--data \"name=rate-limiting\" \\--data \"config.second=50\"curl -X POST http://localhost:8001/routes/&#123;routeId&#125;/plugins \\--data \"name=jwt\" 在官方文档中，我们可以获取全部的插件 https://konghq.com/plugins/，部分插件需要收费的企业版才可使用。 总结Kong 是目前市场上相对较为成熟的开源 API 网关产品，无论是性能，扩展性，还是功能特性，都决定了它是一款优秀的产品，对 OpenResty 和 Lua 感兴趣的同学，Kong 也是一个优秀的学习参考对象。基于 OpenResty，可以在现有 Kong 的基础上进行一些扩展，从而实现更复杂的特性，比如我司内部的 ABTest 插件和定制化的认证插件，开发成本都相对较低。Kong 系列的文章将会在以后持续连载。 阅读扩展 初识 Kong 之负载均衡 https://www.cnkirito.moe/kong-loadbalance/ Kong 集成 Jwt 插件 https://www.cnkirito.moe/kong-jwt/ 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Kong","slug":"Kong","permalink":"http://lexburner.github.io/categories/Kong/"}],"tags":[{"name":"Kong","slug":"Kong","permalink":"http://lexburner.github.io/tags/Kong/"}]},{"title":"天池中间件大赛 dubboMesh 优化总结（qps 从 1000 到 6850）","slug":"dubboMesh","date":"2018-06-19T11:47:28.000Z","updated":"2019-09-26T09:45:30.168Z","comments":true,"path":"dubboMesh/","link":"","permalink":"http://lexburner.github.io/dubboMesh/","excerpt":"天池中间件大赛的初赛在今早终于正式结束了，公众号停更了一个月，主要原因就是博主的空余时间几乎全花在这个比赛上，第一赛季结束，做下参赛总结，总的来说，收获不小。","text":"天池中间件大赛的初赛在今早终于正式结束了，公众号停更了一个月，主要原因就是博主的空余时间几乎全花在这个比赛上，第一赛季结束，做下参赛总结，总的来说，收获不小。 先说结果，最终榜单排名是第 15 名（除去前排大佬的两个小号，加上作弊的第一名，勉强能算是第 12 名），说实话是挺满意的成绩。这篇文章主要是分享给以下读者：比赛中使用了 netty 却没有达到理想 qps 的朋友，netty 刚入门的朋友，对 dubbo mesh 感兴趣的朋友。 在比赛之前我个人对 netty 的认识也仅仅停留在了解的层面，在之前解读 RPC 原理的系列文章中涉及到 netty 传输时曾了解过一二，基本可以算零基础使用 netty 参赛，所以我会更多地站在一个小白的视角来阐述自己的优化历程，一步步地提高 qps，也不会绕开那些自己踩过的坑以及负优化。另一方面，由于自己对 netty 的理解并不是很深，所以文中如果出现错误，敬请谅解，欢迎指正。 Dubbo Mesh 是什么？为了照顾那些不太了解这次比赛内容的读者，我先花少量的篇幅介绍下这次阿里举办的天池中间件大赛到底比的是个什么东西，那就不得不先介绍下 Dubbo Mesh 这个概念。 如果你用过 dubbo，并且对 service mesh 有所了解，那么一定可以秒懂 Dubbo Mesh 是为了解决什么问题。说白了，dubbo 原先是为了 java 语言而准备的，没有考虑到跨语言的问题，这意味着 nodejs，python，go 要想无缝使用 dubbo 服务，要么借助于各自语言的 dubbo 客户端，例如：node-dubbo-client，python-dubbo-client，go-dubbo-client；要么就是借助于 service mesh 的解决方案，让 dubbo 自己提供跨语言的解决方案，来屏蔽不同语言的处理细节，于是乎，dubbo 生态的跨语言 service mesh 解决方案就被命名为了 dubbo mesh。一图胜千言： 在原先的 dubbo 生态下，只有 consumer，provider，注册中心的概念。dubbo mesh 生态下为每个服务（每个 consumer，provider 实例）启动一个 agent，服务间不再进行直接的通信，而是经由各自的 agent 完成交互，并且服务的注册发现也由 agent 完成。图中红色的 agent 便是这次比赛的核心，选手们可以选择合适的语言来实现 agent，最终比拼高并发下各自 agent 实现的 qps，qps 即最终排名的依据。 赛题剖析这次比赛的主要考察点在于高并发下网络通信模型的实现，可以涵盖以下几个关键点：reactor 模型，负载均衡，线程，锁，io 通信，阻塞与非阻塞，零拷贝，序列化，http/tcp/udp 与自定义协议，批处理，垃圾回收，服务注册发现等。它们对最终程序的 qps 起着或大或小的影响，对它们的理解越深，越能够编写出高性能的 dubbo mesh 方案。 语言的选择，初赛结束后的感受，大家主要还是在 java，c++，go 中进行了抉择。语言的选择考虑到了诸多的因素，通用性，轻量级，性能，代码量和 qps 的性价比，选手的习惯等等。虽然前几名貌似都是 c++，但总体来说，排名 top 10 之外，绝不会是因为语言特性在从中阻挠。c++ 选手高性能的背后，可能是牺牲了 600 多行代码在自己维护一个 etcd-lib（比赛限制使用 etcd，但据使用 c++ 的选手说，c++ 没有提供 etcd 的 lib）；且这次比赛提供了预热环节，java 党也露出了欣慰的笑容。java 的主流框架还是在 nio，akka，netty 之间的抉择，netty 应该是众多 java 选手中较为青睐的，博主也选择了 netty 作为 dubbo mesh 的实现；go 的协程和网络库也是两把利器，并不比 java 弱，加上其进程轻量级的特性，也作为了一个选择。 官方提供了一个 qps 并不是很高的 demo，来方便选手们理解题意，可以说是非常贴心了，来回顾一下最简易的 dubbo mesh 实现： 如上图所示，是整个初始 dubbo mesh 的架构图，其中 consumer 和 provider 以灰色表示，因为选手是不能修改其实现的，绿色部分的 agent 是可以由选手们自由发挥的部分。比赛中 consumer，consumer-agent 为 单个实例，provider、provider-agent 分别启动了三个性能不一的实例：small，medium，large，这点我没有在图中表示出来，大家自行脑补。所以所有选手都需要完成以下几件事： consumer-agent 需要启动一个 http 服务器，接收来自 consumer 的 http 请求 consumer-agent 需要转发该 http 请求给 provider-agent，并且由于 provider-agent 有多个实例，所以需要做负载均衡。consumer-agent 与 provider-agent 之间如何通信可以自由发挥。 provider-agent 拿到 consumer-agent 的请求之后，需要组装成 dubbo 协议， 使用 tcp 与 provider 完成通信。 这样一个跨语言的简易 dubbo mesh 便呈现在大家面前了，从 consumer 发出的 http 协议，最终成功调用到了使用 java 语言编写的 dubbo 服务。这中间如何优化，如何使用各种黑科技成就了一场非常有趣的比赛。博主所有的优化都不是一蹴而就的，都是一天天的提交试出来的，所以恰好可以使用时间线顺序叙述自己的改造历程。 优化历程Qps 1000 到 2500 (CA 与 PA 使用异步 http 通信) 官方提供的 demo 直接跑通了整个通信流程，省去了我们大量的时间，初始版本评测可以达到 1000+ 的 qps，所以 1000 可以作为 baseline 给大家提供参考。demo 中 consumer 使用 asyncHttpClient 发送异步的 http 请求， consumer-agent 使用了 springmvc 支持的 servlet3.0 特性；而 consumer-agent 到 provider-agent 之间的通信却使用了同步 http，所以 C 到 CA 这一环节相比 CA 到 PA 这一环节性能是要强很多的。改造起来也很简单，参照 C 到 CA 的设计，直接将 CA 到 PA 也替换成异步 http，qps 可以直接到达 2500。 主要得益于 async-http-client 提供的异步 http-client，以及 servlet3.0 提供的非阻塞 api。 12345&lt;dependency&gt; &lt;groupId&gt;org.asynchttpclient&lt;/groupId&gt; &lt;artifactId&gt;async-http-client&lt;/artifactId&gt; &lt;version&gt;2.4.7&lt;/version&gt;&lt;/dependency&gt; 123456// 非阻塞发送 http 请求ListenableFuture&lt;org.asynchttpclient.Response&gt; responseFuture = asyncHttpClient.executeRequest(request);// 非阻塞返回 http 响应@RequestMapping(value = \"/invoke\")public DeferredResult&lt;ResponseEntity&gt; invoke()&#123;&#125; Qps 2500 到 2800 (负载均衡优化为加权轮询) demo 中提供的负载均衡算法是随机算法，在 small-pa，medium-pa，large-pa 中随机选择一个访问，每个服务的性能不一样，响应时间自然也不同，随机负载均衡算法存在严重的不稳定性，无法按需分配请求，所以成了自然而然的第二个改造点。 优化为加权轮询算法，这一块的实现参考了 motan（weibo 开源的 rpc 框架）的实现，详见 com.alibaba.dubbo.performance.demo.agent.cluster.loadbalance.WeightRoundRobinLoadBalance(文末贴 git 地址)。 在启动脚本中配置权重信息，伴随 pa 启动注册服务地址到 etcd 时，顺带将权重信息一并注册到 etcd 中，ca 拉取服务列表时即可获取到负载比例。 123456large:-Dlb.weight=3medium:-Dlb.weight=2small:-Dlb.weight=1 预热赛时最高并发为 256 连接，这样的比例可以充分发挥每个 pa 的性能。 Qps 2800 到 3500 (future-&gt;callback) c 到 ca 以及 ca 到 pa 此时尽管是 http 通信，但已经实现了非阻塞的特性（请求不会阻塞 io 线程），但 dubbo mesh 的 demo 中 pa 到 p 的这一通信环节还是使用的 future.get + countDownLatch 的阻塞方式，一旦整个环节出现了锁和阻塞，qps 必然上不去。关于几种获取结果的方式，也是老生常谈的话题： future 方式在调用过程中不会阻塞线程，但获取结果是会阻塞线程，provider 固定 sleep 了 50 ms，所以获取 future 结果依旧是一个耗时的过程，加上这种模型一般会使用锁来等待，性能会造成明显的下降。替换成 callback 的好处是，io 线程专注于 io 事件，降低了线程数，这和 netty 的 io 模型也是非常契合的。 12Promise&lt;Integer&gt; agentResponsePromise = new DefaultPromise&lt;&gt;(ctx.executor());agentResponsePromise.addListener(); netty 为此提供了默认的 Promise 的抽象，以及 DefaultPromise 的默认实现，我们可以 out-of-box 的使用 callback 特性。在 netty 的入站 handler 的 channelRead 事件中创建 promise，拿到 requestId，建立 requestId 和 promise 的映射；在出站 handler 的 channelRead 事件中拿到返回的 requestId，查到 promise，调用 done 方法，便完成了非阻塞的请求响应。可参考： 入站 handler ConsumerAgentHttpServerHandler 和 和出站 handler ConsumerAgentClientHandler 的实现。 Qps 3500 到 4200 (http 通信替换为 tcp 通信) ca 到 pa 的通信原本是异步 http 的通信方式，完全可以参考 pa 到 p 的异步 tcp 通信进行改造。自定义 agent 之间的通信协议也非常容易，考虑到 tcp 粘包的问题，使用定长头 + 字节数组来作为自定义协议是一个较为常用的做法。这里踩过一个坑，原本想使用 protoBuffer 来作为自定义协议，netty 也很友好的提供了基于 protoBuffer 协议的编解码器，只需要编写好 DubboMeshProto.proto 文件即可： 123456789101112message AgentRequest &#123; int64 requestId = 1; string interfaceName = 2; string method = 3; string parameterTypesString = 4; string parameter = 5;&#125;message AgentResponse &#123; int64 requestId = 1; bytes hash = 2;&#125; protoBuffer 在实际使用中的优势是毋庸置疑的，其可以尽可能的压缩字节，减少 io 码流。在正式赛之前一直用的好好的，但后来的 512 并发下通过 jprofile 发现，DubboMeshProto 的 getSerializedSize ,getDescriptorForType 等方法存在不必要的耗时，对于这次比赛中如此简单的数据结构而言 protoBuffer 并不是那么优秀。最终还是采取了定长头 + 字节数组的自定义协议。参考：com.alibaba.dubbo.performance.demo.agent.protocol.simple.SimpleDecoder http 通信既然换了，干脆一换到底，ca 的 springmvc 服务器也可以使用 netty 实现，这样更加有利于实现 ca 整体的 reactive。使用 netty 实现 http 服务器很简单，使用 netty 提供的默认编码解码器即可。 12345678910public class ConsumerAgentHttpServerInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override public void initChannel(SocketChannel ch) &#123; ChannelPipeline p = ch.pipeline(); p.addLast(\"encoder\", new HttpResponseEncoder()); p.addLast(\"decoder\", new HttpRequestDecoder()); p.addLast(\"aggregator\", new HttpObjectAggregator(10 * 1024 * 1024)); p.addLast(new ConsumerAgentHttpServerHandler()); &#125;&#125; http 服务器的实现也踩了一个坑，解码 http request 请求时没注意好 ByteBuf 的释放，导致 qps 跌倒了 2000+，反而不如 springmvc 的实现。在队友 @闪电侠的帮助下成功定位到了内存泄露的问题。 123456789101112131415public static Map&lt;String, String&gt; parse(FullHttpRequest req) &#123; Map&lt;String, String&gt; params = new HashMap&lt;&gt;(); // 是 POST 请求 HttpPostRequestDecoder decoder = new HttpPostRequestDecoder(new DefaultHttpDataFactory(false), req); List&lt;InterfaceHttpData&gt; postList = decoder.getBodyHttpDatas(); for (InterfaceHttpData data : postList) &#123; if (data.getHttpDataType() == InterfaceHttpData.HttpDataType.Attribute) &#123; MemoryAttribute attribute = (MemoryAttribute) data; params.put(attribute.getName(), attribute.getValue()); &#125; &#125; // resolve memory leak decoder.destroy(); return params;&#125; 在正式赛后发现还有更快的 decode 方式，不需要借助于上述的 HttpPostRequestDecoder，而是改用 QueryStringDecoder： 123456789101112131415public static Map&lt;String, String&gt; fastParse(FullHttpRequest httpRequest) &#123; String content = httpRequest.content().toString(StandardCharsets.UTF_8); QueryStringDecoder qs = new QueryStringDecoder(content, StandardCharsets.UTF_8, false); Map&lt;String, List&lt;String&gt;&gt; parameters = qs.parameters(); String interfaceName = parameters.get(\"interface\").get(0); String method = parameters.get(\"method\").get(0); String parameterTypesString = parameters.get(\"parameterTypesString\").get(0); String parameter = parameters.get(\"parameter\").get(0); Map&lt;String, String&gt; params = new HashMap&lt;&gt;(); params.put(\"interface\", interfaceName); params.put(\"method\", method); params.put(\"parameterTypesString\", parameterTypesString); params.put(\"parameter\", parameter); return params;&#125; 节省篇幅，直接在这儿将之后的优化贴出来，后续不再对这个优化赘述了。 Qps 4200 到 4400 (netty 复用 eventLoop) 这个优化点来自于比赛认识的一位好友 @半杯水，由于没有使用过 netty，比赛期间恶补了一下 netty 的线程模型，得知了 netty 可以从客户端引导 channel，从而复用 eventLoop。不了解 netty 的朋友可以把 eventLoop 理解为 io 线程，如果入站的 io 线程和 出站的 io 线程使用相同的线程，可以减少不必要的上下文切换，这一点在 256 并发下可能还不明显，只有 200 多 qps 的差距，但在 512 下尤为明显。复用 eventLoop 在《netty 实战》中是一个专门的章节，篇幅虽然不多，但非常清晰地向读者阐释了如何复用 eventLoop（注意复用同时存在于 ca 和 pa 中）。 1234567891011121314// 入站服务端的 eventLoopGroupprivate EventLoopGroup workerGroup;// 为出站客户端预先创建好的 channelprivate void initThreadBoundClient(EventLoopGroup workerGroup) &#123; for (EventExecutor eventExecutor : eventLoopGroup) &#123; if (eventExecutor instanceof EventLoop) &#123; ConsumerAgentClient consumerAgentClient = new ConsumerAgentClient((EventLoop) eventExecutor); consumerAgentClient.init(); ConsumerAgentClient.put(eventExecutor, consumerAgentClient); &#125; &#125;&#125; 使用入站服务端的 eventLoopGroup 为出站客户端预先创建好 channel，这样可以达到复用 eventLoop 的目的。并且此时还有一个伴随的优化点，就是将存储 Map&lt;requestId,Promise&gt; 的数据结构，从 concurrentHashMap 替换为了 ThreadLocal , 因为入站线程和出站线程都是相同的线程，省去一个 concurrentHashMap 可以进一步降低锁的竞争。 到了这一步，整体架构已经清晰了，c-&gt;ca，ca-&gt;pa，pa-&gt;p 都实现了异步非阻塞的 reactor 模型，qps 在 256 并发下，也达到了 4400 qps。 正式赛 512 连接带来的新格局上述这份代码在预热赛 256 并发下表现尚可，但正式赛为了体现出大家的差距，将最高并发数直接提升了一倍，但 qps 却并没有得到很好的提升，卡在了 5400 qps。和 256 连接下同样 4400 的朋友交流过后，发现我们之间的差距主要体现在 ca 和 pa 的 io 线程数，以及 pa 到 p 的连接数上。5400 qps 显然低于我的预期，为了降低连接数，我修改了原来 provider-agent 的设计。从以下优化开始，是正式赛 512 连接下的优化，预热赛只有 256 连接。 Qps 5400 到 5800 (降低连接数) 对 netty 中 channel 的优化搜了很多文章，依旧不是很确定连接数到底是不是影响我代码的关键因素，在和小伙伴沟通之后实在找不到 qps 卡在 5400 的原因，于是乎抱着试试的心态修改了下 provider-agent 的设计，采用了和 consumer-agent 一样的设计，预先拿到 provder-agent 入站服务器的 woker 线程组，创建出站请求的 channel，将原来的 4 个线程，4 个 channel 降低到了 1 个线程，一个 channel。其他方面未做任何改动，qps 顺利达到了 5800。 理论上来说，channel 数应该不至于成为性能的瓶颈，可能和 provider dubbo 的线程池策略有关，最终得出的经验就是：在 server 中合理的在 io 事件处理能力的承受范围内，使用尽可能少的连接数和线程数，可以提升 qps，减少不必要的线程切换。顺带一提（此时 ca 的线程数为 4，入站连接为 http 连接，最高为 512 连接，出站连接由于和线程绑定，又需要做负载均衡，所以为$$线程数 pa 数 =43=12$$这个阶段，还存在另一个问题，由于 provider 线程数固定为 200 个线程，如果 large-pa 继续分配 3/1+2+3=0.5 即 50% 的请求，很容易出现 provider 线程池饱满的异常，所以调整了加权值为 1：2：2。限制加权负载均衡的不再仅仅是机器性能，还要考虑到 provider 的连接处理能力。 Qps 5800 到 6100 (Epoll 替换 Nio) 依旧感谢 @半杯水的提醒，由于评测环境使用了 linux 作为评测环境，所以可以使用 netty 自己封装的 EpollSocketChannel 来代替 NioSocketChannel，这个提升远超我的想象，直接帮助我突破了 6000 的关卡。 12345private EventLoopGroup bossGroup = Epoll.isAvailable()? new EpollEventLoopGroup(1) : new NioEventLoopGroup(1);private EventLoopGroup workerGroup = Epoll.isAvailable()? new EpollEventLoopGroup(2) : new NioEventLoopGroup(2);bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup) .channel(Epoll.isAvailable() ? EpollServerSocketChannel.class : NioServerSocketChannel.class) 本地调试由于我是 mac 环境，没法使用 Epoll，所以加了如上的判断。 NioServerSocketChannel 使用了 jdk 的 nio，其会根据操作系统选择使用不同的 io 模型，在 linux 下同样是 epoll，但默认是 level-triggered ，而 netty 自己封装的 EpollSocketChannel 默认是 edge-triggered。 我原先以为是 et 和 lt 的差距导致了 qps 如此大的悬殊，但后续优化 Epoll 参数时发现 EpollSocketChannel 也可以配置为 level-triggered，qps 并没有下降，在比赛的特殊条件下，个人猜想并不是这两种触发方式带来的差距，而仅仅是 netty 自己封装 epoll 带来的优化。 1234// 默认bootstrap.option(EpollChannelOption.EPOLL_MODE, EpollMode.EDGE_TRIGGERED);// 可修改触发方式bootstrap.option(EpollChannelOption.EPOLL_MODE, EpollMode.LEVEL_TRIGGERED); Qps 6100 到 6300 (agent 自定义协议优化) agent 之间的自定义协议我之前已经介绍过了，由于一开始我使用了 protoBuf，发现了性能问题，就是在这儿发现的。在 512 下 protoBuf 的问题尤为明显，最终为了保险起见，以及为了和我后面的一个优化兼容，最终替换为了自定义协议—Simple 协议，这一点优化之前提到了，不在过多介绍。 Qps 6300 到 6500 (参数调优与 zero-copy) 这一段优化来自于和 @折袖 - 许华建 的交流，非常感谢。又是一个对 netty 不太了解而没注意的优化点： 关闭 netty 的内存泄露检测： 1-Dio.netty.leakDetectionLevel=disabled netty 会在运行期定期抽取 1% 的 ByteBuf 进行内存泄露的检测，关闭这个参数后，可以获得性能的提升。 开启 quick_ack： 1bootstrap.option(EpollChannelOption.TCP_QUICKACK, java.lang.Boolean.TRUE) tcp 相比 udp ，一个区别便是为了可靠传输而进行的 ack，netty 为 Epoll 提供了这个参数，可以进行 quick ack，具体原理没来及研究。 开启 TCP_NODELAY 1serverBootstrap.childOption(ChannelOption.TCP_NODELAY, true) 这个优化可能大多数人都知道，放在这儿一起罗列出来。网上搜到了一篇阿里毕玄的 rpc 优化文章，提到高并发下 ChannelOption.TCP_NODELAY=false 可能更好，但实测之后发现并不会。 其他调优的参数可能都是玄学了，对最终的 qps 影响微乎其微。参数调优并不能体现太多的技巧，但对结果产生的影响却是很可观的。 在这个阶段还同时进行了一个优化，和参数调优一起进行的，所以不知道哪个影响更大一些。demo 中 dubbo 协议编码没有做到 zero-copy，这无形中增加了一份数据从内核态到用户态的拷贝；自定义协议之间同样存在这个问题，在 dubbo mesh 的实践过程中应该尽可能做到：能用 ByteBuf 的地方就不要用其他对象，ByteBuf 提供的 slice 和 CompositeByteBuf 都可以很方便的实现 zero-copy。 Qps 6500 到 6600 (自定义 http 协议编解码) 看着榜单上的人 qps 逐渐上升，而自己依旧停留在 6500，于是乎动了歪心思，GTMD 的通用性，自己解析 http 协议得了，不要 netty 提供的 http 编解码器，不需要比 HttpPostRequestDecoder 更快的 QueryStringDecoder，就一个偏向于固定的 http 请求，实现自定义解析非常简单。 123456POST / HTTP/1.1\\r\\ncontent-length: 560\\r\\ncontent-type: application/x-www-form-urlencoded\\r\\nhost: 127.0.0.1:20000\\r\\n\\r\\ninterface=com.alibaba.dubbo.performance.demo.provider.IHelloService&amp;method=hash&amp;parameterTypesString=Ljava%32lang%32String;&amp;parameter=xxxxx http 文本协议本身还是稍微有点复杂的，所以 netty 的实现考虑到通用性，必然不如我们自己解析来得快，具体的粘包过程就不叙述了，有点 hack 的倾向。 同理，response 也自己解析： 123456HTTP/1.1 200 OK\\r\\nConnection: keep-alive\\r\\nContent-Type: text/plain;charset=UTF-8\\r\\nContent-Length: 6\\r\\n\\r\\n123456 Qps 6600 到 6700 (去除对象) 继续丧心病狂，不考虑通用性，把之前所有的中间对象都省略，encode 和 decode 尽一切可能压缩到 handler 中去处理，这样的代码看起来非常难受，存在不少地方的 hardcoding。但效果是存在的，ygc 的次数降低了不少，全程使用 ByteBuf 和 byte[] 来进行数据交互。这个优化点同样存在存在 hack 倾向，不过多赘述。 Qps 6700 到 6850 (批量 flush，批量 decode) 事实上到了 6700 有时候还是需要看运气的，从群里的吐槽现象就可以发现，512 下的网路 io 非常抖，不清楚是机器的问题还是高并发下的固有现象，6700 的代码都能抖到 5000 分。所以 6700 升 6850 的过程比较曲折，而且很不稳定，提交 20 次一共就上过两次 6800+。 所做的优化是来自队友 @闪电侠的批量 flush 类，一次传输的字节数可以提升，使得网络 io 次数可以降低，原理可以简单理解为：netty 中 write 10 次，flush 1 次。一共实现了两个版本的批量 flush。一个版本是根据同一个 channel write 的次数积累，最终触发 flush；另一个版本是根据一次 eventLoop 结束才强制 flush。经过很多测试，由于环境抖动太厉害，这两者没测出多少差距。 123456789handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) &#123; ch.pipeline() .addLast(new SimpleDecoder()) .addLast(new BatchFlushHandler(false)) .addLast(new ConsumerAgentClientHandler()); &#125;&#125;); 批量 decode 的思想来自于蚂蚁金服的 rpc 框架 sofa-bolt 中提供的一个抽象类：AbstractBatchDecoder Netty 提供了一个方便的解码工具类 ByteToMessageDecoder ，如图上半部分所示，这个类具备 accumulate 批量解包能力，可以尽可能的从 socket 里读取字节，然后同步调用 decode 方法，解码出业务对象，并组成一个 List 。最后再循环遍历该 List ，依次提交到 ChannelPipeline 进行处理。此处我们做了一个细小的改动，如图下半部分所示，即将提交的内容从单个 command ，改为整个 List 一起提交，如此能减少 pipeline 的执行次数，同时提升吞吐量。这个模式在低并发场景，并没有什么优势，而在高并发场景下对提升吞吐量有不小的性能提升。 值得指出的一点：这个对于 dubbo mesh 复用 eventLoop 的特殊场景下的优化效果其实是存疑的，但我的最好成绩的确是使用了 AbstractBatchDecoder 之后跑出来的。我曾经单独将 ByteToMessageDecoder 和 AbstractBatchDecoder 拉出跑了一次分，的确是后者 qps 更高。 总结其实在 qps 6500 时，整体代码还是挺漂亮的，至少感觉能拿的出手给别人看。但最后为了性能，加上时间比较赶，不少地方都进行了 hardcoding，而实际能投入生产使用的代码必然要求通用性和扩展性，赛后有空会整理出两个分支：一个 highest-qps 追求性能，另一个分支保留下通用性。这次比赛从一个 netty 小白，最终学到了不少的知识点，还是收获很大的，最后感谢一下比赛中给过我指导的各位老哥。 最高 qps 分支：highest-qps 考虑通用性的分支（适合 netty 入门）：master https://code.aliyun.com/250577914/agent-demo.git 最后帮队友 @闪电侠推广下他的 netty 视频教程，比赛中两个比较难的优化点，都是由他进行的改造。imooc.com 搜索 Netty，可以获取 netty 源码分析视频。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"性能挑战赛","slug":"性能挑战赛","permalink":"http://lexburner.github.io/categories/性能挑战赛/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"设计 RPC 接口时，你有考虑过这些吗？","slug":"rpc-interface-design","date":"2018-05-16T14:44:34.000Z","updated":"2019-09-26T09:45:30.804Z","comments":true,"path":"rpc-interface-design/","link":"","permalink":"http://lexburner.github.io/rpc-interface-design/","excerpt":"RPC 框架的讨论一直是各个技术交流群中的热点话题，阿里的 dubbo，新浪微博的 motan，谷歌的 grpc，以及不久前蚂蚁金服开源的 sofa，都是比较出名的 RPC 框架。RPC 框架，或者一部分人习惯称之为服务治理框架，更多的讨论是存在于其技术架构，比如 RPC 的实现原理，RPC 各个分层的意义，具体 RPC 框架的源码分析…但却并没有太多话题和“如何设计 RPC 接口”这样的业务架构相关。","text":"RPC 框架的讨论一直是各个技术交流群中的热点话题，阿里的 dubbo，新浪微博的 motan，谷歌的 grpc，以及不久前蚂蚁金服开源的 sofa，都是比较出名的 RPC 框架。RPC 框架，或者一部分人习惯称之为服务治理框架，更多的讨论是存在于其技术架构，比如 RPC 的实现原理，RPC 各个分层的意义，具体 RPC 框架的源码分析…但却并没有太多话题和“如何设计 RPC 接口”这样的业务架构相关。 可能很多小公司程序员还是比较关心这个问题的，这篇文章主要分享下一些个人眼中 RPC 接口设计的最佳实践。 初识 RPC 接口设计由于 RPC 中的术语每个程序员的理解可能不同，所以文章开始，先统一下 RPC 术语，方便后续阐述。 大家都知道共享接口是 RPC 最典型的一个特点，每个服务对外暴露自己的接口，该模块一般称之为 api；外部模块想要实现对该模块的远程调用，则需要依赖其 api；每个服务都需要有一个应用来负责实现自己的 api，一般体现为一个独立的进程，该模块一般称之为 app。 api 和 app 是构建微服务项目的最简单组成部分，如果使用 maven 的多 module 组织代码，则体现为如下的形式。 serviceA 服务 serviceA/pom.xml 定义父 pom 文件 123456789&lt;modules&gt; &lt;module&gt;serviceA-api&lt;/module&gt; &lt;module&gt;serviceA-app&lt;/module&gt;&lt;/modules&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;groupId&gt;moe.cnkirito&lt;/groupId&gt;&lt;artifactId&gt;serviceA&lt;/artifactId&gt;&lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; serviceA/serviceA-api/pom.xml 定义对外暴露的接口，最终会被打成 jar 包供外部服务依赖 12345678&lt;parent&gt; &lt;artifactId&gt;serviceA&lt;/artifactId&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;artifactId&gt;serviceA-api&lt;/artifactId&gt; serviceA/serviceA-app/pom.xml 定义了服务的实现，一般是 springboot 应用，所以下面的配置文件中，我配置了 springboot 应用打包的插件，最终会被打成 jar 包，作为独立的进程运行。 1234567891011121314151617&lt;parent&gt; &lt;artifactId&gt;serviceA&lt;/artifactId&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;artifactId&gt;serviceA-app&lt;/artifactId&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 麻雀虽小，五脏俱全，这样一个微服务模块就实现了。 旧 RPC 接口的痛点统一好术语，这一节来描述下我曾经遭遇过的 RPC 接口设计的痛点，相信不少人有过相同的遭遇。 查询接口过多。 各种 findBy 方法，加上各自的重载，几乎占据了一个接口 80% 的代码量。这也符合一般人的开发习惯，因为页面需要各式各样的数据格式，加上查询条件差异很大，便造成了：一个查询条件，一个方法的尴尬场景。这样会导致另外一个问题，需要使用某个查询方法时，直接新增了方法，但实际上可能这个方法已经出现过了，隐藏在了令人眼花缭乱的方法中。 难以扩展 。接口的任何改动，比如新增一个入参，都会导致调用者被迫升级，这也通常是 RPC 设计被诟病的一点，不合理的 RPC 接口设计会放大这个缺点。 升级困难。 在之前的 “初识 RPC 接口设计”一节中，版本管理的粒度是 project，而不是 module，这意味着：api 即使没有发生变化，app 版本演进，也会造成 api 的被迫升级，因为 project 是一个整体。问题又和上一条一样了，api 一旦发生变化，调用者也得被迫升级，牵一发而动全身。 难以测试 。接口一多，职责随之变得繁杂，业务场景各异，测试用例难以维护。特别是对于那些有良好习惯编写单元测试的程序员而言，简直是噩梦，用例也得跟着改。 异常设计不合理 。在既往的工作经历中曾经有一次会议，就 RPC 调用中的异常设计引发了争议，一派人觉得需要有一个业务 CommonResponse，封装异常，每次调用后，优先判断调用结果是否 success，在进行业务逻辑处理；另一派人觉得这比较麻烦，由于 RPC 框架是可以封装异常调用的，所以应当直接 try catch 异常，不需要进行业务包裹。在没有明确规范时，这两种风格的代码同时存在于项目中，十分难看！ 在千米网的三个月中，看了不少最佳实践。加上一次公司内部易永健老师的分享，涉及到了相同的话题，耳濡目染，这些曾经我发觉的痛点也逐渐有了解决之道。 1 单参数接口如果你使用过 springcloud ，可能会不适应 http 通信的限制，因为 @RequestBody 只能使用单一的参数，也就意味着，springcloud 构建的微服务架构下，接口天然是单参数的。而 RPC 方法入参的个数在语法层面是不会受到限制的，但如果强制要求入参为单参数，会解决一部分的痛点。 1.1 使用 Specification 模式解决查询接口过多的问题 123456public interface StudentApi&#123; Student findByName(String name); List&lt;Student&gt; findAllByName(String name); Student findByNameAndNo(String name,String no); Student findByIdcard(String Idcard);&#125; 如上的多个查询方法目的都是同一个：根据条件查询出 Student，只不过查询条件有所差异。试想一下，Student 对象假设有 10 个属性，最坏的情况下它们的排列组合都可能作为查询条件，这便是查询接口过多的根源。 12345public interface StudentApi&#123; Student findBySpec(StudentSpec spec); List&lt;Student&gt; findListBySpec(StudentListSpec spec); Page&lt;Student&gt; findPageBySpec(StudentPageSpec spec);&#125; 上述接口便是最通用的单参接口，三个方法几乎囊括了 99% 的查询条件。所有的查询条件都被封装在了 StudentSpec,StudentListSpec,StudentPageSpec 之中，分别满足了单对象查询，批量查询，分页查询的需求。如果你了解领域驱动设计，会发现这里借鉴了其中 Specification 模式的思想。 1.2 单参数易于做统一管理 12345public interface SomeProvider &#123; void opA(ARequest request); void opB(BRequest request); CommonResponse&lt;C&gt; opC(CRequest request);&#125; 入参中的入参虽然形态各异，但由于是单个入参，所以可以统一继承 AbstractBaseRequest，即上述的 ARequest，BRequest，CRequest 都是 AbstractBaseRequest 的子类。在千米内部项目中，AbstractBaseRequest 定义了 traceId、clientIp、clientType、operationType 等公共入参，减少了重复命名，我们一致认为，这更加的 OO。 有了 AbstractBaseRequest，我们可以更加轻松地在其之上做 AOP，千米的实践中，大概做了如下的操作： 请求入参统一校验（request.checkParam(); param.checkParam();） 实体变更统一加锁，降低锁粒度 请求分类统一处理（if (request instanceof XxxRequest)） 请求报文统一记日志（log.setRequest(JsonUtil.getJsonString(request))) 操作成功统一发消息 如果不遵守单参数的约定，上述这些功能也并不是无法实现，但所需花费的精力远大于单参数，一个简单的约定带来的优势，我们认为是值得的。 1.3 单参数入参兼容性强 还记得前面的小节中，我提到了 SpringCloud，在 SpringCloud Feign 中，接口的入参通常会被 @RequestBody 修饰，强制做单参数的限制。千米内部使用了 Dubbo 作为 Rpc 框架，一般而言，为 Dubbo 服务设计的接口是不能直接用作 Feign 接口的（主要是因为 @RequestBody 的限制），但有了单参数的限制，便使之成为了可能。为什么我好端端的 Dubbo 接口需要兼容 Feign 接口？可能会有人发出这样的疑问，莫急，这样做的初衷当然不是为了单纯做接口兼容，而是想充分利用 HTTP 丰富的技术栈以及一些自动化工具。 自动生成 HTTP 接口实现（让服务端同时支持 Dubbo 和 HTTP 两种服务接口） 看过我之前文章的朋友应该了解过一个设计：千米内部支持的是 Dubbo 协议和 HTTP 协议族（如 JSON RPC 协议，Restful 协议），这并不意味着程序员需要写两份代码，我们可以通过 Dubbo 接口自动生成 HTTP 接口，体现了单参数设计的兼容性之强。 通过 Swagger UI 实现对 Dubbo 接口的可视化便捷测试 又是一个兼容 HTTP 技术栈带来的便利，在 Restful 接口的测试中，Swagger 一直是备受青睐的一个工具，但可惜的是其无法对 Dubbo 接口进行测试。兼容 HTTP 后，我们只需要做一些微小的工作，便可以实现 Swagger 对 Dubbo 接口的可视化测试。 有利于 TestNg 集成测试 自动生成 TestNG 集成测试代码和缺省测试用例，这使得服务端接口集成测试变得异常简单，程序员更能集中精力设计业务用例，结合缺省用例、JPA 自动建表和 PowerMock 模拟外部依赖接口实现本机环境。 这块涉及到了公司内部的代码，只做下简单介绍，我们一般通过内部项目 com.qianmi.codegenerator:api-dubbo-2-restful ，com.qianmi.codegenerator:api-request-json 生成自动化的测试用例，方便测试。而这些自动化工具中大量使用了反射，而由于单参数的设计，反射用起来比较方便。 2. 接口异常设计首先肯定一点，RPC 框架是可以封装异常的，Exception 也是返回值的一部分。在 go 语言中可能更习惯于返回 err,res 的组合，但 JAVA 中我个人更偏向于 try catch 的方法捕获异常。RPC 接口设计中的异常设计也是一个注意点。 初始方案 12345public interface ModuleAProvider &#123; void opA(ARequest request); void opB(BRequest request); CommonResponse&lt;C&gt; opC(CRequest request);&#125; 我们假设模块 A 存在上述的 ModuleAProvider 接口，ModuleAProvider 的实现中或多或少都会出现异常，例如可能存在的异常 ModuleAException，调用者实际上并不知道 ModuleAException 的存在，只有当出现异常时，才会知晓。对于 ModuleAException 这种业务异常，我们更希望调用方能够显示的处理，所以 ModuleAException 应该被设计成 Checked Excepition。 正确的异常设计姿势 12345public interface ModuleAProvider &#123; void opA(ARequest request) throws ModuleAException; void opB(BRequest request) throws ModuleAException; CommonResponse&lt;C&gt; opC(CRequest request) throws ModuleAException;&#125; 上述接口中定义的异常实际上也是一种契约，契约的好处便是不需要叙述，调用方自然会想到要去处理 Checked Exception，否则连编译都过不了。 调用方的处理方式 在 ModuleB 中，应当如下处理异常： 12345678910111213141516171819202122public class ModuleBService implements ModuleBProvider &#123; @Reference ModuleAProvider moduleAProvider; @Override public void someOp() throws ModuleBexception&#123; try&#123; moduleAProvider.opA(...); &#125;catch(ModuleAException e)&#123; throw new ModuleBException(e.getMessage()); &#125; &#125; @Override public void anotherOp()&#123; try&#123; moduleAProvider.opB(...); &#125;catch(ModuleAException e)&#123; // 业务逻辑处理 &#125; &#125;&#125; someOp 演示了一个异常流的传递，ModuleB 暴露出去的异常应当是 ModuleB 的 api 模块中异常类，虽然其依赖了 ModuleA ，但需要将异常进行转换，或者对于那些意料之中的业务异常可以像 anotherOp() 一样进行处理，不再传递。这时如果新增 ModuleC 依赖 ModuleB，那么 ModuleC 完全不需要关心 ModuleA 的异常。 异常与熔断 作为系统设计者，我们应该认识到一点： RPC 调用，失败是常态。通常我们需要对 RPC 接口做熔断处理，比如千米内部便集成了 Netflix 提供的熔断组件 Hystrix。Hystrix 需要知道什么样的异常需要进行熔断，什么样的异常不能够进行熔断。在没有上述的异常设计之前，回答这个问题可能还有些难度，但有了 Checked Exception 的契约，一切都变得明了清晰了。 123456789101112131415161718192021public class ModuleAProviderProxy &#123; @Reference private ModuleAProvider moduleAProvider; @HystrixCommand(ignoreExceptions = &#123;ModuleAException.class&#125;) public void opA(ARequest request) throws ModuleAException &#123; moduleAProvider.opA(request); &#125; @HystrixCommand(ignoreExceptions = &#123;ModuleAException.class&#125;) public void opB(BRequest request) throws ModuleAException &#123; moduleAProvider.oBB(request); &#125; @HystrixCommand(ignoreExceptions = &#123;ModuleAException.class&#125;) public CommonResponse&lt;C&gt; opC(CRequest request) throws ModuleAException &#123; return moduleAProvider.opC(request); &#125; &#125; 如服务不可用等原因引发的多次接口调用超时异常，会触发 Hystrix 的熔断；而对于业务异常，我们则认为不需要进行熔断，因为对于接口 throws 出的业务异常，我们也认为是正常响应的一部分，只不过借助于 JAVA 的异常机制来表达。实际上，和生成自动化测试类的工具一样，我们使用了另一套自动化的工具，可以由 Dubbo 接口自动生成对应的 Hystrix Proxy。我们坚定的认为开发体验和用户体验一样重要，所以公司内部会有非常多的自动化工具。 3. API 版本单独演进引用一段公司内部的真实对话： A：我下载了你们的代码库怎么编译不通过啊，依赖中 xxx-api-1.1.3 版本的 jar 包找不到了，那可都是 RELEASE 版本啊。 B：你不知道我们 nexus 容量有限，只能保存最新的 20 个 RELEASE 版本吗？那个 API 现在最新的版本是 1.1.31 啦。 A：啊，这才几个月就几十个 RELEASE 版本啦？这接口太不稳定啦。 B： 其实接口一行代码没改，我们业务分析是很牛逼的，一直很稳定。但是这个 API 是和我们项目一起打包的，我们需求更新一次，就发布一次，API 就被迫一起升级版本。发生这种事，大家都不想的。 在单体式架构中，版本演进的单位是整个项目。微服务解决的一个关键的痛点便是其做到了每个服务的单独演进，这大大降低了服务间的耦合。正如我文章开始时举得那个例子一样：serviceA 是一个演进的单位，serviceA-api 和 serviceA-app 这两个 Module 从属于 serviceA，这意味着 app 的一次升级，将会引发 api 的升级，因为他们是共生的！而从微服务的使用角度来看，调用者关心的是 api 的结构，而对其实现压根不在乎。所以对于 api 定义未发生变化，其 app 发生变化的那些升级，其实可以做到对调用者无感知。在实践中也是如此 ​ api 版本的演进应该是缓慢的，而 app 版本的演进应该是频繁的。 所以，对于这两个演进速度不一致的模块，我们应该单独做版本管理，他们有自己的版本号。 4. 问题回归 查询接口过多。 各种 findBy 方法，加上各自的重载，几乎占据了一个接口 80% 的代码量。这也符合一般人的开发习惯，因为页面需要各式各样的数据格式，加上查询条件差异很大，便造成了：一个查询条件，一个方法的尴尬场景。这样会导致另外一个问题，需要使用某个查询方法时，直接新增了方法，但实际上可能这个方法已经出现过了，隐藏在了令人眼花缭乱的方法中。 解决方案：使用单参 +Specification 模式，降低重复的查询方法，大大降低接口中的方法数量。 难以扩展 。接口的任何改动，比如新增一个入参，都会导致调用者被迫升级，这也通常是 RPC 设计被诟病的一点，不合理的 RPC 接口设计会放大这个缺点。 解决方案：单参设计其实无形中包含了所有的查询条件的排列组合，可以直接在 app 实现逻辑的新增，而不需要对 api 进行改动（如果是参数的新增则必须进行 api 的升级，参数的废弃可以用 @Deprecated 标准）。 升级困难。 在之前的 “初识 RPC 接口设计”一节中，版本管理的粒度是 project，而不是 module，这意味着：api 即使没有发生变化，app 版本演进，也会造成 api 的被迫升级，因为 project 是一个整体。问题又和上一条一样了，api 一旦发生变化，调用者也得被迫升级，牵一发而动全身。 解决方案：以 module 为版本演进的粒度。api 和 app 单独演进，减少调用者的不必要升级次数。 难以测试 。接口一多，职责随之变得繁杂，业务场景各异，测试用例难以维护。特别是对于那些有良好习惯编写单元测试的程序员而言，简直是噩梦，用例也得跟着改。 解决方案：单参数设计 + 自动化测试工具，打造良好的开发体验。 异常设计不合理 。在既往的工作经历中曾经有一次会议，就 RPC 调用中的异常设计引发了争议，一派人觉得需要有一个业务 CommonResponse，封装异常，每次调用后，优先判断调用结果是否 success，在进行业务逻辑处理；另一派人觉得这比较麻烦，由于 RPC 框架是可以封装异常调用的，所以应当直接 try catch 异常，不需要进行业务包裹。在没有明确规范时，这两种风格的代码同时存在于项目中，十分难看！ 解决方案：Checked Exception+ 正确异常处理姿势，使得代码更加优雅，降低了调用方不处理异常带来的风险。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"【千米网】从跨语言调用到 dubbo2.js","slug":"dubbojs-in-qianmi","date":"2018-05-15T14:44:34.000Z","updated":"2019-09-26T09:45:31.430Z","comments":true,"path":"dubbojs-in-qianmi/","link":"","permalink":"http://lexburner.github.io/dubbojs-in-qianmi/","excerpt":"dubbo2.js 是 千米网 贡献给 dubbo 社区的一款 nodejs dubbo 客户端，它提供了 nodejs 对原生 dubbo 协议的支持，使得 nodejs 和 java 这两种异构语言的 rpc 调用变得便捷，高效。 微服务跨语言调用微服务架构已成为目前互联网架构的趋势，关于微服务的讨论，几乎占据了各种技术大会的绝大多数版面。国内使用最多的服务治理框架非阿里开源的 dubbo 莫属，千米网也选择了 dubbo 作为微服务治理框架。另一方面，和大多数互联网公司一样，千米的开发语言是多样的，大多数后端业务由 java 支撑，而每个业务线有各自开发语言的选择权，便出现了 nodejs，python，go 多语言调用的问题。","text":"dubbo2.js 是 千米网 贡献给 dubbo 社区的一款 nodejs dubbo 客户端，它提供了 nodejs 对原生 dubbo 协议的支持，使得 nodejs 和 java 这两种异构语言的 rpc 调用变得便捷，高效。 微服务跨语言调用微服务架构已成为目前互联网架构的趋势，关于微服务的讨论，几乎占据了各种技术大会的绝大多数版面。国内使用最多的服务治理框架非阿里开源的 dubbo 莫属，千米网也选择了 dubbo 作为微服务治理框架。另一方面，和大多数互联网公司一样，千米的开发语言是多样的，大多数后端业务由 java 支撑，而每个业务线有各自开发语言的选择权，便出现了 nodejs，python，go 多语言调用的问题。跨语言调用是一个很大的话题，也是一个很有挑战的技术活，目前业界经常被提及的解决方案有如下几种，不妨拿出来老生常谈一番： spring cloud。spring cloud 提供了一整套微服务开发组件，它主要面向 java 开发，但由于其使用的协议是基于 restful 风格的 http 协议，这使得其天然具备跨语言能力，异构语言只需要提供 http 客户端，便可以实现跨语言调用。 service mesh。号称下一代微服务框架的 service mesh，其解决跨语言问题的核心在于 SideCar ，SideCar 在 service mesh 的发展过程中概念不断的迁移，但本质都是完成了一件事：处理服务间通信，负责实现请求的可靠传递。 motan。motan 是新浪微博开源的一款跨语言服务治理框架，在其早期版本中仅支持 motan-java，随着版本演进，在目前最新版本 (1.1.0) 中，提供了 motan-go，motan-php，motan-openresty 等跨语言特性。类似于 service mesh 中的 SideCar，motan 借助于 motan-go 作为 agent 完成协议的转发，并且依赖于定制协议：motan2，实现跨语言调用。 当我们再聊跨语言调用时我们在聊什么？纵观上述几个较为通用，成熟的解决方案，可以得出结论：解决跨语言调用的思路无非是两种： 寻找一个通用的协议 使用 agent 完成协议的适配 如果一个新型的团队面临技术选型，我认为上述的方案都可以纳入参考，可考虑到遗留系统的兼容性问题 旧系统的迁移成本 这也关键的选型因素。我们做出的第一个尝试，便是在 RPC 协议上下功夫。 通用协议的跨语言支持springmvc 的美好时代 在没有实现真正的跨语言调用之前，想要实现“跨语言”大多数方案是使用 http 协议做一层转换，最常见的手段莫过于借助 springmvc 提供的 controller/restController，间接调用 dubbo provider。这种方案的优势和劣势显而易见 优势是简单，是最通俗的解决方案。 劣势是使得调用链路变长，tcp 通信之上又多了一层 http 通信；开发体验差，为了将 rpc 接口暴露出去，需要额外编写一份 controller 层的代码。 通用协议的支持 事实上，大多数服务治理框架都支持多种协议，dubbo 框架除默认的 dubbo 协议之外，还有当当网扩展的 rest 协议和千米网扩展的 json-rpc 协议可供选择。这两者都是通用的跨语言协议。 rest 协议为满足 JAX-RS 2.0 标准规范，在开发过程中引入了 @Path，@POST，@GET 等注解，习惯于编写传统 rpc 接口的人可能不太习惯 rest 风格的 rpc 接口。一方面这样会影响开发体验，另一方面，独树一帜的接口风格使得它与其他协议不太兼容，旧接口的共生和迁移都无法实现。如果没有遗留系统，rest 协议无疑是跨语言方案最简易的实现，绝大多数语言支持 rest 协议。 和 rest 协议类似，json-rpc 的实现也是文本序列化 &amp;http 协议。dubbox 在 restful 接口上已经做出了尝试，但是 rest 架构和 dubbo 原有的 rpc 架构是有区别的，rest 架构需要对资源 (Resources) 进行定义， 需要用到 http 协议的基本操作 GET、POST、PUT、DELETE。在我们看来，restful 更合适互联网系统之间的调用，而 rpc 更适合一个系统内的调用。使用 json-rpc 协议使得旧接口得以兼顾，开发习惯仍旧保留，同时获得了跨语言的能力。 千米网在早期实践中采用了 json-rpc 作为 dubbo 的跨语言协议实现，并开源了基于 json-rpc 协议下的 python 客户端 dubbo-client-py 和 node 客户端 dubbo-node-client，使用 python 和 nodejs 的小伙伴可以借助于它们直接调用 dubbo-provider-java 提供的 rpc 服务。系统中大多数 java 服务之间的互相调用还是以 dubbo 协议为主，考虑到新旧协议的适配，在不影响原有服务的基础上，我们配置了双协议。 12&lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt;&lt;dubbo:protocol name=\"jsonrpc\" port=\"8080\" /&gt; dubbo 协议主要支持 java 间的相互调用，适配老接口；json-rpc 协议主要支持异构语言的调用。 定制协议的跨语言支持微服务框架所谓的协议 (protocol) 可以简单理解为：报文格式和序列化方案。服务治理框架一般都提供了众多的协议配置项供使用者选择，除去上述两种通用协议，还存在一些定制化的协议，如 dubbo 框架的默认协议：dubbo 协议以及 motan 框架提供的跨语言协议：motan2。 motan2 协议的跨语言支持 motan2 协议被设计用来满足跨语言的需求主要体现在两个细节中—MetaData 和 motan-go。在最初的 motan 协议中，协议报文仅由 Header+Body 组成，这样导致 path，param，group 等存储在 Body 中的数据需要反序列得到，这对异构语言来说是很不友好的，所以在 motan2 中修改了协议的组成；weibo 开源了 motan-go ，motan-php ，motan-openresty , 并借助于 motan-go 充当了 agent 这一翻译官的角色，使用 simple 序列化方案来序列化协议报文的 Body 部分（simple 序列化是一种较弱的序列化方案）。 仔细揣摩下可以发现这么做和双协议的配置区别并不是大，只不过这里的 agent 是隐式存在的，与主服务共生。明显的区别在于 agent 方案中异构语言并不直接交互。 dubbo 协议的跨语言支持dubbo 协议设计之初只考虑到了常规的 rpc 调用场景，它并不是为跨语言而设计，但跨语言支持从来不是只有支持、不支持两种选择，而是要按难易程度来划分。是的，dubbo 协议的跨语言调用可能并不好做，但并非无法实现。千米网便实现了这一点，nodejs 构建的前端业务是异构语言的主战场，最终实现了 dubbo2.js，打通了 nodejs 和原生 dubbo 协议。作为本文第二部分的核心内容，重点介绍下我们使用 dubbo2.js 干了什么事。 Dubbo 协议报文格式 dubbo 协议报文消息头详解： magic：类似 java 字节码文件里的魔数，用来判断是不是 dubbo 协议的数据包。魔数是常量 0xdabb flag：标志位, 一共 8 个地址位。低四位用来表示消息体数据用的序列化工具的类型（默认 hessian），高四位中，第一位为 1 表示是 request 请求，第二位为 1 表示双向传输（即有返回 response），第三位为 1 表示是心跳 ping 事件。 status：状态位, 设置请求响应状态，dubbo 定义了一些响应的类型。具体类型见 com.alibaba.dubbo.remoting.exchange.Response invoke id：消息 id, long 类型。每一个请求的唯一识别 id（由于采用异步通讯的方式，用来把请求 request 和返回的 response 对应上） body length：消息体 body 长度, int 类型，即记录 Body Content 有多少个字节 body content：请求参数，响应参数的抽象序列化之后存储于此。 协议报文最终都会变成字节，使用 tcp 传输，任何语言只要支持网络模块，有类似 Socket 之类的封装，那么通信就不成问题。那，跨语言难在哪儿？以其他语言调用 java 来说，主要有两个难点： 异构语言如何表示 java 中的数据类型，特别是动态语言，可能不存在严格的数据类型 序列化方案如何做到跨语言 dubbo2.js 解决方案上面我们分析出了两个难点，dubbo2.js 解决这两个问题的关键依赖于两个类库：js-to-java ，hessian.js 。js-to-java 使得 nodejs 具备 java 对象的表达能力，而 hessian.js 提供了序列化能力。借助于 nodejs 的 socket ，复刻一套 dubbo 协议的报文格式，最终便实现了 nodejs 对 java-dubbo-provider 的调用。 dubbo2.js 快速入门为了让对 dubbo2.js 感兴趣的读者有一个直观的体验，本节呈现一个快速入门示例，让你体会到使用 dubbo2.js 调用 dubbo 服务是一件多么轻松的事。 创建 dubbo-java-provider 后端 dubbo 服务使用 java 来提供，这服务大多数的业务场景。首先定义服务接口： 123456public interface DemoProvider &#123; String sayHello(String name); String echo() ; void test(); UserResponse getUserInfo(UserRequest request);&#125; 其次，实现服务： 1234567891011121314151617181920212223242526public class DemoProviderImpl implements DemoProvider &#123; public String sayHello(String name) &#123; System.out.println(\"[\" + new SimpleDateFormat(\"HH:mm:ss\").format(new Date()) + \"] Hello\" + name + \", request from consumer:\" + RpcContext.getContext().getRemoteAddress()); return \"Hello\" + name + \", response form provider:\" + RpcContext.getContext().getLocalAddress(); &#125; @Override public String echo() &#123; System.out.println(\"receive....\"); return \"pang\"; &#125; @Override public void test() &#123; System.out.println(\"test\"); &#125; @Override public UserResponse getUserInfo(UserRequest request) &#123; System.out.println(request); UserResponse response = new UserResponse(); response.setStatus(\"ok\"); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(\"id\", \"1\"); map.put(\"name\", \"test\"); response.setInfo(map); return response; &#125;&#125; 暴露服务： 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"demo-provider\"/&gt; &lt;dubbo:registry protocol=\"zookeeper\" address=\"localhost:2181\"/&gt; &lt;!-- 用 dubbo 协议在 20880 端口暴露服务 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt; &lt;!-- 和本地 bean 一样实现服务 --&gt; &lt;bean id=\"demoProvider\" class=\"com.alibaba.dubbo.demo.provider.DemoProviderImpl\"/&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface=\"com.alibaba.dubbo.demo.DemoProvider\" ref=\"demoProvider\" version=\"1.0.0\"/&gt;&lt;/beans&gt; 我们完成了服务端的所有配置，启动启动类即可在本地注册一个 dubbo 服务。 1234567public class Provider &#123; public static void main(String[] args) throws Exception &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;\"META-INF/spring/dubbo-demo-provider.xml\"&#125;); context.start(); System.in.read(); &#125;&#125; 实现 nodejs 的 dubbo 客户端 安装 dubbo2.js： 1npm install dubbo2.js --save 配置 dubboConfig.ts： 1234567891011121314151617181920212223242526272829303132333435363738import &#123;Dubbo, java, TDubboCallResult&#125; from 'dubbo2.js'const dubbo = new Dubbo(&#123; application: &#123;name: 'demo-provider'&#125;, register: 'localhost:2181', dubboVersion: '2.0.0', interfaces: [ 'com.alibaba.dubbo.demo.DemoProvider', ],&#125;);interface IDemoService &#123; sayHello(name: string): TDubboCallResult&lt;string&gt;;&#125;export const demoService = dubbo.proxyService&lt;IDemoService&gt;(&#123; dubboInterface: 'com.alibaba.dubbo.demo.DemoProvider', version: '1.0.0', methods: &#123; sayHello(name: string) &#123; return [java.String(name)]; &#125;, echo()&#123;&#125;, test()&#123;&#125;, getUserInfo() &#123; return [ java.combine('com.alibaba.dubbo.demo.UserRequest', &#123; id: 1, name: 'nodejs', email: 'node@qianmi.com', &#125;), ]; &#125;, &#125;,&#125;); 使用 typescript 可以带来更好的开发体验。 编写调用类 main.ts： 12345import &#123;demoService&#125; from './dubboConfig'demoService.sayHello('kirito').then((&#123;res,err&#125;)=&gt;&#123; console.log(res)&#125;); 执行调用 Debug 模式启动 nodejs 客户端： 1DEBUG=dubbo* ts-node main.ts 查看运行结果： 1Hello kirito, response form provider: 172.19.6.151:20880 congratulation！ dubbo2.js 特性 支持 zookeeper 注册中心 支持原生 dubbo 协议 支持服务直连 全链路跟踪 dubbo 接口自动生成 MORE DETAILS本文中的示例代码，提供在此处，https://github.com/lexburner/Dubbojs-Learning 。如果你对 dubbo 协议不慎了解，想要理解它的工作原理，项目中提供了一个子 moudle — java-socket-consumer，使用面向过程的思路实现了 java-socket-consumer，完成了原生 socket 发送 dubbo 协议报文，完成方法调用，并获取响应的全流程。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"Spring Security(六)—SpringSecurityFilterChain 加载流程深度解析","slug":"spring-security-7","date":"2018-05-08T14:44:34.000Z","updated":"2019-09-26T09:45:30.898Z","comments":true,"path":"spring-security-7/","link":"","permalink":"http://lexburner.github.io/spring-security-7/","excerpt":"SpringSecurityFilterChain 作为 SpringSecurity 的核心过滤器链在整个认证授权过程中起着举足轻重的地位，每个请求到来，都会经过该过滤器链，前文 《Spring Security( 四)– 核心过滤器源码分析》 中我们分析了 SpringSecurityFilterChain 的构成，但还有很多疑问可能没有解开：","text":"SpringSecurityFilterChain 作为 SpringSecurity 的核心过滤器链在整个认证授权过程中起着举足轻重的地位，每个请求到来，都会经过该过滤器链，前文 《Spring Security( 四)– 核心过滤器源码分析》 中我们分析了 SpringSecurityFilterChain 的构成，但还有很多疑问可能没有解开： 这个 SpringSecurityFilterChain 是怎么注册到 web 环境中的？ 有读者发出这样的疑问：”SpringSecurityFilterChain 的实现类到底是什么，我知道它是一个 Filter，但是在很多配置类中看到了 BeanName=SpringSecurityFilterChain 相关的类，比如 DelegatingFilterProxy，FilterChainProxy，SecurityFilterChain，他们的的名称实在太相似了，到底哪个才是真正的实现，SpringSecurity 又为什么要这么设计？“ 我们貌似一直在配置 WebSecurity ，但没有对 SpringSecurityFilterChain 进行什么配置，WebSecurity 相关配置是怎么和 SpringSecurityFilterChain 结合在一起的？ 以上是个人 YY 的一些 SpringSecurityFilterChain 相关的问题，因为我当初研究了一段时间 SpringSecurity 源码，依旧没有理清这么多错综复杂的类。那么本文就主要围绕 SpringSecurityFilterChain 展开我们的探索。 ###6.1 SpringSecurityFilterChain 是怎么注册的？ 这个问题并不容易解释，因为 SpringSecurity 仅仅在 web 环境下（SpringSecurity 还支持非 web 环境）就有非常多的支持形式： Java 配置方式 作为独立的 SpringSecurity 依赖提供给朴素的 java web 项目使用，并且项目不使用 Spring！没错，仅仅使用 servlet，jsp 的情况下也是可以集成 SpringSecurity 的。 提供给包含 SpringMVC 项目使用。 提供给具备 Servlet3.0+ 的 web 项目使用。 SpringBoot 内嵌容器环境下使用 SpringSecurity，并且包含了一定程度的自动配置。 XML 配置方式 使用 XML 中的命名空间配置 SpringSecurity。 注意，以上条件可能存在交集，比如我的项目是一个使用 servlet3.0 的 web 项目同时使用了 SpringMVC；也有可能使用了 SpringBoot 同时配合 SpringMVC；还有可能使用了 SpringBoot，却打成了 war 包，部署在外置的支持 Servlet3.0+ 规范的应用容器中… 各种组合方式会导致配置 SpringSecurityFilterChain 的注册方式产生差异，所以，这个问题说复杂还真有点，需要根据你的环境来分析。我主要分析几种较为常见的注册方式。 SpringSecurityFilterChain 抽象概念里最重要的三个类：DelegatingFilterProxy，FilterChainProxy 和 SecurityFilterChain，对这三个类的源码分析和设计将会贯彻本文。不同环境下 DelegatingFilterProxy 的注册方式区别较大，但 FilterChainProxy 和 SecurityFilterChain 的差异不大，所以重点就是分析 DelegatingFilterProxy 的注册方式。它们三者的分析会放到下一节中。 ####6.1.1 servlet3.0+ 环境下 SpringSecurity 的 java config 方式 这是一个比较常见的场景，你可能还没有使用 SpringBoot 内嵌的容器，将项目打成 war 包部署在外置的应用容器中，比如最常见的 tomcat，一般很少 web 项目低于 servlet3.0 版本的，并且该场景摒弃了 XML 配置。 123456import org.springframework.security.web.context.*;public class SecurityWebApplicationInitializer extends AbstractSecurityWebApplicationInitializer &#123;&#125; 主要自定义一个 SecurityWebApplicationInitializer 并且让其继承自 AbstractSecurityWebApplicationInitializer 即可。如此简单的一个继承背后又经历了 Spring 怎样的封装呢？自然要去 AbstractSecurityWebApplicationInitializer 中去一探究竟。经过删减后的源码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractSecurityWebApplicationInitializer implements WebApplicationInitializer &#123;//&lt;1&gt; public static final String DEFAULT_FILTER_NAME = \"springSecurityFilterChain\"; // &lt;1&gt; 父类 WebApplicationInitializer 的加载入口 public final void onStartup(ServletContext servletContext) throws ServletException &#123; beforeSpringSecurityFilterChain(servletContext); if (this.configurationClasses != null) &#123; AnnotationConfigWebApplicationContext rootAppContext = new AnnotationConfigWebApplicationContext(); rootAppContext.register(this.configurationClasses); servletContext.addListener(new ContextLoaderListener(rootAppContext)); &#125; if (enableHttpSessionEventPublisher()) &#123; servletContext.addListener( \"org.springframework.security.web.session.HttpSessionEventPublisher\"); &#125; servletContext.setSessionTrackingModes(getSessionTrackingModes()); insertSpringSecurityFilterChain(servletContext);//&lt;2&gt; afterSpringSecurityFilterChain(servletContext); &#125; // &lt;2&gt; 在这儿初始化了关键的 DelegatingFilterProxy private void insertSpringSecurityFilterChain(ServletContext servletContext) &#123; String filterName = DEFAULT_FILTER_NAME; // &lt;2&gt; 该方法中最关键的一个步骤，DelegatingFilterProxy 在此被创建 DelegatingFilterProxy springSecurityFilterChain = new DelegatingFilterProxy( filterName); String contextAttribute = getWebApplicationContextAttribute(); if (contextAttribute != null) &#123; springSecurityFilterChain.setContextAttribute(contextAttribute); &#125; registerFilter(servletContext, true, filterName, springSecurityFilterChain); &#125; // &lt;3&gt; 使用 servlet3.0 的新特性，动态注册 springSecurityFilterChain(实际上注册的是 springSecurityFilterChain 代理类) private final void registerFilter(ServletContext servletContext, boolean insertBeforeOtherFilters, String filterName, Filter filter) &#123; Dynamic registration = servletContext.addFilter(filterName, filter); registration.setAsyncSupported(isAsyncSecuritySupported()); EnumSet&lt;DispatcherType&gt; dispatcherTypes = getSecurityDispatcherTypes(); registration.addMappingForUrlPatterns(dispatcherTypes, !insertBeforeOtherFilters, \"/*\"); &#125;&#125; 放在一起讲，因为他们都和 servlet3.0 新特性以及 spring 对 servlet3.0 的支持相关，这也是为什么在场景描述中我特地强调了需要 servlet3.0 环境。如果你对 servlet3.0 的新特性不了解，这儿准备了一篇详细的介绍为你阐述 《Spring 揭秘 – 寻找遗失的 web.xml》 。得益于 Spring 的封装，在 servlet3.0 环境下，web 容器启动时会自行去寻找类路径下所有实现了 WebApplicationInitializer 接口的 Initializer 实例，并调用他们的 onStartup 方法。所以，我们只需要继承 AbstractSecurityWebApplicationInitializer ，便可以自动触发 web 容器的加载，进而配置和 SpringSecurityFilterChain 第一个密切相关的类，第 步中的 DelegatingFilterProxy。 DelegatingFilterProxy 在此被实例化出来。在第 步中，它作为一个 Filter 正式注册到了 web 容器中。 6.1.2 XML 配置这个真的是简单易懂，因为它是被指名道姓配置成一个 Filter 的。 web.xml 123456789&lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; web.xml 的存在注定了其无所谓当前环境是不是 servlet3.0+，虽然我个人不太喜欢 xml 的配置方式，但不得不说，这样真的很简单粗暴。 6.1.3 SpringBoot 内嵌应用容器并且使用自动配置《Spring 揭秘 – 寻找遗失的 web.xml》 中我曾经得出一个结论，内嵌容器是完全不会使用 SPI 机制加载 servlet3.0 新特性的那些 Initializer 的，springboot 又推崇 java configuration，所以上述两种方案完全被抛弃了。那么 SpringBoot 如何注册 DelegatingFilterProxy 呢？ 12345678910111213141516171819202122232425262728@Configuration@ConditionalOnWebApplication@EnableConfigurationProperties@ConditionalOnClass(&#123; AbstractSecurityWebApplicationInitializer.class, SessionCreationPolicy.class &#125;)@AutoConfigureAfter(SecurityAutoConfiguration.class)public class SecurityFilterAutoConfiguration &#123; private static final String DEFAULT_FILTER_NAME = AbstractSecurityWebApplicationInitializer.DEFAULT_FILTER_NAME;//springSecurityFilterChain // &lt;1&gt; @Bean @ConditionalOnBean(name = DEFAULT_FILTER_NAME) public DelegatingFilterProxyRegistrationBean securityFilterChainRegistration( SecurityProperties securityProperties) &#123; DelegatingFilterProxyRegistrationBean registration = new DelegatingFilterProxyRegistrationBean( DEFAULT_FILTER_NAME); registration.setOrder(securityProperties.getFilterOrder()); registration.setDispatcherTypes(getDispatcherTypes(securityProperties)); return registration; &#125; @Bean @ConditionalOnMissingBean public SecurityProperties securityProperties() &#123; return new SecurityProperties(); &#125;&#125; DelegatingFilterProxyRegistrationBean 的分析在之前那篇文章中也有详细的介绍，其作用便是在 SpringBoot 环境下通过 TomcatStarter 等内嵌容器启动类来注册一个 DelegatingFilterProxy。这下，和前面两种配置方式都对应上了。 ###SpringSecurityFilterChain 三个核心类的源码分析 理解 SpringSecurityFilterChain 的工作流程必须搞懂三个类：org.springframework.web.filter.DelegatingFilterProxy，org.springframework.security.web.FilterChainProxy ， org.springframework.security.web.SecurityFilterChain DelegatingFilterProxy上面一节主要就是介绍 DelegatingFilterProxy 在不同环境下的注册方式，可以很明显的发现，DelegatingFilterProxy 是 SpringSecurity 的“门面”，注意它的包结构：org.springframework.web.filter，它本身是 Spring Web 包中的类，并不是 SpringSecurity 中的类。因为 Spring 考虑到了多种使用场景，自然希望将侵入性降到最低，所以使用了这个委托代理类来代理真正的 SpringSecurityFilterChain。DelegatingFilterProxy 实现了 javax.servlet.Filter 接口，使得它可以作为一个 java web 的标准过滤器，其职责也很简单，只负责调用真正的 SpringSecurityFilterChain。 删减掉非重要代码后的 DelegatingFilterProxy： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class DelegatingFilterProxy extends GenericFilterBean &#123; private WebApplicationContext webApplicationContext; // springSecurityFilterChain private String targetBeanName; // &lt;1&gt; 关键点 private volatile Filter delegate; private final Object delegateMonitor = new Object(); public DelegatingFilterProxy(String targetBeanName, WebApplicationContext wac) &#123; Assert.hasText(targetBeanName, \"Target Filter bean name must not be null or empty\"); this.setTargetBeanName(targetBeanName); this.webApplicationContext = wac; if (wac != null) &#123; this.setEnvironment(wac.getEnvironment()); &#125; &#125; @Override protected void initFilterBean() throws ServletException &#123; synchronized (this.delegateMonitor) &#123; if (this.delegate == null) &#123; if (this.targetBeanName == null) &#123; this.targetBeanName = getFilterName(); &#125; // Fetch Spring root application context and initialize the delegate early, // if possible. If the root application context will be started after this // filter proxy, we'll have to resort to lazy initialization. WebApplicationContext wac = findWebApplicationContext(); if (wac != null) &#123; this.delegate = initDelegate(wac); &#125; &#125; &#125; &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; // 过滤器代理支持懒加载 Filter delegateToUse = this.delegate; if (delegateToUse == null) &#123; synchronized (this.delegateMonitor) &#123; delegateToUse = this.delegate; if (delegateToUse == null) &#123; WebApplicationContext wac = findWebApplicationContext(); delegateToUse = initDelegate(wac); &#125; this.delegate = delegateToUse; &#125; &#125; // 让代理过滤器执行实际的过滤行为 invokeDelegate(delegateToUse, request, response, filterChain); &#125; // 初始化过滤器代理 // &lt;2&gt; protected Filter initDelegate(WebApplicationContext wac) throws ServletException &#123; Filter delegate = wac.getBean(getTargetBeanName(), Filter.class); if (isTargetFilterLifecycle()) &#123; delegate.init(getFilterConfig()); &#125; return delegate; &#125; // 调用代理过滤器 protected void invokeDelegate( Filter delegate, ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; delegate.doFilter(request, response, filterChain); &#125;&#125; 可以发现整个 DelegatingFilterProxy 的逻辑就是为了调用 private volatile Filter delegate; 那么问题来了，这个 delegate 的真正实现是什么呢？ 可以看到，DelegatingFilterProxy 尝试去容器中获取名为 targetBeanName 的类，而 targetBeanName 的默认值便是 Filter 的名称，也就是 springSecurityFilterChain！也就是说，DelegatingFilterProxy 只是名称和 targetBeanName 叫 springSecurityFilterChain，真正容器中的 Bean(name=”springSecurityFilterChain”) 其实另有其人（这里 springboot 稍微有点区别，不过不影响理解，我们不纠结这个细节了）。通过 debug，我们发现了真正的 springSecurityFilterChain — FilterChainProxy。 FilterChainProxy 和 SecurityFilterChainorg.springframework.security.web.FilterChainProxy 已经是 SpringSecurity 提供的类了，原来它才是真正的 springSecurityFilterChain，我们来看看它的源码（有删减，不影响理解）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class FilterChainProxy extends GenericFilterBean &#123; // &lt;1&gt; 包含了多个 SecurityFilterChain private List&lt;SecurityFilterChain&gt; filterChains; public FilterChainProxy(SecurityFilterChain chain) &#123; this(Arrays.asList(chain)); &#125; public FilterChainProxy(List&lt;SecurityFilterChain&gt; filterChains) &#123; this.filterChains = filterChains; &#125; @Override public void afterPropertiesSet() &#123; filterChainValidator.validate(this); &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; doFilterInternal(request, response, chain); &#125; private void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FirewalledRequest fwRequest = firewall .getFirewalledRequest((HttpServletRequest) request); HttpServletResponse fwResponse = firewall .getFirewalledResponse((HttpServletResponse) response); // &lt;1&gt; List&lt;Filter&gt; filters = getFilters(fwRequest); if (filters == null || filters.size() == 0) &#123; fwRequest.reset(); chain.doFilter(fwRequest, fwResponse); return; &#125; VirtualFilterChain vfc = new VirtualFilterChain(fwRequest, chain, filters); vfc.doFilter(fwRequest, fwResponse); &#125; /** * &lt;1&gt; 可能会有多个过滤器链，返回第一个和请求 URL 匹配的过滤器链 */ private List&lt;Filter&gt; getFilters(HttpServletRequest request) &#123; for (SecurityFilterChain chain : filterChains) &#123; if (chain.matches(request)) &#123; return chain.getFilters(); &#125; &#125; return null; &#125;&#125; 看 FilterChainProxy 的名字就可以发现，它依旧不是真正实施过滤的类，它内部维护了一个 SecurityFilterChain，这个过滤器链才是请求真正对应的过滤器链，并且同一个 Spring 环境下，可能同时存在多个安全过滤器链，如 private List filterChains 所示，需要经过 chain.matches(request) 判断到底哪个过滤器链匹配成功，每个 request 最多只会经过一个 SecurityFilterChain。为何要这么设计？因为 Web 环境下可能有多种安全保护策略，每种策略都需要有自己的一条链路，比如我曾经设计过 Oauth2 服务，在极端条件下，可能同一个服务本身既是资源服务器，又是认证服务器，还需要做 Web 安全！ 如上图，4 个 SecurityFilterChain 存在于 FilterChainProxy 中，值得再次强调：实际每次请求，最多只有一个安全过滤器链被返回。 SecurityFilterChain 才是真正意义上的 SpringSecurityFilterChain： 123456789101112public final class DefaultSecurityFilterChain implements SecurityFilterChain &#123; private final RequestMatcher requestMatcher; private final List&lt;Filter&gt; filters; public List&lt;Filter&gt; getFilters() &#123; return filters; &#125; public boolean matches(HttpServletRequest request) &#123; return requestMatcher.matches(request); &#125;&#125; 其中的 List filters 就是我们在 《Spring Security( 四)– 核心过滤器源码分析》 中分析的诸多核心过滤器，包含了 UsernamePasswordAuthenticationFilter，SecurityContextPersistenceFilter，FilterSecurityInterceptor 等之前就介绍过的 Filter。 ###SecurityFilterChain 的注册过程 还记得 DelegatingFilterProxy 从 Spring 容器中寻找了一个 targetBeanName=springSecurityFilterChain 的 Bean 吗？我们通过 debug 直接定位到了其实现是 SecurityFilterChain，但它又是什么时候被放进去的呢？ 这就得说到老朋友 WebSecurity 了，还记得一般我们都会选择使用 @EnableWebSecurity 和 WebSecurityConfigurerAdapter 来进行 web 安全配置吗，来到 WebSecurity 的源码： 123456789101112131415161718192021222324252627public final class WebSecurity extends AbstractConfiguredSecurityBuilder&lt;Filter, WebSecurity&gt; implements SecurityBuilder&lt;Filter&gt;, ApplicationContextAware &#123; @Override protected Filter performBuild() throws Exception &#123; int chainSize = ignoredRequests.size()+ securityFilterChainBuilders.size(); List&lt;SecurityFilterChain&gt; securityFilterChains = new ArrayList&lt;SecurityFilterChain&gt;( chainSize); for (RequestMatcher ignoredRequest : ignoredRequests) &#123; securityFilterChains.add(new DefaultSecurityFilterChain(ignoredRequest)); &#125; for (SecurityBuilder&lt;? extends SecurityFilterChain&gt; securityFilterChainBuilder : securityFilterChainBuilders) &#123; securityFilterChains.add(securityFilterChainBuilder.build()); &#125; // &lt;1&gt; FilterChainProxy 由 WebSecurity 构建 FilterChainProxy filterChainProxy = new FilterChainProxy(securityFilterChains); if (httpFirewall != null) &#123; filterChainProxy.setFirewall(httpFirewall); &#125; filterChainProxy.afterPropertiesSet(); Filter result = filterChainProxy; postBuildAction.run(); return result; &#125;&#125; 最终定位到 WebSecurity 的 performBuild 方法，我们之前配置了一堆参数的 WebSecurity 最终帮助我们构建了 FilterChainProxy。 并且，最终在 org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration 中被注册为默认名称为 SpringSecurityFilterChain。 总结一个名称 SpringSecurityFilterChain，借助于 Spring 的 IOC 容器，完成了 DelegatingFilterProxy 到 FilterChainProxy 的连接，并借助于 FilterChainProxy 内部维护的 List 中的某一个 SecurityFilterChain 来完成最终的过滤。 推荐阅读 https://www.cnkirito.moe/spring-security-1/ Spring Security( 一)–Architecture Overview https://www.cnkirito.moe/spring-security-2/ Spring Security( 二)–Guides https://www.cnkirito.moe/spring-security-3/ Spring Security( 三)– 核心配置解读 https://www.cnkirito.moe/spring-security-4/ Spring Security( 四)– 核心过滤器源码分析 https://www.cnkirito.moe/spring-security-5/ Spring Security( 五)– 动手实现一个 IP_Login https://www.cnkirito.moe/spring-security-6/ 该如何设计你的 PasswordEncoder?","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/categories/Spring-Security/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/tags/Spring-Security/"}]},{"title":"Spring 揭秘 -- 寻找遗失的 web.xml","slug":"servlet-explore","date":"2018-05-04T14:44:34.000Z","updated":"2019-09-26T09:45:30.666Z","comments":true,"path":"servlet-explore/","link":"","permalink":"http://lexburner.github.io/servlet-explore/","excerpt":"今天我们来放松下心情，不聊分布式，云原生，来聊一聊初学者接触的最多的 java web 基础。几乎所有人都是从 servlet，jsp，filter 开始编写自己的第一个 hello world 工程。那时，还离不开 web.xml 的配置，在 xml 文件中编写繁琐的 servlet 和 filter 的配置。随着 spring 的普及，配置逐渐演变成了两种方式—java configuration 和 xml 配置共存。现如今，springboot 的普及，java configuration 成了主流，xml 配置似乎已经“灭绝”了。不知道你有没有好奇过，这中间都发生了哪些改变，web.xml 中的配置项又是被什么替代项取代了？","text":"今天我们来放松下心情，不聊分布式，云原生，来聊一聊初学者接触的最多的 java web 基础。几乎所有人都是从 servlet，jsp，filter 开始编写自己的第一个 hello world 工程。那时，还离不开 web.xml 的配置，在 xml 文件中编写繁琐的 servlet 和 filter 的配置。随着 spring 的普及，配置逐渐演变成了两种方式—java configuration 和 xml 配置共存。现如今，springboot 的普及，java configuration 成了主流，xml 配置似乎已经“灭绝”了。不知道你有没有好奇过，这中间都发生了哪些改变，web.xml 中的配置项又是被什么替代项取代了？ servlet3.0 以前的时代为了体现出整个演进过程，还是来回顾下 n 年前我们是怎么写 servlet 和 filter 代码的。 项目结构（本文都采用 maven 项目结构） 12345678910111213141516.├── pom.xml├── src ├── main │ ├── java │ │ └── moe │ │ └── cnkirito │ │ ├── filter │ │ │ └── HelloWorldFilter.java │ │ └── servlet │ │ └── HelloWorldServlet.java │ └── resources │ └── WEB-INF │ └── web.xml └── test └── java 12345678910public class HelloWorldServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; resp.setContentType(\"text/plain\"); PrintWriter out = resp.getWriter(); out.println(\"hello world\"); &#125;&#125; 123456789101112131415161718public class HelloWorldFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; System.out.println(\"触发 hello world 过滤器...\"); filterChain.doFilter(servletRequest,servletResponse); &#125; @Override public void destroy() &#123; &#125;&#125; 别忘了在 web.xml 中配置 servlet 和 filter 123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;servlet&gt; &lt;servlet-name&gt;HelloWorldServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;moe.cnkirito.servlet.HelloWorldServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloWorldServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/hello&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;HelloWorldFilter&lt;/filter-name&gt; &lt;filter-class&gt;moe.cnkirito.filter.HelloWorldFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HelloWorldFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/hello&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 这样，一个 java web hello world 就完成了。当然，本文不是 servlet 的入门教程，只是为了对比。 servlet3.0 新特性 Servlet 3.0 作为 Java EE 6 规范体系中一员，随着 Java EE 6 规范一起发布。该版本在前一版本（Servlet 2.5）的基础上提供了若干新特性用于简化 Web 应用的开发和部署。其中一项新特性便是提供了无 xml 配置的特性。 servlet3.0 首先提供了 @WebServlet，@WebFilter 等注解，这样便有了抛弃 web.xml 的第一个途径，凭借注解声明 servlet 和 filter 来做到这一点。 除了这种方式，servlet3.0 规范还提供了更强大的功能，可以在运行时动态注册 servlet ，filter，listener。以 servlet 为例，过滤器与监听器与之类似。ServletContext 为动态配置 Servlet 增加了如下方法： ServletRegistration.Dynamic addServlet(String servletName,Class&lt;? extends Servlet&gt; servletClass) ServletRegistration.Dynamic addServlet(String servletName, Servlet servlet) ServletRegistration.Dynamic addServlet(String servletName, String className) T createServlet(Class clazz) ServletRegistration getServletRegistration(String servletName) Map&lt;String,? extends ServletRegistration&gt; getServletRegistrations() 其中前三个方法的作用是相同的，只是参数类型不同而已；通过 createServlet()方法创建的 Servlet，通常需要做一些自定义的配置，然后使用 addServlet() 方法来将其动态注册为一个可以用于服务的 Servlet。两个 getServletRegistration() 方法主要用于动态为 Servlet 增加映射信息，这等价于在 web.xml 中使用 标签为存在的 Servlet 增加映射信息。 以上 ServletContext 新增的方法要么是在 ServletContextListener 的 contexInitialized 方法中调用，要么是在 ServletContainerInitializer 的 onStartup() 方法中调用。 ServletContainerInitializer 也是 Servlet 3.0 新增的一个接口，容器在启动时使用 JAR 服务 API(JAR Service API) 来发现 ServletContainerInitializer 的实现类，并且容器将 WEB-INF/lib 目录下 JAR 包中的类都交给该类的 onStartup()方法处理，我们通常需要在该实现类上使用 @HandlesTypes 注解来指定希望被处理的类，过滤掉不希望给 onStartup() 处理的类。 一个典型的 servlet3.0+ 的 web 项目结构如下： 123456789101112131415161718.├── pom.xml└── src ├── main │ ├── java │ │ └── moe │ │ └── cnkirito │ │ ├── CustomServletContainerInitializer.java │ │ ├── filter │ │ │ └── HelloWorldFilter.java │ │ └── servlet │ │ └── HelloWorldServlet.java │ └── resources │ └── META-INF │ └── services │ └── javax.servlet.ServletContainerInitializer └── test └── java 我并未对 HelloWorldServlet 和 HelloWorldFilter 做任何改动，而是新增了一个 CustomServletContainerInitializer , 它实现了 javax.servlet.ServletContainerInitializer 接口，用来在 web 容器启动时加载指定的 servlet 和 filter，代码如下： 123456789101112131415161718192021222324252627public class CustomServletContainerInitializer implements ServletContainerInitializer &#123; private final static String JAR_HELLO_URL = \"/hello\"; @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; c, ServletContext servletContext) &#123; System.out.println(\"创建 helloWorldServlet...\"); ServletRegistration.Dynamic servlet = servletContext.addServlet( HelloWorldServlet.class.getSimpleName(), HelloWorldServlet.class); servlet.addMapping(JAR_HELLO_URL); System.out.println(\"创建 helloWorldFilter...\"); FilterRegistration.Dynamic filter = servletContext.addFilter( HelloWorldFilter.class.getSimpleName(), HelloWorldFilter.class); EnumSet&lt;DispatcherType&gt; dispatcherTypes = EnumSet.allOf(DispatcherType.class); dispatcherTypes.add(DispatcherType.REQUEST); dispatcherTypes.add(DispatcherType.FORWARD); filter.addMappingForUrlPatterns(dispatcherTypes, true, JAR_HELLO_URL); &#125;&#125; 对上述代码进行一些解读。ServletContext 我们称之为 servlet 上下文，它维护了整个 web 容器中注册的 servlet，filter，listener，以 servlet 为例，可以使用 servletContext.addServlet 等方法来添加 servlet。而方法入参中 Set&lt;Class&lt;?&gt;&gt; c 和 @HandlesTypes 注解在 demo 中我并未使用，感兴趣的朋友可以 debug 看看到底获取了哪些 class ，一般正常的流程是使用 @HandlesTypes 指定需要处理的 class，而后对 Set&lt;Class&lt;?&gt;&gt; 进行判断是否属于该 class，正如前文所言，onStartup 会加载不需要被处理的一些 class。 这么声明一个 ServletContainerInitializer 的实现类，web 容器并不会识别它，所以，需要借助 SPI 机制来指定该初始化类，这一步骤是通过在项目路径下创建 META-INF/services/javax.servlet.ServletContainerInitializer 来做到的，它只包含一行内容： 1moe.cnkirito.CustomServletContainerInitializer 使用 ServletContainerInitializer 和 SPI 机制，我们的 web 应用便可以彻底摆脱 web.xml 了。 Spring 是如何支持 servlet3.0 的？回到我们的 spring 全家桶，可能已经忘了具体是什么时候开始不写 web.xml 了，我只知道现在的项目已经再也看不到它了，spring 又是如何支持 servlet3.0 规范的呢？ 寻找 spring 中 ServletContainerInitializer 的实现类并不困难，可以迅速定位到 SpringServletContainerInitializer 该实现类。 1234567891011121314151617181920212223242526272829303132333435363738@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer &#123; @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext) throws ServletException &#123; List&lt;WebApplicationInitializer&gt; initializers = new LinkedList&lt;WebApplicationInitializer&gt;(); if (webAppInitializerClasses != null) &#123; for (Class&lt;?&gt; waiClass : webAppInitializerClasses) &#123; // Be defensive: Some servlet containers provide us with invalid classes, // no matter what @HandlesTypes says... // &lt;1&gt; if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp; WebApplicationInitializer.class.isAssignableFrom(waiClass)) &#123; try &#123; initializers.add((WebApplicationInitializer) waiClass.newInstance()); &#125; catch (Throwable ex) &#123; throw new ServletException(\"Failed to instantiate WebApplicationInitializer class\", ex); &#125; &#125; &#125; &#125; if (initializers.isEmpty()) &#123; servletContext.log(\"No Spring WebApplicationInitializer types detected on classpath\"); return; &#125; servletContext.log(initializers.size() + \"Spring WebApplicationInitializers detected on classpath\"); AnnotationAwareOrderComparator.sort(initializers); // &lt;2&gt; for (WebApplicationInitializer initializer : initializers) &#123; initializer.onStartup(servletContext); &#125; &#125;&#125; 查看其 java doc，描述如下： Servlet 3.0 {@link ServletContainerInitializer} designed to support code-based configuration of the servlet container using Spring’s {@link WebApplicationInitializer} SPI as opposed to (or possibly in combination with) the traditional {@code web.xml}-based approach. 注意我在源码中标注两个序号，这对于我们理解 spring 装配 servlet 的流程来说非常重要。 英文注释是 spring 源码中自带的，它提示我们由于 servlet 厂商实现的差异，onStartup 方法会加载我们本不想处理的 class，所以进行了特判。 spring 与我们之前的 demo 不同，并没有在 SpringServletContainerInitializer 中直接对 servlet 和 filter 进行注册，而是委托给了一个陌生的类 WebApplicationInitializer ，WebApplicationInitializer 类便是 spring 用来初始化 web 环境的委托者类，它通常有三个实现类： 你一定不会对 dispatcherServlet 感到陌生，AbstractDispatcherServletInitializer#registerDispatcherServlet 便是无 web.xml 前提下创建 dispatcherServlet 的关键代码。 可以去项目中寻找一下 org.springframework:spring-web:version 的依赖，它下面就存在一个 servletContainerInitializer 的扩展，指向了 SpringServletContainerInitializer，这样只要在 servlet3.0 环境下部署，spring 便可以自动加载进行初始化： 注意，上述这一切特性从 spring 3 就已经存在了，而如今 spring 5 已经伴随 springboot 2.0 一起发行了。 SpringBoot 如何加载 Servlet？读到这儿，你已经阅读了全文的 1/2。springboot 对于 servlet 的处理才是重头戏，其一，是因为 springboot 使用范围很广，很少有人用 spring 而不用 springboot 了；其二，是因为它没有完全遵守 servlet3.0 的规范！ 是的，前面所讲述的 servlet 的规范，无论是 web.xml 中的配置，还是 servlet3.0 中的 ServletContainerInitializer 和 springboot 的加载流程都没有太大的关联。按照惯例，先卖个关子，先看看如何在 springboot 中注册 servlet 和 filter，再来解释下 springboot 的独特之处。 注册方式一：servlet3.0 注解 +@ServletComponentScanspringboot 依旧兼容 servlet3.0 一系列以 @Web* 开头的注解：@WebServlet，@WebFilter，@WebListener 12@WebServlet(\"/hello\")public class HelloWorldServlet extends HttpServlet&#123;&#125; 12@WebFilter(\"/hello/*\")public class HelloWorldFilter implements Filter &#123;&#125; 不要忘记让启动类去扫描到这些注解 12345678@SpringBootApplication@ServletComponentScanpublic class SpringBootServletApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootServletApplication.class, args); &#125;&#125; 我认为这是几种方式中最为简洁的方式，如果真的有特殊需求，需要在 springboot 下注册 servlet，filter，可以采用这样的方式，比较直观。 注册方式二：RegistrationBean123456789101112131415@Beanpublic ServletRegistrationBean helloWorldServlet() &#123; ServletRegistrationBean helloWorldServlet = new ServletRegistrationBean(); myServlet.addUrlMappings(\"/hello\"); myServlet.setServlet(new HelloWorldServlet()); return helloWorldServlet;&#125;@Beanpublic FilterRegistrationBean helloWorldFilter() &#123; FilterRegistrationBean helloWorldFilter = new FilterRegistrationBean(); myFilter.addUrlPatterns(\"/hello/*\"); myFilter.setFilter(new HelloWorldFilter()); return helloWorldFilter;&#125; ServletRegistrationBean 和 FilterRegistrationBean 都集成自 RegistrationBean ，RegistrationBean 是 springboot 中广泛应用的一个注册类，负责把 servlet，filter，listener 给容器化，使他们被 spring 托管，并且完成自身对 web 容器的注册。这种注册方式也值得推崇。 从图中可以看出 RegistrationBean 的地位，它的几个实现类作用分别是：帮助容器注册 filter，servlet，listener，最后的 DelegatingFilterProxyRegistrationBean 使用的不多，但熟悉 SpringSecurity 的朋友不会感到陌生，SpringSecurityFilterChain 就是通过这个代理类来调用的。另外 RegistrationBean 实现了 ServletContextInitializer 接口，这个接口将会是下面分析的核心接口，大家先混个眼熟，了解下它有一个抽象实现 RegistrationBean 即可。 SpringBoot 中 servlet 加载流程的源码分析暂时只介绍这两种方式，下面解释下之前卖的关子，为什么说 springboot 没有完全遵守 servlet3.0 规范。讨论的前提是 springboot 环境下使用内嵌的容器，比如最典型的 tomcat。高能预警，以下内容比较烧脑，觉得看起来吃力的朋友可以跳过本节直接看下一节的总结！ Initializer 被替换为 TomcatStarter当使用内嵌的 tomcat 时，你会发现 springboot 完全走了另一套初始化流程，完全没有使用前面提到的 SpringServletContainerInitializer，实际上一开始我在各种 ServletContainerInitializer 的实现类中打了断点，最终定位到，根本没有运行到 SpringServletContainerInitializer 内部，而是进入了 TomcatStarter 这个类中。 并且，仔细扫了一眼源码的包，并没有发现有 SPI 文件对应到 TomcatStarter。于是我猜想，内嵌 tomcat 的加载可能不依赖于 servlet3.0 规范和 SPI！它完全走了一套独立的逻辑。为了验证这一点，我翻阅了 spring github 中的 issue，得到了 spring 作者肯定的答复：https://github.com/spring-projects/spring-boot/issues/321 This was actually an intentional design decision. The search algorithm used by the containers was problematic. It also causes problems when you want to develop an executable WAR as you often want a javax.servlet.ServletContainerInitializer for the WAR that is not executed when you run java -jar. See the org.springframework.boot.context.embedded.ServletContextInitializer for an option that works with Spring Beans. springboot 这么做是有意而为之。springboot 考虑到了如下的问题，我们在使用 springboot 时，开发阶段一般都是使用内嵌 tomcat 容器，但部署时却存在两种选择：一种是打成 jar 包，使用 java -jar 的方式运行；另一种是打成 war 包，交给外置容器去运行。前者就会导致容器搜索算法出现问题，因为这是 jar 包的运行策略，不会按照 servlet3.0 的策略去加载 ServletContainerInitializer！最后作者还提供了一个替代选项：ServletContextInitializer，注意是 ServletContextInitializer！它和 ServletContainerInitializer 长得特别像，别搞混淆了，前者 ServletContextInitializer 是 org.springframework.boot.web.servlet.ServletContextInitializer，后者 ServletContainerInitializer 是 javax.servlet.ServletContainerInitializer，前文还提到 RegistrationBean 实现了 ServletContextInitializer 接口。 TomcatStarter 中的 ServletContextInitializer 是关键TomcatStarter 中的 org.springframework.boot.context.embedded.ServletContextInitializer 是 springboot 初始化 servlet，filter，listener 的关键。 12345678910111213141516class TomcatStarter implements ServletContainerInitializer &#123; private final ServletContextInitializer[] initializers; TomcatStarter(ServletContextInitializer[] initializers) &#123; this.initializers = initializers; &#125; @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; classes, ServletContext servletContext) throws ServletException &#123; for (ServletContextInitializer initializer : this.initializers) &#123; initializer.onStartup(servletContext); &#125; &#125;&#125; 经过删减源码后，可以看出 TomcatStarter 的主要逻辑，它其实就是负责调用一系列 ServletContextInitializer 的 onStartup 方法，那么在 debug 中，ServletContextInitializer[] initializers 到底包含了哪些类呢？会不会有我们前面介绍的 RegisterBean 呢？ 太天真了，RegisterBean 并没有出现在 TomcatStarter 的 debug 信息中，initializers 只包含了三个类，其中只有第一个类看上去比较核心，注意第一个类不是 EmbeddedWebApplicationContext！而是这个类中的 $1 匿名类，为了搞清楚 springboot 如何加载 filter servlet listener ，看来还得研究下 EmbeddedWebApplicationContext 的结构。 EmbeddedWebApplicationContext 中的 6 层迭代加载ApplicationContext 大家应该是比较熟悉的，这是 spring 一个比较核心的类，一般我们可以从中获取到那些注册在容器中的托管 Bean，而这篇文章，主要分析的便是它在内嵌容器中的实现类：EmbeddedWebApplicationContext，重点分析它加载 filter servlet listener 这部分的代码。这里是整个代码中迭代层次最深的部分，做好心理准备起航，来看看 EmbeddedWebApplicationContext 是怎么获取到所有的 servlet filter listener 的！以下方法均出自于 EmbeddedWebApplicationContext。 第一层：onRefresh() onRefresh 是 ApplicationContext 的生命周期方法，EmbeddedWebApplicationContext 的实现非常简单，只干了一件事： 1234567891011@Overrideprotected void onRefresh() &#123; super.onRefresh(); try &#123; createEmbeddedServletContainer();// 第二层的入口 &#125; catch (Throwable ex) &#123; throw new ApplicationContextException(\"Unable to start embedded container\", ex); &#125;&#125; createEmbeddedServletContainer 连接到了第二层 第二层：createEmbeddedServletContainer() 看名字 spring 是想创建一个内嵌的 servlet 容器，ServletContainer 其实就是 servlet filter listener 的总称。 12345678910111213141516171819private void createEmbeddedServletContainer() &#123; EmbeddedServletContainer localContainer = this.embeddedServletContainer; ServletContext localServletContext = getServletContext(); if (localContainer == null &amp;&amp; localServletContext == null) &#123; EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer());// 第三层的入口 &#125; else if (localServletContext != null) &#123; try &#123; getSelfInitializer().onStartup(localServletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException(\"Cannot initialize servlet context\", ex); &#125; &#125; initPropertySources();&#125; 凡是带有 servlet，initializer 字样的方法都是我们需要留意的，getSelfInitializer() 便涉及到了我们最为关心的初始化流程。 第三层：getSelfInitializer() 123456789101112131415161718192021222324private org.springframework.boot.web.servlet.ServletContextInitializer getSelfInitializer() &#123; return new ServletContextInitializer() &#123; @Override public void onStartup(ServletContext servletContext) throws ServletException &#123; selfInitialize(servletContext); &#125; &#125;;&#125;private void selfInitialize(ServletContext servletContext) throws ServletException &#123; prepareEmbeddedWebApplicationContext(servletContext); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); ExistingWebApplicationScopes existingScopes = new ExistingWebApplicationScopes( beanFactory); WebApplicationContextUtils.registerWebApplicationScopes(beanFactory, getServletContext()); existingScopes.restore(); WebApplicationContextUtils.registerEnvironmentBeans(beanFactory, getServletContext()); // 第四层的入口 for (ServletContextInitializer beans : getServletContextInitializerBeans()) &#123; beans.onStartup(servletContext); &#125;&#125; 还记得前面 TomcatStarter 的 debug 信息中，第一个 ServletContextInitializer 就是出现在 EmbeddedWebApplicationContext 中的一个匿名类，没错了，就是这里的 getSelfInitializer()方法创建的！解释下这里的 getSelfInitializer() 和 selfInitialize(ServletContext servletContext) 为什么要这么设计：这是典型的回调式方式，当匿名 ServletContextInitializer 类被 TomcatStarter 的 onStartup 方法调用，设计上是触发了 selfInitialize(ServletContext servletContext) 的调用。所以这下就清晰了，为什么 TomcatStarter 中没有出现 RegisterBean ，其实是隐式触发了 EmbeddedWebApplicationContext 中的 selfInitialize 方法。selfInitialize 方法中的 getServletContextInitializerBeans() 成了关键。 第四层：getServletContextInitializerBeans() 12345678910/** * Returns &#123;@link ServletContextInitializer&#125;s that should be used with the embedded * Servlet context. By default this method will first attempt to find * &#123;@link ServletContextInitializer&#125;, &#123;@link Servlet&#125;, &#123;@link Filter&#125; and certain * &#123;@link EventListener&#125; beans. * @return the servlet initializer beans */protected Collection&lt;ServletContextInitializer&gt; getServletContextInitializerBeans() &#123; return new ServletContextInitializerBeans(getBeanFactory());// 第五层的入口&#125; 没错了，注释都告诉我们，这个 ServletContextInitializerBeans 是用来加载 Servlet 和 Filter 的。 第五层：ServletContextInitializerBeans 的构造方法 123456789101112public ServletContextInitializerBeans(ListableBeanFactory beanFactory) &#123; this.initializers = new LinkedMultiValueMap&lt;Class&lt;?&gt;, ServletContextInitializer&gt;(); addServletContextInitializerBeans(beanFactory);// 第六层的入口 addAdaptableBeans(beanFactory); List&lt;ServletContextInitializer&gt; sortedInitializers = new ArrayList&lt;ServletContextInitializer&gt;(); for (Map.Entry&lt;?, List&lt;ServletContextInitializer&gt;&gt; entry : this.initializers .entrySet()) &#123; AnnotationAwareOrderComparator.sort(entry.getValue()); sortedInitializers.addAll(entry.getValue()); &#125; this.sortedList = Collections.unmodifiableList(sortedInitializers);&#125; 第六层：addServletContextInitializerBeans(beanFactory) 1234567private void addServletContextInitializerBeans(ListableBeanFactory beanFactory) &#123; for (Entry&lt;String, ServletContextInitializer&gt; initializerBean : getOrderedBeansOfType( beanFactory, ServletContextInitializer.class)) &#123; addServletContextInitializerBean(initializerBean.getKey(), initializerBean.getValue(), beanFactory); &#125;&#125; getOrderedBeansOfType 方法便是去容器中寻找注册过得 ServletContextInitializer ，这时候就可以把之前那些 RegisterBean 全部加载出来了，并且 RegisterBean 还实现了 Ordered 接口，在这儿用于排序。不再往下迭代了。 EmbeddedWebApplicationContext 加载流程总结如果你对具体的代码流程不感兴趣，可以跳过上述的 6 层分析，直接看本节的结论。总结如下： EmbeddedWebApplicationContext 的 onRefresh 方法触发配置了一个匿名的 ServletContextInitializer。 这个匿名的 ServletContextInitializer 的 onStartup 方法会去容器中搜索到了所有的 RegisterBean 并按照顺序加载到 ServletContext 中。 这个匿名的 ServletContextInitializer 最终传递给 TomcatStarter，由 TomcatStarter 的 onStartup 方法去触发 ServletContextInitializer 的 onStartup 方法，最终完成装配！ 第三种注册 Servlet 的方式研究完了上述 springboot 启动的内部原理，可以发现 ServletContextInitializer 其实是 spring 中 ServletContainerInitializer 的代理，虽然 springboot 中 Servlet3.0 不起作用了，但它的代理还是会被加载的，于是我们有了第三种方式注册 servlet。 1234567891011121314151617181920212223242526@Configurationpublic class CustomServletContextInitializer implements ServletContextInitializer &#123; private final static String JAR_HELLO_URL = \"/hello\"; @Override public void onStartup(ServletContext servletContext) throws ServletException &#123; System.out.println(\"创建 helloWorldServlet...\"); ServletRegistration.Dynamic servlet = servletContext.addServlet( HelloWorldServlet.class.getSimpleName(), HelloWorldServlet.class); servlet.addMapping(JAR_HELLO_URL); System.out.println(\"创建 helloWorldFilter...\"); FilterRegistration.Dynamic filter = servletContext.addFilter( HelloWorldFilter.class.getSimpleName(), HelloWorldFilter.class); EnumSet&lt;DispatcherType&gt; dispatcherTypes = EnumSet.allOf(DispatcherType.class); dispatcherTypes.add(DispatcherType.REQUEST); dispatcherTypes.add(DispatcherType.FORWARD); filter.addMappingForUrlPatterns(dispatcherTypes, true, JAR_HELLO_URL); &#125;&#125; 虽然 ServletCantainerInitializer 不能被内嵌容器加载，ServletContextInitializer 却能被 springboot 的 EmbeddedWebApplicationContext 加载到，从而装配其中的 servlet 和 filter。实际开发中，还是以一，二两种方法来注册为主，这里只是提供一个可能性，来让我们理解 springboot 的加载流程。 加载流程拾遗 TomcatStarter 既然不是通过 SPI 机制装配的，那是怎么被 spring 使用的？ 自然是被 new 出来的，在 TomcatEmbeddedServletContainerFactory#configureContext 中可以看到，TomcatStarter 是被主动实例化出来的，并且还传入了 ServletContextInitializer 的数组，和上面分析的一样，一共有三个 ServletContextInitializer，包含了 EmbeddedWebApplicationContext 中的匿名实现。 1234567891011protected void configureContext(Context context, ServletContextInitializer[] initializers) &#123; TomcatStarter starter = new TomcatStarter(initializers); if (context instanceof TomcatEmbeddedContext) &#123; // Should be true ((TomcatEmbeddedContext) context).setStarter(starter); &#125; context.addServletContainerInitializer(starter, NO_CLASSES); ... &#125;&#125; TomcatEmbeddedServletContainerFactory 又是如何被声明的？ 123456789101112131415161718192021@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)public class EmbeddedServletContainerAutoConfiguration &#123; /** * Nested configuration if Tomcat is being used. */ @Configuration @ConditionalOnClass(&#123;Servlet.class, Tomcat.class&#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125;&#125; 只要类路径下存在 Tomcat 类，以及在 web 环境下，就会触发 springboot 的自动配置。 总结存在 web.xml 配置的 java web 项目，servlet3.0 的 java web 项目，springboot 内嵌容器的 java web 项目加载 servlet，filter，listener 的流程都是有所差异的，理解清楚这其中的原来，其实并不容易，至少得搞懂 servlet3.0 的规范，springboot 内嵌容器的加载流程等等前置逻辑。 最后感谢下小马哥的点拨，在此之前误以为： TomcatStarter 既然继承了 ServletContainerInitializer，应该也是符合 servlet3.0 规范的，但实际上并没有被 SPI 加载。 推荐阅读JAVA 拾遗 – 关于 SPI 机制 https://www.cnkirito.moe/spi/ 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Servlet","slug":"Servlet","permalink":"http://lexburner.github.io/tags/Servlet/"}]},{"title":"该如何设计你的 PasswordEncoder?","slug":"spring-security-6","date":"2018-04-23T14:44:34.000Z","updated":"2019-09-26T09:45:31.245Z","comments":true,"path":"spring-security-6/","link":"","permalink":"http://lexburner.github.io/spring-security-6/","excerpt":"缘起前端时间将一个集成了 spring-security-oauth2 的旧项目改造了一番，将 springboot 升级成了 springboot 2.0，众所周知 springboot 2.0 依赖的是 spring5，并且许多相关的依赖都发生了较大的改动，与本文相关的改动罗列如下，有兴趣的同学可以看看：Spring Security 5.0 New Features ，增强了 oauth2 集成的功能以及和一个比较有意思的改动—重构了密码编码器的实现（Password Encoding，由于大多数 PasswordEncoder 相关的算法是 hash 算法，所以本文将 PasswordEncoder 翻译成‘密码编码器’和并非‘密码加密器’）官方称之为 Modernized Password Encoding — 现代化的密码编码方式","text":"缘起前端时间将一个集成了 spring-security-oauth2 的旧项目改造了一番，将 springboot 升级成了 springboot 2.0，众所周知 springboot 2.0 依赖的是 spring5，并且许多相关的依赖都发生了较大的改动，与本文相关的改动罗列如下，有兴趣的同学可以看看：Spring Security 5.0 New Features ，增强了 oauth2 集成的功能以及和一个比较有意思的改动—重构了密码编码器的实现（Password Encoding，由于大多数 PasswordEncoder 相关的算法是 hash 算法，所以本文将 PasswordEncoder 翻译成‘密码编码器’和并非‘密码加密器’）官方称之为 Modernized Password Encoding — 现代化的密码编码方式另外，springboot2.0 的自动配置也做了一些调整，其中也有几点和 spring-security 相关，戳这里看所有细节 springboot2.0 迁移指南 一开始，我仅仅修改了依赖，将 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt;&lt;/parent&gt; 升级成了 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt; 不出意料出现了兼容性的问题，我在尝试登陆时，出现了如下的报错 1java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id \"null\" 原因也很明显，正如 spring security 的更新文档中描述的那样，spring security 5 对 PasswordEncoder 做了相关的重构，原先默认配置的 PlainTextPasswordEncoder（明文密码）被移除了。这引起了我的兴趣，spring security 在新版本中对于 passwordEncoder 进行了哪些改造，这些改造背后又是出于什么样的目的呢？卖个关子，先从远古时期的案例来一步步演化出所谓的“现代化密码编码方式”。 密码存储演进史自从互联网有了用户的那一刻起，存储用户密码这件事便成为了一个健全的系统不得不面对的一件事。远古时期，明文存储密码可能还不被认为是一个很大的系统缺陷（事实上这是一件很恐怖的事）。提及明文存储密码，我立刻联想到的是 CSDN 社区在 2011 年末发生的 600 万用户密码泄露的事件，谁也不会想到这个和程序员密切相关的网站会犯如此低级的错误。明文存储密码使得恶意用户可以通过 sql 注入等攻击方式来获取用户名和密码，虽然安全框架和良好的编码规范可以规避很多类似的攻击，但依旧避免不了系统管理员，DBA 有途径获取用户密码这一事实。事实上，不用明文存储存储密码，程序员们早在 n 多年前就已经达成了共识。 不能明文存储，一些 hash 算法便被广泛用做密码的编码器，对密码进行单向 hash 处理后存储数据库，当用户登录时，计算用户输入的密码的 hash 值，将两者进行比对。单向 hash 算法，顾名思义，它无法（或者用不能轻易更为合适）被反向解析还原出原密码。这杜绝了管理员直接获取密码的途径，可仅仅依赖于普通的 hash 算法（如 md5，sha256）是不合适的，他主要有 3 个特点： 同一密码生成的 hash 值一定相同 不同密码的生成的 hash 值可能相同（md5 的碰撞问题相比 sha256 还要严重） 计算速度快。 以上三点结合在一起，破解此类算法成了不是那么困难的一件事，尤其是第三点，会在下文中再次提到，多快才算非常快？按照相关资料的说法： modern hardware perform billions of hash calculations a second. 考虑到大多数用户使用的密码多为数字 + 字母 + 特殊符号的组合，攻击者将常用的密码进行枚举，甚至通过排列组合来暴力破解，这被称为 rainbow table。算法爱好者能够立刻看懂到上述的方案，这被亲切地称之为—打表，一种暴力美学，这张表是可以被复用的。 虽然仅仅依赖于传统 hash 算法的思路被否决了，但这种 hash 后比对的思路，几乎被后续所有的优化方案继承。 hash 方案迎来的第一个改造是对引入一个“随机的因子”来掺杂进明文中进行 hash 计算，这样的随机因子通常被称之为盐 （salt）。salt 一般是用户相关的，每个用户持有各自的 salt。此时狗蛋和二丫的密码即使相同，由于 salt 的影响，存储在数据库中的密码也是不同的，除非…为每个用户单独建议一张 rainbow table。很明显 salted hash 相比普通的单向 hash 方案加大了 hacker 攻击的难度。但了解过 GPU 并行计算能力之强大的童鞋，都能够意识到，虽然破解 salted hash 比较麻烦，却并非不可行，勤劳勇敢的安全专家似乎也对这个方案不够满意。 为解决上述 salted hash 仍然存在的问题，一些新型的单向 hash 算法被研究了出来。其中就包括：Bcrypt，PBKDF2，Scrypt，Argon2。为什么这些 hash 算法能保证密码存储的安全性？因为他们足够慢，恰到好处的慢。这么说不严谨，只是为了给大家留个深刻的映像：慢。这类算法有一个特点，存在一个影响因子，可以用来控制计算强度，这直接决定了破解密码所需要的资源和时间，直观的体会可以见下图，在一年内破解如下算法所需要的硬件资源花费（折算成美元） 这使得破解成了一件极其困难的事，并且，其中的计算强度因子是可控的，这样，即使未来量子计算机的计算能力爆表，也可以通过其控制计算强度以防破解。注意，普通的验证过程只需要计算一次 hash 计算，使用此类 hash 算法并不会影响到用户体验。 慢 hash 算法真的安全吗？Bcrypt，Scrypt，PBKDF2 这些慢 hash 算法是目前最为推崇的 password encoding 方式，好奇心驱使我思考了这样一个问题：慢 hash 算法真的安全吗？ 我暂时还没有精力仔细去研究他们中每一个算法的具体实现，只能通过一些文章来拾人牙慧，简单看看这几个算法的原理和安全性。 PBKDF2 被设计的很简单，它的基本原理是通过一个伪随机函数（例如 HMAC 函数），把明文和一个盐值作为输入参数，然后按照设置的计算强度因子重复进行运算，并最终产生密钥。这样的重复 hash 已经被认为足够安全，但也有人提出了不同意见，此类算法对于传统的 CPU 来说的确是足够安全，但 GPU 被搬了出来，前文提到过 GPU 的并行计算能力非常强大。 Bcrypt 强大的一点在于，其不仅仅是 CPU 密集型，还是 RAM 密集型！双重的限制因素，导致 GPU，ASIC（专用集成电路）无法应对 Bcrypt 带来的破解困境。 然后…看了 Scrypt 的相关资料之后我才意识到这个坑有多深。一个熟悉又陌生的词出现在了我面前：FPGA（现场可编程逻辑门阵列），这货就比较厉害了。现成的芯片指令结构如传统的 CPU，GPU，ASIC 都无法破解 Bcrypt，但是 FPGA 支持烧录逻辑门（如 AND、OR、XOR、NOT），通过编程的方式烧录指令集的这一特性使得可以定制硬件来破解 Bcrypt。尽管我不认为懂这个技术的人会去想办法破解真正的系统，但，只要这是一个可能性，就总有方法会被发明出来与之对抗。Scrypt 比 Bcrypt 额外考虑到的就是大规模的 自定义硬件攻击 ，从而刻意设计需要大量内存运算。 理论终归是理论，实际上 Bcrypt 算法被发明至今 18 年，使用范围广，且从未因为安全问题而被修改，其有限性是已经被验证过的，相比之下 Scrypt 据我看到的文章显示是 9 年的历史，没有 Bcrypt 使用的广泛。从破解成本和权威性的角度来看，Bcrypt 用作密码编码器是不错的选择。 spring security 废弃的接口回到文档中，spring security 5 对 PasswordEncoder 做了相关的重构，原先默认配置的 PlainTextPasswordEncoder（明文密码）被移除了，想要做到明文存储密码，只能使用一个过期的类来过渡 1234@BeanPasswordEncoder passwordEncoder()&#123; return NoOpPasswordEncoder.getInstance();&#125; 实际上，spring security 提供了 BCryptPasswordEncoder 来进行密码编码，并作为了相关配置的默认配置，只不过没有暴露为全局的 Bean。使用明文存储的风险在文章一开始就已经强调过，NoOpPasswordEncoder 只能存在于 demo 中。 1234@BeanPasswordEncoder passwordEncoder()&#123; return new BCryptPasswordEncoder();&#125; 别忘了对你数据库中的密码进行同样的编码，否则无法对应。 更深层的思考实际上，spring security 5 的另一个设计是促使我写成本文的初衷。 不知道有没有读者产生跟我相同的困扰： 如果我要设计一个 QPS 很高的登录系统，使用 spring security 推荐的 BCrypt 会不会存在性能问题？ spring security 怎么这么坑，原来的密码编码器都给改了，我需要怎么迁移旧密码编码的应用程序？ 万一以后出了更高效的加密算法，这种笨重的硬编码方式配置密码编码器是不是不够灵活？ 在 spring security 5 提供了这样一个思路，应该将密码编码之后的 hash 值和加密方式一起存储，并提供了一个 DelegatingPasswordEncoder 来作为众多密码密码编码方式的集合。 1234@BeanPasswordEncoder passwordEncoder()&#123; return PasswordEncoderFactories.createDelegatingPasswordEncoder();&#125; 负责生产 DelegatingPasswordEncoder 的工厂方法： 123456789101112131415161718192021public class PasswordEncoderFactories &#123; public static PasswordEncoder createDelegatingPasswordEncoder() &#123; String encodingId = \"bcrypt\"; Map&lt;String, PasswordEncoder&gt; encoders = new HashMap&lt;&gt;(); encoders.put(encodingId, new BCryptPasswordEncoder()); encoders.put(\"ldap\", new LdapShaPasswordEncoder()); encoders.put(\"MD4\", new Md4PasswordEncoder()); encoders.put(\"MD5\", new MessageDigestPasswordEncoder(\"MD5\")); encoders.put(\"noop\", NoOpPasswordEncoder.getInstance()); encoders.put(\"pbkdf2\", new Pbkdf2PasswordEncoder()); encoders.put(\"scrypt\", new SCryptPasswordEncoder()); encoders.put(\"SHA-1\", new MessageDigestPasswordEncoder(\"SHA-1\")); encoders.put(\"SHA-256\", new MessageDigestPasswordEncoder(\"SHA-256\")); encoders.put(\"sha256\", new StandardPasswordEncoder()); return new DelegatingPasswordEncoder(encodingId, encoders); &#125; private PasswordEncoderFactories()&#123;&#125;&#125; 如此注入 PasswordEncoder 之后，我们在数据库中需要这么存储数据： 12345&#123;bcrypt&#125;$2a$10$dXJ3SW6G7P50lGmMkkmwe.20cQQubK3.HZWzG3YB1tlRy.fqvM/BG &#123;noop&#125;password &#123;pbkdf2&#125;5d923b44a6d129f3ddf3e3c8d29412723dcbde72445e8ef6bf3b508fbf17fa4ed4d6b99ca763d8dc &#123;scrypt&#125;$e0801$8bWJaSu2IKSn9Z9kM+TPXfOc/9bdYSrN1oD9qfVThWEwdRTnO7re7Ei+fUZRJ68k9lTyuTeUp4of4g24hHnazw==$OAOec05+bXxvuu/1qZ6NUR+xQYvYv7BeL1QxwRpY5Pc= &#123;sha256&#125;97cde38028ad898ebc02e690819fa220e88c62e0699403e94fff291cfffaf8410849f27605abcbc0 还记得文章开始的报错吗？ 1java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id \"null\" 这个 id 就是因为我们没有为数据库中的密码添加 {bcrypt} 此类的前缀导致的。 你会不会担心密码泄露后，{bcrypt}，{pbkdf2}，{scrypt}，{sha256} 此类前缀会直接暴露密码的编码方式？其实这个考虑是多余的，因为密码存储的依赖算法并不是一个秘密。大多数能搞到你密码的 hacker 都可以轻松的知道你用的是什么算法，例如，bcrypt 算法通常以 \\$2a$ 开头 稍微思考下，前面的三个疑问就可以迎刃而解，这就是文档中所谓的： 能够自适应服务器性能的现代化密码编码方案 。 参考Password Hashing: PBKDF2, Scrypt, Bcrypt core-services-password-encoding show me the codespring security oauth2 的 github 代码示例，体会下 spring security 4 -&gt; spring security 5 的相关变化。 https://github.com/lexburner/oauth2-demo 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/categories/Spring-Security/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/tags/Spring-Security/"}]},{"title":"理解 JWT 的使用场景和优劣","slug":"jwt-learn-3","date":"2018-04-20T14:57:45.000Z","updated":"2019-10-10T08:54:55.359Z","comments":true,"path":"jwt-learn-3/","link":"","permalink":"http://lexburner.github.io/jwt-learn-3/","excerpt":"经过前面两篇文章《JSON Web Token - 在 Web 应用间安全地传递信息》《八幅漫画理解使用 JSON Web Token 设计单点登录系统》的科普，相信大家应该已经知道了 JWT 协议是什么了。至少看到","text":"经过前面两篇文章《JSON Web Token - 在 Web 应用间安全地传递信息》《八幅漫画理解使用 JSON Web Token 设计单点登录系统》的科普，相信大家应该已经知道了 JWT 协议是什么了。至少看到 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJxaWFubWlJZCI6InFtMTAzNTNzaEQiLCJpc3MiOiJhcHBfcW0xMDM1M3NoRCIsInBsYXRmb3JtIjoiYXBwIn0.cMNwyDTFVYMLL4e7ts50GFHTvlSJLDpePtHXzu7z9j4 这样形如 A.B.C 的字符串时能敏感地认出这是使用了 jwt。发了这两篇文章后，有不少读者在文末留言，表达了对 jwt 使用方式的一些疑惑，以及到底哪些场景适合使用 jwt。我并不是 jwt 方面的专家，和不少读者一样，起初研究时我也存在相同疑惑，甚至在逐渐接触后产生了更大的疑惑，经过这段时间项目中的使用和一些自己思考，把个人的总结整理成此文。 编码，签名，加密这些基础知识简单地介绍下，千万别搞混了三个概念。在 jwt 中恰好同时涉及了这三个概念，笔者用大白话来做下通俗的讲解（非严谨定义，供个人理解） 编码 (encode) 和解码(decode)一般是编码解码是为了方便以字节的方式表示数据，便于存储和网络传输。整个 jwt 串会被置于 http 的 Header 或者 url 中，为了不出现乱码解析错误等意外，编码是有必要的。在 jwt 中以 . 分割的三个部分都经过 base64 编码 (secret 部分是否进行 base64 编码是可选的，header 和 payload 则是必须进行 base64 编码)。注意，编码的一个特点：编码和解码的整个过程是可逆的。得知编码方式后，整个 jwt 串便是明文了，随意找个网站验证下解码后的内容： 所以注意一点，payload 是一定不能够携带敏感数据如密码等信息的 。 签名 (signature)签名的目的主要是为了验证我是“我”。jwt 中常用的签名算法是 HS256，可能大多数人对这个签名算法不熟悉，但 md5,sha 这样的签名算法肯定是为人熟知的，签名算法共同的特点是整个过程是不可逆的。由于签名之前的主体内容 (header,payload) 会携带在 jwt 字符串中，所以需要使用带有密钥 (yuè) 的签名算法，密钥是服务器和签发者共享的。header 部分和 payload 部分如果被篡改，由于篡改者不知道密钥是什么，也无法生成新的 signature 部分，服务端也就无法通过，在 jwt 中，消息体是透明的，使用签名可以保证消息不被篡改。 前面转载的文章中，原作者将 HS256 称之为加密算法，不太严谨。 加密 (encryption)加密是将明文信息改变为难以读取的密文内容，使之不可读。只有拥有解密方法的对象，经由解密过程，才能将密文还原为正常可读的内容。加密算法通常按照加密方式的不同分为对称加密 (如 AES) 和非对称加密(如 RSA)。你可能会疑惑：“jwt 中哪儿涉及加密算法了？”，其实 jwt 的 第一部分(header) 中的 alg 参数便可以指定不同的算法来生成第三部分(signature)，大部分支持 jwt 的框架至少都内置 rsa 这种非对称加密方式。这里诞生了第一个疑问 疑问：一提到 rsa，大多数人第一想到的是非对称加密算法，而 jwt 的第三部分明确的英文定义是 signature，这不是矛盾吗？ 划重点！ rsa 加密 和 rsa 签名 是两个概念！(吓得我都换行了) 这两个用法很好理解： 既然是加密，自然是不希望别人知道我的消息，只有我自己才能解密，所以 公钥负责加密，私钥负责解密 。这是大多数的使用场景，使用 rsa 来加密。 既然是签名，自然是希望别人不能冒充我发消息，只有我才能发布签名，所以 私钥负责签名，公钥负责验证 。 所以，在客户端使用 rsa 算法生成 jwt 串时，是使用私钥来“加密”的，而公钥是公开的，谁都可以解密，内容也无法变更（篡改者无法得知私钥）。 所以，在 jwt 中并没有纯粹的加密过程，而是使加密之虚，行签名之实。 什么场景该适合使用 jwt？来聊聊几个场景，注意，以下的几个场景不是都和 jwt 贴合。 一次性验证 比如用户注册后需要发一封邮件让其激活账户，通常邮件中需要有一个链接，这个链接需要具备以下的特性：能够标识用户，该链接具有时效性（通常只允许几小时之内激活），不能被篡改以激活其他可能的账户…这种场景就和 jwt 的特性非常贴近，jwt 的 payload 中固定的参数：iss 签发者和 exp 过期时间正是为其做准备的。 restful api 的无状态认证 使用 jwt 来做 restful api 的身份认证也是值得推崇的一种使用方案。客户端和服务端共享 secret；过期时间由服务端校验，客户端定时刷新；签名信息不可被修改…spring security oauth jwt 提供了一套完整的 jwt 认证体系，以笔者的经验来看：使用 oauth2 或 jwt 来做 restful api 的认证都没有大问题，oauth2 功能更多，支持的场景更丰富，后者实现简单。 使用 jwt 做单点登录 + 会话管理 (不推荐) 在《八幅漫画理解使用 JSON Web Token 设计单点登录系统》一文中提及了使用 jwt 来完成单点登录，本文接下来的内容主要就是围绕这一点来进行讨论。如果你正在考虑使用 jwt+cookie 代替 session+cookie ，我强力不推荐你这么做。 首先明确一点：使用 jwt 来设计单点登录系统是一个不太严谨的说法。首先 cookie+jwt 的方案前提是非跨域的单点登录 (cookie 无法被自动携带至其他域名)，其次单点登录系统包含了很多技术细节，至少包含了身份认证和会话管理，这还不涉及到权限管理。如果觉得比较抽象，不妨用传统的 session+cookie 单点登录方案来做类比，通常我们可以选择 spring security（身份认证和权限管理的安全框架）和 spring session（session 共享）来构建，而选择用 jwt 设计单点登录系统需要解决很多传统方案中同样存在和本不存在的问题，以下一一详细罗列。 jwt token 泄露了怎么办？前面的文章下有不少人留言提到这个问题，我则认为这不是问题。传统的 session+cookie 方案，如果泄露了 sessionId，别人同样可以盗用你的身份。扬汤止沸不如釜底抽薪，不妨来追根溯源一下，什么场景会导致你的 jwt 泄露。 遵循如下的实践可以尽可能保护你的 jwt 不被泄露：使用 https 加密你的应用，返回 jwt 给客户端时设置 httpOnly=true 并且使用 cookie 而不是 LocalStorage 存储 jwt，这样可以防止 XSS 攻击和 CSRF 攻击（对这两种攻击感兴趣的童鞋可以看下 spring security 中对他们的介绍 CSRF,XSS） 你要是正在使用 jwt 访问一个接口，这个时候你的同事跑过来把你的 jwt 抄走了，这种泄露，恕在下无力 secret 如何设计jwt 唯一存储在服务端的只有一个 secret，个人认为这个 secret 应该设计成和用户相关的，而不是一个所有用户公用的统一值。这样可以有效的避免一些注销和修改密码时遇到的窘境。 注销和修改密码传统的 session+cookie 方案用户点击注销，服务端清空 session 即可，因为状态保存在服务端。但 jwt 的方案就比较难办了，因为 jwt 是无状态的，服务端通过计算来校验有效性。没有存储起来，所以即使客户端删除了 jwt，但是该 jwt 还是在有效期内，只不过处于一个游离状态。分析下痛点：注销变得复杂的原因在于 jwt 的无状态。我提供几个方案，视具体的业务来决定能不能接受。 仅仅清空客户端的 cookie，这样用户访问时就不会携带 jwt，服务端就认为用户需要重新登录。这是一个典型的假注销，对于用户表现出退出的行为，实际上这个时候携带对应的 jwt 依旧可以访问系统。 清空或修改服务端的用户对应的 secret，这样在用户注销后，jwt 本身不变，但是由于 secret 不存在或改变，则无法完成校验。这也是为什么将 secret 设计成和用户相关的原因。 借助第三方存储自己管理 jwt 的状态，可以以 jwt 为 key，实现去 redis 一类的缓存中间件中去校验存在性。方案设计并不难，但是引入 redis 之后，就把无状态的 jwt 硬生生变成了有状态了，违背了 jwt 的初衷。实际上这个方案和 session 都差不多了。 修改密码则略微有些不同，假设号被到了，修改密码（是用户密码，不是 jwt 的 secret）之后，盗号者在原 jwt 有效期之内依旧可以继续访问系统，所以仅仅清空 cookie 自然是不够的，这时，需要强制性的修改 secret。在我的实践中就是这样做的。 续签问题续签问题可以说是我抵制使用 jwt 来代替传统 session 的最大原因，因为 jwt 的设计中我就没有发现它将续签认为是自身的一个特性。传统的 cookie 续签方案一般都是框架自带的，session 有效期 30 分钟，30 分钟内如果有访问，session 有效期被刷新至 30 分钟。而 jwt 本身的 payload 之中也有一个 exp 过期时间参数，来代表一个 jwt 的时效性，而 jwt 想延期这个 exp 就有点身不由己了，因为 payload 是参与签名的，一旦过期时间被修改，整个 jwt 串就变了，jwt 的特性天然不支持续签！ 如果你一定要使用 jwt 做会话管理（payload 中存储会话信息），也不是没有解决方案，但个人认为都不是很令人满意 每次请求刷新 jwt jwt 修改 payload 中的 exp 后整个 jwt 串就会发生改变，那…就让它变好了，每次请求都返回一个新的 jwt 给客户端。太暴力了，不用我赘述这样做是多么的不优雅，以及带来的性能问题。 但，至少这是最简单的解决方案。 只要快要过期的时候刷新 jwt 一个上述方案的改造点是，只在最后的几分钟返回给客户端一个新的 jwt。这样做，触发刷新 jwt 基本就要看运气了，如果用户恰巧在最后几分钟访问了服务器，触发了刷新，万事大吉；如果用户连续操作了 27 分钟，只有最后的 3 分钟没有操作，导致未刷新 jwt，无疑会令用户抓狂。 完善 refreshToken 借鉴 oauth2 的设计，返回给客户端一个 refreshToken，允许客户端主动刷新 jwt。一般而言，jwt 的过期时间可以设置为数小时，而 refreshToken 的过期时间设置为数天。 我认为该方案并可行性是存在的，但是为了解决 jwt 的续签把整个流程改变了，为什么不考虑下 oauth2 的 password 模式和 client 模式呢？ 使用 redis 记录独立的过期时间 实际上我的项目中由于历史遗留问题，就是使用 jwt 来做登录和会话管理的，为了解决续签问题，我们在 redis 中单独会每个 jwt 设置了过期时间，每次访问时刷新 jwt 的过期时间，若 jwt 不存在与 redis 中则认为过期。 tips: 精确控制 redis 的过期时间不是件容易的事，可以参考我最近的一篇借助于 spring session 讲解 redis 过期时间的排坑记录。 同样改变了 jwt 的流程，不过嘛，世间安得两全法。我只能奉劝各位还未使用 jwt 做会话管理的朋友，尽量还是选用传统的 session+cookie 方案，有很多成熟的分布式 session 框架和安全框架供你开箱即用。 jwt,oauth2,session 千丝万缕的联系具体的对比不在此文介绍，就一位读者的留言回复下它的提问 这么长一个字符串，还不如我把数据存到数据库，给一个长的很难碰撞的 key 来映射，也就是专用 token。 这位兄弟认为 jwt 太长了，是不是可以考虑使用和 oauth2 一样的 uuid 来映射。这里面自然是有问题的，jwt 不仅仅是作为身份的认证（验证签名是否正确，签发者是否存在，有限期是否过期），还在其 payload 中存储着会话信息，这是 jwt 和 session 的最大区别，一个在客户端携带会话信息，一个在服务端存储会话信息。如果真的是要将 jwt 的信息置于在共享存储中，那再找不到任何使用 jwt 的意义了。 jwt 和 oauth2 都可以用于 restful 的认证，就我个人的使用经验来看，spring security oauth2 可以很好的使用多种认证模式：client 模式，password 模式，implicit 模式（authorization code 模式不算单纯的接口认证模式），也可以很方便的实现权限控制，什么样的 api 需要什么样的权限，什么样的资源需要什么样的 scope…而 jwt 我只用它来实现过身份认证，功能较为单一（可能是我没发现更多用法）。 总结在 web 应用中，使用 jwt 代替 session 存在不小的风险，你至少得解决本文中提及的那些问题，绝大多数情况下，传统的 cookie-session 机制工作得更好。jwt 适合做简单的 restful api 认证，颁发一个固定有效期的 jwt，降低 jwt 暴露的风险，不要对 jwt 做服务端的状态管理，这样才能体现出 jwt 无状态的优势。 可能对 jwt 的使用场景还有一些地方未被我察觉，后续会研究下 spring security oauth jwt 的源码，不知到时会不会有新发现。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JWT","slug":"JWT","permalink":"http://lexburner.github.io/categories/JWT/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"http://lexburner.github.io/tags/JWT/"}]},{"title":"从 Spring-Session 源码看 Session 机制的实现细节","slug":"spring-session-4","date":"2018-04-17T12:57:43.000Z","updated":"2019-09-26T09:45:31.323Z","comments":true,"path":"spring-session-4/","link":"","permalink":"http://lexburner.github.io/spring-session-4/","excerpt":"去年我曾经写过几篇和 Spring Session 相关的文章，从一个未接触过 Spring Session 的初学者视角介绍了 Spring Session 如何上手，如果你未接触过 Spring Session，推荐先阅读下「从零开始学习 Spring Session」系列（https://www.cnkirito.moe/categories/Spring-Session/） Spring Session 主要解决了分布式场景下 Session 的共享问题，本文将从 Spring Session 的源码出发，来讨论一些 Session 设计的细节。","text":"去年我曾经写过几篇和 Spring Session 相关的文章，从一个未接触过 Spring Session 的初学者视角介绍了 Spring Session 如何上手，如果你未接触过 Spring Session，推荐先阅读下「从零开始学习 Spring Session」系列（https://www.cnkirito.moe/categories/Spring-Session/） Spring Session 主要解决了分布式场景下 Session 的共享问题，本文将从 Spring Session 的源码出发，来讨论一些 Session 设计的细节。 Spring Session 数据结构解读想象一个场景，现在一到面试题呈现在你面前，让你从零开始设计一个 Session 存储方案，你会怎么回答？ 说白了就是让你设计一套数据结构存储 Session，并且我相信提出这个问题时，大多数读者脑海中会浮现出 redis，设计一个 map，使用 ttl 等等，但没想到的细节可能会更多。先来预览一下 Spring Session 的实际数据结构是什么样的（使用 spring-session-redis 实现），当我们访问一次集成了 Spring Session 的 web 应用时 12345@RequestMapping(\"/helloworld\")public String hello(HttpSession session)&#123; session.setAttribute(\"name\",\"xu\"); return \"hello.html\";&#125; 可以在 Redis 中看到如下的数据结构： 12345A) &quot;spring:session:sessions:39feb101-87d4-42c7-ab53-ac6fe0d91925&quot;B) &quot;spring:session:expirations:1523934840000&quot;C) &quot;spring:session:sessions:expires:39feb101-87d4-42c7-ab53-ac6fe0d91925&quot; 这三种键职责的分析将会贯彻全文，为了统一叙述，在此将他们进行编号，后续简称为 A 类型键，B 类型键，C 类型键。先简单分析下他们的特点 他们公用的前缀是 spring:session A 类型键的组成是前缀 +”sessions”+sessionId，对应的值是一个 hash 数据结构。在我的 demo 中，其值如下 123456&#123; \"lastAccessedTime\": 1523933008926,/*2018/4/17 10:43:28*/ \"creationTime\": 1523933008926, /*2018/4/17 10:43:28*/ \"maxInactiveInterval\": 1800, \"sessionAttr:name\": \"xu\"&#125; 其中 creationTime（创建时间），lastAccessedTime（最后访问时间），maxInactiveInterval（session 失效的间隔时长） 等字段是系统字段，sessionAttr:xx 可能会存在多个键值对，用户存放在 session 中的数据如数存放于此。 A 类型键对应的默认 TTL 是 35 分钟。 B 类型键的组成是前缀 +”expirations”+ 时间戳，无需纠结这个时间戳的含义，先卖个关子。其对应的值是一个 set 数据结构，这个 set 数据结构中存储着一系列的 C 类型键。在我的 demo 中，其值如下 123[ \"expires:39feb101-87d4-42c7-ab53-ac6fe0d91925\"] B 类型键对应的默认 TTL 是 30 分钟 C 类型键的组成是前缀 +”sessions:expires”+sessionId，对应一个空值，它仅仅是 sessionId 在 redis 中的一个引用，具体作用继续卖关子。 C 类型键对应的默认 TTL 是 30 分钟。 kirito-session 的天使轮方案介绍完 Spring Session 的数据结构，我们先放到一边，来看看如果我们自己设计一个 Session 方案，拟定为 kirito-session 吧，该如何设计。 kirito 的心路历程是这样的：“使用 redis 存 session 数据，对，session 需要有过期机制，redis 的键可以自动过期，肯定很方便。” 于是 kirito 设计出了 spring-session 中的 A 类型键，复用它的数据结构： 123456&#123; \"lastAccessedTime\": 1523933008926, \"creationTime\": 1523933008926, \"maxInactiveInterval\": 1800, key/value...&#125; 然后对 A 类型的键设置 ttl A 30 分钟，这样 30 分钟之后 session 过期，0-30 分钟期间如果用户持续操作，那就根据 sessionId 找到 A 类型的 key，刷新 lastAccessedTime 的值，并重新设置 ttl，这样就完成了「续签」的特性。 显然 Spring Session 没有采用如此简练的设计，为什么呢？翻看 Spring Session 的文档 One problem with relying on Redis expiration exclusively is that Redis makes no guarantee of when the expired event will be fired if the key has not been accessed. Specifically the background task that Redis uses to clean up expired keys is a low priority task and may not trigger the key expiration. For additional details see Timing of expired events section in the Redis documentation. 大致意思是说，redis 的键过期机制不“保险”，这和 redis 的设计有关，不在此拓展开，研究这个的时候翻了不少资料，得出了如下的总结： redis 在键实际过期之后不一定会被删除，可能会继续存留，但具体存留的时间我没有做过研究，可能是 1~2 分钟，可能会更久。 具有过期时间的 key 有两种方式来保证过期，一是这个键在过期的时候被访问了，二是后台运行一个定时任务自己删除过期的 key。划重点： 这启发我们在 key 到期后只需要访问一下 key 就可以确保 redis 删除该过期键 如果没有指令持续关注 key，并且 redis 中存在许多与 TTL 关联的 key，则 key 真正被删除的时间将会有显著的延迟！显著的延迟！显著的延迟！ 天使轮计划惨遭破产，看来单纯依赖于 redis 的过期时间是不可靠的，秉持着力求严谨的态度，迎来了 A 轮改造。 A 轮改造—引入 B 类型键确保 session 的过期机制redis 的官方文档启发我们，可以启用一个后台定时任务，定时去删除那些过期的键，配合上 redis 的自动过期，这样可以双重保险。第一个问题来了，我们将这些过期键存在哪儿呢？不找个合适的地方存起来，定时任务到哪儿去删除这些应该过期的键呢？总不能扫描全库吧！来解释我前面卖的第一个关子，看看 B 类型键的特点： 1spring:session:expirations:1523934840000 时间戳的含义1523934840000 这明显是个 Unix 时间戳，它的含义是存放着这一分钟内应该过期的键，所以它是一个 set 数据结构。解释下这个时间戳是怎么计算出来的 org.springframework.session.data.redis.RedisSessionExpirationPolicy#roundUpToNextMinute 12345678static long roundUpToNextMinute(long timeInMs) &#123; Calendar date = Calendar.getInstance(); date.setTimeInMillis(timeInMs); date.add(Calendar.MINUTE, 1); date.clear(Calendar.SECOND); date.clear(Calendar.MILLISECOND); return date.getTimeInMillis(); &#125; 还记得 lastAccessedTime=1523933008926，maxInactiveInterval=1800 吧，lastAccessedTime 转换成北京时间是: 2018/4/17 10:43:28，向上取整是 2018/4/17 10:44:00，再次转换为 Unix 时间戳得到 1523932980000，单位是 ms，1800 是过期时间的间隔，单位是 s，二者相加 1523932980000+1800*1000=1523934840000。这样 B 类型键便作为了一个「桶」，存放着这一分钟应当过期的 session 的 key。 后台定时任务org.springframework.session.data.redis.RedisSessionExpirationPolicy#cleanupExpiredSessions 1234@Scheduled(cron = \"$&#123;spring.session.cleanup.cron.expression:0 * * * * *&#125;\")public void cleanupExpiredSessions() &#123; this.expirationPolicy.cleanExpiredSessions();&#125; 后台提供了定时任务去“删除”过期的 key，来补偿 redis 到期未删除的 key。方案再描述下，方便大家理解：取得当前时间的时间戳作为 key，去 redis 中定位到 spring:session:expirations:{当前时间戳} ，这个 set 里面存放的便是所有过期的 key 了。 续签的影响每次 session 的续签，需要将旧桶中的数据移除，放到新桶中。验证这一点很容易。 在第一分钟访问一次 http://localhost:8080/helloworld 端点，得到的 B 类型键为：spring:session:expirations:1523934840000；第二分钟再访问一次 http://localhost:8080/helloworld 端点，A 类型键的 lastAccessedTime 得到更新，并且 spring:session:expirations:1523934840000 这个桶被删除了，新增了 spring:session:expirations:1523934900000 这个桶。当众多用户活跃时，桶的增删和以及 set 中数据的增删都是很频繁的。对了，没提到的一点，对应 key 的 ttl 时间也会被更新。 kirito-session 方案貌似比之前严谨了，目前为止使用了 A 类型键和 B 类型键解决了 session 存储和 redis 键到期不删除的两个问题，但还是存在问题的。 B 轮改造—优雅地解决 B 类型键的并发问题引入 B 类型键看似解决了问题，却也引入了一个新的问题：并发问题。 来看看一个场景： 假设存在一个 sessionId=1 的会话，初始时间戳为 1420656360000 12spring:session:expirations:1420656360000 -&gt; [1]spring:session:session:1 -&gt; &lt;session&gt; 接下来迎来了并发访问，（用户可能在浏览器中多次点击）： 线程 1 在第 2 分钟请求，产生了续签，session:1 应当从 1420656360000 这个桶移动到 142065642000 这个桶 线程 2 在第 3 分钟请求，也产生了续签，session:1 本应当从 1420656360000 这个桶移动到 142065648000 这个桶 如果上两步按照次序执行，自然不会有问题。但第 3 分钟的请求可能已经执行完毕了，第 2 分钟才刚开始执行。 像下面这样： 线程 2 从第一分钟的桶中移除 session:1，并移动到第三分钟的桶中 123spring:session:expirations:1420656360000 -&gt; []spring:session:session:1 -&gt; &lt;session&gt;spring:session:expirations:1420656480000 -&gt; [1] 线程 1 完成相同的操作，它也是基于第一分钟来做的，但会移动到第二分钟的桶中 123spring:session:expirations:1420656360000 -&gt; []spring:session:session:1 -&gt; &lt;session&gt;spring:session:expirations:1420656420000 -&gt; [1] 最后 redis 中键的情况变成了这样： 1234spring:session:expirations:1420656360000 -&gt; []spring:session:session:1 -&gt; &lt;session&gt;spring:session:expirations:1420656480000 -&gt; [1]spring:session:expirations:1420656420000 -&gt; [1] 后台定时任务会在第 32 分钟扫描到 spring:session:expirations:1420656420000 桶中存在的 session，这意味着，本应该在第 33 分钟才会过期的 key，在第 32 分钟就会被删除！ 一种简单的方法是用户的每次 session 续期加上分布式锁，这显然不能被接受。来看看 Spring Session 是怎么巧妙地应对这个并发问题的。 org.springframework.session.data.redis.RedisSessionExpirationPolicy#cleanExpiredSessions 1234567891011121314151617181920212223242526272829303132public void cleanExpiredSessions() &#123; long now = System.currentTimeMillis(); long prevMin = roundDownMinute(now); if (logger.isDebugEnabled()) &#123; logger.debug(\"Cleaning up sessions expiring at\" + new Date(prevMin)); &#125; // 获取到 B 类型键 String expirationKey = getExpirationKey(prevMin); // 取出当前这一分钟应当过期的 session Set&lt;Object&gt; sessionsToExpire = this.redis.boundSetOps(expirationKey).members(); // 注意：这里删除的是 B 类型键，不是删除 session 本身！ this.redis.delete(expirationKey); for (Object session : sessionsToExpire) &#123; String sessionKey = getSessionKey((String) session); // 遍历一下 C 类型的键 touch(sessionKey); &#125;&#125;/** * By trying to access the session we only trigger a deletion if it the TTL is * expired. This is done to handle * https://github.com/spring-projects/spring-session/issues/93 * * @param key the key */private void touch(String key) &#123; // 并不是删除 key，而只是访问 key this.redis.hasKey(key);&#125; 这里面逻辑主要是拿到过期键的集合（实际上是 C 类型的 key，但这里可以理解为 sessionId，C 类型我下面会介绍），此时这个集合里面存在三种类型的 sessionId。 已经被 redis 删除的过期键。万事大吉，redis 很靠谱的及时清理了过期的键。 已经过期，但是还没来得及被 redis 清除的 key。还记得前面 redis 文档里面提到的一个技巧吗？我们在 key 到期后只需要访问一下 key 就可以确保 redis 删除该过期键，所以 redis.hasKey(key); 该操作就是为了触发 redis 的自己删除。 并发问题导致的多余数据，实际上并未过期。如上所述，第 32 分钟的桶里面存在的 session:1 实际上并不应该被删除，使用 touch 的好处便是我只负责检测，删不删交给 redis 判断。session:1 在第 32 分钟被 touch 了一次，并未被删除，在第 33 分钟时应当被 redis 删除，但可能存在延时，这个时候 touch 一次，确保删除。 所以，源码里面特别强调了一下：要用 touch 去触发 key 的删除，而不能直接 del key。 参考 https://github.com/spring-projects/spring-session/issues/93 C 轮改造—增加 C 类型键完善过期通知事件虽然引入了 B 类型键，并且在后台加了定时器去确保 session 的过期，但似乎…emmmmm… 还是不够完善。在此之前，kirito-session 的设计方案中，存储 session 实际内容的 A 类型键和用于定时器确保删除的桶 B 类型键过期时间都是 30 分钟 (key 的 TTL 是 30 分钟)，注意一个细节，spring-session 中 A 类型键的过期时间是 35 分钟，比实际的 30 分钟多了 5 分钟，这意味着即便 session 已经过期，我们还是可以在 redis 中有 5 分钟间隔来操作过期的 session。于此同时，spring-session 引入了 C 类型键来作为 session 的引用。 解释下之前卖的第二个关子，C 类型键的组成为前缀 +”sessions:expires”+sessionId，对应一个空值，同时也是 B 类型键桶中存放的 session 引用，ttl 为 30 分钟，具体作用便是在自身过期后触发 redis 的 keyspace notifications (http://redis.io/topics/notifications)，具体如何监听 redis 的过期事件简单介绍下：org.springframework.session.data.redis.config.ConfigureNotifyKeyspaceEventsAction 该类配置了相关的过期监听，并使用 SessionExpiredEvent 事件发放 session 的过期事件。为什么引入 C 类型键？keyspace notifications 只会告诉我们哪个键过期了，不会告诉我们内容是什么。 关键就在于如果 session 过期后监听器可能想要访问 session 的具体内容，然而自身都过期了，还怎么获取内容 。所以，C 类型键存在的意义便是解耦 session 的存储和 session 的过期，并且使得 server 获取到过期通知后可以访问到 session 真实的值。对于用户来说，C 类型键过期后，意味着登录失效，而对于服务端而言，真正的过期其实是 A 类型键过期，这中间会有 5 分钟的误差。 一点点想法，担忧，疑惑本文大概介绍了 Spring Session 的三种 key 的原因，理清楚其中的逻辑花了不少时间，项目改造正好涉及到相关的缓存值过期这一需求，完全可以参考 Spring Session 的方案。但担忧也是有的，如果真的只是 1~2 两分钟的延迟过期（对应 A 轮改造中遇到的问题），以及 1 分钟的提前删除（对应 B 轮改造中的并发问题）其实个人感觉没必要计较。从产品体验上来说，用户应该不会在意 32 分钟自动退出和 30 分钟退出，可以说 Spring Session 是为了严谨而设计了这一套方案，但引入了定时器和很多辅助的键值对，无疑对内存消耗和 cpu 消耗都是一种浪费。如果在生产环境大量使用 Spring Session，最好权衡下本文提及的相关问题。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/categories/Spring-Session/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/tags/Spring-Session/"}]},{"title":"八幅漫画理解使用 JSON Web Token 设计单点登录系统","slug":"jwt-learn-2","date":"2018-04-16T14:57:45.000Z","updated":"2019-10-10T08:54:03.809Z","comments":true,"path":"jwt-learn-2/","link":"","permalink":"http://lexburner.github.io/jwt-learn-2/","excerpt":"转载自：http://blog.leapoahead.com/2015/09/06/understanding-jwt/ 作者：John Wu 博主前言这篇转载的文章和上一篇《JSON Web Token - 在 Web 应用间安全地传递信息》文章均为转载，是我个人在研究 jwt 时浏览下来发现的两篇质量比较高的文章，所以分享给大家。个人对于 jwt 使用场景的理解，包括微信公众号留言中的提问，我都会在下一篇文章中来聊一聊。实际上使用 jwt 设计单点登录系统存在诸多的问题，很多有经验的工程师比较抵制用 jwt 做会话和所谓的单点登录系统，但不妨碍大家作为一个知识点去学习。","text":"转载自：http://blog.leapoahead.com/2015/09/06/understanding-jwt/ 作者：John Wu 博主前言这篇转载的文章和上一篇《JSON Web Token - 在 Web 应用间安全地传递信息》文章均为转载，是我个人在研究 jwt 时浏览下来发现的两篇质量比较高的文章，所以分享给大家。个人对于 jwt 使用场景的理解，包括微信公众号留言中的提问，我都会在下一篇文章中来聊一聊。实际上使用 jwt 设计单点登录系统存在诸多的问题，很多有经验的工程师比较抵制用 jwt 做会话和所谓的单点登录系统，但不妨碍大家作为一个知识点去学习。以下是原文 上次在 《JSON Web Token - 在 Web 应用间安全地传递信息》 中我提到了 JSON Web Token 可以用来设计单点登录系统。我尝试用八幅漫画先让大家理解如何设计正常的用户认证系统，然后再延伸到单点登录系统。 如果还没有阅读 《JSON Web Token - 在 Web 应用间安全地传递信息》，我强烈建议你花十分钟阅读它，理解 JWT 的生成过程和原理。 用户认证八步走所谓用户认证（Authentication），就是让用户登录，并且在接下来的一段时间内让用户访问网站时可以使用其账户，而不需要再次登录的机制。 小知识：可别把用户认证和用户授权（Authorization）搞混了。用户授权指的是规定并允许用户使用自己的权限，例如发布帖子、管理站点等。 首先，服务器应用（下面简称“应用”）让用户通过 Web 表单将自己的用户名和密码发送到服务器的接口。这一过程一般是一个 HTTP POST 请求。建议的方式是通过 SSL 加密的传输（https 协议），从而避免敏感信息被嗅探。 接下来，应用和数据库核对用户名和密码。 核对用户名和密码成功后，应用将用户的 id（图中的 user_id）作为 JWT Payload 的一个属性，将其与头部分别进行 Base64 编码拼接后签名，形成一个 JWT。这里的 JWT 就是一个形同 lll.zzz.xxx 的字符串。 应用将 JWT 字符串作为该请求 Cookie 的一部分返回给用户。注意，在这里必须使用 HttpOnly 属性来防止 Cookie 被 JavaScript 读取，从而避免 跨站脚本攻击（XSS 攻击）。 在 Cookie 失效或者被删除前，用户每次访问应用，应用都会接受到含有 jwt 的 Cookie。从而应用就可以将 JWT 从请求中提取出来。 应用通过一系列任务检查 JWT 的有效性。例如，检查签名是否正确；检查 Token 是否过期；检查 Token 的接收方是否是自己（可选）。 应用在确认 JWT 有效之后，JWT 进行 Base64 解码（可能在上一步中已经完成），然后在 Payload 中读取用户的 id 值，也就是 user_id 属性。这里用户的 id 为 1025。 应用从数据库取到 id 为 1025 的用户的信息，加载到内存中，进行 ORM 之类的一系列底层逻辑初始化。 应用根据用户请求进行响应。 和 Session 方式存储 id 的差异Session 方式存储用户 id 的最大弊病在于要占用大量服务器内存，对于较大型应用而言可能还要保存许多的状态。一般而言，大型应用还需要借助一些 KV 数据库和一系列缓存机制来实现 Session 的存储。 而 JWT 方式将用户状态分散到了客户端中，可以明显减轻服务端的内存压力。除了用户 id 之外，还可以存储其他的和用户相关的信息，例如该用户是否是管理员、用户所在的分桶（见 [《你所应该知道的 A/B 测试基础》一文] 等。 虽说 JWT 方式让服务器有一些计算压力（例如加密、编码和解码），但是这些压力相比磁盘 I/O 而言或许是半斤八两。具体是否采用，需要在不同场景下用数据说话。 单点登录Session 方式来存储用户 id，一开始用户的 Session 只会存储在一台服务器上。对于有多个子域名的站点，每个子域名至少会对应一台不同的服务器，例如： www.taobao.com nv.taobao.com nz.taobao.com login.taobao.com 所以如果要实现在 login.taobao.com 登录后，在其他的子域名下依然可以取到 Session，这要求我们在多台服务器上同步 Session。 使用 JWT 的方式则没有这个问题的存在，因为用户的状态已经被传送到了客户端。因此，我们只需要将含有 JWT 的 Cookie 的 domain 设置为顶级域名即可，例如 1Set-Cookie: jwt=lll.zzz.xxx; HttpOnly; max-age=980000; domain=.taobao.com 注意 domain 必须设置为一个点加顶级域名，即 .taobao.com。这样，taobao.com 和 *.taobao.com 就都可以接受到这个 Cookie，并获取 JWT 了。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JWT","slug":"JWT","permalink":"http://lexburner.github.io/categories/JWT/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"http://lexburner.github.io/tags/JWT/"}]},{"title":"JSON Web Token - 在 Web 应用间安全地传递信息","slug":"jwt-learn","date":"2018-04-14T14:57:45.000Z","updated":"2019-09-26T09:45:31.481Z","comments":true,"path":"jwt-learn/","link":"","permalink":"http://lexburner.github.io/jwt-learn/","excerpt":"转载自：http://blog.leapoahead.com/2015/09/06/understanding-jwt/ 作者：John Wu JSON Web Token（JWT）是一个非常轻巧的 规范。这个规范允许我们使用 JWT 在用户和服务器之间传递安全可靠的信息。 让我们来假想一下一个场景。在 A 用户关注了 B 用户的时候，系统发邮件给 B 用户，并且附有一个链接“点此关注 A 用户”。链接的地址可以是这样的","text":"转载自：http://blog.leapoahead.com/2015/09/06/understanding-jwt/ 作者：John Wu JSON Web Token（JWT）是一个非常轻巧的 规范。这个规范允许我们使用 JWT 在用户和服务器之间传递安全可靠的信息。 让我们来假想一下一个场景。在 A 用户关注了 B 用户的时候，系统发邮件给 B 用户，并且附有一个链接“点此关注 A 用户”。链接的地址可以是这样的1https://your.awesome-app.com/make-friend/?from_user=B&amp;target_user=A 上面的 URL 主要通过 URL 来描述这个当然这样做有一个弊端，那就是要求用户 B 用户是一定要先登录的。可不可以简化这个流程，让 B 用户不用登录就可以完成这个操作。JWT 就允许我们做到这点。 JWT 的组成一个 JWT 实际上就是一个字符串，它由三部分组成， 头部 、 载荷 与 签名 。 载荷（Payload）我们先将上面的添加好友的操作描述成一个 JSON 对象。其中添加了一些其他的信息，帮助今后收到这个 JWT 的服务器理解这个 JWT。 123456789&#123; &quot;iss&quot;: &quot;John Wu JWT&quot;, &quot;iat&quot;: 1441593502, &quot;exp&quot;: 1441594722, &quot;aud&quot;: &quot;www.example.com&quot;, &quot;sub&quot;: &quot;jrocket@example.com&quot;, &quot;from_user&quot;: &quot;B&quot;, &quot;target_user&quot;: &quot;A&quot;&#125; 这里面的前五个字段都是由 JWT 的标准所定义的。 iss: 该 JWT 的签发者 sub: 该 JWT 所面向的用户 aud: 接收该 JWT 的一方 exp(expires): 什么时候过期，这里是一个 Unix 时间戳 iat(issued at): 在什么时候签发的 这些定义都可以在 标准 中找到。 将上面的 JSON 对象进行 [base64 编码] 可以得到下面的字符串。这个字符串我们将它称作 JWT 的 Payload（载荷）。 1eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 如果你使用 Node.js，可以用 Node.js 的包 base64url 来得到这个字符串。 1234567var base64url = require(&apos;base64url&apos;)var header = &#123; &quot;from_user&quot;: &quot;B&quot;, &quot;target_user&quot;: &quot;A&quot;&#125;console.log(base64url(JSON.stringify(header)))// 输出：eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 小知识：Base64 是一种编码，也就是说，它是可以被翻译回原来的样子来的。它并不是一种加密过程。 头部（Header）JWT 还需要一个头部，头部用于描述关于该 JWT 的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个 JSON 对象。 1234&#123; &quot;typ&quot;: &quot;JWT&quot;, &quot;alg&quot;: &quot;HS256&quot;&#125; 在这里，我们说明了这是一个 JWT，并且我们所用的签名算法（后面会提到）是 HS256 算法。 对它也要进行 Base64 编码，之后的字符串就成了 JWT 的 Header（头部）。 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 签名（签名）将上面的两个编码后的字符串都用句号 . 连接在一起（头部在前），就形成了 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0 这一部分的过程在 node-jws 的源码 中有体现 最后，我们将上面拼接完的字符串用 HS256 算法进行加密。在加密的时候，我们还需要提供一个密钥（secret）。如果我们用 mystar 作为密钥的话，那么就可以得到我们加密后的内容 1rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 这一部分又叫做 签名 。 最后将这一部分签名也拼接在被签名的字符串后面，我们就得到了完整的 JWT 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 于是，我们就可以将邮件中的 URL 改成 1https://your.awesome-app.com/make-friend/?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 这样就可以安全地完成添加好友的操作了！ 且慢，我们一定会有一些问题： 签名的目的是什么？ Base64 是一种编码，是可逆的，那么我的信息不就被暴露了吗？ 让我逐一为你说明。 签名的目的最后一步签名的过程，实际上是对头部以及载荷内容进行签名。一般而言，加密算法对于不同的输入产生的输出总是不一样的。对于两个不同的输入，产生同样的输出的概率极其地小（有可能比我成世界首富的概率还小）。所以，我们就把“不一样的输入产生不一样的输出”当做必然事件来看待吧。 所以，如果有人对头部以及载荷的内容解码之后进行修改，再进行编码的话，那么新的头部和载荷的签名和之前的签名就将是不一样的。而且，如果不知道服务器加密的时候用的密钥的话，得出来的签名也一定会是不一样的。 服务器应用在接受到 JWT 后，会首先对头部和载荷的内容用同一算法再次签名。那么服务器应用是怎么知道我们用的是哪一种算法呢？别忘了，我们在 JWT 的头部中已经用 alg 字段指明了我们的加密算法了。 如果服务器应用对头部和载荷再次以同样方法签名之后发现，自己计算出来的签名和接受到的签名不一样，那么就说明这个 Token 的内容被别人动过的，我们应该拒绝这个 Token，返回一个 HTTP 401 Unauthorized 响应。 信息会暴露？是的。 所以，在 JWT 中，不应该在载荷里面加入任何敏感的数据。在上面的例子中，我们传输的是用户的 User ID。这个值实际上不是什么敏感内容，一般情况下被知道也是安全的。 但是像密码这样的内容就不能被放在 JWT 中了。如果将用户的密码放在了 JWT 中，那么怀有恶意的第三方通过 Base64 解码就能很快地知道你的密码了。 JWT 的适用场景我们可以看到，JWT 适合用于向 Web 应用传递一些非敏感信息。例如在上面提到的完成加好友的操作，还有诸如下订单的操作等等。 其实 JWT 还经常用于设计用户认证和授权系统，甚至实现 Web 应用的单点登录。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JWT","slug":"JWT","permalink":"http://lexburner.github.io/categories/JWT/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"http://lexburner.github.io/tags/JWT/"}]},{"title":"Kong 集成 Jwt 插件","slug":"kong-jwt","date":"2018-04-11T14:57:45.000Z","updated":"2019-09-26T09:45:29.767Z","comments":true,"path":"kong-jwt/","link":"","permalink":"http://lexburner.github.io/kong-jwt/","excerpt":"上一篇文章使用 Kong 完成了负载均衡的配置，本文介绍下在此基础上如何集成 jwt 插件来保护内部服务的安全。前置知识点：Jwt 基础概念。推荐阅读：","text":"上一篇文章使用 Kong 完成了负载均衡的配置，本文介绍下在此基础上如何集成 jwt 插件来保护内部服务的安全。前置知识点：Jwt 基础概念。推荐阅读：通俗易懂地介绍 Jwt https://blog.leapoahead.com/2015/09/06/understanding-jwt/ Jwt 的官网 https://jwt.io/ 为 Kong 安装 Jwt 插件Kong 官方提供了 Jwt 插件，可以对 某个 service 或者 route 添加 Jwt 认证，我以 service 为例介绍 Jwt 插件的使用 为 hello（上篇文章创建的 service）添加 Jwt 插件 1curl -X POST http://localhost:8001/services/hello/plugins --data \"name=jwt\" 接着尝试访问这个受保护的服务 12kirito$ curl http://localhost:8000/hello/hi=&gt; &#123;\"message\":\"Unauthorized\"&#125; 说明该 service 已经被 Jwt 保护起来了。 在 Kong 中创建用户1curl -X POST http://localhost:8001/consumers --data \"username=kirito\" 使用了新的端点 consumers 创建了一个名称为 kirito 的用户。 查看用户信息1curl http://127.0.0.1:8001/consumers/kirito/jwt 响应如下： 12345678910111213&#123; \"total\": 1, \"data\": [ &#123; \"created_at\": 1523432449000, \"id\": \"cb01a6cf-7371-4f23-8193-fa69a0bb070c\", \"algorithm\": \"HS256\", \"key\": \"vcnvYSFzTIGyMxzKSgnNU0uvxixdYWB9\", \"secret\": \"qQ9tSqIYjilnJmKuZXvJpgNo4ZqJDrim\", \"consumer_id\": \"7d34e6bc-89ea-4f33-9346-9c10600e4afd\" &#125; ]&#125; 重点关注三个值 algorithm，key，secret，他们和 Jwt 算法的参数密切相关 生成 Jwt使用 jwt 官网 (jwt.io) 提供的 Debugger 功能可以很方便的生成 jwt。 HEADER 部分声明了验证方式为 JWT，加密算法为 HS256 PAYLOAD 部分原本有 5 个参数 1234567&#123; \"iss\": \"kirito\", \"iat\": 1441593502, \"exp\": 1441594722, \"aud\": \"cnkirito.moe\", \"sub\": \"250577914@qq.com\",&#125; 这里面的前五个字段都是由 JWT 的标准（RFC7519）所定义的。 iss: 该 JWT 的签发者 sub: 该 JWT 所面向的用户 aud: 接收该 JWT 的一方 exp(expires): 什么时候过期，这里是一个 Unix 时间戳 iat(issued at): 在什么时候签发的 iss 这一参数在 Kong 的 Jwt 插件中对应的是 curl http://127.0.0.1:8001/consumers/kirito/jwt 获取的用户信息中的 key 值。 而其他值都可以不填写 最后还要一个没有用到的用户信息：secret。HS256 加密算法是对称加密算法，加密和解密都依赖于同一个密钥，在生成 Jwt 的消息签名时（Verify Signature）需要被使用到。 我们使用 jwt 官网 (jwt.io) 提供的 Debugger 功能快速生成我们的 Jwt 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJ2Y252WVNGelRJR3lNeHpLU2duTlUwdXZ4aXhkWVdCOSJ9.3iL4sXgZyvRx2XtIe2X73yplfmSSu1WPGcvyhwq7TVE 由三个圆点分隔的长串便是用户身份的标识了 携带 Jwt 访问受限资源12kirito$ curl http://localhost:8000/hello/hi=&gt; &#123;\"message\":\"Unauthorized\"&#125; 在此之前直接访问 hello 服务是处于未验证状态 携带 Jwt 访问 12curl http://localhost:8000/hello/hi -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJ2Y252WVNGelRJR3lNeHpLU2duTlUwdXZ4aXhkWVdCOSJ9.3iL4sXgZyvRx2XtIe2X73yplfmSSu1WPGcvyhwq7TVE'=&gt; 3000 成功获取到了服务端的响应，Jwt 插件就这样正常工作了。 补充 可以指定生成的 key（对应 Jwt 中的 iss），和 secret 1curl -X POST http://localhost:8001/consumers/kirito/jwt --data \"secret=YmxvYiBkYXRh\" --data \"key=kirito\" 如果想要修改 secret 和 key，经过目前笔者的尝试后，似乎只能够先删除，后新增。 Jwt 也可以作为 QueryString 参数携带在 get 请求中 1curl http://localhost:8000/hello/hi?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJ2Y252WVNGelRJR3lNeHpLU2duTlUwdXZ4aXhkWVdCOSJ9.3iL4sXgZyvRx2XtIe2X73yplfmSSu1WPGcvyhwq7TVE 通常用户需要自己写一个服务去帮助 Consumer 生成自己的 Jwt，自然不能总是依赖于 Jwt 官方的 Debugger，当然也没必要重复造轮子（尽管这并不难），可以考虑使用开源实现，比如 Java 中推荐使用 jjwt(https://github.com/jwtk/jjwt) 123456String jwt = Jwts.builder() .setHeaderParam(\"typ\",\"jwt\") .setHeaderParam(\"alg\",\"HS256\") .setIssuer(\"kirito\") .signWith(SignatureAlgorithm.HS256, Base64.getEncoder().encodeToString(\"YmxvYiBkYXRh\".getBytes(Charset.forName(\"utf-8\")))) .compact(); 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Kong","slug":"Kong","permalink":"http://lexburner.github.io/categories/Kong/"}],"tags":[{"name":"Kong","slug":"Kong","permalink":"http://lexburner.github.io/tags/Kong/"},{"name":"网关","slug":"网关","permalink":"http://lexburner.github.io/tags/网关/"}]},{"title":"初识 Kong 之负载均衡","slug":"kong-loadbalance","date":"2018-04-11T14:56:45.000Z","updated":"2019-09-26T09:45:30.810Z","comments":true,"path":"kong-loadbalance/","link":"","permalink":"http://lexburner.github.io/kong-loadbalance/","excerpt":"使用 Kong Community Edition（社区版 v1.3.0）来搭建一个负载均衡器，由于 Kong 是基于 Openresty 的，而 Openresty 又是 Nginx 的二次封装，所有很多配置项和 Nginx 类似。 来看一个较为典型的 Nginx 负载均衡配置","text":"使用 Kong Community Edition（社区版 v1.3.0）来搭建一个负载均衡器，由于 Kong 是基于 Openresty 的，而 Openresty 又是 Nginx 的二次封装，所有很多配置项和 Nginx 类似。 来看一个较为典型的 Nginx 负载均衡配置1234567891011upstream hello &#123; server localhost:3000 weight=100; server localhost:3001 weight=50;&#125;server &#123; listen 80; location /hello &#123; proxy_pass http://hello; &#125;&#125; nginx 监听来自本地 80 端口的请求，如果路径与 /hello 匹配，便将请求原封不动的转发到名称为 hello 的 upstream，而该 upstream 我们配置了一个负载均衡器，会路由到本地的 3000 端口和 3001 端口。 12345678910111213141516@SpringBootApplication@RestControllerpublic class KongDemoApplication &#123; public static void main(String[] args) &#123; System.setProperty(\"server.port\",\"3000\"); //System.setProperty(\"server.port\",\"3001\"); SpringApplication.run(KongDemoApplication.class, args); &#125; @RequestMapping(\"/hi\") public String port()&#123; return System.getProperty(\"server.port\"); &#125;&#125; 启动两个 server 分别监听本地 3000 端口和 3001 端口。 如何你的机器已经安装好了 Kong，并对 Kong 的 admin api 有了基础的认识，接下来便可以针对 Kong 进行负载均衡的配置了。 配置 upstream 和 target创建一个名称 hello 的 upstream 1curl -X POST http://localhost:8001/upstreams --data \"name=hello\" 为 hello 添加两个负载均衡节点 1curl -X POST http://localhost:8001/upstreams/hello/targets --data \"target=localhost:3000\" --data \"weight=100\" 1curl -X POST http://localhost:8001/upstreams/hello/targets --data \"target=localhost:3001\" --data \"weight=50\" 如上的配置对应了 Nginx 的配置 1234upstream hello &#123; server localhost:3000 weight=100; server localhost:3001 weight=50;&#125; 配置 service 和 route使用老版本 Kong 的用户可能会接触过 api 这个概念，但是在 Kong v1.3.0 中，已经被废除了，取而代之的是 service 和 route 的配置。 配置一个 service 1curl -X POST http://localhost:8001/services --data \"name=hello\" --data \"host=hello\" host 的值便对应了 upstream 的名称，配置成功后会返回生成的 service 的 id，我的返回结果：8695cc65-16c1-43b1-95a1-5d30d0a50409 为上面的 service 配置路由信息 1curl -X POST http://localhost:8001/routes --data \"paths[]=/hello\" --data \"service.id=8695cc65-16c1-43b1-95a1-5d30d0a50409\" 请求路径包含 /hello 的请求都会被转移到对应的 service 进行处理。 如上的配置便对应了 123location /hello &#123; proxy_pass http://hello;&#125; 测试 Kong 的负载均衡1curl http://localhost:8000/hello/hi 因为复杂均衡的原因，需要多测试几次，多次 curl 之后结果如下： 123456789101130003000300030003000300030013001300130003001 参考文档https://getkong.org/docs/0.13.x/loadbalancing/ https://getkong.org/docs/0.13.x/configuration/ 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Kong","slug":"Kong","permalink":"http://lexburner.github.io/categories/Kong/"}],"tags":[{"name":"Kong","slug":"Kong","permalink":"http://lexburner.github.io/tags/Kong/"},{"name":"网关","slug":"网关","permalink":"http://lexburner.github.io/tags/网关/"}]},{"title":"技术精进的三境界","slug":"java-how-to-learn","date":"2018-04-04T14:56:45.000Z","updated":"2019-09-26T09:45:29.572Z","comments":true,"path":"java-how-to-learn/","link":"","permalink":"http://lexburner.github.io/java-how-to-learn/","excerpt":"最近更新了一篇 Docker 的文章，朋友跟我反馈说效果并不是很好，我回头看了下，的确没有我自己的特色，没有太多思考，让公众号显得有些「百货」了。经过反思，今后只在个人博客更新 Docker 相关的个人学习经验（传送门），个人公众号还是主要推送和 Java 结合较为紧密的内容。","text":"最近更新了一篇 Docker 的文章，朋友跟我反馈说效果并不是很好，我回头看了下，的确没有我自己的特色，没有太多思考，让公众号显得有些「百货」了。经过反思，今后只在个人博客更新 Docker 相关的个人学习经验（传送门），个人公众号还是主要推送和 Java 结合较为紧密的内容。 前言前不久公众号后台有人给我留言，请教如何体系地学习 Java 知识，我当时心想：这话题太大，Java 技术栈也太深，不是一篇文章能说清楚的，但要说学习技巧，却的确是有规律所寻，秉持着「授人以鱼不如授人以渔」的想法，这篇文章便分享下我个人的一些学习技巧。 王国维在《人间词话》中提到了古今之成大事业、大学问者，必经的三种境界： “昨夜西风凋碧树，独上高楼，望尽天涯路。” 此第一境也。 “ 衣带渐宽终不悔，为伊消得人憔悴。” 此第二境也。 “ 众里寻他千百度，蓦然回首，那人却在，灯火阑珊处。”此第三境也。我也按照我的理解，将精进技术分成了三个境界。 第一境: 从 overview 和 guides 获取新知识的直观感受善用搜索，推荐 google。google 第一页搜索出来权威内容的概率要大于 baidu，人很容易有先入为主的观念，前五篇文章对一个知识点的直观感受，就会形成固化映像。（ 技术精进的第一层关卡：你可能缺少一个梯子 ） 以一个可能大多数读者都觉得陌生的知识点：图形数据库 Neo4j 作为引子，来介绍。 搜索 neo4j 关键词时大概率会搜索到官网，但作为一门技术的初学者，我更习惯于阅读下中文博客，教程，以对这个陌生的技术有一个宏观的了解。虽然大家都很赞同一个观点：英文文档更加权威，但是我个人还是觉得，中文教程更加直观，实际上我读中文文档的速度是英文文档的 2-3 倍。 不需要细读每个语法，我一般习惯看下概览，再看下目录对整体的知识点有个宏观的掌握。这种入门级的网站有很多，大多出现在搜索引擎的第一页。而官方的 overview 通常也是很适合入门的手段。 英文阅读能力强的读者可以直接上手官方的 guides，overview，get started 等入门教程，它们比中文教程强在很多方面 ( 技术精进的第二层关卡：你可能需要一定的英语阅读能力 )： 避免了语言转换带来的翻译失真。很多中文教程读起来总觉得拗口，太过于书面化，语句也不符合中国人阅读的习惯。翻译烂的原因不需要我总结，事实上我对翻译这个事有过比较深的真实体验，我曾经和 spring4all 的小伙伴们一起对 spring 文档进行过翻译，大家积极性都很高，一周之类几乎所有的 guides 文档全部翻译完成了，但质量真的惨不忍睹，参与校对时，竟然有人将 「jar」翻译成「蜜罐」，而且不在少数。 官方文档维护着最新的版本。对于一些热门的软件技术，比如我最近接触的 docker，之前研究过得 lucene，它们都一些共同点：版本差异非常大，版本更迭速度快。翻看 docker 在国内零散的博客，大多数比最新的 docker 版本落后 3 个大版本以上；而像 lucene 这种大版本演进非常迅速的技术（大版本演进意味着不兼容老版本），api 几乎是翻天覆地的变化。 权威性。 英语能力要求并不是很高，大学英语 4 级足矣，毕竟有个东西叫 谷歌翻译 。 再比如 spring 体系的知识点，有一个通用的学习路线。还是以 neo4j 为例，得知 spring 对 neo4j 有二次封装之后，便熟练地来到了 spring 的 guides 专栏 (https://spring.io/guides)，spring 对所有的知识点提供了两个维度的学习文档，其中 https://spring.io/guides 一般都是一个 15 分钟上手的 hello world，让你快速上手一门新的技术；另一个是较为完善的文档：https://spring.io/docs/reference，成体系地介绍技术细节。第一阶段主要关注前者，一般它长这样： 敲完 hello world，一般就可以对应简历上「了解 XXXX」的描述了 ( 斜眼笑。 第二境：官方文档与社区大多数时候，一个停留在 hello world 认知级别的知识点对于我们的帮助不会很大，你甚至连在群里装逼的机会都没有！恐怖如斯！ 了解完毕这门技术是用来解决什么问题的，它大概是怎么使用的，有了这些直观体验之后再来看文档，会直观不少。下面主要介绍个人阅读官方文档的一些心路历程。 首先来看看宇宙级开源项目 spring 的官方文档，它长这样： 琳琅满目的项目，所有与 spring 相关的技术都可以在这儿获取最权威的解读，怎么学习 springboot，springcloud 还需要问吗？平时经常接触 spring 的同学如果这个页面都没见过，私以为在学习认知上是有所欠缺的。 文档除了主体知识内容之外还有整体介绍，新旧版本迭代的改动，新特性，依赖分析，性能测试等，文档内容一般都是非常多的，可以撷取其中核心的几节，将主要用法和注意事项掌握，至于不常用的特性，可以在碰到时再翻阅。 曾经一个项目需求中涉及到 spring security 的改造，而相关的文档又比较少，我至少通读过 5 遍 spring security 完整的文档，从一开始的大概了解，到最后的基本掌握，很多细节点一开始无法 get 到，读多了之后很多常用词汇和语感都会提升，细节会被消化，整体阅读速度也会随着文档阅读量提高而提升（比如 out-of-box 这个高频词一开始是不知道什么意思，谷歌翻译也翻不出来，后来得知是「开箱即用」）。 开源社区也是精进一门技术的重要途径，比如 spring4all，k8s，netty，elk 社区汇聚了不少文章和问答，初中高级的使用者都在社区中扮演着各自的角色（部分中文社区甚至样式都差不多，估计是用同一套开源代码搭建的 [捂脸])，社区活跃度也是一门技术火热的衡量指标。经常被大家调侃的面向 github 编程背后的 github，以及 Stack Overflow，都是质量比较硬的社区。 第三境：源码阅读（ 技术精进的第三层关卡：对源码的恐惧阻止了一个人探索的步伐 ）如果你觉得看完前面的文字是在说废话，那么这一节可能稍微能勾起你的兴趣，权当之前是一个铺垫，照顾下一些初学者。 在交流群里面发现的一个现象，很多人对源码有一种天生的畏惧感，诸如：“我才刚毕业 / 我才工作三年，还没到看源码的阶段”，“源码不是架构师看的吗”，“源码看不懂“，”看看别人的源码分析不就行了“…这一节主要聊聊源码阅读技巧，以及一些个人对阅读源码的感悟。 首先澄清几点：阅读源码绝对和工作年限无关；阅读源码绝对和工作职位无关；大多数源码并不是很难；debug+ 源码分析绝对比看文章来的直观。 1 源码中的测试用例还是以 neo4j 为例，我们在 github 找到 spring-data-neo4j 的源码，然后 git clone 到本地，在本地 idea 中打开。 和源码相关的第一点介绍的便是源码中的测试用例，对于大多数的开源项目而言，测试覆盖率是一个质量衡量的指标。大部分 Java 相关开源项目会包含测试用例，项目的一些功能特性可能在文档中无法一一介绍，通常可以在 src/test/java 中找到对应的用法，比如 neo4j 是怎么支持事务的，怎么维护边和边的关系的，在测试用例中都可以看到官方是怎么使用的。再举个例子，之前在使用 orika 这个拷贝工具时，一开始不知道怎么实现泛型的拷贝（泛型的运行时擦除特性），谷歌搜索和 Stack Overflow 提问无果之后，终于在源码的诸多测试用例中找到了我需要的代码。 2 通过核心接口 / 包结构分析框架层次结构我猜测有人拒绝阅读源码的一个原因：源码注释量不够，压根不知道一段代码是干嘛用的。的确，我在阅读有些源码时也会出现这样的情况：这儿会什么要加锁？为什么要用 AtomicReference 这个类？为什么这个方法放在父类，而另外看似功能差不多的代码放在子类实现？框架编写者不会像培训班的老师一样跟你讲解他为什么要这么写，也不是所有的源码都能像 HashMap 的源码那样被大家泛滥地解读，是的，可能大多数情况下你的境地是「虽然不懂，还没法问！」气不气，尴不尴尬？没办法，因为这已经是第三境了，曲高和寡，但还是有些方法规避这样的情况的，那就是：主要关心核心接口，通过接口暴露的方法，猜测出作者的意图。据我不多的源码阅读经验，一个实现类的注释可能不多，但接口的注释通常会很多，毕竟一个原则是面向接口编程。 上图是我分析 spring security 源码时，根据接口间的关系整理出来的 UML 类图，对于绿色实现类的细节我可能并不是特别关注，浅蓝色代表的接口才是我们理解整个架构体系的切入点，配合 idea 这些优秀的集成开发环境，可以很方便的整理出 UML 类图。接口是全局架构，实现类是源码细节。 顺带一提：熟练使用 IDE 很重要。无论你是 eclipse 玩家还是 intellij idea 玩家，你都应该熟练掌握快捷键和一些常用操作，方便你阅读源码。比如 idea 右键可以自动生成类的继承关系图（聚合关系的体现不够智能），方便分析层次关系；显示方法 outline 快速查看一个类的方法概览，在成片的源码中非常有用；快速定位一个接口的实现类，一个类的子类等等。 再比如我在阅读 motan 这款 rpc 框架源码时遵循的顺序是其包结构的层次关系。 写源码分析文章时基本就是按照一个包一篇文章来分析，从而化繁为简。无论是模块结构，包结构，还是代码层面的接口结构，重点都是在强调：我们需要从宏观掌握一个框架，再去扣细节，否则我个人感觉学习状态就是很迷，不知道学到哪儿了。 3 带着问题阅读实现类源码具体的实现类源码真的没什么技巧可讲，一定是看一个人的写代码功底，以及代码敏感度了，非要说技巧的话，可能就是多写代码，培养代码敏感度了。此外，带着问题去读源码个人体验下来感觉不错，在阅读 spring security 源码时，我带着的问题是，怎么结合 zuul 实现动态的权限控制，一步步地 debug，看它原来的实现，之后是改源码，debug 看改变的效果。 具体的源码的阅读难度也是参差不齐的，个人学习经历中发现 motan 的源码就很容易阅读，spring 的源码因为文档比较齐全，阅读体验也很好，但 lucene 的源码和 hibernate 的源码，我也尝试阅读过，简直是天书，又比如说 netty，单单熟练使用它就已很难，何论源码。一方面跟个人阅历有关，一方面跟框架实现难度有关，很难盖棺定论得出方法论。个人建议是，明确自己需要解决什么问题去阅读源码，不必为了装逼而读源码。 贴下之前几个系列的源码解读链接： 【RPC 系列】 https://www.cnkirito.moe/categories/RPC/ 【Spring Security 系列】https://www.cnkirito.moe/categories/Spring-Security/ 【OAuth2 系列】https://www.cnkirito.moe/categories/Spring-Security-OAuth2/ 三境之外除了学习技术的三种境界，还有一些其他个人的感悟。比如类比学习法，一开始学习 spring-data-jpa 时效率比较慢，这对于我是一个比较新的技术，但当我后来再接触 spring-data-redis，spring-data-neo4j 时，虽然同样是第一次接触这些数据访问层，但有了之前 spring-data-jpa 的参考，可以说是事半功倍。关于视频，博客，书，文档可以说关系很微妙，从视频到文档，越来越不直观，但学习效率越来越高，这些没有高低贵贱之分，私以为都是很好的学习方法。怎么提升代码技巧？说真的方法论归方法论，重点还是代码行数锻炼出来的代码敏感度，这是看书，看代码，写博客，看方法论学不来的，不多说了，滚去写代码了 [抱拳]。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"Docker Network—Bridge 模式","slug":"docker-network-bridge","date":"2018-04-03T14:56:45.000Z","updated":"2019-09-26T09:45:30.488Z","comments":true,"path":"docker-network-bridge/","link":"","permalink":"http://lexburner.github.io/docker-network-bridge/","excerpt":"概述Docker 强大的原因之一在于多个 Docker 容器之间的互相连接。涉及到连接，就引出了网络通信的几种模式。Docker 默认提供了 5 种网络驱动模式。","text":"概述Docker 强大的原因之一在于多个 Docker 容器之间的互相连接。涉及到连接，就引出了网络通信的几种模式。Docker 默认提供了 5 种网络驱动模式。 bridge: 默认的网络驱动模式。如果不指定驱动程序，bridge 便会作为默认的网络驱动模式。当应用程序运行在需要通信的独立容器 (standalone containers) 中时，通常会选择 bridge 模式。 host：移除容器和 Docker 宿主机之间的网络隔离，并直接使用主机的网络。host 模式仅适用于 Docker 17.06+。 overlay：overlay 网络将多个 Docker 守护进程连接在一起，并使集群服务能够相互通信。您还可以使用 overlay 网络来实现 swarm 集群和独立容器之间的通信，或者不同 Docker 守护进程上的两个独立容器之间的通信。该策略实现了在这些容器之间进行操作系统级别路由的需求。 macvlan：Macvlan 网络允许为容器分配 MAC 地址，使其显示为网络上的物理设备。 Docker 守护进程通过其 MAC 地址将流量路由到容器。对于希望直连到物理网络的传统应用程序而言，使用 macvlan 模式一般是最佳选择，而不应该通过 Docker 宿主机的网络进行路由。 none：对于此容器，禁用所有联网。通常与自定义网络驱动程序一起使用。none 模式不适用于集群服务。 通过在 Docker 上安装和使用第三方网络插件可以算作额外的扩展方式。 默认网络12345kiritodeMacBook-Pro:~ kirito$ docker network lsNETWORK ID NAME DRIVER SCOPE15315759c263 bridge bridge locald72064d9febf host host local83ea989d3fec none null local 这 3 个网络包含在 Docker 实现中。运行一个容器时，可以使用 –network 参数指定在哪种网络模式下运行该容器。 这篇文章重点介绍 bridge 模式。 所有 Docker 安装后都存在的 docker0 网络，这在 Docker 基础中有过介绍。除非使用 docker run –network= 选项另行指定，否则 Docker 守护进程默认情况下会将容器连接到 docker0 这个网络。 创建自定义的网络使用如下命令就可以创建一个名称为 my-net ，网络驱动模式为 bridge 的自定义网络。 1$ docker network create my-net 再次查看存在的网络可以发现上述命令执行之后产生的变化： 123456kiritodeMacBook-Pro:~ kirito$ docker network lsNETWORK ID NAME DRIVER SCOPE15315759c263 bridge bridge locald72064d9febf host host local73e32007f19f my-net bridge local83ea989d3fec none null local 使用 busybox 测试容器连通性 BusyBox 是一个集成了一百多个最常用 Linux 命令和工具（如 cat、echo、grep、mount、telnet 、ping、ifconfig 等）的精简工具箱，它只需要几 MB 的大小，很方便进行各种快速验证，被誉为“Linux 系统的瑞士军刀”。 我们使用 busybox 来测试容器间的网络情况。(一开始我尝试使用 ubuntu 作为基础镜像来构建测试容器，但 ubuntu 镜像删减了几乎所有的常用工具，连同 ping，ifconfig 等命令都需要额外安装软件，而 busybox 则不存在这些问题。) 使用默认网桥 docker01234kiritodeMacBook-Pro:~ kirito$ docker run --name box1 -it --rm busybox sh/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:07 inet addr:172.17.0.7 Bcast:172.17.255.255 Mask:255.255.0.0 —rm 指令可以让我们在退出容器时自动销毁该容器，这样便于测试。查看自身的 ip 为 172.17.0.7，接下来创建第二个容器 box2。 1234kiritodeMacBook-Pro:~ kirito$ docker run --name box2 -it --rm busybox sh/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:08 inet addr:172.17.0.8 Bcast:172.17.255.255 Mask:255.255.0.0 查看自身的 ip 为 172.17.0.8。 在 box2 中执行 ping 命令测试与 box1 的连通性： 1234567891011使用 IP/ # ping 172.17.0.8PING 172.17.0.8 (172.17.0.8): 56 data bytes64 bytes from 172.17.0.8: seq=0 ttl=64 time=0.107 ms64 bytes from 172.17.0.8: seq=1 ttl=64 time=0.116 ms64 bytes from 172.17.0.8: seq=2 ttl=64 time=0.114 ms64 bytes from 172.17.0.8: seq=3 ttl=64 time=0.126 ms使用容器名称/ # ping box1无响应 我们发现使用默认网桥 docker0 的桥接模式下，ip 是通的，但是无法使用容器名作为通信的 host。 使用自定义网桥 my-net1234kiritodeMacBook-Pro:~ kirito$ docker run --name box3 -it --rm --network my-net busybox sh/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:15:00:02 inet addr:172.21.0.2 Bcast:172.21.255.255 Mask:255.255.0.0 使用 —network 指定使用的网络模式，my-net 便是在此之前我们通过 docker network create 命令新创建的网络。新启动一个 shell 创建 box4 1234kiritodeMacBook-Pro:~ kirito$ docker run -it --name box4 --rm --network my-net busybox sh/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:15:00:03 inet addr:172.21.0.3 Bcast:172.21.255.255 Mask:255.255.0.0 在 box4 中执行 ping 命令测试与 box3 的连通性： 123456789101112131415使用 IP/ # ping 172.21.0.2PING 172.21.0.2 (172.21.0.2): 56 data bytes64 bytes from 172.21.0.2: seq=0 ttl=64 time=0.203 ms64 bytes from 172.21.0.2: seq=1 ttl=64 time=0.167 ms64 bytes from 172.21.0.2: seq=2 ttl=64 time=0.169 ms64 bytes from 172.21.0.2: seq=3 ttl=64 time=0.167 ms使用容器名称/ # ping box3PING box3 (172.21.0.2): 56 data bytes64 bytes from 172.21.0.2: seq=0 ttl=64 time=0.229 ms64 bytes from 172.21.0.2: seq=1 ttl=64 time=0.170 ms64 bytes from 172.21.0.2: seq=2 ttl=64 time=0.165 ms64 bytes from 172.21.0.2: seq=3 ttl=64 time=0.168 ms 与默认的网络 docker0 不同的是，指定了自定义 network 的容器可以使用容器名称相互通信，实际上这也是 docker 官方推荐使用 —network 参数运行容器的原因之一。 对比自定义 bridge(my-net) 与默认 bridge(docker0)自定义 bridge 提供更好的隔离性和容器间的互操作性连接到同一个自定义 bridge 网络的容器会自动将所有端口相互暴露，并且无法连接到容器之外的网络。这使得容器化的应用能轻松地相互通信，并且与外部环境产生了良好的隔离性。 例如一个包含了 web 应用，数据库，redis 等组件的应用程序。很有可能只希望对外界暴露 80 端口，而不允许外界访问数据库端口和 redis 端口，而又不至于让 web 应用本身无法访问数据库和 redis， 便可以使用自定义 bridge 网络轻松实现。如果在默认 bridge 网络上运行相同的应用程序，则需要使用 -p 或 —publish 标志打开 web 端口，数据库端口，redis 端口。这意味着 Docker 宿主机需要通过其他方式阻止对数据库端口，redis 端口的访问，无意增大了工作量。 自定义 bridge 提供容器间的自动 DNS 解析这一点在上一节的实验中已经验证过了。默认 bridge 网络上的容器只能通过 IP 地址互相访问，除非使用在 docker run 时添加 —link 参数。这么做个人认为有两点不好的地方： 一：容器关系只要稍微复杂一些，便会对管理产生不便。 二： —link 参数在官方文档中已经被标记为过期的参数，不被建议使用。 在用户定义的桥接网络上，容器可以通过容器名称 (--name 指定的名称) 或别名来解析对方。可能有人说，在默认 bridge 模式下我可以去修改 /etc/hosts 文件呀，但这显然不是合理的做法。 容器可以在运行中与自定义 bridge 网络连接和分离在容器的生命周期中，可以在运行中将其与自定义网络连接或断开连接。 而要从默认 bridge 网络中移除容器，则需要停止容器并使用不同的网络选项重新创建容器。 每个自定义的 bridge 网络都会创建一个可配置的网桥如果容器使用默认 bridge 网络，虽然可以对其进行配置，但所有容器都使用相同的默认设置，例如 MTU 和防火墙规则。另外，配置默认 bridge 网络隔离于 Docker 本身之外，并且需要重新启动 Docker 才可以生效。 自定义的 bridge 是使用 docker network create 创建和配置的。如果不同的应用程序组具有不同的网络要求，则可以在创建时分别配置每个用户定义的 bridge 网络，这无疑增加了灵活性和可控性。 使用默认 bridge 容器共享所有的环境变量在 Docker 的旧版本中，两个容器之间共享环境变量的唯一方法是使用 —link 标志来进行链接。这种类型的变量共享对于自定义的网络是不存在的。但是，自定义网络有更好方式来实现共享环境变量： 多个容器可以使用 Docker 卷来挂载包含共享信息的文件或目录。 多个容器可以使用 docker-compose 一起启动，并且 docker-compose.yml 文件可以定义共享变量。 使用集群服务而不是独立容器，并利用共享密钥和配置。 结合上述这些论述和官方文档的建议，使用 bridge 网络驱动模式时，最好添加使用 —network 来指定自定义的网络。 参考资料https://docs.docker.com/network/bridge/#connect-a-container-to-the-default-bridge-network https://www.ibm.com/developerworks/cn/linux/l-docker-network/index.html","categories":[{"name":"Docker","slug":"Docker","permalink":"http://lexburner.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://lexburner.github.io/tags/Docker/"},{"name":"Network","slug":"Network","permalink":"http://lexburner.github.io/tags/Network/"}]},{"title":"JAVA 拾遗 --eqauls 和 hashCode 方法","slug":"java-eqaulsandhashcode","date":"2018-03-28T14:56:45.000Z","updated":"2019-09-26T09:45:30.974Z","comments":true,"path":"java-eqaulsandhashcode/","link":"","permalink":"http://lexburner.github.io/java-eqaulsandhashcode/","excerpt":"缘起—lombok 引发的惨案 Lombok 是一种 Java™ 实用工具，可用于帮助开发人员消除 Java 的冗长，尤其是对于简单的 Java 对象（POJO）。它通过注解实现这一目的。 最近一个新项目中开始使用了 lombok，由于其真的是太简单易懂了，以至于我连文档都没看，直接就上手使用了，引发了一桩惨案。","text":"缘起—lombok 引发的惨案 Lombok 是一种 Java™ 实用工具，可用于帮助开发人员消除 Java 的冗长，尤其是对于简单的 Java 对象（POJO）。它通过注解实现这一目的。 最近一个新项目中开始使用了 lombok，由于其真的是太简单易懂了，以至于我连文档都没看，直接就上手使用了，引发了一桩惨案。 实体类定义 123456@Datapublic class Project &#123; private Long id; private String projectName; private List&lt;Project&gt; projects;&#125; 我在项目中设计了一个 Project 类，其包含了一个 List projects 属性，表达了项目间的依赖关系。@Data 便是 Lombok 提供的常用注解，我的本意是使用它来自动生成 getter/setter 方法。这样的实体类定义再简单不过了。 意外出现 使用 Project 类表达项目间的依赖关系是我的初衷，具体的分析步骤不在此赘述，对 Project 类的操作主要包括创建，打印，保存几个简单操作。运行初期，一切看似风平浪静，但经过长时间运行后，我意外的获得了如下的异常： 123Exception in thread \"Tmoe.cnkirito.dependency0\" java.lang.StackOverflowError at moe.cnkirito.dependency.model.Project.hashCode(Project.java:20) at java.util.AbstracList.hashCode(AbstractList.java:541) 这让我感到很意外，我并没有对 Project 类进行什么复杂的操作，也没有进行什么递归操作，怎么会得到 StackOverflowError 这个错误呢？更令我百思不得其解的地方在于，怎么报错的日志中还出现了 hashCode 和 AbstractList 这两个家伙？等等…hashCode…emmmmm…我压根没有重写过它啊，怎么可能会报错呢…. 再想了想 Lombok 的 @Data 注解，我似乎发现了什么…emmmmm…抱着怀疑的态度翻阅了下 Lombok 的文档，看到了如下的介绍 @Data is a convenient shortcut annotation that bundles the features of @ToString, @EqualsAndHashCode, @Getter / @Setter and @RequiredArgsConstructor together: In other words, @Data generates all the boilerplate that is normally associated with simple POJOs (Plain Old Java Objects) and beans: getters for all fields, setters for all non-final fields, and appropriate toString, equals and hashCode implementations that involve the fields of the class, and a constructor that initializes all final fields, as well as all non-final fields with no initializer that have been marked with @NonNull, in order to ensure the field is never null. 原来 @Data 注解不仅帮我们实现了生成了 @Getter / @Setter 注解，还包含了 @ToString, @EqualsAndHashCode, 和 @RequiredArgsConstructor 注解，这其中的 @EqualsAndHashCode 注解似乎和我这次的惨案密切相关了。顺藤摸瓜，看看 @EqualsAndHashCode 的文档： Any class definition may be annotated with @EqualsAndHashCode to let lombok generate implementations of the equals(Object other) and hashCode() methods. By default, it’ll use all non-static, non-transient fields @EqualsAndHashCode 会自动生成 equals(Object other) 和 hashCode() 两个方法，默认会使用所有非静态，非瞬时状态的字段。 回到我的案例中，也就是说，Lombok 会将 Project 类中的 List projects 当做是 hashCode 计算的一部分（同理，equals,toString 也会存在同样的问题），而如果我的项目中出现循环引用，这就会导致死循环，最终就会抛出 StackOverFlowError。 为了验证我的想法，简化的项目中的代码后，来测试下 12345678public String testHashCode()&#123; Project project = new Project(); Project other = new Project(); other.setProjects(Arrays.asList(project)); project.setProjects(Arrays.asList(other)); System.out.println(project.hashCode()); return \"success\";&#125; 调用该代码后，复现了上述的异常。 123Exception in thread \"Tmoe.cnkirito.dependency0\" java.lang.StackOverflowError at moe.cnkirito.dependency.model.Project.hashCode(Project.java:20) at java.util.AbstracList.hashCode(AbstractList.java:541) 紧接着，继续测试下 toString 和 eqauls 方法 1234567891011121314## 测试循环引用实体类中下的 toString 方法java.lang.StackOverflowError: null at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:125) ~[na:1.8.0_161] at java.lang.AbstractStringBuilder.appendNull(AbstractStringBuilder.java:493) ~[na:1.8.0_161] at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:446) ~[na:1.8.0_161] at java.lang.StringBuilder.append(StringBuilder.java:136) ~[na:1.8.0_161] at com.qianmi.dependency.model.Project.toString(Project.java:18) ~[classes/:na]## 测试循环引用实体类中下的 equals 方法 java.lang.StackOverflowError: null at java.util.AbstractList.rangeCheckForAdd(AbstractList.java:604) ~[na:1.8.0_161] at java.util.AbstractList.listIterator(AbstractList.java:325) ~[na:1.8.0_161] at java.util.AbstractList.listIterator(AbstractList.java:299) ~[na:1.8.0_161] at java.util.AbstractList.equals(AbstractList.java:518) ~[na:1.8.0_161] at com.qianmi.dependency.model.Project.equals(Project.java:18) ~[classes/:na] 不出所料，都存在同样的问题。 这一案例可以稍微总结下，一是在使用新的技术框架（Lombok）之前没有看文档，对其特性不太了解，望文生义，认为 @Data 不会重写 hashCode 等方法，二是没有考虑到 hashCode，eqauls 等方法应该如何正确地覆盖。 回顾 JAVA 中最基础的方法： hashCode 和 equals这两个方法说是 JAVA 最基础的方法一点不为过，但往往越基础的东西越容易被人忽视，让我想起了 JAVA 闲聊群中一位长者经常吐槽的一点：『现在的面试、群聊动不动就是高并发，JVM，中间件，却把基础给遗忘了』。 我感觉很幸运，在当初刚学 JAVA 时，便接触了一本神书《effective java》，一本号称怎么夸都不为过的书，它的序是这么写的 我很希望 10 年前就拥有这本书。可能有人认为我不需要任何 Java 方面的书籍，但是我需要这本书。 ——Java 之父 James Gosling 其书中的第三章第 8 条，第 9 条阐述了 equals 和 hashCode 的一些重写原则，我将一些理论言简意赅的阐述在本节中，喜欢的话推荐去看原书哦。 第 8 条：覆盖 equals 时请遵守通用约定 什么时候应该覆盖 Object.equals 呢？如果类具有自己特有的“逻辑相等”概念（不同于对象等同的概念），而且超类还没有覆盖 equals 以实现期望的行为，这时我们就需要覆盖 equals 方法。这通常属于“值类（value class）”的情形。值类仅仅是一个表示值的类，例如 Integer 或者 Date。程序员在利用 equals 方法来比较值对象的引用时，希望知道它们在逻辑上是否相等，而不是想了解它们是否指向同一个对象。为了满足程序员的要求，不仅必需覆盖 equals 方法，而且这样做也使得这个类的实例可以被用作映射表（map）的键（key），或者集合（set）的元素，使映射或者集合表现出预期的行为。 在覆盖 equals 方法的时候，你必须要遵守它的通用约定。下面是约定的内容，来自 Object 的规范 [JavaSE6]： equals 方法实现了 等价关系（equivalence relation）： 自反性（reflexive）。对于任何非 null 的引用值 x，x.equals(x) 必须返回 true。 对称性（symmetric）。对于任何非 null 的引用值 x 和 y，当且仅当 y.equals(x) 返回 true 时，x.equals(y) 必须返回 true。 传递性（transitive）。对于任何非 null 的引用值 x、y 和 z。如果 x.equals(y) 返回 true，并且 y.equals(z) 也返回 true，那么 x.equals(z) 也必须返回 true。 一致性（consistent）。对于任何非 null 的引用值 x 和 y，只要 equals 的比较操作在对象中所用的信息没有被修改，多次调用 x.equals(x) 就会一致地返回 true，或者一致的返回 false。 对于任何非 null 的引用值 x，x.equals(null) 必须返回 false。 学过高数，离散的同学不会对上述的理论陌生，它们源自于数学理论，没了解过这些概念的同学也不必有所顾忌，因为你只需要养成习惯，在设计一个实体类时时刻惦记着上述几个关系，能符合的话大概就没有问题。结合所有这些要求，得出了以下实现高质量 equals 方法的诀窍： 使用 == 操作符检查“参数是否为这个对象的引用”。如果是，则返回 true。这只不过是一种性能优化，如果比较操作有可能很昂贵，就值得这么做。 使用 instanceof 操作符检查“参数是否为正确的类型”。如果不是，则返回 false。一般说来，所谓“正确的类型”是指 equals 方法所在的那个类。有些情况下，是指该类所实现的某个接口。如果类实现的接口改进了 equals 约定，允许在实现了该接口的类之间进行比较，那么就使用接口。集合接口（collection interface）如 Set、List、Map 和 Map.Entry 具有这样的特性。 把参数转换成正确的类型 。因为转换之前进行过 instanceof 测试，所以确保会成功。 对于该类中每个“关键（significant）域，检查参数中的域是否与该对象中对应的域相匹配”。如果这些测试全部成功，则返回 true；否则返回 false。如果第 2 步中的类型是个借口，就必须通过接口方法访问参数中的域；如果该类型是个类，也许就能够直接访问参数中的域，这要取决于它们的可访问性。 对于既不是 float 也不是 double 类型的基本类型域，可以使用 == 操作符进行比较；对于对象引用域，可以递归地调用 equals 方法；对于 float 域，可以使用 Float.compare 方法；对于 double 域，则使用 Double.compare。对于 float 和 double 域进行特殊的处理是有必要的，因为存在着 Float.NaN、-0.0f 以及类似的 double 常量；详细信息请参考 Float.equals 的文档。对于数组域，则要把以上这些指导原则应用到每个元素上。如果数组域中的每个元素都很重要，就可以使用发行版本 1.5 中新增的其中一个 Arrays.equals 方法。 有些对象引用域包含 null 可能是合法的，所以，为了避免可能导致 NullPointerException 异常，则使用下面的习惯用法来比较这样的域： 1(field == null ? o.field == null : field.equals(o.field)) 如果 field 域和 o.field 通常是相同的对象引用，那么下面的做法就会更快一些： 1(field == o.field || (field != null &amp;&amp; field.equals(o.field))) 当你编写完成了 equals 方法之后，应该问自己三个问题：它是不是对称的、传递的、一致的？ 并且不要只是自问，还要编写单元测试来检验这些特性！如果答案是否定的，就要找出原因，再相应地修改 equals 方法的代码。当然，equals 方法也必须满足其他两个特性（自反性和非空性），但是这两种特性通常会自动满足。 其他原则还包括： 覆盖 equals 时总要覆盖 hashCode。(在下一节中介绍) 不要企图让 equals 方法过于智能 。如果只是简单地测试域中的值是否相等，则不难做到遵守 equals 约定。如果想过度地去寻求各种等价关系，则很容易陷入麻烦之中。把任何一种别名形式考虑到等价的范围内，往往不会是个好主意。例如，File 类不应该视图把指向同一个文件的符号链接（symbolic link）当作相等的对象来看待。所幸 File 类没有这样做。 不要将 equals 声明中的 Object 对象替换为其他的类型 。 第 9 条：覆盖 equals 时总要覆盖 hashCode 一个很常见的错误根源在于没有覆盖 hashCode 方法。 在每个覆盖了 equals 方法的类中，也必须覆盖 hashCode 方法 。如果不这样做的话，就会违反 Object.hashcode 的通用约定，从而导致该类无法结合所有基于散列的集合一起正常工作，这样的集合包括 HashMap、HashSet 和 Hashtable。 下面是约定的内容，摘自 Object 规范 [JavaSE6]： 在应用程序的执行期间，只要对象的 equals 方法的比较操作所用到的信息没有被修改，那么对同一个对象调用多次，hashCode 方法都必须始终如一地返回同一个整数。在同一个应用程序的多次执行过程中，每次执行所返回的整数可以不一致。 如果两个对象根据 equals(Object) 方法比较是相等的，那么调用这两个对象中任意一个对象的 hashCode 方法都必须产生同样的整数结果。 如果两个对象根据 equals(Object) 方法比较是不相等的，那么调用这两个对象中任意一个对象的 hashCode 方法，则不一定要产生不同的整数结果。但是程序员应该知道，给不相等的对象产生截然不同的整数结果，有可能提高散列表（hash table）的性能。 因没有覆盖 hashCode 而违反的关键约定是第二条：相等的对象必须具有相等的散列码 *（hash code）。根据类的 equals 方法，两个截然不同的实例在逻辑上有可能是相等的，但是，根据 Object 类的 hashCode 方法，它们仅仅是两个没有任何共同之处的对象。因此，对象的 hashCode 方法返回两个看起来是随机的整数，而不是根据第二个约定所要求的那样，返回两个相等的整数。 默默看完书中的文字，是不是觉得有点哲学的韵味呢，写好一手代码真的不容易。 实战中如何重写 hashCode 和 equals？hashCode 和 equals 很重要，在使用中，与之密切相关的一般是几个容器类：HashMap 和 HashSet，意味着当我们将一个类作为其中的元素时，尤其需要考量下 hashCode 和 equals 的写法。 话不多数，即刻介绍。对了，你指望我手敲 hashCode 和 equals 吗？不存在的，程序员应该优雅的偷懒，无论你是 eclipse 玩家还是 idea 玩家，都能找到对应的快捷键，帮你自动重写这两个方式，我们要做的就是对参数的选择做一些微调。例如使用 idea 生成下面这个类的 hashCode 和 equals 方法，设置前提：将所有字段当做关键（significant）域。 123456789public class Example &#123; private int a; private float b; private double c; private BigDecimal d; private char e; private byte f; private String g;&#125; 方法一：Intellij Default12345678910111213141516171819202122232425262728293031@Overridepublic boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; if (!super.equals(o)) return false; Example example = (Example) o; if (a != example.a) return false; if (Float.compare(example.b, b) != 0) return false; if (Double.compare(example.c, c) != 0) return false; if (e != example.e) return false; if (f != example.f) return false; if (!d.equals(example.d)) return false; return g.equals(example.g);&#125;@Overridepublic int hashCode() &#123; int result = super.hashCode(); long temp; result = 31 * result + a; result = 31 * result + (b != +0.0f ? Float.floatToIntBits(b) : 0); temp = Double.doubleToLongBits(c); result = 31 * result + (int) (temp ^ (temp &gt;&gt;&gt; 32)); result = 31 * result + d.hashCode(); result = 31 * result + (int) e; result = 31 * result + (int) f; result = 31 * result + g.hashCode(); return result;&#125; 这可能是大家最熟悉的方法，先来分析下 equals 的写法。看样子的确是遵循了《effective java》中提及的 java1.6 规范的，值得注意的点再强调下：Float 和 Double 类型的比较应该使用各自的静态方法 Float.compare 和 Double.compare。 hashCode 方法则更加有趣一点，你可能会有如下的疑问： Double.doubleToLongBits 是干嘛用的？ 为啥是 31？ 为什么还有 ^，&gt;&gt;&gt; 这些运算符号？ 带着疑问来看看下面的解释。 一个好的散列函数通常倾向于“为不相等的对象产生不相等的散列码”。这正是上一节中 hashCode 约定中第三条的含义。理想情况下，散列函数应该把集合中不相等的实例均匀地分布到所有可能的散列值上。要想完全达到这种理想的情形是非常困难的。但相对接近这种理想情形则并不太苦难。《effective java》给出了一种简单的解决办法： 把某个非零的常数值，比如说 17，保存在一个名为 result 的 int 类型的变量中。 对于对象中每个关键域 f（指 equals 方法中涉及的每个域），完成以下步骤： a. 为该域计算 int 类型的散列码 c: i. 如果该域是 boolean 类型，则计算 (f ? 1 : 0). ii. 如果该域是 byte、char、short 或者 int 类型，则计算 (int)f。 iii. 如果该域是 long 类型，则计算 (int)(f ^ (f &gt;&gt;&gt; 32))。 iv. 如果该域是 float 类型，则计算 Float.floatToIntBits(f)。 v. 如果该域是 double 类型，则计算 Double.doubleToLongBits(f)，然后按照步骤 2.a.iii，为得到的 long 类型值计算散列值。 vi. 如果该域是一个对象引用，并且该域的 equals 方法通过递归地调用 equals 的方式来比较这个域，则同样为这个域递归地调用 hashCode。如果需要更复杂的比较，则为这个域计算一个“范式（canonical representation）”，然后针对这个范式调用 hashCode。如果这个域的值为 null，则返回 0（或者其他某个常数，但通常是 0）。 vii. 如果该域是一个数组，则要把每一个元素当做单独的域来处理。也就是说，递归地应用上述规则，对每个重要的元素计算一个散列码，然后根据步骤 2.b 中的做法把这些散列值组合起来。如果数组域中的每个元素都很重要，可以利用发行版本 1.5 中增加的其中一个 Arrays.hashCode 方法。 b. 按照下面的公式，把步骤 2.a 中计算得到的散列码 c 合并到 result 中： 12&gt; result = 31 * result + c;&gt; 返回 result。 写完了 hashCode 方法之后，问问自己“相等的实例是否都具有相等的散列码”。要编写单元测试来验证你的推断。如果相等实例有着不相等的散列码，则要找出原因，并修正错误。 在散列码的计算过程中，可以把 冗余域（redundant field） 排除在外。换句话说，如果一个域的值可以根据参与计算的其他域值计算出来，则可以把这样的域排除在外。必须排除 equals 比较计算中没有用到的任何域，否则很有可能违反 hashCode 约定的第二条。 上述步骤 1 中用到了一个非零的初始值，因此步骤 2.a 中计算的散列值为 0 的那些初始域，会影响到散列值。如果步骤 1 中的初始值为 0，则整个散列值将不受这些初始域的影响，因为这些初始域会增加冲突的可能性。值 17 则是任选的。 步骤 2.b 中的乘法部分使得散列值依赖于域的顺序，如果一个类包含多个相似的域，这样的乘法运算就会产生一个更好的散列函数。例如，如果 String 散列函数省略了这个乘法部分，那么只是字母顺序不同的所有字符串都会有相同的散列码。之所以选择 31，是因为它是一个奇素数。如果乘数是偶数，并且乘法溢出的话，信息就会丢失，因为与 2 相乘等价于位移运算。使用素数的好处并不很明显，但是习惯上都使用素数来计算散列结果。31 有个很好的特性，即用位移和减法来代替乘法，可以得到更好的性能，31 * i == (i &lt;&lt; 5) - i。现代的 VM 可以自动完成这种优化。 是不是几个疑惑都解开了呢？ 方法二：Objects.hash 和 Objects.equals12345678910111213141516171819@Overridepublic boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; if (!super.equals(o)) return false; Example example = (Example) o; return a == example.a &amp;&amp; Float.compare(example.b, b) == 0 &amp;&amp; Double.compare(example.c, c) == 0 &amp;&amp; e == example.e &amp;&amp; f == example.f &amp;&amp; Objects.equals(d, example.d) &amp;&amp; Objects.equals(g, example.g);&#125;@Overridepublic int hashCode() &#123; return Objects.hash(super.hashCode(), a, b, c, d, e, f, g);&#125; JAVA 是一个与时俱进的语言，有问题从自身解决，便利了开发者，如《effective java》所言，在 jdk1.6 中上述那些原则只是一纸空文。错误同真理的关系，就象睡梦同清醒的关系一样。一个人从错误中醒来，就会以新的力量走向真理。在 jdk1.7 中便造就了诸多的方法 Objects.hash 和 Objects.equals 帮助你智能的实现 hashCode 和 equals 方法。很明显，代码量上比方法一少了很多，并且有了 jdk 的原生支持，心里也更加有底了。 方法三：Lombok 的 @EqualsAndHashCode前面已经提到了 Lombok 的这个注解，在此详细介绍下这个注解的用法，方便大家写出规范的 hashCode 和 equals 方法。 此注解会生成 equals(Object other) 和 hashCode() 方法。 它默认使用非静态，非瞬态的属性 可通过参数 exclude 排除一些属性 可通过参数 of 指定仅使用哪些属性 它默认仅使用该类中定义的属性且不调用父类的方法 可通过 callSuper=true 解决上一点问题。让其生成的方法中调用父类的方法。 使用 Lombok 很便捷，整个代码也很清爽 12345678910111213@Data@EqualsAndHashCode(of = &#123;\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\"&#125;)// 默认就是所有参数public class Example &#123; private int a; private float b; private double c; private BigDecimal d; private char e; private byte f; private String g;&#125; 如果想知道编译过后的庐山真面目，也可以在 target 包中找到 Example.java 生成的 Example.class，: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public boolean equals(Object o) &#123; if (o == this) &#123; return true; &#125; else if (!(o instanceof Example)) &#123; return false; &#125; else &#123; Example other = (Example)o; if (!other.canEqual(this)) &#123; return false; &#125; else if (this.getA() != other.getA()) &#123; return false; &#125; else if (Float.compare(this.getB(), other.getB())!= 0) &#123; return false; &#125; else if (Double.compare(this.getC(), other.getC())!= 0) &#123; return false; &#125; else &#123; Object this$d = this.getD(); Object other$d = other.getD(); if (this$d == null) &#123; if (other$d != null) &#123; return false; &#125; &#125; else if (!this$d.equals(other$d)) &#123; return false; &#125; if (this.getE() != other.getE()) &#123; return false; &#125; else if (this.getF() != other.getF()) &#123; return false; &#125; else &#123; Object this$g = this.getG(); Object other$g = other.getG(); if (this$g == null) &#123; if (other$g != null) &#123; return false; &#125; &#125; else if (!this$g.equals(other$g)) &#123; return false; &#125; return true; &#125; &#125; &#125;&#125;protected boolean canEqual(Object other) &#123; return other instanceof Example;&#125;public int hashCode() &#123; int PRIME = true; int result = 1; int result = result * 59 + this.getA(); result = result * 59 + Float.floatToIntBits(this.getB()); long $c = Double.doubleToLongBits(this.getC()); result = result * 59 + (int)($c &gt;&gt;&gt; 32 ^ $c); Object $d = this.getD(); result = result * 59 + ($d == null ? 43 : $d.hashCode()); result = result * 59 + this.getE(); result = result * 59 + this.getF(); Object $g = this.getG(); result = result * 59 + ($g == null ? 43 : $g.hashCode()); return result;&#125; 大致和前两种行为一致，这里选择素数从 31 替换成了 59，没有太大差异。 总结我在开发时也曾考虑一个问题：一个数据库持久化对象到底怎么正确覆盖 hashCode 和 equals？以订单为例，是用主键 id 来判断，还是 流水编号 orderNo 来判断，可能没有准确的答案，各有各的道理，但如果将它丢进 HashSet，HashMap 中就要额外注意，hashCode 和 equals 会影响它们的行为！ 这次 Lombok 发生的惨案主要还是由于不合理的 hashCode 和 equals（也包括了 toString）方法导致的，循环引用这种问题虽然没有直接在《effective java》中介绍，但一个引用，一个集合类是不是应该作为 hashCode 和 equals 的关键域参与计算，还是值得开发者仔细推敲的。本文还介绍了一些 hashCode 和 equals 的通用原则，弱弱地推荐 Lombok 便捷开发，强烈安利《effective java》一书。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"JAVA 拾遗 --Future 模式与 Promise 模式","slug":"future-and-promise","date":"2018-03-28T10:22:14.000Z","updated":"2019-09-26T09:45:31.085Z","comments":true,"path":"future-and-promise/","link":"","permalink":"http://lexburner.github.io/future-and-promise/","excerpt":"写这篇文章的动机，是缘起于微信闲聊群的一场讨论，粗略整理下，主要涉及了以下几个具体的问题：","text":"写这篇文章的动机，是缘起于微信闲聊群的一场讨论，粗略整理下，主要涉及了以下几个具体的问题： 同步，异步，阻塞，非阻塞的关联及区别。 JAVA 中有 callback 调用吗？ jdk 包中的 Future 怎么用？ Future 模式和 Promise 模式是包含的关系，还是交集的关系，还是没有关系？ 带着上面这些疑问，来看看我到底要拾遗些啥。 浅析同步，异步，阻塞，非阻塞这几个概念一直困扰着我，说实话我现在依旧不能从一个很深的层次去和一个小白解释，这几个概念到底有什么区别。本节我不掺杂自己的描述，主要列出几个我学习过程中认为不错的点，分享给大家，以供诸位理解。 翻看知乎高赞答案，『怎样理解阻塞非阻塞与同步异步的区别？』 文章从『消息通信机制』和『程序在等待调用结果时的状态』两个方面来区分这两组概念，并举例说明了理解他们的方式。但我相信很多人会有跟我一样的感觉，例子看的时候都觉得自己懂了，但要从理论上的层面去解释，又会觉得词穷。以至于一探讨到这四个概念，大家都开始了举例子大会。 正确理解这四个概念，有很多前置条件，比如得框定上下文，Linux 中的 network IO 具有“同步，异步，阻塞，非阻塞”这些概念，而 JAVA 相关框架以及原生 jdk 也涉及这些概念（比如 socket，netty），他们具有很多的相似性，但概念又不尽相同，这也是导致这几个概念难以被理解的原因。从 Linux 层面来理解这几个概念的区别，我也找到一篇不错的文章：『IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇）』 如果想要从 JAVA 的角度来理解这四个概念，就必须对 IO 模型有所了解，首先明晰如下的概念：Java 对于 IO 的封装分为 BIO、NIO 和 AIO。Java 目前并不支持异步 IO，BIO 对应的是阻塞同步 IO，NIO 和 AIO 对应的都是非阻塞同步 IO。特别是最后一点有不少文章会曲解，认为 AIO 是异步 IO。细致的讲解可以参考张亮大神的这篇文章：https://mp.weixin.qq.com/s/uDgueoMIEjl-HCE_fcSmSw 同步调用模式我个人认为，一味地想要搞清楚上述这四个知识点，对我们理解方法调用模式并不会有太大帮助。我们来看看下面的这个比较简单的例子。 1234567891011121314151617181920212223public class SyncDemo &#123; public static void main(String[] args) throws InterruptedException &#123; long l = System.currentTimeMillis(); int i = syncCalculate(); System.out.println(\"计算结果:\" + i); System.out.println(\"主线程运算耗时:\" + (System.currentTimeMillis() - l)+ \"ms\"); &#125; // 最常用的同步调用 static int syncCalculate() &#123; System.out.println(\"执行耗时操作...\"); timeConsumingOperation(); return 100; &#125; static void timeConsumingOperation() &#123; try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 控制台输出： 1执行耗时操作... 计算结果:100 主线程运算耗时:3000 ms 同步调用模式是我们最最最常用的方式，如果是业务开发，几乎 99% 的方法是同步方法。再回到一开始的纠结点：是同步调用还是异步调用，毫无疑问是同步调用；是阻塞还是非阻塞？其实压根就不涉及到这个问题，说是阻塞也没毛病，syncCalculate 方法阻塞了主线程，但我们通常不会讨论这里是阻塞还是非阻塞。 Future 模式上述的例子是较为简单的引子，本节将会介绍 JAVA 中的 Future 模式。上述的 syncCalculate 方法是一个耗时的操作，为了优化性能，我们可以考虑使用 Future 模式。Future 模式相当于一个占位符，代表一个操作的未来的结果，其简单的概念不在本文中介绍，直接给出总结：Future 模式可以细分为将来式和回调式两种模式。 Future 模式 – 将来式 1 12345678910111213141516171819202122232425public class FutureDemo1 &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; long l = System.currentTimeMillis(); ExecutorService executorService = Executors.newSingleThreadExecutor(); Future&lt;Integer&gt; future = executorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; System.out.println(\"执行耗时操作...\"); timeConsumingOperation(); return 100; &#125; &#125;); //&lt;1&gt; // 其他耗时操作..&lt;3&gt; System.out.println(\"计算结果:\" + future.get());//&lt;2&gt; System.out.println(\"主线程运算耗时:\" + (System.currentTimeMillis() - l)+ \"ms\"); &#125; static void timeConsumingOperation() &#123; try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 控制台输出： 1执行耗时操作... 计算结果:100 主线程运算耗时:3007 ms 将回调接口交给线程池去执行，这一步是非阻塞的，返回了一个运算结果的占位符 –future。 在这一步中我们调用了 future 的 get 方法，那么如果 future 的计算还未完成，主线程将会被这一步阻塞。 我们观察一下控制台的输出，发现依旧耗费 3s 来完成这次耗时操作，并没有比同步调用方式快。但是提交任务（非阻塞）和获取结果（阻塞）之间我们可以进行一些额外的操作，而这将形成一个并行执行的效果。 我们会发现如果 future 提交给线程池执行之后立刻 get()，其实执行效率并不会变高，反而由于线程的开销会比同步调用更慢。这种将来式的 future 适用多个耗时操作并发执行的场景。 Future 模式 – 将来式 2 除了这个阻塞式的 get() 获取结果，jdk 的 future 还提供了非阻塞式的方式用来获取 future 的结果。查看 jdk 中 Future 的定义： 1234567891011public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 其中可以通过轮询 isDone()方法来达到非阻塞式获取结果的效果。但个人认为与阻塞式的 get() 并没有什么差异，实际项目中也没有需要使用非阻塞式的场景。 Future 模式 – 回调式 写过前端 ajax 代码的朋友对 callback 的写法并不会陌生，而 Future 模式的第二种用法便是回调。很不幸的事，jdk 实现的 Future 并没有实现 callback,addListener 这样的方法，想要在 JAVA 中体验到 callback 的特性，得引入一些额外的框架。 回调式实现一 –Netty Netty 除了是一个高性能的网络通信框架之外，还对 jdk 的 Future 做了扩展，翻看其文档 http://netty.io/wiki/using-as-a-generic-library.html#wiki-h2-5 可以发现其扩展了一个 listener 接口。 引入 Netty 的 maven 依赖 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.22.Final&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930public class NettyFutureDemo &#123; public static void main(String[] args) throws InterruptedException &#123; long l = System.currentTimeMillis(); EventExecutorGroup group = new DefaultEventExecutorGroup(4); Future&lt;Integer&gt; f = group.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; System.out.println(\"执行耗时操作...\"); timeConsumingOperation(); return 100; &#125; &#125;); f.addListener(new FutureListener&lt;Object&gt;() &#123; @Override public void operationComplete(Future&lt;Object&gt; objectFuture) throws Exception &#123; System.out.println(\"计算结果:：\" + objectFuture.get()); &#125; &#125;); System.out.println(\"主线程运算耗时:\" + (System.currentTimeMillis() - l)+ \"ms\"); new CountDownLatch(1).await(); &#125; static void timeConsumingOperation() &#123; try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 控制台输出： 1主线程运算耗时:329 ms 执行耗时操作... 计算结果:：100 结果分析：使用了 addListener 这样的方法为一个 future 结果添加回调，从而达到“当耗时操作完成后，自行触发钩子去执行打印操作”的效果。细心的朋友会发现，主线程只耗费了不到 1s 的时间，整个过程没有被耗时操作阻塞，这才是异步编程的推荐方式：回调。 回调式实现二 –Guava 不仅仅 Netty 想到了这一点，google 提供的扩展包 Guava 也为回调式的 Future 提供了实现，其核心接口为 引入 Guava 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;21.0&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132public class GuavaFutureDemo &#123; public static void main(String[] args) throws InterruptedException &#123; long l = System.currentTimeMillis(); ListeningExecutorService service = MoreExecutors.listeningDecorator(Executors.newSingleThreadExecutor()); ListenableFuture&lt;Integer&gt; future = service.submit(new Callable&lt;Integer&gt;() &#123; public Integer call() throws Exception &#123; System.out.println(\"执行耗时操作...\"); timeConsumingOperation(); return 100; &#125; &#125;);//&lt;1&gt; Futures.addCallback(future, new FutureCallback&lt;Integer&gt;() &#123; public void onSuccess(Integer result) &#123; System.out.println(\"计算结果:\" + result); &#125; public void onFailure(Throwable throwable) &#123; System.out.println(\"异步处理失败,e=\" + throwable); &#125; &#125;);//&lt;2&gt; System.out.println(\"主线程运算耗时:\" + (System.currentTimeMillis() - l)+ \"ms\"); new CountDownLatch(1).await(); &#125; static void timeConsumingOperation() &#123; try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 控制台输出： 1执行耗时操作... 主线程运算耗时:65 ms 计算结果:100 结果分析：几乎和 Netty 的异步回调效果一样，在这儿顺便补充一下之前我自己学习时的一个疑惑：我一直会担心一个问题，由于 处的执行是异步，会不会存在一种特殊情况，即 future 结果已经计算好了，但 操作添加监听器还未执行完成，会导致接收不到回调。实际上后来翻阅了一些资料，这么写是没问题的，无论是在何时 addListener，都可以接收到异步回调。 由 Callback Hell 引出 Promise 模式同样的如果你对 ES6 有所接触，就不会对 Promise 这个模式感到陌生，如果你对前端不熟悉，也不要紧，我们先来看看回调地狱（Callback Hell）是个什么概念。 回调是一种我们推崇的异步调用方式，但也会遇到问题，也就是回调的嵌套。当需要多个异步回调一起书写时，就会出现下面的代码 (以 js 为例): 123456789asyncFunc1(opt, (...args1) =&gt; &#123; asyncFunc2(opt, (...args2) =&gt; &#123; asyncFunc3(opt, (...args3) =&gt; &#123; asyncFunc4(opt, (...args4) =&gt; &#123; // some operation &#125;); &#125;); &#125;);&#125;); 虽然在 JAVA 业务代码中很少出现回调的多层嵌套（至少我目前的业务没有接触过），但总归是个问题，这样的代码不易读，嵌套太深修改也麻烦。于是 ES6 提出了 Promise 模式来解决回调地狱的问题。由于我的博客主要还是面向于 JAVA 读者，就不介绍 JavaScript 中的 Promise 用法了。可能就会有人想问：java 中存在 Promise 模式吗？答案是肯定的。 前面提到了 Netty 和 Guava 的扩展都提供了 addListener 这样的接口，用于处理 Callback 调用，但其实 jdk1.8 已经提供了一种更为高级的回调方式：CompletableFuture。首先尝试用 CompletableFuture 来解决回调的问题。 1234567891011121314151617181920212223public class CompletableFutureDemo &#123; public static void main(String[] args) throws InterruptedException &#123; long l = System.currentTimeMillis(); CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(\"执行耗时操作...\"); timeConsumingOperation(); return 100; &#125;); completableFuture.whenComplete((result, e) -&gt; &#123; System.out.println(\"结果：\" + result); &#125;); System.out.println(\"主线程运算耗时:\" + (System.currentTimeMillis() - l)+ \"ms\"); new CountDownLatch(1).await(); &#125; static void timeConsumingOperation() &#123; try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 控制台输出： 1执行耗时操作... 主线程运算耗时:55 ms 结果：100 可以发现耗时操作没有占用主线程的时间片，达到了异步调用的效果。我们也不需要引入任何第三方的依赖，这都是依赖于 java.util.concurrent.CompletableFuture 的出现。CompletableFuture 提供了近 50 多个方法，大大便捷了 java 多线程操作，和异步调用的写法。 使用 CompletableFuture 解决回调地狱问题： 123456789101112131415161718192021222324252627282930public class CompletableFutureDemo &#123; public static void main(String[] args) throws InterruptedException &#123; long l = System.currentTimeMillis(); CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(\"在回调中执行耗时操作...\"); timeConsumingOperation(); return 100; &#125;); completableFuture = completableFuture.thenCompose(i -&gt; &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(\"在回调的回调中执行耗时操作...\"); timeConsumingOperation(); return i + 100; &#125;); &#125;);//&lt;1&gt; completableFuture.whenComplete((result, e) -&gt; &#123; System.out.println(\"计算结果:\" + result); &#125;); System.out.println(\"主线程运算耗时:\" + (System.currentTimeMillis() - l)+ \"ms\"); new CountDownLatch(1).await(); &#125; static void timeConsumingOperation() &#123; try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 控制台输出： 1在回调中执行耗时操作... 主线程运算耗时:63 ms 在回调的回调中执行耗时操作... 计算结果:200 使用 thenCompose 或者 thenComposeAsync 等方法可以实现回调的回调，且写出来的方法易于维护。 总结同步，异步，阻塞，非阻塞的理解需要花费很大的精力，从 IO 模型和内核进行深入地理解，才能分清区别。在日常开发中往往没必要过于纠结到底是何种调用，但得对调用的特性有所了解，比如是否占用主线程的时间片，出现异常怎么捕获，超时怎么解决等等（后面这些本文未介绍）。 Future 有两种模式：将来式和回调式。而回调式会出现回调地狱的问题，由此衍生出了 Promise 模式来解决这个问题。这才是 Future 模式和 Promise 模式的相关性。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"离开魔都后的一点感想","slug":"thinking-1","date":"2018-03-19T14:18:51.000Z","updated":"2019-09-26T09:45:30.247Z","comments":true,"path":"thinking-1/","link":"","permalink":"http://lexburner.github.io/thinking-1/","excerpt":"","text":"看过我公众号简介的朋友会发现，我公众号的定位是分享一些个人的技术博客和杂谈，这其中的杂谈不仅包括了技术杂谈，也包含了自己的一些感悟。所以借此澄清，这是一篇杂文！总结了我在魔都这一年半不同角度的感悟。 技术沙龙我前几天刚发过一个朋友圈：魔都得天独厚的优势便是各种技术沙龙，其中不乏有很多是免费的。我在魔都这些日子，参加了大概 13-15 场技术沙龙。参加这种技术分享会的动机很单纯，大家都是去学习互联网最前沿的技术的，但隐性的好处也很多： 你可以认识很多跟你同样有积极性的同行们，试想一下，这样一批放弃了周末休息时间，不睡懒觉，不打游戏，不陪妹子的人，必然是对技术充满了热情的一帮人。我有不少微信好友是在技术分享会上添加的。 有些朋友身处传统行业，平时的业务接触不到高并发，JVM 这些看似高大上的名词，但是技术沙龙带来了这样的可能性，让你没吃过猪肉，至少见过猪跑。映像比较深刻的是“美团点评技术团队”定期举办的技术沙龙，参加了两次，分享的很棒，而且大多数情况下，只需要在 APP 中报名即可参加。 同行间的技术方案分享。很有可能你正在负责公司某块业务的技术选型，而沙龙正好涉及了相关的内容，可以静静聆听下别人的解决方案，通过别人落地的架构，来指导自己的选型。这一点我也有例子真实的例子与之对应，大概是 17 年初，有一场 daocloud 举办的 springcloud 社区沙龙，由 DD 带来的 zuul 源码解读以及案例分享，记忆尤为深刻，当时我所在的公司也恰巧在对 zuul 进行改造，而 DD 分享的主题对于我的工作非常有帮助。 参加过不少沙龙，也踩过不少坑，我甚至误打误撞参加过两次“偏运维的技术分享”，权当作经历吧，总结参加的技术沙龙后，有以下几点建议：选择人数少的沙龙，越大的技术分享，讲师越想着受众面广，从而扼不住主题，会出现很多干货之外的内容；多举手提问，事实上我参加过的沙龙，我都会主动举手提问，并且是主持人刚问完“有没有观众有问题的”，我就立马举手，这时候大家都比较内敛，自己的命中率才会高。为什么要举手提问？期待讲师一句话把你的疑惑讲清楚是不现实的，但是这创造了你们后续交流的话题。分享结束后，主动加讲师的微信，进入深度交流阶段，这时候你便多了一个大牛好友。大牛好友用来干嘛？也不必指望为你解答疑惑，如果可以当然最好，偶尔看看他们的朋友圈都在分享些什么，至少能掌握最前沿的信息；有网红讲师参加的技术分享，尤其需要做好功课，刷几遍讲师最近的博客，提问时简明扼要的说出你提前准备了几天的问题，带上讲师出版的书索要签名，这样做的效果谁用谁知道。 [活动行] 是一款非常不错的 APP，再算上各个公众号（如 IT 大咖说），各种技术峰会（这个门票可能会有点贵，自费用户比较吃力），周末完全可以很充实。 博客 / 公众号与知识付费这几个词放到一起说，作为一个博主 &amp; 公众号作者，我接触到很多这个圈子的人，他们聪明，努力，乐于分享，而且往往是各自领域最厉害的那群人。以公众号粉丝数来评价，有近 10w 粉丝的大 V（在某个专业领域拥有这么多粉丝我认为已经算的上是 V 了，不同于鸡汤文作者受众广）；以努力程度来评价，深夜 1-2 点还在桌边伏案的博主不在少数，就拿「芋艿源码」的博主「芋艿」来说吧，加班回家的地铁上笔记本一摊开就是一顿源码分析，年纪也老大不小了，保持着如同刚开始工作一般的热情，丝毫不给我们这些年轻人一口喘气的机会；还有一些博主，身处互联网公司，加班严重，依旧会挤出时间分享一线互联网的工作经验。身处这样一群人中间，时刻让你体会到什么叫「比你优秀的人还比你努力」。 介绍完我的所见，来聊聊我的所想，写作到底有什么意义。 一个直观的体验是成就感，当你的文章确切地帮助到了别人，获得了阅读量与赞，便会由衷地受到鼓舞，从而激发自己的创作欲。你会迸发出下一个目标，去帮助更多的人。收获自然也是会有的，靠公众号和博客积攒出的粉丝，成了那些知名博主的第一批付费粉丝。知名大牛在「极客时间」，「得到」等付费平台活跃，不愿意抛头露面的博主也有「知识星球」这样的平台和自己付费粉丝互动。知识付费是件好事，粉丝出了物力，赞助了自己认同的博主，交过钱后自然会更加用心；博主也有了挣钱的动力，一定会有激励作用，同时也会更加对自己的粉丝负责。未来这一块必然会越来越普及。 二来还是回到人脉、眼界这样的话题，当有了博主这个身份，被拉进一些社区原创作者交流群便成了顺利成章的事，在大佬云集的群里默默地看着讨论的话题，会提升自己的眼界。收到猎头的邮件也成了日常的习惯，来自 github 的招聘启事和来自博客的猎头，HR 流量可能会让你不堪其扰，那种感到愉悦的骚扰。「先生，游泳健身了解一下」下一份工作机会，可能就是来自于你的博客 &amp; 公众号，毕竟这两个东西比你的简历更会说话。 魔都的生活大四上初到上海寻找实习机会，直到今年 3 月份离开，算是有一年半了，对魔都这个陌生的城市也算了解了不少。年轻时不来魔都闯闯，后面迟早会有这个念头的，不如趁早体验下：高峰时期人潮拥挤的 1 号线，与日常乘坐的 9 号线末站，这都是魔都。跟同事去过人山人海的城隍庙，并没有太多惊喜，反倒是无意间逛到的思南路，仿佛给人穿越到欧洲小镇的错觉，惊喜。高楼林立下的田子坊，和远在厦门的鼓浪屿竟让我难以区分，这种相似只是那种一瞬间的感觉，最后留在脑海中的回忆还是在上海这种繁华的大都市竟然还有这样的净土。无论是浦东图书馆静谧的翻书声还是 MAO Livehouse 震颤到心脏的摇滚声，和同事们在外滩留下的足迹，联洋广场令人流连忘返的捞王… 魔都从不缺少物质享受。 说回魔都的工作，特指 IT 行业，也有了自己的一点认知，都说一线城市是北上广深，但说到底，上海的 IT/ 互联网并不是原以为的那样发达。美团点评，唯品会，饿了么，携程说大也大，还有金融领域的陆金所，蚂蚁金服（刚搬来）但总体来说肯定比不上北京，但这丝毫阻挡不了江浙沪有志青年的热情，即使有房价这个负面光环加护。 上海的压力来自于各个方面：孤独，消费，房价，工作额度，任意一个方面都会击垮一个人，再加上互联网的人来人往，都让我感受到上海这座现代化都市背后的冷漠。初到南京，HR 问我为什么不在上海发展，我竟答不出来。是啊，普遍都认为上海机遇更多，但是，机遇的定义没人说的清，正如离开上海的原因说不清一般。值得留恋的景，值得留恋的机遇，值得留恋的人，都带不走。 应届生的境遇到了 18 年的春招，似乎已经挂不上「应届生」的名号了。时隔毕业半年多，同学们的工作也都稳定了下来，校园时光真的只存在于念想中了。曾经的自己仰仗着自己的应届光环，如今办理入职后才发现，自己已经是往届生了，有什么区别？心境真的会变，我自觉认识到再也不能仗着应届那么有恃无恐了。现在的职场上必须得拿能力和那些工作比你早几年接触工作的人去竞争了，应聘时再也不会说：我是来贵司学习的。公司需要为之创造价值的人，说来不怕矫情，以上这种念头最近在脑海中酝酿了很久。 与应届生相对的是那些工作十几年的老人，为什么放到这儿一起说，主要是在魔都见识到了一些年纪较大的应聘者，简历空有十年工作经验，实际怕是十个一年经验。不知道是否只有我会出现这种情况，刚毕业时知识储备不足每天下班坚持看书，看文章都不觉累，反倒是工作半年后有了熟练度了，这股学习的激情会下降。这点我尤其佩服我原来的老大和朋友圈一些年纪较大的程序员，几年如一日地对技术痴迷。警惕成为一个重复工作的码农。 学习技巧编程技术如何精进？我秉承自上而下的顺序来谈下自己的思考，仅供各位参考。 业务驱动型。编程是为了解决问题，如果你的程序应用于生产中，这是最锻炼编码水平，无论是导入一个超大的 excel 这种小 case，还是抗住千万级别并发的电商系统，伴随着业务问题而进行的 coding 最有意义。反观我交接的最后一个星期，干不了什么活，都是些零碎琐事，完全提炼不出什么精髓用于写作。如果你的系统日活只有几百，考虑百万级别的并发压力实属是杞人忧天，还是优先把项目上线了更为实在。 源码阅读型。talk is cheap，show me the code。大多数设计精良的框架源码都伴随着巧妙的设计和丰富的注释，这些是学习编码技巧的绝佳途径，代码不会说谎，他就放在那儿，关键就在于你愿不愿点进去，去分析他。很多人拒绝阅读源码，自认为水平不够，其实实在是妄自菲薄，很多优秀的源码（如 spring）不仅可以提升你对框架工作原理的理解，也有助于自身编码的规范。 文档型。很多技术博客文章来源于这项技术的官方文档，很多小白喜欢阅读博客，殊不知博客已经是别人二次消化后的产物，存在不少理解的缺失。再者，较为前沿的技术，第一手博客还没出产，只有官方文档，比如 springboot 2.0，其实官方文档已经很细致入微地介绍了各种特性，完全没必要等待别人的翻译。学习一门新的技术，我通常的做法是：博客了解其大概用途，紧接着直接阅读官方文档，同时也避免了版本滞后性等问题。 博客型、搜索引擎型。这两者放到最下面，并不是排斥它们，也不是在否认 google 和 Stack Overflow 的伟大。而是想提出这样的观点：博客和搜索引擎适用于解决问题，从宏观的了解一项技术。博客和搜索引擎并不向你保证其准确性，他只告诉这样做或许有效，这样做或许正确。但是好处也很明显，经过了博主的梳理，可以更好的帮助读者建立知识体系，毕竟我自己也是写博客的 [微笑 face]，但不要忘了有空去翻一翻 2，3 两点 夜深了，先写这么多吧。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"}]},{"title":"深入理解 RPC 之集群篇","slug":"rpc-cluster","date":"2018-02-27T14:18:51.000Z","updated":"2019-09-26T09:45:29.714Z","comments":true,"path":"rpc-cluster/","link":"","permalink":"http://lexburner.github.io/rpc-cluster/","excerpt":"","text":"上一篇文章分析了服务的注册与发现，这一篇文章着重分析下 RPC 框架都会用到的集群的相关知识。 集群 (Cluster) 本身并不具备太多知识点，在分布式系统中，集群一般涵盖了负载均衡（LoadBalance），高可用（HA），路由（Route）等等概念，每个 RPC 框架对集群支持的程度不同，本文着重分析前两者 – 负载均衡和高可用。 集群概述在此之前的《深入理解 RPC》系列文章，对 RPC 的分析着重还是放在服务之间的点对点调用，而分布式服务中每个服务必然不止一个实例，不同服务的实例和相同服务的多个实例构成了一个错综复杂的分布式环境，在服务治理框架中正是借助了 Cluster 这一层来应对这一难题。还是以博主较为熟悉的 motan 这个框架来介绍 Cluster 的作用。 先来看看 Cluster 的顶层接口： 1234567891011@Spi(scope = Scope.PROTOTYPE)public interface Cluster&lt;T&gt; extends Caller&lt;T&gt; &#123; @Override void init(); void setUrl(URL url); void setLoadBalance(LoadBalance&lt;T&gt; loadBalance);//&lt;1&gt; void setHaStrategy(HaStrategy&lt;T&gt; haStrategy);//&lt;2&gt; void onRefresh(List&lt;Referer&lt;T&gt;&gt; referers); List&lt;Referer&lt;T&gt;&gt; getReferers(); LoadBalance&lt;T&gt; getLoadBalance();&#125; 在概述中，我们只关心 Cluster 接口中的两个方法，它揭示了 Cluster 在服务治理中的地位 指定负载均衡算法 指定高可用策略（容错机制） 我们需要对所谓的负载均衡策略和高可用策略有一定的理解，才能够搞清楚集群是如何运作的。 负载均衡说到负载均衡，大多数人可能立刻联想到了 nginx。负载均衡可以分为服务端负载均衡和客户端负载均衡，而服务端负载均衡又按照实现方式的不同可以划分为软件负载均衡和硬件负载均衡，nginx 便是典型的软件负载均衡。而我们今天所要介绍的 RPC 中的负载均衡则主要是客户端负载均衡。如何区分也很简单，用笔者自己的话来描述下 在 RPC 调用中，客户端持有所有的服务端节点引用，自行通过负载均衡算法选择一个节点进行访问，这便是客户端负载均衡。 客户端如何获取到所有的服务端节点引用呢？一般是通过配置的方式，或者是从上一篇文章介绍的服务注册与发现组件中获取。 负载均衡接口分析motan 中的负载均衡抽象： 1234567@Spi(scope = Scope.PROTOTYPE)public interface LoadBalance&lt;T&gt; &#123; void onRefresh(List&lt;Referer&lt;T&gt;&gt; referers); Referer&lt;T&gt; select(Request request);//&lt;1&gt; void selectToHolder(Request request, List&lt;Referer&lt;T&gt;&gt; refersHolder); void setWeightString(String weightString);&#125; ribbon 中的负载均衡抽象： 12345public interface IRule&#123; public Server choose(Object key);//&lt;1&gt; public void setLoadBalancer(ILoadBalancer lb); public ILoadBalancer getLoadBalancer();&#125; 对比下两个 RPC 框架对负载均衡的抽象可以发现，其实负载均衡策略干的事很简单，就是根据请求返回一个服务节点。在 motan 中对服务端的点对点调用抽象成了 Referer，而在 ribbon 中则是 Server。 几种负载均衡算法负载均衡算法有几种经典实现，已经是老生常谈了，总结后主要有如下几个： 轮询（Round Robin） 加权轮询（Weight Round Robin） 随机（Random） 加权随机（Weight Random） 源地址哈希（Hash） 一致性哈希（ConsistentHash） 最小连接数（Least Connections） 低并发优先（Active Weight） 每个框架支持的实现都不太一样，如 ribbon 支持的负载均衡策略 ： 策略名 策略描述 实现说明 BestAvailableRule 选择一个最小并发请求的 server 逐个考察 Server，如果 Server 被 tripped 了，则忽略，在选择其中 ActiveRequestsCount 最小的 server AvailabilityFilteringRule 过滤掉那些因为一直连接失败的被标记为 circuit tripped 的后端 server，并过滤掉那些高并发的的后端 server（active connections 超过配置的阈值） 使用一个 AvailabilityPredicate 来包含过滤 server 的逻辑，其实就就是检查 status 里记录的各个 server 的运行状态 WeightedResponseTimeRule 根据响应时间分配一个 weight，响应时间越长，weight 越小，被选中的可能性越低。 一个后台线程定期的从 status 里面读取评价响应时间，为每个 server 计算一个 weight。Weight 的计算也比较简单 responsetime 减去每个 server 自己平均的 responsetime 是 server 的权重。当刚开始运行，没有形成 status 时，使用 RoundRobinRule 策略选择 server。 RetryRule 对选定的负载均衡策略机上重试机制。 在一个配置时间段内当选择 server 不成功，则一直尝试使用 subRule 的方式选择一个可用的 server RoundRobinRule roundRobin 方式轮询选择 server 轮询 index，选择 index 对应位置的 server RandomRule 随机选择一个 server 在 index 上随机，选择 index 对应位置的 server ZoneAvoidanceRule 复合判断 server 所在区域的性能和 server 的可用性选择 server 使用 ZoneAvoidancePredicate 和 AvailabilityPredicate 来判断是否选择某个 server，前一个判断判定一个 zone 的运行性能是否可用，剔除不可用的 zone（的所有 server），AvailabilityPredicate 用于过滤掉连接数过多的 Server。 motan 支持的负载均衡策略 ： 策略名 策略描述 Random 随机选择一个 server RoundRobin roundRobin 方式轮询选择 server ConsistentHash 一致性 Hash，保证同一源地址的请求落到同一个服务端，能够应对服务端机器的动态上下线 (实际上并没有严格做到一致性 hash，motan 的实现只能满足粘滞 hash，只保证 server 节点变更周期内相同对请求落在相同的 server 上，比较适合用在二级缓存场景) LocalFirst 当 server 列表中包含本地暴露的可用服务时，优先使用此服务。否则使用低并发优先 ActiveWeight 负载均衡策略 ActiveWeight 并发量越小的 server，优先级越高 ConfigurableWeight 加权随机 算法很多，有些负载均衡算法的实现复杂度也很高，请教了一些朋友，发现用的最多还是 RoundRobin，Random 这两种。可能和他们实现起来很简单有关，很多运用到 RPC 框架的项目也都是保持了默认配置。 而这两种经典复杂均衡算法实现起来是很简单的，在此给出网上的简易实现，方便大家更直观的了解。 服务列表 1234567891011121314151617181920212223public class IpMap&#123; // 待路由的 Ip 列表，Key 代表 Ip，Value 代表该 Ip 的权重 public static HashMap&lt;String, Integer&gt; serverWeightMap = new HashMap&lt;String, Integer&gt;(); static &#123; serverWeightMap.put(\"192.168.1.100\", 1); serverWeightMap.put(\"192.168.1.101\", 1); // 权重为 4 serverWeightMap.put(\"192.168.1.102\", 4); serverWeightMap.put(\"192.168.1.103\", 1); serverWeightMap.put(\"192.168.1.104\", 1); // 权重为 3 serverWeightMap.put(\"192.168.1.105\", 3); serverWeightMap.put(\"192.168.1.106\", 1); // 权重为 2 serverWeightMap.put(\"192.168.1.107\", 2); serverWeightMap.put(\"192.168.1.108\", 1); serverWeightMap.put(\"192.168.1.109\", 1); serverWeightMap.put(\"192.168.1.110\", 1); &#125;&#125; 轮询（Round Robin） 12345678910111213141516171819202122232425262728public class RoundRobin&#123; private static Integer pos = 0; public static String getServer() &#123; // 重建一个 Map，避免服务器的上下线导致的并发问题 Map&lt;String, Integer&gt; serverMap = new HashMap&lt;String, Integer&gt;(); serverMap.putAll(IpMap.serverWeightMap); // 取得 Ip 地址 List Set&lt;String&gt; keySet = serverMap.keySet(); ArrayList&lt;String&gt; keyList = new ArrayList&lt;String&gt;(); keyList.addAll(keySet); String server = null; synchronized (pos) &#123; if (pos &gt; keySet.size()) pos = 0; server = keyList.get(pos); pos ++; &#125; return server; &#125;&#125; 随机（Random） 1234567891011121314151617181920public class Random&#123; public static String getServer() &#123; // 重建一个 Map，避免服务器的上下线导致的并发问题 Map&lt;String, Integer&gt; serverMap = new HashMap&lt;String, Integer&gt;(); serverMap.putAll(IpMap.serverWeightMap); // 取得 Ip 地址 List Set&lt;String&gt; keySet = serverMap.keySet(); ArrayList&lt;String&gt; keyList = new ArrayList&lt;String&gt;(); keyList.addAll(keySet); java.util.Random random = new java.util.Random(); int randomPos = random.nextInt(keyList.size()); return keyList.get(randomPos); &#125;&#125; 高可用策略高可用（HA）策略一般也被称作容错机制，分布式系统中出错是常态，但服务却不能停止响应，6 个 9 一直是各个公司的努力方向。当一次请求失败之后，是重试呢？还是继续请求其他机器？抑或是记录下这次失败？下面是集群中的几种常用高可用策略： 失效转移（failover） 当出现失败，重试其他服务器，通常用于读操作等幂等行为，重试会带来更长延迟。该高可用策略会受到负载均衡算法的限制，比如失效转移强调需要重试其他机器，但一致性 Hash 这类负载均衡算法便会与其存在冲突（个人认为一致性 Hash 在 RPC 的客户端负载均衡中意义不是很大） 快速失败（failfast） 只发起一次调用，失败立即报错，通常用于非幂等性的写操作。 如果在 motan，dubbo 等配置中设置了重试次数 &gt;0，又配置了该高可用策略，则重试效果也不会生效，由此可见集群中的各个配置可能是会相互影响的。 失效安全（failsafe） 出现异常时忽略，但记录这一次失败，存入日志中。 失效自动恢复（failback） 后台记录失败请求，定时重发。通常用于消息通知操作。 并行调用（forking） 只要一个成功即返回，通常用于实时性要求较高的读操作。需要牺牲一定的服务资源。 广播（broadcast） 广播调用，所有提供逐个调用，任意一台报错则报错。通常用于更新提供方本地状态，速度慢，任意一台报错则报错。 高可用接口分析以 motan 的 HaStrategy 为例来介绍高可用在集群中的实现细节 12345@Spi(scope = Scope.PROTOTYPE)public interface HaStrategy&lt;T&gt; &#123; void setUrl(URL url); Response call(Request request, LoadBalance&lt;T&gt; loadBalance);//&lt;1&gt;&#125; 如我之前所述，高可用策略依赖于请求和一个特定的负载均衡算法，返回一个响应。 快速失败（failfast） 123456789@SpiMeta(name = \"failfast\")public class FailfastHaStrategy&lt;T&gt; extends AbstractHaStrategy&lt;T&gt; &#123; @Override public Response call(Request request, LoadBalance&lt;T&gt; loadBalance) &#123; Referer&lt;T&gt; refer = loadBalance.select(request); return refer.call(request); &#125;&#125; motan 实现了两个高可用策略，其一便是 failfast，非常简单，只进行一次负载均衡节点的选取，接着发起点对点的调用。 失效转移（failover） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@SpiMeta(name = \"failover\")public class FailoverHaStrategy&lt;T&gt; extends AbstractHaStrategy&lt;T&gt; &#123; protected ThreadLocal&lt;List&lt;Referer&lt;T&gt;&gt;&gt; referersHolder = new ThreadLocal&lt;List&lt;Referer&lt;T&gt;&gt;&gt;() &#123; @Override protected java.util.List&lt;com.weibo.api.motan.rpc.Referer&lt;T&gt;&gt; initialValue() &#123; return new ArrayList&lt;Referer&lt;T&gt;&gt;(); &#125; &#125;; @Override public Response call(Request request, LoadBalance&lt;T&gt; loadBalance) &#123; List&lt;Referer&lt;T&gt;&gt; referers = selectReferers(request, loadBalance); if (referers.isEmpty()) &#123; throw new MotanServiceException(String.format(\"FailoverHaStrategy No referers for request:%s, loadbalance:%s\", request, loadBalance)); &#125; URL refUrl = referers.get(0).getUrl(); // 先使用 method 的配置 int tryCount = refUrl.getMethodParameter(request.getMethodName(), request.getParamtersDesc(), URLParamType.retries.getName(), URLParamType.retries.getIntValue()); // 如果有问题，则设置为不重试 if (tryCount &lt; 0) &#123; tryCount = 0; &#125; // 只有 failover 策略才会有重试 for (int i = 0; i &lt;= tryCount; i++) &#123; Referer&lt;T&gt; refer = referers.get(i % referers.size()); try &#123; request.setRetries(i); return refer.call(request); &#125; catch (RuntimeException e) &#123; // 对于业务异常，直接抛出 if (ExceptionUtil.isBizException(e)) &#123; throw e; &#125; else if (i &gt;= tryCount) &#123; throw e; &#125; LoggerUtil.warn(String.format(\"FailoverHaStrategy Call false for request:%s error=%s\", request, e.getMessage())); &#125; &#125; throw new MotanFrameworkException(\"FailoverHaStrategy.call should not come here!\"); &#125; protected List&lt;Referer&lt;T&gt;&gt; selectReferers(Request request, LoadBalance&lt;T&gt; loadBalance) &#123; List&lt;Referer&lt;T&gt;&gt; referers = referersHolder.get(); referers.clear(); loadBalance.selectToHolder(request, referers); return referers; &#125;&#125; 其二的高可用策略是 failover，实现相对复杂一些，容忍在重试次数内的失败调用。这也是 motan 提供的默认策略。 其他集群相关的知识点在 Dubbo 中也有 cluster 这一分层，除了 loadbalance 和 ha 这两层之外还包含了路由（Router）用来做读写分离，应用隔离；合并结果（Merger）用来做响应结果的分组聚合。 在 SpringCloud-Netflix 中整合了 Zuul 来做服务端的负载均衡 参考资料 几种简单的负载均衡算法及其 Java 代码实现 搜索业务和技术介绍及容错机制","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"JAVA 拾遗 --JPA 二三事","slug":"jpa-ddd","date":"2018-02-14T14:18:51.000Z","updated":"2019-09-26T09:45:29.842Z","comments":true,"path":"jpa-ddd/","link":"","permalink":"http://lexburner.github.io/jpa-ddd/","excerpt":"","text":"记得前几个月，spring4all 社区刚搞过一次技术话题讨论：如何对 JPA 或者 MyBatis 进行技术选型？传送门：http://www.spring4all.com/article/391 由于平时工作接触较多的是 JPA，所以对其更熟悉一些，这一篇文章记录下个人在使用 JPA 时的一些小技巧。补充说明：JPA 是一个规范，本文所提到的 JPA，特指 spring-data-jpa。 tips： 阅读本文之前，建议了解值对象和实体这两个概念的区别。 使用 @Embedded 关联一对一的值对象现实世界有很多一对一的关联关系，如人和身份证，订单和购买者… 而在 JPA 中表达一对一的关联，通常有三种方式。下面就以订单（Order）和购买者（CustomerVo）为例来介绍这三种方式，这里 CustomerVo 的 Vo 指的是 Value Object。 字段平铺 这可能是最简单的方式了，由于一对一关联的特殊性，完全可以在 Order 类中，使用几个字段记录 CustomerVo 的属性。 12345678public class Order &#123; /* 其他字段 */ ... /* Customer 相关字段 */ private int customerId; private String customerName; private String customerMobile;&#125; 实际上大多数人就是这么做的，甚至都没有意识到这三个字段其实是属于同一个实体类。这种形式优点是很明显的：简单；缺点也是很明显的，这不符合 OO 的原则，且不利于统一检索和维护 CustomerVo 信息。 使用 @OneToOne 1234public class Order &#123; @OneToOne private CustomerVo customerVo;&#125; 这么做的确更“面向对象”了，但代价似乎太大了，我们需要在数据库中额外维护一张 CustomerVo 表，关联越多，代码处理起来就越麻烦，得不偿失。 使用 @Embedded 那有没有能中和上述矛盾的方案呢？引出 @Embedded 这个注解。分析下初始需求，我们发现：CustomerVo 仅仅是作为一个值对象，并不是一个实体（这里牵扯到一些领域驱动设计的知识，值对象的特点是：作为实体对象的修饰，即 CustomerVo 这个整体是 Order 实体的一个属性；不变性，CustomerVo 一旦生成后便不可被修改，除非被整体替换） @Embedded 注解便是内嵌值对象最好的表达形式。 12345@Entitypublic class Order &#123; @Embedded private CustomerVo customerVo;&#125; 123456@Embeddablepublic class CustomerVo &#123; private int customerId; private String customerName; private String customerMobile;&#125; Order 拥有 @Entity 注解，表明其是 DDD 中的实体；而 CustomerVo 拥有 @Embeddable 注解，表明其是 DDD 中的值对象。这也是为什么我一直在表达这样一种观点：JPA 是对 DDD 很好的实践的。 关于实体类的设计技巧，在曹祖鹏老师的 github 中可以看到很成熟的方案，可能会颠覆你对实体类设计的认知：https://github.com/JoeCao/qbike/。 使用 @Convert 关联一对多的值对象说到一对多，第一反应自然是使用 @OneToMany 注解。的确，我自己在项目中也主要使用这个注解来表达一对多的关联，但这里提供另一个思路，来关联一对多的值对象。 以商品和商品组图来举例。 使用 @OneToMany 还是先想想我们原来会怎么做，保存一个 List, 一种方式是这样 1234public class Goods &#123; // 以逗号分隔 private String pictures;&#125; 使用字符串存储，保存成 JSON 数组的形式，或者以逗号分隔都行。 如果图片还要保存顺序，缩略图，那就必须要得使用一对多的关联了。 12345@Entitypublic class Goods &#123; @OneToMany private List&lt;GoodsPicture&gt; goodsPictures;&#125; 123456@Entitypublic class GoodsPicture &#123; private String path; private Integer index; private String thumbnail;&#125; 我们应当发现这样的劣势是什么，从设计的角度来看：我们并不想单独为 GoodsPicture 单独建立一张表，正如前面使用 String pictures 来表示 List 一样，这违反了数据库设计的第一范式，但这对于使用者来说非常方便， 这是关系型数据库的表达能力有限而进行的妥协 。关于这一点我曾和芋艿，曹大师都进行过讨论，并达成了一致的结论：数据库中可以保存 JSON，使用时在应用层进行转换。 使用 JSON 存储复杂对象 123456789@Entitypublic class Goods &#123; /** * 图片 JSON * &#123;@link GoodsPicture&#125; */ @Column(columnDefinition = \"text\") private String goodsPictures;&#125; 使用 @Convert 上述的 String 使得在数据库层面少了一张表，使得 Goods 和 GoodsPictures 的关联更容易维护，但也有缺点：单纯的 String goodsPictures 对于使用者来说毫无含义，必须经过应用层的转换才可以使用。而 JPA 实际上也提供了自定义的转换器来帮我们自动完成这一转换工作，这便到了 @Convert 注解派上用场的时候了。 1 声明 Convert 类 123456@Entitypublic class Goods &#123; @Convert(converter = PicturesWrapperConverter.class) @Column(columnDefinition = \"text\") private PicturesWrapper picturesWrapper;&#125; 2 设置转换类 PicturesWrapperConverter 12345678910public class PicturesWrapperConverter implements AttributeConverter&lt;PicturesWrapper, String&gt; &#123; @Override public String convertToDatabaseColumn(PicturesWrapper picturesWrapper) &#123; return JSON.toJSONString(picturesWrapper); &#125; @Override public PicturesWrapper convertToEntityAttribute(String dbData) &#123; return JSON.parseObject(dbData, PicturesWrapper.class); &#125;&#125; PicturesWrapperConverter 实现了 AttributeConverter&lt;X,Y&gt; 接口，它表明了如何将 PicturesWrapper 转换成 String 类型。这样的好处是显而易见的，对于数据库而言，它知道 String 类型如何保存；对于 Goods 的使用者而言，也只关心 PicturesWrapper 的格式，并不关心它如何持久化。 123public class PicturesWrapper &#123; List&lt;GoodsPicture&gt; goodsPictures;&#125; 对于 List 的保存，我暂时只找到了这种方式，借助一个 Wrapper 对象去存储一个 List 对象。没有找到直接持久化 List 的方式，如果可以实现这样的方式，会更好一些： 123456@Entitypublic class Goods &#123; @Convert(converter = SomeConverter.class) @Column(columnDefinition = \"text\") List&lt;GoodsPicture&gt; goodsPictures;&#125; 但 converter 无法获取到 List 的泛型参数 GoodsPicture，在实践中没找到方案来解决这一问题，只能退而求其次，使用一个 Wrapper 对象。 与 OneToMany 对比，这样虽然使得维护变得灵活，但也丧失了查找的功能，我们将之保存成了 JSON 的形式，导致其不能作为查询条件被检索。 使用 orphanRemoval 来删除值对象你可能有两个疑问：1 在实际项目中，不是不允许对数据进行物理删除吗？ 2 删除对象还不简单，JPA 自己不是有 delete 方法吗？ 关于第一点，需要区分场景，一般实体不允许做物理删除，而是用标记位做逻辑删除，也有部分不需要追溯历史的实体可以做物理删除，而值对象一般而言是可以做物理删除的，因为它只是属性而已。 第二点就有意思了，delete 不就可以直接删除对象吗，为什么需要介绍 orphanRemoval 呢？ 以活动和礼包这个一对多的关系来举例。 12345678@Entitypublic class Activity &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; @OneToMany(cascade = CascadeType.ALL, orphanRemoval = true, mappedBy = \"activity\") private List&lt;GiftPackVo&gt; giftPackVos;&#125; 12345678910@Entitypublic class GiftPackVo &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; private String name; @ManyToOne @JoinColumn(name = \"activity_id\") private Activity activity;&#125; 这是一个再简单不过的一对多关系了，唯一可能觉得陌生的便是这个属性了 orphanRemoval = true 。 如果想要删除某个活动下的某个礼包，在没有 orphanRemoval 之前，你只能这么做： GiftPackVoRepository.delete(GiftPackVo); 但其实这违反了 DDD 中的聚合根模式，GiftPackVo 只是一个值对象，其不具备实体的生命周期，删除一个礼包其实是一个不准确的做法，应当是删除某一个活动下的某一个礼包，对礼包的维护，应当由活动来负责。也就是说：应该借由 Activity 删除 GiftPackVo。使用 orphanRemoval 便可以完成这一操作，它表达这样的含义：内存中的某个 Activity 对象属于持久化态，对 List 的移除操作，将被直接认为是删除操作。 于是删除某个“name = 狗年新春大礼包”的礼包便可以这样完成： 123Activity activity = activityRepository.findOne(1);activity.getGiftPackVos().removeIf(giftPackVo -&gt; \"狗年新春大礼包\".equals(giftPackVo.getName()));activityRepository.save(activity); 整个代码中只出现了 activityRepository 这一个仓储接口。 使用 @Version 来实现乐观锁乐观锁一直是保证并发问题的一个有效途径，spring data jpa 对 @Version 进行了实现，我们给需要做乐观锁控制的对象加上一个 @Version 注解即可。 12345@Entitypublic class Activity &#123; @Version private Integer version;&#125; 我们在日常操作 Activity 对象时完全不需要理会 version 这个字段，当做它不存在即可，spring 借助这个字段来做乐观锁控制。每次创建对象时，version 默认值为 0，每次修改时，会检查对象获取时和保存时的 version 是否相差 1，转化为 sql 便是这样的语句：update activity set xx = xx,yy = yy,version= 10 where id = 1 and version = 9; 然后通过返回影响行数来判断是否更新成功。 测试乐观锁 12345678910111213141516@Servicepublic class ActivityService &#123; @Autowired ActivityRepos activityRepos; public void test()&#123; Activity one = activityRepos.findOne(1); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; one.setName(&quot;xx&quot;+ new Random().nextInt()); activityRepos.save(one); &#125;&#125; 当 test 方法被并发调用时，可能会存在并发问题。控制台打印出了更新信息 123452018-02-14 23:44:25.373 INFO 16256 --- [nio-8080-exec-2] jdbc.sqltiming : update activity set name=&apos;xx-1863402614&apos;, version=1 where id=1 and version=0 2018-02-14 23:44:25.672 INFO 16256 --- [nio-8080-exec-4] jdbc.sqltiming : update activity set name=&apos;xx-1095770865&apos;, version=1 where id=1 and version=0 org.hibernate.StaleStateException: Batch update returned unexpected row count from update [0]; actual row count: 0; expected: 1 表面上看出现的是 StaleStateException，但实际捕获时，如果你想 catch 该异常，根本没有效果，通过 debug 信息，可以发现，真正的异常其实是 ObjectOptimisticLockingFailureException（以 Mysql 为例，实际可能和数据库方言有关，其他数据库未测试）。 123456789@RequestMapping(\"/test\")public void test()&#123; try&#123; activityService.test(); &#125;catch (ObjectOptimisticLockingFailureException oolfe)&#123; System.out.println(\"捕获到乐观锁并发异常\"); oolfe.printStackTrace(); &#125;&#125; 在 Controller 层尝试捕获该异常，控制输出如下： 12捕获到乐观锁并发异常org.springframework.orm.ObjectOptimisticLockingFailureException: Batch update returned unexpected row count from update [0]; actual row count: 0; expected: 1; nested exception is org.hibernate.StaleStateException: Batch update returned unexpected row count from update [0]; actual row count: 0; expected: 1 成功捕获到了并发冲突，这一切都是 @Version 帮我们完成的，非常方便，不需要我们通过编码去实现乐观锁。 总结本文简单聊了几个个人感触比较深的 JPA 小技巧，JPA 真的很强大，也很复杂，可能还有不少“隐藏”的特性等待我们挖掘。它不仅仅是一个技术框架，本文的所有内容即使不被使用，也无伤大雅，但在领域驱动设计等软件设计思想的指导下，它完全可以实践的更好。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"JAVA 拾遗 --Instrument 机制","slug":"instrument","date":"2018-02-04T14:18:51.000Z","updated":"2019-09-26T09:45:30.856Z","comments":true,"path":"instrument/","link":"","permalink":"http://lexburner.github.io/instrument/","excerpt":"","text":"最近在研究 skywalking，发现其作为一个 APM 框架，比起作为 trace 框架的 zipkin 多了一个监控维度：对 JVM 的监控。而 skywalking 集成进系统的方式也和传统的框架不太一样，由于其需要对 JVM 进行无侵入式的监控，所以借助了 JAVA5 提供的 Instrument 机制。关于“Instrument”这个单词，没找到准确的翻译，个人理解为“增强，装配”。 如果我们想要无侵入式的修改一个方法，大多数人想到的可能是 AOP 技术，Instrument 有异曲同工之处，它可以对方法进行增强，甚至替换整个类。 下面借助一个 demo，了解下 Instrument 是如何使用的。第一个 demo 很简单，在某一方法调用时，额外打印出其调用时的时间。 12345public class Dog &#123; public String hello() &#123; return \"wow wow~\"; &#125;&#125; 1234567public class Main &#123; public static void main(String[] args) &#123; System.out.println(new Dog().hello()); &#125;&#125; Dog 存在一个 hello 方法，希望在调用该方法时打印出是什么时刻发生的调用。 实现 AgentGreetingTransformer 12345678910public class GreetingTransformer implements ClassFileTransformer &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; if (\"moe/cnkirito/agent/Dog\".equals(className)) &#123; System.out.println(\"Dog's method invoke at\\t\" + new Date()); &#125; return null; &#125;&#125; 对类进行装配的第一步是编写一个 GreetingTransformer 类，其继承自：java.lang.instrument.ClassFileTransformer，打印语句便编写在其中。对于入参和返参我们先不去纠结，因为仅仅完成这么一个简单的 AOP 功能，还不需要了解它们。 GreetingAgent 除了上述的 Transformer，我们还需要有一个容器去加载它。 12345678910public class GreetingAgent &#123; public static void premain(String options, Instrumentation ins) &#123; if (options != null) &#123; System.out.printf(\"I've been called with options: \\\"%s\\\"\\n\", options); &#125; else System.out.println(\"I've been called with no options.\"); ins.addTransformer(new GreetingTransformer()); &#125;&#125; GreetingAgent 便是我们后面要用的代理，可以发现它只有一个 premain 方法，很简单很形象，它和 main 方法真的很像 12public static void main(String[] args) &#123;&#125; 不同的是 main 函数的参数是一个 string[]，而 premain 的入参是一个 String 和一个 Instrumentation。 前者不用过多赘述，而后者 Instrumentation 便是 JAVA5 的 Instrument 机制的核心，它负责为类添加 ClassFileTransformer 的实现，从而对类进行装配。注意 premain 和它的两个参数不能随意修改，为啥？我们使用 main 函数的时候也没问为啥一定是 public static void main(String[] args) 啊，规定！规定！从 premain 的命名也可以看出，它的运行显然是在 main 函数之前的。 MANIFEST.MF 我们最终会把上面的 GreetingTransformer 和 GreetingAgent 打成一个 jar 包，然后让 Main 函数在启动时加载，但想要使用这个 jar 包还得额外做的工作。 我们得告诉 JVM 在哪儿加载我们的 premain 方法，所以需要在 classpath 下增加一个 resources\\META-INF\\MANIFEST.MF 文件 123Manifest-Version: 1.0Premain-Class: moe.cnkirito.agent.GreetingAgentCan-Redefine-Classes: true MAVEN 插件 为了打包 agent 我们需要额外添加 maven 插件，将 mf 文件和两个类一起打包 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;build&gt; &lt;finalName&gt;agent&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifestFile&gt;src/main/resources/META-INF/MANIFEST.MF&lt;/manifestFile&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;basedir&#125;&lt;/outputDirectory&gt; &lt;archive&gt; &lt;index&gt;true&lt;/index&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Premain-Class&gt;moe.cnkirito.agent.GreetingAgent&lt;/Premain-Class&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 完成上述的配置，使用 maven install 即可得到一个 agent.jar，到这儿一切的准备工作就完成了。 使用代理运行 Main 方法如果不使用代理运行 Main 方法，毫无疑问我们只会得到一行 wow wow~。 如果你使用的 IDEA，eclipse，只需要添加一行启动参数即可： -javaagent:jar_path=[options] 其中的 jar_path 为 agent.jar 的路径，options 是一个可选参数，其值会被 premain 方法的第一个参数接收 public static void premain(String options, Instrumentation ins). 当需要装配多个 agent.jar 时，重复书写多次即可 -javaagent:C:\\Users\\xujingfeng\\Desktop\\agent.jar=hello -javaagent:C:\\Users\\xujingfeng\\Desktop\\agent.jar=hello2 … 运行 Main.jar 的话就是这样的形式：java -javaagent:C:\\Users\\xujingfeng\\Desktop\\agent.jar=hello Main 运行结果 123 I&apos;ve been called with options:&quot;hello&quot;Dog&apos;s method invoke at Sun Feb 04 23:54:45 CST 2018wow wow~ I’ve been called with options:”hello” 代表我们的 premain 已经装载成功，并且正确接收到了启动参数。第二行语句也正常打印出了调用时间，至此便完成了 Dog 的装配。 Instrument 进阶什么？为了打印一行调用时间，我们花了这么大精力，这是要跟自己过不去吗？你可能会有这样的疑惑，但请不要质疑 Instrument 的价值。 12345678public interface ClassFileTransformer &#123; byte[] transform( ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException;&#125; ClassFileTransformer 可以对所有的方法进行拦截，看见返回值 byte[] 了没有 The implementation of this method may transform the supplied class file and return a new replacement class file. 这个方法的实现可能会改变提供的类文件并返回一个新的替换类文件。 这给了我们足够的操作自由度，我们甚至可以替换一个类的实现，只要你能够返回一个正确的替换类。ClassLoader 代表被转换类的类加载器，如果是 bootstrap loader 则可以省略，className 代表全类名，注意是以 / 作为分隔符。其他参数我也不是太懂，想深究的同学自行翻看下文档。byte[] 代表被转换后的类的字节，为 null 则代表不转换。 替换 Dog 的实现12345public class Dog &#123; public String hello() &#123; return \"miao miao~\"; &#125;&#125; 注意，这里我修改了 Dog 的实现，不是打印 wow wow~ 而是 miao miao ~，只是为了得到新 Dog 的字节码 Dog.class。我将新的 Dog.class 丢在了我的桌面方便加载：C:/Users/xujingfeng/Desktop 1234567891011121314151617181920212223242526272829303132333435363738394041public class DogTransformer implements ClassFileTransformer &#123; public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; System.out.println(\"className:\" + className); if (!className.equalsIgnoreCase(\"moe/cnkirito/agent/Dog\")) &#123; return null; &#125; return getBytesFromFile(\"C:/Users/xujingfeng/Desktop/Dog.class\");// 新的 Dog// return getBytesFromFile(\"app/target/classes/moe/cnkirito/agent/Dog.class\"); &#125; public static byte[] getBytesFromFile(String fileName) &#123; File file = new File(fileName); try (InputStream is = new FileInputStream(file)) &#123; // precondition long length = file.length(); byte[] bytes = new byte[(int) length]; // Read in the bytes int offset = 0; int numRead = 0; while (offset &lt;bytes.length &amp;&amp; (numRead = is.read(bytes, offset, bytes.length - offset)) &gt;= 0) &#123; offset += numRead; &#125; if (offset &lt; bytes.length) &#123; throw new IOException(\"Could not completely read file\" + file.getName()); &#125; is.close(); return bytes; &#125; catch (Exception e) &#123; System.out.println(\"error occurs in _ClassTransformer!\" + e.getClass().getName()); return null; &#125; &#125;&#125; return getBytesFromFile(“C:/Users/xujingfeng/Desktop/Dog.class”) 一行返回了新的 Dog 试图替换原先的 Dog。注意，这一切都放生在 Agent.jar 之中，我并没有对 Main 函数（也就是我们自己的源代码）做任何改动。 控制台输出 1miao miao~ 替换成功！我们并没有对 Main 程序的 Dog 做任何修改，只是加载了一个新的 Dog.class 替换了 Main 程序中的 Dog。 统计方法运行耗时这个需求有点接近我们研究 Instrument 的初衷了，统计方法的运行耗时。由于代码的篇幅问题，在本文中只给出思路，详细的实现，可以参考文末的 github 链接，本文的三个例子： 打印 hello 替换 Dog 统计方法运行耗时 代码都在其中。 思路：对每个需要统计耗时的方法替换字节码，在方法开始前插入开始时间，在方法结束时插入结束时间，计算差值，more 你可以连同 methodName 和耗时一起发送出去，给 collector 统一采集…wait，这不就是一个简易的监控吗?!~ 运行结果： 12Call to method hello_timing took 1 ms.wow wow~ JAVA6 的 agentmain值得一提的是，java6 提供了 public static void agentmain (String agentArgs, Instrumentation inst); 这个新的方法，可以在 main 函数之后装配（premain 是在 main 之前），这使得操控现有程序的自由度变得更高了，有兴趣的朋友可以去了解下 premain 和 agentmain 的特性。 本文示例代码https://github.com/lexburner/java5-Instrumentation-demo 参考资料Java 5 特性 Instrumentation 实践 Java SE 6 的新特性：虚拟机启动后的动态 instrument 芋道源码","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"中文文案排版指北","slug":"chinese-copywriting-guidelines","date":"2018-01-16T12:16:28.000Z","updated":"2019-11-03T07:11:04.487Z","comments":true,"path":"chinese-copywriting-guidelines/","link":"","permalink":"http://lexburner.github.io/chinese-copywriting-guidelines/","excerpt":"","text":"统一中文文案、排版的相关用法，降低团队成员之间的沟通成本，增强网站气质。原文出处：https://github.com/mzlogin/chinese-copywriting-guidelines 目录 空格 中英文之间需要增加空格 中文与数字之间需要增加空格 数字与单位之间无需增加空格 全角标点与其他字符之间不加空格 -ms-text-autospace to the rescue? 标点符号 不重复使用标点符号 全角和半角 使用全角中文标点 数字使用半角字符 遇到完整的英文整句、特殊名词，其內容使用半角标点 名词 专有名词使用正确的大小写 不要使用不地道的缩写 争议 链接之间增加空格 简体中文使用直角引号 工具 谁在这样做？ 参考文献 空格「有研究显示，打字的时候不喜欢在中文和英文之间加空格的人，感情路都走得很辛苦，有七成的比例会在 34 岁的时候跟自己不爱的人结婚，而其余三成的人最后只能把遗产留给自己的猫。毕竟爱情跟书写都需要适时地留白。 与大家共勉之。」——vinta/paranoid-auto-spacing 中英文之间需要增加空格正确： 在 LeanCloud 上，数据存储是围绕 AVObject 进行的。 错误： 在LeanCloud上，数据存储是围绕AVObject进行的。 在 LeanCloud上，数据存储是围绕AVObject 进行的。 完整的正确用法： 在 LeanCloud 上，数据存储是围绕 AVObject 进行的。每个 AVObject 都包含了与 JSON 兼容的 key-value 对应的数据。数据是 schema-free 的，你不需要在每个 AVObject 上提前指定存在哪些键，只要直接设定对应的 key-value 即可。 例外：「豆瓣FM」等产品名词，按照官方所定义的格式书写。 中文与数字之间需要增加空格正确： 今天出去买菜花了 5000 元。 错误： 今天出去买菜花了 5000元。 今天出去买菜花了5000元。 数字与单位之间无需增加空格正确： 我家的光纤入户宽带有 10Gbps，SSD 一共有 10TB。 错误： 我家的光纤入户宽带有 10 Gbps，SSD 一共有 20 TB。 另外，度／百分比与数字之间不需要增加空格： 正确： 今天是 233° 的高温。 新 MacBook Pro 有 15% 的 CPU 性能提升。 错误： 今天是 233 ° 的高温。 新 MacBook Pro 有 15 % 的 CPU 性能提升。 全角标点与其他字符之间不加空格正确： 刚刚买了一部 iPhone，好开心！ 错误： 刚刚买了一部 iPhone ，好开心！ -ms-text-autospace to the rescue?Microsoft 有个 -ms-text-autospace.aspx) 的 CSS 属性可以实现自动为中英文之间增加空白。不过目前并未普及，另外在其他应用场景，例如 OS X、iOS 的用户界面目前并不存在这个特性，所以请继续保持随手加空格的习惯。 标点符号不重复使用标点符号正确： 德国队竟然战胜了巴西队！ 她竟然对你说「喵」？！ 错误： 德国队竟然战胜了巴西队！！ 德国队竟然战胜了巴西队！！！！！！！！ 她竟然对你说「喵」？？！！ 她竟然对你说「喵」？！？！？？！！ 全角和半角不明白什么是全角（全形）与半角（半形）符号？请查看维基百科词条『全角和半角』。 使用全角中文标点正确： 嗨！你知道嘛？今天前台的小妹跟我说「喵」了哎！ 核磁共振成像（NMRI）是什么原理都不知道？JFGI！ 错误： 嗨! 你知道嘛? 今天前台的小妹跟我说 “喵” 了哎! 嗨!你知道嘛?今天前台的小妹跟我说”喵”了哎! 核磁共振成像 (NMRI) 是什么原理都不知道? JFGI! 核磁共振成像(NMRI)是什么原理都不知道?JFGI! 数字使用半角字符正确： 这件蛋糕只卖 1000 元。 错误： 这件蛋糕只卖 １０００ 元。 例外：在设计稿、宣传海报中如出现极少量数字的情形时，为方便文字对齐，是可以使用全角数字的。 遇到完整的英文整句、特殊名词，其內容使用半角标点正确： 乔布斯那句话是怎么说的？「Stay hungry, stay foolish.」 推荐你阅读《Hackers &amp; Painters: Big Ideas from the Computer Age》，非常的有趣。 错误： 乔布斯那句话是怎么说的？「Stay hungry，stay foolish。」 推荐你阅读《Hackers＆Painters：Big Ideas from the Computer Age》，非常的有趣。 名词专有名词使用正确的大小写大小写相关用法原属于英文书写范畴，不属于本 wiki 讨论內容，在这里只对部分易错用法进行简述。 正确： 使用 GitHub 登录 我们的客户有 GitHub、Foursquare、Microsoft Corporation、Google、Facebook, Inc.。 错误： 使用 github 登录 使用 GITHUB 登录 使用 Github 登录 使用 gitHub 登录 使用 gｲんĤЦ8 登录 我们的客户有 github、foursquare、microsoft corporation、google、facebook, inc.。 我们的客户有 GITHUB、FOURSQUARE、MICROSOFT CORPORATION、GOOGLE、FACEBOOK, INC.。 我们的客户有 Github、FourSquare、MicroSoft Corporation、Google、FaceBook, Inc.。 我们的客户有 gitHub、fourSquare、microSoft Corporation、google、faceBook, Inc.。 我们的客户有 gｲんĤЦ8、ｷouЯƧquﾑгє、๓เςг๏ร๏Ŧt ς๏гק๏гคtเ๏ภn、900913、ƒ4ᄃëв๏๏к, IПᄃ.。 注意：当网页中需要配合整体视觉风格而出现全部大写／小写的情形，HTML 中请使用标准的大小写规范进行书写；并通过 text-transform: uppercase;／text-transform: lowercase; 对表现形式进行定义。 不要使用不地道的缩写正确： 我们需要一位熟悉 JavaScript、HTML5，至少理解一种框架（如 Backbone.js、AngularJS、React 等）的前端开发者。 错误： 我们需要一位熟悉 Js、h5，至少理解一种框架（如 backbone、angular、RJS 等）的 FED。 争议以下用法略带有个人色彩，即：无论是否遵循下述规则，从语法的角度来讲都是正确的。 链接之间增加空格用法： 请 提交一个 issue 并分配给相关同事。 访问我们网站的最新动态，请 点击这里 进行订阅！ 对比用法： 请提交一个 issue 并分配给相关同事。 访问我们网站的最新动态，请点击这里进行订阅！ 简体中文使用直角引号用法： 「老师，『有条不紊』的『紊』是什么意思？」 对比用法： “老师，‘有条不紊’的‘紊’是什么意思？” 工具| 仓库 | 语言 || ———————————————————— | ————— || vinta/paranoid-auto-spacing | JavaScript || huei90/pangu.node | Node.js || huacnlee/auto-correct | Ruby || sparanoid/space-lover | PHP (WordPress) || nauxliu/auto-correct | PHP || ricoa/copywriting-correct | PHP || hotoo/pangu.vim | Vim || sparanoid/grunt-auto-spacing | Node.js (Grunt) || hjiang/scripts/add-space-between-latin-and-cjk | Python | 谁在这样做？| 网站 | 文案 | UGC || ————————————————- | —- | ———— || Apple 中国 | Yes | N/A || Apple 香港 | Yes | N/A || Apple 台湾 | Yes | N/A || Microsoft 中国 | Yes | N/A || Microsoft 香港 | Yes | N/A || Microsoft 台湾 | Yes | N/A || LeanCloud | Yes | N/A || 知乎 | Yes | 部分用户达成 || V2EX | Yes | Yes || SegmentFault | Yes | 部分用户达成 || Apple4us | Yes | N/A || 豌豆荚 | Yes | N/A || Ruby China | Yes | 标题达成 || PHPHub | Yes | 标题达成 || 少数派 | Yes | N/A || 力扣 LeetCode | Yes | Yes | 参考文献 Guidelines for Using Capital Letters Letter case - Wikipedia Punctuation - Oxford Dictionaries Punctuation - The Purdue OWL How to Use English Punctuation Corrently - wikiHow 格式 - openSUSE 全角和半角 - 维基百科 引号 - 维基百科 疑问惊叹号 - 维基百科","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"中文排版","slug":"中文排版","permalink":"http://lexburner.github.io/tags/中文排版/"}]},{"title":"研究优雅停机时的一点思考","slug":"gracefully-shutdown","date":"2018-01-14T12:16:28.000Z","updated":"2019-09-26T09:45:31.472Z","comments":true,"path":"gracefully-shutdown/","link":"","permalink":"http://lexburner.github.io/gracefully-shutdown/","excerpt":"","text":"开头先废话几句，有段时间没有更新博客了，除了公司项目比较忙之外，还有个原因就是开始思考如何更好地写作。远的来说，我从大一便开始在 CSDN 上写博客，回头看那时的文笔还很稚嫩，一心想着反正只有自己看，所以更多的是随性发挥，随意吐槽，内容也很简陋：刷完一道算法题记录下解题思路，用 JAVA 写完一个 demo 之后，记录下配置步骤。近的来看，工作之后开始维护自己的博客站点: www.cnkirito.moe 也会同步更新自己公众号。相比圈子里其他前辈来说，读者会少很多，但毕竟有人看，每次动笔之前便会开始思考一些事。除了给自己的学习经历做一个归档，还多了一些顾虑：会不会把知识点写错？会不会误人子弟？自己的理解会不会比较片面，不够深刻？等等等等。但自己的心路历程真的发生了一些改变。在我还是个小白的时候，学习技术：第一个想法是百度，搜别人的博客，一步步跟着别人后面配置，把 demo run 起来。而现在，遇到问题的第一思路变成了：源码 debug，官方文档。我便开始思考官方文档和博客的区别，官方文档的优势除了更加全面之外，还有就是：“它只教你怎么做”，对于一个有经验有阅历的程序员来说，这反而是好事，这可以让你有自己的思考。而博客则不一样，如果这个博主特别爱 BB，便会产生很多废话（就像本文的第一段），它会有很多作者自己思考的产物，一方面它比官方文档更容易出错，更容易片面，一方面它比官方文档更容易启发人，特别是读到触动到我的好文时，会抑制不住内心的喜悦想要加到作者的好友，这便是共情。我之后的文章也会朝着这些点去努力：不避重就轻，多思考不想当然，求精。 最近瞥了一眼项目的重启脚本，发现运维一直在使用 kill -9 &lt;pid&gt; 的方式重启 springboot embedded tomcat，其实大家几乎一致认为：kill -9 &lt;pid&gt; 的方式比较暴力，但究竟会带来什么问题却很少有人能分析出个头绪。这篇文章主要记录下自己的思考过程。 kill -9 和 kill -15 有什么区别？在以前，我们发布 WEB 应用通常的步骤是将代码打成 war 包，然后丢到一个配置好了应用容器（如 Tomcat，Weblogic）的 Linux 机器上，这时候我们想要启动 / 关闭应用，方式很简单，运行其中的启动 / 关闭脚本即可。而 springboot 提供了另一种方式，将整个应用连同内置的 tomcat 服务器一起打包，这无疑给发布应用带来了很大的便捷性，与之而来也产生了一个问题：如何关闭 springboot 应用呢？一个显而易见的做法便是，根据应用名找到进程 id，杀死进程 id 即可达到关闭应用的效果。 上述的场景描述引出了我的疑问：怎么优雅地杀死一个 springboot 应用进程呢？这里仅仅以最常用的 Linux 操作系统为例，在 Linux 中 kill 指令负责杀死进程，其后可以紧跟一个数字，代表 信号编号 (Signal)，执行 kill -l 指令，可以一览所有的信号编号。 12xu@ntzyz-qcloud ~ % kill -l HUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS 本文主要介绍下第 9 个信号编码 KILL，以及第 15 个信号编号 TERM 。 先简单理解下这两者的区别：kill -9 pid 可以理解为操作系统从内核级别强行杀死某个进程，kill -15 pid 则可以理解为发送一个通知，告知应用主动关闭。这么对比还是有点抽象，那我们就从应用的表现来看看，这两个命令杀死应用到底有啥区别。 代码准备 由于笔者 springboot 接触较多，所以以一个简易的 springboot 应用为例展开讨论，添加如下代码。 1 增加一个实现了 DisposableBean 接口的类 1234567@Componentpublic class TestDisposableBean implements DisposableBean&#123; @Override public void destroy() throws Exception &#123; System.out.println(\"测试 Bean 已销毁 ...\"); &#125;&#125; 2 增加 JVM 关闭时的钩子 1234567891011121314@SpringBootApplication@RestControllerpublic class TestShutdownApplication implements DisposableBean &#123; public static void main(String[] args) &#123; SpringApplication.run(TestShutdownApplication.class, args); Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"执行 ShutdownHook ...\"); &#125; &#125;)); &#125;&#125; 测试步骤 执行 java -jar test-shutdown-1.0.jar 将应用运行起来 测试 kill -9 pid，kill -15 pid，ctrl + c 后输出日志内容 测试结果 kill -15 pid &amp; ctrl + c，效果一样，输出结果如下 123452018-01-14 16:55:32.424 INFO 8762 --- [Thread-3] ationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2cdf8d8a: startup date [Sun Jan 14 16:55:24 UTC 2018]; root of context hierarchy2018-01-14 16:55:32.432 INFO 8762 --- [Thread-3] o.s.j.e.a.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown执行 ShutdownHook ...测试 Bean 已销毁 ...java -jar test-shutdown-1.0.jar 7.46s user 0.30s system 80% cpu 9.674 total kill -9 pid，没有输出任何应用日志 12[1] 8802 killed java -jar test-shutdown-1.0.jarjava -jar test-shutdown-1.0.jar 7.74s user 0.25s system 41% cpu 19.272 total 可以发现，kill -9 pid 是给应用杀了个措手不及，没有留给应用任何反应的机会。而反观 kill -15 pid，则比较优雅，先是由 AnnotationConfigEmbeddedWebApplicationContext （一个 ApplicationContext 的实现类）收到了通知，紧接着执行了测试代码中的 Shutdown Hook，最后执行了 DisposableBean#destory() 方法。孰优孰劣，立判高下。 一般我们会在应用关闭时处理一下“善后”的逻辑，比如 关闭 socket 链接 清理临时文件 发送消息通知给订阅方，告知自己下线 将自己将要被销毁的消息通知给子进程 各种资源的释放 等等 而 kill -9 pid 则是直接模拟了一次系统宕机，系统断电，这对于应用来说太不友好了，不要用收割机来修剪花盆里的花。取而代之，便是使用 kill -15 pid 来代替。如果在某次实际操作中发现：kill -15 pid 无法关闭应用，则可以考虑使用内核级别的 kill -9 pid ，但请事后务必排查出是什么原因导致 kill -15 pid 无法关闭。 springboot 如何处理 -15 TERM Signal上面解释过了，使用 kill -15 pid 的方式可以比较优雅的关闭 springboot 应用，我们可能有以下的疑惑： springboot/spring 是如何响应这一关闭行为的呢？是先关闭了 tomcat，紧接着退出 JVM，还是相反的次序？它们又是如何互相关联的？ 尝试从日志开始着手分析，AnnotationConfigEmbeddedWebApplicationContext 打印出了 Closing 的行为，直接去源码中一探究竟，最终在其父类 AbstractApplicationContext 中找到了关键的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243@Overridepublic void registerShutdownHook() &#123; if (this.shutdownHook == null) &#123; this.shutdownHook = new Thread() &#123; @Override public void run() &#123; synchronized (startupShutdownMonitor) &#123; doClose(); &#125; &#125; &#125;; Runtime.getRuntime().addShutdownHook(this.shutdownHook); &#125;&#125;@Overridepublic void close() &#123; synchronized (this.startupShutdownMonitor) &#123; doClose(); if (this.shutdownHook != null) &#123; Runtime.getRuntime().removeShutdownHook(this.shutdownHook); &#125; &#125;&#125;protected void doClose() &#123; if (this.active.get() &amp;&amp; this.closed.compareAndSet(false, true)) &#123; LiveBeansView.unregisterApplicationContext(this); // 发布应用内的关闭事件 publishEvent(new ContextClosedEvent(this)); // Stop all Lifecycle beans, to avoid delays during individual destruction. if (this.lifecycleProcessor != null) &#123; this.lifecycleProcessor.onClose(); &#125; // spring 的 BeanFactory 可能会缓存单例的 Bean destroyBeans(); // 关闭应用上下文 &amp;BeanFactory closeBeanFactory(); // 执行子类的关闭逻辑 onClose(); this.active.set(false); &#125;&#125; 为了方便排版以及便于理解，我去除了源码中的部分异常处理代码，并添加了相关的注释。在容器初始化时，ApplicationContext 便已经注册了一个 Shutdown Hook，这个钩子调用了 Close()方法，于是当我们执行 kill -15 pid 时，JVM 接收到关闭指令，触发了这个 Shutdown Hook，进而由 Close() 方法去处理一些善后手段。具体的善后手段有哪些，则完全依赖于 ApplicationContext 的 doClose() 逻辑，包括了注释中提及的销毁缓存单例对象，发布 close 事件，关闭应用上下文等等，特别的，当 ApplicationContext 的实现类是 AnnotationConfigEmbeddedWebApplicationContext 时，还会处理一些 tomcat/jetty 一类内置应用服务器关闭的逻辑。 窥见了 springboot 内部的这些细节，更加应该了解到优雅关闭应用的必要性。JAVA 和 C 都提供了对 Signal 的封装，我们也可以手动捕获操作系统的这些 Signal，在此不做过多介绍，有兴趣的朋友可以自己尝试捕获下。 还有其他优雅关闭应用的方式吗？spring-boot-starter-actuator 模块提供了一个 restful 接口，用于优雅停机。 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置 1234#启用 shutdownendpoints.shutdown.enabled=true#禁用密码验证endpoints.shutdown.sensitive=false 生产中请注意该端口需要设置权限，如配合 spring-security 使用。 执行 curl -X POST host:port/shutdown 指令，关闭成功便可以获得如下的返回： 1&#123;\"message\":\"Shutting down, bye...\"&#125; 虽然 springboot 提供了这样的方式，但按我目前的了解，没见到有人用这种方式停机，kill -15 pid 的方式达到的效果与此相同，将其列于此处只是为了方案的完整性。 如何销毁作为成员变量的线程池？尽管 JVM 关闭时会帮我们回收一定的资源，但一些服务如果大量使用异步回调，定时任务，处理不当很有可能会导致业务出现问题，在这其中，线程池如何关闭是一个比较典型的问题。 123456789101112@Servicepublic class SomeService &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); public void concurrentExecute() &#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"executed...\"); &#125; &#125;); &#125;&#125; 我们需要想办法在应用关闭时（JVM 关闭，容器停止运行），关闭线程池。 初始方案：什么都不做。在一般情况下，这不会有什么大问题，因为 JVM 关闭，会释放之，但显然没有做到本文一直在强调的两个字，没错 —- 优雅。 方法一的弊端在于线程池中提交的任务以及阻塞队列中未执行的任务变得极其不可控，接收到停机指令后是立刻退出？还是等待任务执行完成？抑或是等待一定时间任务还没执行完成则关闭？ 方案改进： 发现初始方案的劣势后，我立刻想到了使用 DisposableBean 接口，像这样： 1234567891011121314151617181920@Servicepublic class SomeService implements DisposableBean&#123; ExecutorService executorService = Executors.newFixedThreadPool(10); public void concurrentExecute() &#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"executed...\"); &#125; &#125;); &#125; @Override public void destroy() throws Exception &#123; executorService.shutdownNow(); //executorService.shutdown(); &#125;&#125; 紧接着问题又来了，是 shutdown 还是 shutdownNow 呢？这两个方法还是经常被误用的，简单对比这两个方法。 ThreadPoolExecutor 在 shutdown 之后会变成 SHUTDOWN 状态，无法接受新的任务，随后等待正在执行的任务执行完成。意味着，shutdown 只是发出一个命令，至于有没有关闭还是得看线程自己。 ThreadPoolExecutor 对于 shutdownNow 的处理则不太一样，方法执行之后变成 STOP 状态，并对执行中的线程调用 Thread.interrupt() 方法（但如果线程未处理中断，则不会有任何事发生），所以并不代表“立刻关闭”。 查看 shutdown 和 shutdownNow 的 java doc，会发现如下的提示： shutdown()：Initiates an orderly shutdown in which previously submitted tasks are executed, but no new tasks will be accepted.Invocation has no additional effect if already shut down.This method does not wait for previously submitted tasks to complete execution.Use {@link #awaitTermination awaitTermination} to do that. shutdownNow()：Attempts to stop all actively executing tasks, halts the processing of waiting tasks, and returns a list of the tasks that were awaiting execution. These tasks are drained (removed) from the task queue upon return from this method.This method does not wait for actively executing tasks to terminate. Use {@link #awaitTermination awaitTermination} to do that.There are no guarantees beyond best-effort attempts to stop processing actively executing tasks. This implementation cancels tasks via {@link Thread#interrupt}, so any task that fails to respond to interrupts may never terminate. 两者都提示我们需要额外执行 awaitTermination 方法，仅仅执行 shutdown/shutdownNow 是不够的。 最终方案：参考 spring 中线程池的回收策略，我们得到了最终的解决方案。 1234567891011121314151617181920212223242526272829303132333435363738public abstract class ExecutorConfigurationSupport extends CustomizableThreadFactory implements DisposableBean&#123; @Override public void destroy() &#123; shutdown(); &#125; /** * Perform a shutdown on the underlying ExecutorService. * @see java.util.concurrent.ExecutorService#shutdown() * @see java.util.concurrent.ExecutorService#shutdownNow() * @see #awaitTerminationIfNecessary() */ public void shutdown() &#123; if (this.waitForTasksToCompleteOnShutdown) &#123; this.executor.shutdown(); &#125; else &#123; this.executor.shutdownNow(); &#125; awaitTerminationIfNecessary(); &#125; /** * Wait for the executor to terminate, according to the value of the * &#123;@link #setAwaitTerminationSeconds \"awaitTerminationSeconds\"&#125; property. */ private void awaitTerminationIfNecessary() &#123; if (this.awaitTerminationSeconds &gt; 0) &#123; try &#123; this.executor.awaitTermination(this.awaitTerminationSeconds, TimeUnit.SECONDS)); &#125; catch (InterruptedException ex) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125;&#125; 保留了注释，去除了一些日志代码，一个优雅关闭线程池的方案呈现在我们的眼前。 1 通过 waitForTasksToCompleteOnShutdown 标志来控制是想立刻终止所有任务，还是等待任务执行完成后退出。 2 executor.awaitTermination(this.awaitTerminationSeconds, TimeUnit.SECONDS)); 控制等待的时间，防止任务无限期的运行（前面已经强调过了，即使是 shutdownNow 也不能保证线程一定停止运行）。 更多需要我们的思考的优雅停机策略在我们分析 RPC 原理的系列文章里面曾经提到，服务治理框架一般会考虑到优雅停机的问题。通常的做法是事先隔断流量，接着关闭应用。常见的做法是将服务节点从注册中心摘除，订阅者接收通知，移除节点，从而优雅停机；涉及到数据库操作，则可以使用事务的 ACID 特性来保证即使 crash 停机也能保证不出现异常数据，正常下线则更不用说了；又比如消息队列可以依靠 ACK 机制 + 消息持久化，或者是事务消息保障；定时任务较多的服务，处理下线则特别需要注意优雅停机的问题，因为这是一个长时间运行的服务，比其他情况更容易受停机问题的影响，可以使用幂等和标志位的方式来设计定时任务… 事务和 ACK 这类特性的支持，即使是宕机，停电，kill -9 pid 等情况，也可以使服务尽量可靠；而同样需要我们思考的还有 kill -15 pid，正常下线等情况下的停机策略。最后再补充下整理这个问题时，自己对 jvm shutdown hook 的一些理解。 When the virtual machine begins its shutdown sequence it will start all registered shutdown hooks in some unspecified order and let them run concurrently. When all the hooks have finished it will then run all uninvoked finalizers if finalization-on-exit has been enabled. Finally, the virtual machine will halt. shutdown hook 会保证 JVM 一直运行，知道 hook 终止 (terminated)。这也启示我们，如果接收到 kill -15 pid 命令时，执行阻塞操作，可以做到等待任务执行完成之后再关闭 JVM。同时，也解释了一些应用执行 kill -15 pid 无法退出的问题，没错，中断被阻塞了。 参考资料 [1] https://stackoverflow.com/questions/2921945/useful-example-of-a-shutdown-hook-in-java [2] spring 源码 [3] jdk 文档","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"深入理解 RPC 之服务注册与发现篇","slug":"rpc-registry","date":"2018-01-05T12:16:28.000Z","updated":"2019-09-26T09:45:30.378Z","comments":true,"path":"rpc-registry/","link":"","permalink":"http://lexburner.github.io/rpc-registry/","excerpt":"","text":"在我们之前 RPC 原理的分析中，主要将笔墨集中在 Client 和 Server 端。而成熟的服务治理框架中不止存在这两个角色，一般还会有一个 Registry（注册中心）的角色。一张图就可以解释注册中心的主要职责。 注册中心，用于服务端注册远程服务以及客户端发现服务 服务端，对外提供后台服务，将自己的服务信息注册到注册中心 客户端，从注册中心获取远程服务的注册信息，然后进行远程过程调用 目前主要的注册中心可以借由 zookeeper，eureka，consul，etcd 等开源框架实现。互联网公司也会因为自身业务的特性自研，如美团点评自研的 MNS，新浪微博自研的 vintage。 本文定位是对注册中心有一定了解的读者，所以不过多阐述注册中心的基础概念。 注册中心的抽象借用开源框架中的核心接口，可以帮助我们从一个较为抽象的高度去理解注册中心。例如 motan 中的相关接口： 服务注册接口 123456789101112public interface RegistryService &#123; //1. 向注册中心注册服务 void register(URL url); //2. 从注册中心摘除服务 void unregister(URL url); //3. 将服务设置为可用，供客户端调用 void available(URL url); //4. 禁用服务，客户端无法发现该服务 void unavailable(URL url); //5. 获取已注册服务的集合 Collection&lt;URL&gt; getRegisteredServiceUrls();&#125; 服务发现接口 12345678public interface DiscoveryService &#123; //1. 订阅服务 void subscribe(URL url, NotifyListener listener); //2. 取消订阅 void unsubscribe(URL url, NotifyListener listener); //3. 发现服务列表 List&lt;URL&gt; discover(URL url);&#125; 主要使用的方法是 RegistryService#register(URL) 和 DiscoveryService#discover(URL)。其中这个 URL 参数被传递，显然也是很重要的一个类。 123456789public class URL &#123; private String protocol;// 协议名称 private String host; private int port; // interfaceName, 也代表着路径 private String path; private Map&lt;String, String&gt; parameters; private volatile transient Map&lt;String, Number&gt; numbers;&#125; 注册中心也没那么玄乎，其实可以简单理解为：提供一个存储介质，供服务提供者和服务消费者共同连接，而存储的主要信息就是这里的 URL。但是具体 URL 都包含了什么实际信息，我们还没有一个直观的感受。 注册信息概览以元老级别的注册中心 zookeeper 为例，看看它实际都存储了什么信息以及它是如何持久化上一节的 URL。 为了测试，我创建了一个 RPC 服务接口 com.sinosoft.student.api.DemoApi , 并且在 6666 端口暴露了这个服务的实现类，将其作为服务提供者。在 6667 端口远程调用这个服务，作为服务消费者。两者都连接本地的 zookeeper，本机 ip 为 192.168.150.1。 使用 zkClient.bash 或者 zkClient.sh 作为客户端连接到本地的 zookeeper，执行如下的命令： 12[zk: localhost:2181(CONNECTED) 1] ls /motan/demo_group/com.sinosoft.student.api.DemoApi&gt; [client, server, unavailableServer] zookeeper 有着和 linux 类似的命令和结构，其中 motan，demo_group，com.sinosoft.student.api.DemoApi，client, server, unavailableServer 都是一个个节点。可以从上述命令看出他们的父子关系。 /motan/demo_group/com.sinosoft.student.api.DemoApi 的结构为 / 框架标识 / 分组名 / 接口名，其中的分组是 motan 为了隔离不同组的服务而设置的。这样，接口名称相同，分组不同的服务无法互相发现。如果此时有一个分组名为 demo_group2 的服务，接口名称为 DemoApi2，则 motan 会为其创建一个新的节点 /motan/demo_group2/com.sinosoft.student.api.DemoApi2 而 client，server，unavailableServer 则就是服务注册与发现的核心节点了。我们先看看这些节点都存储了什么信息。 server 节点： 12345[zk: localhost:2181(CONNECTED) 2] ls /motan/demo_group/com.sinosoft.student.api.DemoApi/server&gt; [192.168.150.1:6666][zk: localhost:2181(CONNECTED) 3] get /motan/demo_group/com.sinosoft.student.api.DemoApi/server/192.168.150.1:6666&gt; motan://192.168.150.1:6666/com.sinosoft.student.api.DemoApi?serialization=hessian2&amp;protocol=motan&amp;isDefault=true&amp;maxContentLength=1548576&amp;shareChannel=true&amp;refreshTimestamp=1515122649835&amp;id=motanServerBasicConfig&amp;nodeType=service&amp;export=motan:6666&amp;requestTimeout=9000000&amp;accessLog=false&amp;group=demo_group&amp; client 节点： 1234[zk: localhost:2181(CONNECTED) 4] ls /motan/demo_group/com.sinosoft.student.api.DemoApi/client&gt; [192.168.150.1][zk: localhost:2181(CONNECTED) 5] get /motan/demo_group/com.sinosoft.student.api.DemoApi/client/192.168.150.1&gt; motan://192.168.150.1:0/com.sinosoft.student.api.DemoApi?singleton=true&amp;maxContentLength=1548576&amp;check=false&amp;nodeType=service&amp;version=1.0&amp;throwException=true&amp;accessLog=false&amp;serialization=hessian2&amp;retries=0&amp;protocol=motan&amp;isDefault=true&amp;refreshTimestamp=1515122631758&amp;id=motanClientBasicConfig&amp;requestTimeout=9000&amp;group=demo_group&amp; unavailableServer 节点是一个过渡节点，所以在一切正常的情况下不会存在信息，它的具体作用在下面会介绍。 从这些输出数据可以发现，注册中心承担的一个职责就是存储服务调用中相关的信息，server 向 zookeeper 注册信息，保存在 server 节点，而 client 实际和 server 共享同一个接口，接口名称就是路径名，所以也到达了同样的 server 节点去获取信息。并且同时注册到了 client 节点下（为什么需要这么做在下面介绍）。 注册信息详解Server 节点server 节点承担着最重要的职责，它由服务提供者创建，以供服务消费者获取节点中的信息，从而定位到服务提供者真正网络拓扑位置以及得知如何调用。demo 中我只在本机 [192.168.150.1:6666] 启动了一个实例，所以在 server 节点之下，只存在这么一个节点，继续 get 这个节点，可以获取更详细的信息 1motan://192.168.150.1:6666/com.sinosoft.student.api.DemoApi?serialization=hessian2&amp;protocol=motan&amp;isDefault=true&amp;maxContentLength=1548576&amp;shareChannel=true&amp;refreshTimestamp=1515122649835&amp;id=motanServerBasicConfig&amp;nodeType=service&amp;export=motan:6666&amp;requestTimeout=9000000&amp;accessLog=false&amp;group=demo_group&amp; 作为一个 value 值，它和 http 协议的请求十分相似，不过是以 motan:// 开头，表达的意图也很明确，这是 motan 协议和相关的路径及参数，关于 RPC 中的协议，可以翻看我的上一篇文章《深入理解 RPC 之协议篇》。 serialization 对应序列化方式，protocol 对应协议名称，maxContentLength 对应 RPC 传输中数据报文的最大长度，shareChannel 是传输层用到的参数，netty channel 中的一个属性，group 对应分组名称。 上述的 value 包含了 RPC 调用中所需要的全部信息。 Client 节点在 motan 中使用 zookeeper 作为注册中心时，客户端订阅服务时会向 zookeeper 注册自身，主要是方便对调用方进行统计、管理。但订阅时是否注册 client 不是必要行为，和不同的注册中心实现有关，例如使用 consul 时便没有注册。 由于我们使用 zookeeper，也可以分析下 zookeeper 中都注册了什么信息。 1motan://192.168.150.1:0/com.sinosoft.student.api.DemoApi?singleton=true&amp;maxContentLength=1548576&amp;check=false&amp;nodeType=service&amp;version=1.0&amp;throwException=true&amp;accessLog=false&amp;serialization=hessian2&amp;retries=0&amp;protocol=motan&amp;isDefault=true&amp;refreshTimestamp=1515122631758&amp;id=motanClientBasicConfig&amp;requestTimeout=9000&amp;group=demo_group 和 Server 节点的值类似，但也有客户独有的一些属性，如 singleton 代表服务是否单例，check 检查服务提供者是否存在，retries 代表重试次数，这也是 RPC 中特别需要注意的一点。 UnavailableServer 节点unavailableServer 节点也不是必须存在的一个节点，它主要用来做 server 端的延迟上线，优雅关机。 延迟上线：一般推荐的服务端启动流程为：server 向注册中心的 unavailableServer 注册，状态为 unavailable，此时整个服务处于启动状态，但不对外提供服务，在服务验证通过，预热完毕，此时打开心跳开关，此时正式提供服务。 优雅关机：当需要对 server 方进行维护升级时，如果直接关闭，则会影响到客户端的请求。所以理想的情况应当是首先切断流量，再进行 server 的下线。具体的做法便是：先关闭心跳开关，客户端感知停止调用后，再关闭服务进程。 感知服务的下线服务上线时自然要注册到注册中心，但下线时也得从注册中心中摘除。注册是一个主动的行为，这没有特别要注意的地方，但服务下线却是一个值得思考的问题。服务下线包含了主动下线和系统宕机等异常方式的下线。 临时节点 + 长连接在 zookeeper 中存在持久化节点和临时节点的概念。持久化节点一经创建，只要不主动删除，便会一直持久化存在；临时节点的生命周期则是和客户端的连接同生共死的，应用连接到 zookeeper 时创建一个临时节点，使用长连接维持会话，这样无论何种方式服务发生下线，zookeeper 都可以感知到，进而删除临时节点。zookeeper 的这一特性和服务下线的需求契合的比较好，所以临时节点被广泛应用。 主动下线 + 心跳检测并不是所有注册中心都有临时节点的概念，另外一种感知服务下线的方式是主动下线。例如在 eureka 中，会有 eureka-server 和 eureka-client 两个角色，其中 eureka-server 保存注册信息，地位等同于 zookeeper。当 eureka-client 需要关闭时，会发送一个通知给 eureka-server，从而让 eureka-server 摘除自己这个节点。但这么做最大的一个问题是，如果仅仅只有主动下线这么一个手段，一旦 eureka-client 非正常下线（如断电，断网），eureka-server 便会一直存在一个已经下线的服务节点，一旦被其他服务发现进而调用，便会带来问题。为了避免出现这样的情况，需要给 eureka-server 增加一个心跳检测功能，它会对服务提供者进行探测，比如每隔 30s 发送一个心跳，如果三次心跳结果都没有返回值，就认为该服务已下线。 注册中心对比 Feature Consul zookeeper etcd euerka 服务健康检查 服务状态，内存，硬盘等 (弱) 长连接，keepalive 连接心跳 可配支持 多数据中心 支持 — — — kv 存储服务 支持 支持 支持 — 一致性 raft paxos raft — cap ca cp cp ap 使用接口 (多语言能力) 支持 http 和 dns 客户端 http/grpc http（sidecar） watch 支持 全量 / 支持 long polling 支持 支持 long polling 支持 long polling/ 大部分增量 自身监控 metrics — metrics metrics 安全 acl /https acl https 支持（弱） — spring cloud 集成 已支持 已支持 已支持 已支持 一般而言注册中心的特性决定了其使用的场景，例如很多框架支持 zookeeper，在我自己看来是因为其老牌，易用，但业界也有很多人认为 zookeeper 不适合做注册中心，它本身是一个分布式协调组件，并不是为注册服务而生，server 端注册一个服务节点，client 端并不需要在同一时刻拿到完全一致的服务列表，只要最终一致性即可。在跨 IDC，多数据中心等场景下 consul 发挥了很大的优势，这也是很多互联网公司选择使用 consul 的原因。 eureka 是 ap 注册中心，并且是 spring cloud 默认使用的组件，spring cloud eureka 较为贴近 spring cloud 生态。 总结注册中心主要用于解耦服务调用中的定位问题，是分布式系统必须面对的一个问题。更多专业性的对比，可以期待 spring4all.com 的注册中心专题讨论，相信会有更为细致地对比。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"深入理解 RPC 之协议篇","slug":"rpc-protocol","date":"2017-12-28T12:16:28.000Z","updated":"2019-09-26T09:45:30.592Z","comments":true,"path":"rpc-protocol/","link":"","permalink":"http://lexburner.github.io/rpc-protocol/","excerpt":"","text":"协议（Protocol）是个很广的概念，RPC 被称为远程过程调用协议，HTTP 和 TCP 也是大家熟悉的协议，也有人经常拿 RPC 和 RESTFUL 做对比，后者也可以被理解为一种协议… 我个人偏向于把“协议”理解为不同厂家不同用户之间的“约定”，而在 RPC 中，协议的含义也有多层。 Protocol 在 RPC 中的层次关系翻看 dubbo 和 motan 两个国内知名度数一数二的 RPC 框架（或者叫服务治理框架可能更合适）的文档，他们都有专门的一章介绍自身对多种协议的支持。RPC 框架是一个分层结构，从我的这个《深入理解 RPC》系列就可以看出，是按照分层来介绍 RPC 的原理的，前面已经介绍过了传输层，序列化层，动态代理层，他们各自负责 RPC 调用生命周期中的一环，而协议层则是凌驾于它们所有层之上的一层。简单描述下各个层之间的关系： protocol 层主要用于配置 refer（发现服务） 和 exporter（暴露服务） 的实现方式，transport 层定义了传输的方式，codec 层诠释了具体传输过程中报文解析的方式，serialize 层负责将对象转换成字节，以用于传输，proxy 层负责将这些细节屏蔽。 它们的包含关系如下：protocol &gt; transport &gt; codec &gt; serialize motan 的 Protocol 接口可以佐证这一点： 12345public interface Protocol &#123; &lt;T&gt; Exporter&lt;T&gt; export(Provider&lt;T&gt; provider, URL url); &lt;T&gt; Referer&lt;T&gt; refer(Class&lt;T&gt; clz, URL url, URL serviceUrl); void destroy();&#125; 我们都知道 RPC 框架支持多种协议，由于协议处于框架层次的较高位置，任何一种协议的替换，都可能会导致服务发现和服务注册的方式，传输的方式，以及序列化的方式，而不同的协议也给不同的业务场景带来了更多的选择，下面就来看看一些常用协议。 Dubbo 中的协议dubbo://Dubbo 缺省协议采用单一长连接和 NIO 异步通讯，适合于小数据量高并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 反之，Dubbo 缺省协议不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。 适用场景：常规远程服务方法调用 rmi://RMI 协议采用 JDK 标准的 java.rmi.* 实现，采用阻塞式短连接和 JDK 标准序列化方式。 适用场景：常规远程服务方法调用，与原生 RMI 服务互操作 hessian://Hessian 协议用于集成 Hessian 的服务，Hessian 底层采用 Http 通讯，采用 Servlet 暴露服务，Dubbo 缺省内嵌 Jetty 作为服务器实现。 Dubbo 的 Hessian 协议可以和原生 Hessian 服务互操作，即： 提供者用 Dubbo 的 Hessian 协议暴露服务，消费者直接用标准 Hessian 接口调用 或者提供方用标准 Hessian 暴露服务，消费方用 Dubbo 的 Hessian 协议调用。 Hessian 在之前介绍过，当时仅仅是用它来作为序列化工具，但其本身其实就是一个协议，可以用来做远程通信。 适用场景：页面传输，文件传输，或与原生 hessian 服务互操作 http://基于 HTTP 表单的远程调用协议，采用 Spring 的 HttpInvoker 实现 适用场景：需同时给应用程序和浏览器 JS 使用的服务。 webserivice://基于 WebService 的远程调用协议，基于 Apache CXF 的 frontend-simple 和 transports-http 实现。 可以和原生 WebService 服务互操作，即： 提供者用 Dubbo 的 WebService 协议暴露服务，消费者直接用标准 WebService 接口调用， 或者提供方用标准 WebService 暴露服务，消费方用 Dubbo 的 WebService 协议调用 适用场景：系统集成，跨语言调用 thrift://当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如 service name，magic number 等。 memcached://基于 memcached 实现的 RPC 协议 redis://基于 Redis 实现的 RPC 协议。 dubbo 支持的众多协议详见 http://dubbo.io/books/dubbo-user-book/references/protocol/dubbo.html dubbo 的一个分支 dangdangdotcom/dubbox 扩展了 REST 协议 rest://JAX-RS 是标准的 Java REST API，得到了业界的广泛支持和应用，其著名的开源实现就有很多，包括 Oracle 的 Jersey，RedHat 的 RestEasy，Apache 的 CXF 和 Wink，以及 restlet 等等。另外，所有支持 JavaEE 6.0 以上规范的商用 JavaEE 应用服务器都对 JAX-RS 提供了支持。因此，JAX-RS 是一种已经非常成熟的解决方案，并且采用它没有任何所谓 vendor lock-in 的问题。 JAX-RS 在网上的资料非常丰富，例如下面的入门教程： Oracle 官方的 tutorial：http://docs.oracle.com/javaee/7/tutorial/doc/jaxrs.htm IBM developerWorks 中国站文章：http://www.ibm.com/developerworks/cn/java/j-lo-jaxrs/ 更多的资料请自行 google 或者百度一下。就学习 JAX-RS 来说，一般主要掌握其各种 annotation 的用法即可。 注意：dubbo 是基于 JAX-RS 2.0 版本的，有时候需要注意一下资料或 REST 实现所涉及的版本。 适用场景：跨语言调用 千米网也给 dubbo 贡献了一个扩展协议：https://github.com/dubbo/dubbo-rpc-jsonrpc jsonrpc://Why HTTP在互联网快速迭代的大潮下，越来越多的公司选择 nodejs、django、rails 这样的快速脚本框架来开发 web 端应用 而后端的服务用 Java 又是最合适的，这就产生了大量的跨语言的调用需求。而 http、json 是天然合适作为跨语言的标准，各种语言都有成熟的类库虽然 Dubbo 的异步长连接协议效率很高，但是在脚本语言中，这点效率的损失并不重要。 Why Not RESTfulDubbox 在 RESTful 接口上已经做出了尝试，但是 REST 架构和 dubbo 原有的 RPC 架构是有区别的，区别在于 REST 架构需要有资源 (Resources) 的定义， 需要用到 HTTP 协议的基本操作 GET、POST、PUT、DELETE 对资源进行操作。Dubbox 需要重新定义接口的属性，这对原有的 Dubbo 接口迁移是一个较大的负担。相比之下，RESTful 更合适互联网系统之间的调用，而 RPC 更合适一个系统内的调用，所以我们使用了和 Dubbo 理念较为一致的 JsonRPC JSON-RPC 2.0 规范 和 JAX-RS 一样，也是一个规范，JAVA 对其的支持可参考 jsonrpc4j 适用场景：跨语言调用 Motan 中的协议motan://motan 协议之于 motan，地位等同于 dubbo 协议之于 dubbo，两者都是各自默认的且都是自定义的协议。内部使用 netty 进行通信（旧版本使用 netty3 ，最新版本支持 netty4），默认使用 hessian 作为序列化器。 适用场景：常规远程服务方法调用 injvm://顾名思义，如果 Provider 和 Consumer 位于同一个 jvm，motan 提供了 injvm 协议。这个协议是 jvm 内部调用，不经过本地网络，一般在服务化拆分时，作为过渡方案使用，可以通过开关机制在本地和远程调用之间进行切换，等过渡完成后再去除本地实现的引用。 grpc:// 和 yar://这两个协议的诞生缘起于一定的历史遗留问题，moton 是新浪微博开源的，而其内部有很多 PHP 应用，为解决跨语言问题，这两个协议进而出现了。 适用场景：较为局限的跨语言调用 restful://motan 在 0.3.1 (2017-07-11) 版本发布了 restful 协议的支持（和 dubbo 的 rest 协议本质一样），dubbo 默认使用 jetty 作为 http server，而 motan 使用则是 netty 。主要实现的是 java 对 restful 指定的规范，即 javax.ws.rs 包下的类。 适用场景：跨语言调用 motan2://motan 1.0.0 (2017-10-31) 版本发布了 motan2 协议，用于对跨语言的支持，不同于 restful，jsonrpc 这样的通用协议，motan2 把请求的一些元数据作为单独的部分传输，更适合不同语言解析。 适用场景：跨语言调用 Motan is a cross-language remote procedure call(RPC) framework for rapid development of high performance distributed services. Motan-go is golang implementation. Motan-PHP is PHP client can interactive with Motan server directly or through Motan-go agent. Motan-openresty is a Lua(Luajit) implementation based on Openresty 从 motan 的 changeLog 以及 github 首页的介绍来看，其致力于打造成一个跨语言的服务治理框架，这倒是比较亦可赛艇的事。 面向未来的协议motan 已经支持 motan2://，计划支持 mcq://，kafka:// … 支持更多的协议，以应对复杂的业务场景。对这个感兴趣的朋友，可以参见这篇文章：http://mp.weixin.qq.com/s/XZVCHZZzCX8wwgNKZtsmcA 总结如果仅仅是将 dubbo，motan 作为一个 RPC 框架使用，那大多人会选择其默认的协议（dubbo 协议，motan 协议），而如果是有历史遗留原因，如需要对接异构系统，就需要替换成其他协议了。大多数互联网公司选择自研 RPC 框架，或者改造自己的协议，都是为了适配自身业务的特殊性，协议层的选择非常重要。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"Motan 中使用异步 RPC 接口","slug":"motan-async","date":"2017-12-27T13:34:34.000Z","updated":"2019-09-26T09:45:30.919Z","comments":true,"path":"motan-async/","link":"","permalink":"http://lexburner.github.io/motan-async/","excerpt":"","text":"这周六参加了一个美团点评的技术沙龙，其中一位老师在介绍他们自研的 RPC 框架时提到一点：RPC 请求分为 sync，future，callback，oneway，并且需要遵循一个原则：能够异步的地方就不要使用同步。正好最近在优化一个业务场景：在一次页面展示中，需要调用 5 个 RPC 接口，导致页面响应很慢。正好启发了我。 为什么慢？大多数开源的 RPC 框架实现远程调用的方式都是同步的，假设 [接口 1，…，接口 5] 的每一次调用耗时为 200ms （其中接口 2 依赖接口 1，接口 5 依赖接口 3，接口 4），那么总耗时为 1s，这整个是一个串行的过程。 多线程加速第一个想到的解决方案便是多线程，那么 [1=&gt;2] 编为一组，[[3,4]=&gt;5]编为一组，两组并发执行，[1=&gt;2]串行执行耗时 400ms，[3,4]并发执行耗时 200ms，[[3,4]=&gt;5]总耗时 400ms ，最终 [[1=&gt;2],[[3,4]=&gt;5]] 总耗时 400ms（理论耗时）。相比较于原来的 1s，的确快了不少，但实际编写接口花了不少功夫，创建线程池，管理资源，分析依赖关系… 总之代码不是很优雅。 RPC 中，多线程着重考虑的点是在客户端优化代码，这给客户端带来了一定的复杂性，并且编写并发代码对程序员的要求更高，且不利于调试。 异步调用如果有一种既能保证速度，又能像同步 RPC 调用那样方便，岂不美哉？于是引出了 RPC 中的异步调用。 在 RPC 异步调用之前，先回顾一下 java.util.concurrent 中的基础知识：Callable 和 Future 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class Main &#123; public static void main(String[] args) throws Exception&#123; final ExecutorService executorService = Executors.newFixedThreadPool(10); long start = System.currentTimeMillis(); Future&lt;Integer&gt; resultFuture1 = executorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; return method1()+ method2(); &#125; &#125;); Future&lt;Integer&gt; resultFuture2 = executorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; Future&lt;Integer&gt; resultFuture3 = executorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; return method3(); &#125; &#125;); Future&lt;Integer&gt; resultFuture4 = executorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; return method4(); &#125; &#125;); return method5()+resultFuture3.get()+resultFuture4.get(); &#125; &#125;); int result = resultFuture1.get()+ resultFuture2.get(); System.out.println(\"result =\"+result+\", total cost\"+(System.currentTimeMillis()-start)+\"ms\"); executorService.shutdown(); &#125; static int method1()&#123; delay200ms(); return 1; &#125; static int method2()&#123; delay200ms(); return 2; &#125; static int method3()&#123; delay200ms(); return 3; &#125; static int method4()&#123; delay200ms(); return 4; &#125; static int method5()&#123; delay200ms(); return 5; &#125; static void delay200ms()&#123; try&#123; Thread.sleep(200); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 最终控制台打印： result = 15, total cost 413 ms 五个接口，如果同步调用，便是串行的效果，最终耗时必定在 1s 之上，而异步调用的优势便是，submit 任务之后立刻返回，只有在调用 future.get() 方法时才会阻塞，而这期间多个异步方法便可以并发的执行。 RPC 异步调用我们的项目使用了 Motan 作为 RPC 框架，查看其 changeLog ，0.3.0 (2017-03-09) 该版本已经支持了 async 特性。可以让开发者很方便地实现 RPC 异步调用。 1 为接口增加 @MotanAsync 注解 1234@MotanAsyncpublic interface DemoApi &#123; DemoDto randomDemo(String id);&#125; 2 添加 Maven 插件 12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;build-helper-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;add-source&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;sources&gt; &lt;source&gt;$&#123;project.build.directory&#125;/generated-sources/annotations&lt;/source&gt; &lt;/sources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 安装插件后，可以借助它生成一个和 DemoApi 关联的异步接口 DemoApiAsync 。 123public interface DemoApiAsync extends DemoApi &#123; ResponseFuture randomDemoAsync(String id);&#125; 3 注入接口即可调用 123456789101112131415161718192021@Servicepublic class DemoService &#123; @MotanReferer DemoApi demoApi; @MotanReferer DemoApiAsync demoApiAsync;//&lt;1&gt; public DemoDto randomDemo(String id)&#123; DemoDto demoDto = demoApi.randomDemo(id); return demoDto; &#125; public DemoDto randomDemoAsync(String id)&#123; ResponseFuture responseFuture = demoApiAsync.randomDemoAsync(id);//&lt;2&gt; DemoDto demoDto = (DemoDto) responseFuture.getValue(); return demoDto; &#125;&#125; DemoApiAsync 如何生成的已经介绍过，它和 DemoApi 并没有功能性的区别，仅仅是同步异步调用的差距，而 DemoApiAsync 实现的的复杂性完全由 RPC 框架帮助我们完成，开发者无需编写 Callable 接口。 ResponseFuture 是 RPC 中 Future 的抽象，其本身也是 juc 中 Future 的子类，当 responseFuture.getValue() 调用时会阻塞。 总结在异步调用中，如果发起一次异步调用后，立刻使用 future.get()，则大致和同步调用等同。其真正的优势是在 submit 和 future.get() 之间可以混杂一些非依赖性的耗时操作，而不是同步等待，从而充分利用时间片。 另外需要注意，如果异步调用涉及到数据的修改，则多个异步操作直接不能保证 happens-before 原则，这属于并发控制的范畴了，谨慎使用。查询操作则大多没有这样的限制。 在能使用并发的地方使用并发，不能使用的地方才选择同步，这需要我们思考更多细节，但可以最大限度的提升系统的性能。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"},{"name":"motan","slug":"motan","permalink":"http://lexburner.github.io/tags/motan/"}]},{"title":"深入理解 RPC 之传输篇","slug":"rpc-transport","date":"2017-12-22T12:16:28.000Z","updated":"2019-09-26T09:45:31.596Z","comments":true,"path":"rpc-transport/","link":"","permalink":"http://lexburner.github.io/rpc-transport/","excerpt":"","text":"RPC 被称为“远程过程调用”，表明了一个方法调用会跨越网络，跨越进程，所以传输层是不可或缺的。一说到网络传输，一堆名词就蹦了出来：TCP、UDP、HTTP，同步 or 异步，阻塞 or 非阻塞，长连接 or 短连接… 本文介绍两种传输层的实现：使用 Socket 和使用 Netty。前者实现的是阻塞式的通信，是一个较为简单的传输层实现方式，借此可以了解传输层的工作原理及工作内容；后者是非阻塞式的，在一般的 RPC 场景下，性能会表现的很好，所以被很多开源 RPC 框架作为传输层的实现方式。 RpcRequest 和 RpcResponse传输层传输的主要对象其实就是这两个类，它们封装了请求 id，方法名，方法参数，返回值，异常等 RPC 调用中需要的一系列信息。 12345678910public class RpcRequest implements Serializable &#123; private String interfaceName; private String methodName; private String parametersDesc; private Object[] arguments; private Map&lt;String, String&gt; attachments; private int retries = 0; private long requestId; private byte rpcProtocolVersion;&#125; 123456789public class RpcResponse implements Serializable &#123; private Object value; private Exception exception; private long requestId; private long processTime; private int timeout; private Map&lt;String, String&gt; attachments;// rpc 协议版本兼容时可以回传一些额外的信息 private byte rpcProtocolVersion;&#125; Socket 传输Server 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class RpcServerSocketProvider &#123; public static void main(String[] args) throws Exception &#123; // 序列化层实现参考之前的章节 Serialization serialization = new Hessian2Serialization(); ServerSocket serverSocket = new ServerSocket(8088); ExecutorService executorService = Executors.newFixedThreadPool(10); while (true) &#123; final Socket socket = serverSocket.accept(); executorService.execute(() -&gt; &#123; try &#123; InputStream is = socket.getInputStream(); OutputStream os = socket.getOutputStream(); try &#123; DataInputStream dis = new DataInputStream(is); int length = dis.readInt(); byte[] requestBody = new byte[length]; dis.read(requestBody); // 反序列化 requestBody =&gt; RpcRequest RpcRequest rpcRequest = serialization.deserialize(requestBody, RpcRequest.class); // 反射调用生成响应 并组装成 rpcResponse RpcResponse rpcResponse = invoke(rpcRequest); // 序列化 rpcResponse =&gt; responseBody byte[] responseBody = serialization.serialize(rpcResponse); DataOutputStream dos = new DataOutputStream(os); dos.writeInt(responseBody.length); dos.write(responseBody); dos.flush(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; is.close(); os.close(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; socket.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; public static RpcResponse invoke(RpcRequest rpcRequest) &#123; // 模拟反射调用 RpcResponse rpcResponse = new RpcResponse(); rpcResponse.setRequestId(rpcRequest.getRequestId()); //... some operation return rpcResponse; &#125;&#125; Client 1234567891011121314151617181920212223242526272829303132public class RpcSocketConsumer &#123; public static void main(String[] args) throws Exception &#123; // 序列化层实现参考之前的章节 Serialization serialization = new Hessian2Serialization(); Socket socket = new Socket(\"localhost\", 8088); InputStream is = socket.getInputStream(); OutputStream os = socket.getOutputStream(); // 封装 rpc 请求 RpcRequest rpcRequest = new RpcRequest(); rpcRequest.setRequestId(12345L); // 序列化 rpcRequest =&gt; requestBody byte[] requestBody = serialization.serialize(rpcRequest); DataOutputStream dos = new DataOutputStream(os); dos.writeInt(requestBody.length); dos.write(requestBody); dos.flush(); DataInputStream dis = new DataInputStream(is); int length = dis.readInt(); byte[] responseBody = new byte[length]; dis.read(responseBody); // 反序列化 responseBody =&gt; rpcResponse RpcResponse rpcResponse = serialization.deserialize(responseBody, RpcResponse.class); is.close(); os.close(); socket.close(); System.out.println(rpcResponse.getRequestId()); &#125;&#125; dis.readInt()和 dis.read(byte[] bytes) 决定了使用 Socket 通信是一种阻塞式的操作，报文头 + 报文体的传输格式是一种常见的格式，除此之外，使用特殊的字符如空行也可以划分出报文结构。在示例中，我们使用一个 int（4 字节）来传递报问题的长度，之后传递报文体，在复杂的通信协议中，报文头除了存储报文体还会额外存储一些信息，包括协议名称，版本，心跳标识等。 在网络传输中，只有字节能够被识别，所以我们在开头引入了 Serialization 接口，负责完成 RpcRequest 和 RpcResponse 与字节的相互转换。（Serialization 的工作机制可以参考之前的文章） 使用 Socket 通信可以发现：每次 Server 处理 Client 请求都会从线程池中取出一个线程来处理请求，这样的开销对于一般的 Rpc 调用是不能够接受的，而 Netty 一类的网络框架便派上了用场。 Netty 传输Server 和 ServerHandler 1234567891011121314151617181920212223242526272829303132public class RpcNettyProvider &#123; public static void main(String[] args) throws Exception&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; // 创建并初始化 Netty 服务端 Bootstrap 对象 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup); bootstrap.channel(NioServerSocketChannel.class); bootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel channel) throws Exception &#123; ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new RpcDecoder(RpcRequest.class)); // 解码 RPC 请求 pipeline.addLast(new RpcEncoder(RpcResponse.class)); // 编码 RPC 响应 pipeline.addLast(new RpcServerHandler()); // 处理 RPC 请求 &#125; &#125;); bootstrap.option(ChannelOption.SO_BACKLOG, 1024); bootstrap.childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture future = bootstrap.bind(\"127.0.0.1\", 8087).sync(); // 关闭 RPC 服务器 future.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125; 1234567891011121314151617181920212223public class RpcServerHandler extends SimpleChannelInboundHandler&lt;RpcRequest&gt; &#123; @Override public void channelRead0(final ChannelHandlerContext ctx, RpcRequest request) throws Exception &#123; RpcResponse rpcResponse = invoke(request); // 写入 RPC 响应对象并自动关闭连接 ctx.writeAndFlush(rpcResponse).addListener(ChannelFutureListener.CLOSE); &#125; private RpcResponse invoke(RpcRequest rpcRequest) &#123; // 模拟反射调用 RpcResponse rpcResponse = new RpcResponse(); rpcResponse.setRequestId(rpcRequest.getRequestId()); //... some operation return rpcResponse; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; Client 和 ClientHandler 1234567891011121314151617181920212223242526272829303132333435public class RpcNettyConsumer &#123; public static void main(String[] args) throws Exception&#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建并初始化 Netty 客户端 Bootstrap 对象 Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group); bootstrap.channel(NioSocketChannel.class); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel channel) throws Exception &#123; ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new RpcEncoder(RpcRequest.class)); // 编码 RPC 请求 pipeline.addLast(new RpcDecoder(RpcResponse.class)); // 解码 RPC 响应 pipeline.addLast(new RpcClientHandler()); // 处理 RPC 响应 &#125; &#125;); bootstrap.option(ChannelOption.TCP_NODELAY, true); // 连接 RPC 服务器 ChannelFuture future = bootstrap.connect(\"127.0.0.1\", 8087).sync(); // 写入 RPC 请求数据并关闭连接 Channel channel = future.channel(); RpcRequest rpcRequest = new RpcRequest(); rpcRequest.setRequestId(123456L); channel.writeAndFlush(rpcRequest).sync(); channel.closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 1234567891011121314public class RpcClientHandler extends SimpleChannelInboundHandler&lt;RpcResponse&gt; &#123; @Override public void channelRead0(ChannelHandlerContext ctx, RpcResponse response) throws Exception &#123; System.out.println(response.getRequestId());// 处理响应 &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 使用 Netty 的好处是很方便地实现了非阻塞式的调用，关键部分都给出了注释。上述的代码虽然很多，并且和我们熟悉的 Socket 通信代码大相径庭，但大多数都是 Netty 的模板代码，启动服务器，配置编解码器等。真正的 RPC 封装操作大多集中在 Handler 的 channelRead 方法（负责读取）以及 channel.writeAndFlush 方法（负责写入）中。 12345678910111213141516171819public class RpcEncoder extends MessageToByteEncoder &#123; private Class&lt;?&gt; genericClass; Serialization serialization = new Hessian2Serialization(); public RpcEncoder(Class&lt;?&gt; genericClass) &#123; this.genericClass = genericClass; &#125; @Override public void encode(ChannelHandlerContext ctx, Object in, ByteBuf out) throws Exception &#123; if (genericClass.isInstance(in)) &#123; byte[] data = serialization.serialize(in); out.writeInt(data.length); out.writeBytes(data); &#125; &#125;&#125; 1234567891011121314151617181920212223242526public class RpcDecoder extends ByteToMessageDecoder &#123; private Class&lt;?&gt; genericClass; public RpcDecoder(Class&lt;?&gt; genericClass) &#123; this.genericClass = genericClass; &#125; Serialization serialization = new Hessian2Serialization(); @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; if (in.readableBytes() &lt; 4) &#123; return; &#125; in.markReaderIndex(); int dataLength = in.readInt(); if (in.readableBytes() &lt; dataLength) &#123; in.resetReaderIndex(); return; &#125; byte[] data = new byte[dataLength]; in.readBytes(data); out.add(serialization.deserialize(data, genericClass)); &#125;&#125; 使用 Netty 不能保证返回的字节大小，所以需要加上 in.readableBytes()&lt; 4 这样的判断，以及 in.markReaderIndex() 这样的标记，用来区分报文头和报文体。 同步与异步 阻塞与非阻塞这两组传输特性经常被拿来做对比，很多文章声称 Socket 是同步阻塞的，Netty 是异步非阻塞，其实有点问题。 其实这两组并没有必然的联系，同步阻塞，同步非阻塞，异步非阻塞都有可能（同步非阻塞倒是没见过），而大多数使用 Netty 实现的 RPC 调用其实应当是同步非阻塞的（当然一般 RPC 也支持异步非阻塞）。 同步和异步关注的是 消息通信机制 所谓同步，就是在发出一个 调用 时，在没有得到结果之前，该 调用 就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由 调用者 主动等待这个 调用 的结果。 而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在 调用 发出后， 被调用者 通过状态、通知来通知调用者，或通过回调函数处理这个调用。 如果需要 RPC 调用返回一个结果，该结果立刻被使用，那意味着着大概率需要是一个同步调用。如果不关心其返回值，则可以将其做成异步接口，以提升效率。 阻塞和非阻塞关注的是 程序在等待调用结果（消息，返回值）时的状态 . 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 在上述的例子中可以看出 Socket 通信我们显示声明了一个包含 10 个线程的线程池，每次请求到来，分配一个线程，等待客户端传递报文头和报文体的行为都会阻塞该线程，可以见得其整体是阻塞的。而在 Netty 通信的例子中，每次请求并没有分配一个线程，而是通过 Handler 的方式处理请求（联想 NIO 中 Selector），是非阻塞的。 使用同步非阻塞方式的通信机制并不一定同步阻塞式的通信强，所谓没有最好，只有更合适，而一般的同步非阻塞 通信适用于 1. 网络连接数量多 2. 每个连接的 io 不频繁 的场景，与 RPC 调用较为契合。而成熟的 RPC 框架的传输层和协议层通常也会提供多种选择，以应对不同的场景。 总结本文堆砌了一些代码，而难点主要是对 Socket 的理解，和 Netty 框架的掌握。Netty 的学习有一定的门槛，但实际需要掌握的知识点其实并不多（仅仅针对 RPC 框架所涉及的知识点而言），学习 Netty ，个人推荐《Netty IN ACTION》以及 https://waylau.gitbooks.io/netty-4-user-guide/Getting%20Started/Before%20Getting%20Started.html 该网站的例子。 参考资料： http://javatar.iteye.com/blog/1123915 – 梁飞 https://gitee.com/huangyong/rpc – 黄勇","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"深入理解 RPC 之动态代理篇","slug":"rpc-dynamic-proxy","date":"2017-12-15T12:16:28.000Z","updated":"2019-09-26T09:45:31.700Z","comments":true,"path":"rpc-dynamic-proxy/","link":"","permalink":"http://lexburner.github.io/rpc-dynamic-proxy/","excerpt":"","text":"提到 JAVA 中的动态代理，大多数人都不会对 JDK 动态代理感到陌生，Proxy，InvocationHandler 等类都是 J2SE 中的基础概念。动态代理发生在服务调用方 / 客户端，RPC 框架需要解决的一个问题是：像调用本地接口一样调用远程的接口。于是如何组装数据报文，经过网络传输发送至服务提供方，屏蔽远程接口调用的细节，便是动态代理需要做的工作了。RPC 框架中的代理层往往是单独的一层，以方便替换代理方式（如 motan 代理层位于 com.weibo.api.motan.proxy ，dubbo 代理层位于 com.alibaba.dubbo.common.bytecode ）。 实现动态代理的方案有下列几种： jdk 动态代理 cglib 动态代理 javassist 动态代理 ASM 字节码 javassist 字节码 其中 cglib 底层实现依赖于 ASM，javassist 自成一派。由于 ASM 和 javassist 需要程序员直接操作字节码，导致使用门槛相对较高，但实际上他们的应用是非常广泛的，如 Hibernate 底层使用了 javassist（默认）和 cglib，Spring 使用了 cglib 和 jdk 动态代理。 RPC 框架无论选择何种代理技术，所需要完成的任务其实是固定的，不外乎‘整理报文’，‘确认网络位置’，‘序列化’,’网络传输’，‘反序列化’，’返回结果’… 技术选型的影响因素框架中使用何种动态代理技术，影响因素也不少。 性能从早期 dubbo 的作者梁飞的博客 http://javatar.iteye.com/blog/814426 中可以得知 dubbo 选择使用 javassist 作为动态代理方案主要考虑的因素是 性能 。 从其博客的测试结果来看 javassist &gt; cglib &gt; jdk 。但实际上他的测试过程稍微有点瑕疵：在 cglib 和 jdk 代理对象调用时，走的是反射调用，而在 javassist 生成的代理对象调用时，走的是直接调用（可以先阅读下梁飞大大的博客）。这意味着 cglib 和 jdk 慢的原因并不是由动态代理产生的，而是由反射调用产生的（顺带一提，很多人认为 jdk 动态代理的原理是反射，其实它的底层也是使用的字节码技术）。而最终我的测试结果，结论如下： javassist ≈ cglib &gt; jdk 。javassist 和 cglib 的效率基本持平 ，而他们两者的执行效率基本可以达到 jdk 动态代理的 2 倍（这取决于测试的机器以及 jdk 的版本，jdk1.8 相较于 jdk1.6 动态代理技术有了质的提升，所以并不是传闻中的那样：cglib 比 jdk 快 10 倍）。文末会给出我的测试代码。 依赖 motan 默认的实现是 jdk 动态代理，代理方案支持 SPI 扩展，可以自行扩展其他实现方式。 使用 jdk 做为默认，主要是减少 core 包依赖，性能不是唯一考虑因素。另外使用字节码方式 javaassist 性能比较优秀，动态代理模式下 jdk 性能也不会差多少。 – rayzhang0603(motan 贡献者) motan 选择使用 jdk 动态代理，原因主要有两个：减少 motan-core 的依赖，方便。至于扩展性，dubbo 并没有预留出动态代理的扩展接口，而是写死了 bytecode ，这点上 motan 做的较好。 易用性从 dubbo 和 motan 的源码中便可以直观的看出两者的差距了，dubbo 为了使用 javassist 技术花费不少的精力，而 motan 使用 jdk 动态代理只用了一个类。dubbo 的设计者为了追求极致的性能而做出的工作是值得肯定的，motan 也预留了扩展机制，两者各有千秋。 动态代理入门指南为了方便对比几种动态代理技术，先准备一个统一接口。 123public interface BookApi &#123; void sell();&#125; JDK 动态代理123456789101112131415161718192021222324private static BookApi createJdkDynamicProxy(final BookApi delegate) &#123; BookApi jdkProxy = (BookApi) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;BookApi.class&#125;, new JdkHandler(delegate)); return jdkProxy;&#125;private static class JdkHandler implements InvocationHandler &#123; final Object delegate; JdkHandler(Object delegate) &#123; this.delegate = delegate; &#125; @Override public Object invoke(Object object, Method method, Object[] objects) throws Throwable &#123; // 添加代理逻辑 &lt;1&gt; if(method.getName().equals(\"sell\"))&#123; System.out.print(\"\"); &#125; return null;// return method.invoke(delegate, objects); &#125; 在真正的 RPC 调用中 ，需要填充‘整理报文’，‘确认网络位置’，‘序列化’,’网络传输’，‘反序列化’，’返回结果’ 等逻辑。 Cglib 动态代理123456789101112131415161718192021222324252627private static BookApi createCglibDynamicProxy(final BookApi delegate) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setCallback(new CglibInterceptor(delegate)); enhancer.setInterfaces(new Class[]&#123;BookApi.class&#125;); BookApi cglibProxy = (BookApi) enhancer.create(); return cglibProxy; &#125; private static class CglibInterceptor implements MethodInterceptor &#123; final Object delegate; CglibInterceptor(Object delegate) &#123; this.delegate = delegate; &#125; @Override public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; // 添加代理逻辑 if(method.getName().equals(\"sell\")) &#123; System.out.print(\"\"); &#125; return null;// return methodProxy.invoke(delegate, objects); &#125; &#125; 和 JDK 动态代理的操作步骤没有太大的区别，只不过是替换了 cglib 的 API 而已。 需要引入 cglib 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.2.5&lt;/version&gt;&lt;/dependency&gt; Javassist 字节码到了 javassist，稍微有点不同了。因为它是通过直接操作字节码来生成代理对象。 1234567891011private static BookApi createJavassistBytecodeDynamicProxy() throws Exception &#123; ClassPool mPool = new ClassPool(true); CtClass mCtc = mPool.makeClass(BookApi.class.getName() + \"JavaassistProxy\"); mCtc.addInterface(mPool.get(BookApi.class.getName())); mCtc.addConstructor(CtNewConstructor.defaultConstructor(mCtc)); mCtc.addMethod(CtNewMethod.make( \"public void sell()&#123; System.out.print(\\\"\\\") ; &#125;\", mCtc)); Class&lt;?&gt; pc = mCtc.toClass(); BookApi bytecodeProxy = (BookApi) pc.newInstance(); return bytecodeProxy;&#125; 需要引入 javassist 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.21.0-GA&lt;/version&gt;&lt;/dependency&gt; 动态代理测试测试环境：window i5 8g jdk1.8 cglib3.2.5 javassist3.21.0-GA 动态代理其实分成了两步：代理对象的创建，代理对象的调用。坊间流传的动态代理性能对比主要指的是后者；前者一般不被大家考虑，如果远程 Refer 的对象是单例的，其只会被创建一次，而如果是原型模式，多例对象的创建其实也是性能损耗的一个考虑因素（只不过远没有调用占比大）。 Create JDK Proxy: 21 ms Create CGLIB Proxy: 342 ms Create Javassist Bytecode Proxy: 419 ms 可能出乎大家的意料，JDK 创建动态代理的速度比后两者要快 10 倍左右。 下面是调用速度的测试： case 1: JDK Proxy invoke cost 1912 ms CGLIB Proxy invoke cost 1015 ms JavassistBytecode Proxy invoke cost 1280 ms case 2: JDK Proxy invoke cost 1747 ms CGLIB Proxy invoke cost 1234 ms JavassistBytecode Proxy invoke cost 1175 ms case 3: JDK Proxy invoke cost 2616 ms CGLIB Proxy invoke cost 1373 ms JavassistBytecode Proxy invoke cost 1335 ms Jdk 的执行速度一定会慢于 Cglib 和 Javassist，但最慢也就 2 倍，并没有达到数量级的差距；Cglib 和 Javassist 不相上下，差距不大（测试中偶尔发现 Cglib 实行速度会比平时慢 10 倍，不清楚是什么原因） 所以出于易用性和性能，私以为使用 Cglib 是一个很好的选择（性能和 Javassist 持平，易用性和 Jdk 持平）。 反射调用既然提到了动态代理和 cglib ，顺带提一下反射调用如何加速的问题。RPC 框架中在 Provider 服务端需要根据客户端传递来的 className + method + param 来找到容器中的实际方法执行反射调用。除了反射调用外，还可以使用 Cglib 来加速。 JDK 反射调用12Method method = serviceClass.getMethod(methodName, new Class[]&#123;&#125;);method.invoke(delegate, new Object[]&#123;&#125;); Cglib 调用123FastClass serviceFastClass = FastClass.create(serviceClass);FastMethod serviceFastMethod = serviceFastClass.getMethod(methodName, new Class[]&#123;&#125;);serviceFastMethod.invoke(delegate, new Object[]&#123;&#125;); 但实测效果发现 Cglib 并不一定比 JDK 反射执行速度快，还会跟具体的方法实现有关 (大雾)。 测试代码略长… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147public class Main &#123; public static void main(String[] args) throws Exception &#123; BookApi delegate = new BookApiImpl(); long time = System.currentTimeMillis(); BookApi jdkProxy = createJdkDynamicProxy(delegate); time = System.currentTimeMillis() - time; System.out.println(\"Create JDK Proxy:\" + time + \"ms\"); time = System.currentTimeMillis(); BookApi cglibProxy = createCglibDynamicProxy(delegate); time = System.currentTimeMillis() - time; System.out.println(\"Create CGLIB Proxy:\" + time + \"ms\"); time = System.currentTimeMillis(); BookApi javassistBytecodeProxy = createJavassistBytecodeDynamicProxy(); time = System.currentTimeMillis() - time; System.out.println(\"Create JavassistBytecode Proxy:\" + time + \"ms\"); for (int i = 0; i &lt; 10; i++) &#123; jdkProxy.sell();//warm &#125; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) &#123; jdkProxy.sell(); &#125; System.out.println(\"JDK Proxy invoke cost\" + (System.currentTimeMillis() - start)+ \"ms\"); for (int i = 0; i &lt; 10; i++) &#123; cglibProxy.sell();//warm &#125; start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) &#123; cglibProxy.sell(); &#125; System.out.println(\"CGLIB Proxy invoke cost\" + (System.currentTimeMillis() - start)+ \"ms\"); for (int i = 0; i &lt; 10; i++) &#123; javassistBytecodeProxy.sell();//warm &#125; start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) &#123; javassistBytecodeProxy.sell(); &#125; System.out.println(\"JavassistBytecode Proxy invoke cost\" + (System.currentTimeMillis() - start)+ \"ms\"); Class&lt;?&gt; serviceClass = delegate.getClass(); String methodName = \"sell\"; for (int i = 0; i &lt; 10; i++) &#123; cglibProxy.sell();//warm &#125; // 执行反射调用 for (int i = 0; i &lt; 10; i++) &#123;//warm Method method = serviceClass.getMethod(methodName, new Class[]&#123;&#125;); method.invoke(delegate, new Object[]&#123;&#125;); &#125; start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) &#123; Method method = serviceClass.getMethod(methodName, new Class[]&#123;&#125;); method.invoke(delegate, new Object[]&#123;&#125;); &#125; System.out.println(\"反射 invoke cost\" + (System.currentTimeMillis() - start)+ \"ms\"); // 使用 CGLib 执行反射调用 for (int i = 0; i &lt; 10; i++) &#123;//warm FastClass serviceFastClass = FastClass.create(serviceClass); FastMethod serviceFastMethod = serviceFastClass.getMethod(methodName, new Class[]&#123;&#125;); serviceFastMethod.invoke(delegate, new Object[]&#123;&#125;); &#125; start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000000; i++) &#123; FastClass serviceFastClass = FastClass.create(serviceClass); FastMethod serviceFastMethod = serviceFastClass.getMethod(methodName, new Class[]&#123;&#125;); serviceFastMethod.invoke(delegate, new Object[]&#123;&#125;); &#125; System.out.println(\"CGLIB invoke cost\" + (System.currentTimeMillis() - start)+ \"ms\"); &#125; private static BookApi createJdkDynamicProxy(final BookApi delegate) &#123; BookApi jdkProxy = (BookApi) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;BookApi.class&#125;, new JdkHandler(delegate)); return jdkProxy; &#125; private static class JdkHandler implements InvocationHandler &#123; final Object delegate; JdkHandler(Object delegate) &#123; this.delegate = delegate; &#125; @Override public Object invoke(Object object, Method method, Object[] objects) throws Throwable &#123; // 添加代理逻辑 if(method.getName().equals(\"sell\"))&#123; System.out.print(\"\"); &#125; return null;// return method.invoke(delegate, objects); &#125; &#125; private static BookApi createCglibDynamicProxy(final BookApi delegate) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setCallback(new CglibInterceptor(delegate)); enhancer.setInterfaces(new Class[]&#123;BookApi.class&#125;); BookApi cglibProxy = (BookApi) enhancer.create(); return cglibProxy; &#125; private static class CglibInterceptor implements MethodInterceptor &#123; final Object delegate; CglibInterceptor(Object delegate) &#123; this.delegate = delegate; &#125; @Override public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; // 添加代理逻辑 if(method.getName().equals(\"sell\")) &#123; System.out.print(\"\"); &#125; return null;// return methodProxy.invoke(delegate, objects); &#125; &#125; private static BookApi createJavassistBytecodeDynamicProxy() throws Exception &#123; ClassPool mPool = new ClassPool(true); CtClass mCtc = mPool.makeClass(BookApi.class.getName() + \"JavaassistProxy\"); mCtc.addInterface(mPool.get(BookApi.class.getName())); mCtc.addConstructor(CtNewConstructor.defaultConstructor(mCtc)); mCtc.addMethod(CtNewMethod.make( \"public void sell()&#123; System.out.print(\\\"\\\") ; &#125;\", mCtc)); Class&lt;?&gt; pc = mCtc.toClass(); BookApi bytecodeProxy = (BookApi) pc.newInstance(); return bytecodeProxy; &#125;&#125;","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"深入理解 RPC 之序列化篇 -- 总结篇","slug":"rpc-serialize-2","date":"2017-12-11T14:58:54.000Z","updated":"2019-09-26T09:45:30.015Z","comments":true,"path":"rpc-serialize-2/","link":"","permalink":"http://lexburner.github.io/rpc-serialize-2/","excerpt":"","text":"上一篇 《深入理解 RPC 之序列化篇 –Kryo》, 介绍了序列化的基础概念，并且详细介绍了 Kryo 的一系列特性，在这一篇中，简略的介绍其他常用的序列化器，并对它们进行一些比较。序列化篇仅仅由 Kryo 篇和总结篇构成可能有点突兀，等待后续有时间会补充详细的探讨。 定义抽象接口123456public interface Serialization &#123; byte[] serialize(Object obj) throws IOException; &lt;T&gt; T deserialize(byte[] bytes, Class&lt;T&gt; clz) throws IOException;&#125; RPC 框架中的序列化实现自然是种类多样，但它们必须遵循统一的规范，于是我们使用 Serialization 作为序列化的统一接口，无论何种方案都需要实现该接口。 Kryo 实现Kryo 篇已经给出了实现代码。 1234567891011121314151617181920212223242526272829303132public class KryoSerialization implements Serialization &#123; @Override public byte[] serialize(Object obj) &#123; Kryo kryo = kryoLocal.get(); ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); Output output = new Output(byteArrayOutputStream); kryo.writeObject(output, obj); output.close(); return byteArrayOutputStream.toByteArray(); &#125; @Override public &lt;T&gt; T deserialize(byte[] bytes, Class&lt;T&gt; clz) &#123; Kryo kryo = kryoLocal.get(); ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes); Input input = new Input(byteArrayInputStream); input.close(); return (T) kryo.readObject(input, clz); &#125; private static final ThreadLocal&lt;Kryo&gt; kryoLocal = new ThreadLocal&lt;Kryo&gt;() &#123; @Override protected Kryo initialValue() &#123; Kryo kryo = new Kryo(); kryo.setReferences(true); kryo.setRegistrationRequired(false); return kryo; &#125; &#125;;&#125; 所需依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.esotericsoftware&lt;/groupId&gt; &lt;artifactId&gt;kryo&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt;&lt;/dependency&gt; Hessian 实现1234567891011121314151617public class Hessian2Serialization implements Serialization &#123; @Override public byte[] serialize(Object data) throws IOException &#123; ByteArrayOutputStream bos = new ByteArrayOutputStream(); Hessian2Output out = new Hessian2Output(bos); out.writeObject(data); out.flush(); return bos.toByteArray(); &#125; @Override public &lt;T&gt; T deserialize(byte[] bytes, Class&lt;T&gt; clz) throws IOException &#123; Hessian2Input input = new Hessian2Input(new ByteArrayInputStream(bytes)); return (T) input.readObject(clz); &#125;&#125; 所需依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.caucho&lt;/groupId&gt; &lt;artifactId&gt;hessian&lt;/artifactId&gt; &lt;version&gt;4.0.51&lt;/version&gt;&lt;/dependency&gt; 大名鼎鼎的 Hessian 序列化方案经常被 RPC 框架用来作为默认的序列化方案，可见其必然具备一定的优势。其具体的优劣我们放到文末的总结对比中与其他序列化方案一起讨论。而在此，着重提一点 Hessian 使用时的坑点。 BigDecimal 的反序列化 使用 Hessian 序列化包含 BigDecimal 字段的对象时会导致其值一直为 0，不注意这个 bug 会导致很大的问题，在最新的 4.0.51 版本仍然可以复现。解决方案也很简单，指定 BigDecimal 的序列化器即可，通过添加两个文件解决这个 bug： resources\\META-INF\\hessian\\serializers 1java.math.BigDecimal=com.caucho.hessian.io.StringValueSerializer resources\\META-INF\\hessian\\deserializers 1java.math.BigDecimal=com.caucho.hessian.io.BigDecimalDeserializer Protostuff 实现12345678910111213141516171819202122232425262728public class ProtostuffSerialization implements Serialization &#123; @Override public byte[] serialize(Object obj) throws IOException &#123; Class clz = obj.getClass(); LinkedBuffer buffer = LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE); try &#123; Schema schema = RuntimeSchema.createFrom(clz); return ProtostuffIOUtil.toByteArray(obj, schema, buffer); &#125; catch (Exception e) &#123; throw e; &#125; finally &#123; buffer.clear(); &#125; &#125; @Override public &lt;T&gt; T deserialize(byte[] bytes, Class&lt;T&gt; clz) throws IOException &#123; T message = objenesis.newInstance(clz); // &lt;1&gt; Schema&lt;T&gt; schema = RuntimeSchema.createFrom(clz); ProtostuffIOUtil.mergeFrom(bytes, message, schema); return message; &#125; private Objenesis objenesis = new ObjenesisStd(); // &lt;2&gt;&#125; 所需依赖： 1234567891011121314151617&lt;!-- Protostuff --&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Objenesis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.objenesis&lt;/groupId&gt; &lt;artifactId&gt;objenesis&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt;&lt;/dependency&gt; Protostuff 可以理解为 google protobuf 序列化的升级版本，protostuff-runtime 无需静态编译，这比较适合 RPC 通信时的特性，很少见到有人直接拿 protobuf 作为 RPC 的序列化器，而 protostuff-runtime 仍然占据一席之地。 使用 Protostuff 的一个坑点在于其反序列化时需用户自己实例化序列化后的对象，所以才有了 T message = objenesis.newInstance(clz); 这行代码。使用 objenesis 工具实例化一个需要的对象，而后使用 ProtostuffIOUtil 完成赋值操作。 上述的 objenesis.newInstance(clz) 可以由 clz.newInstance() 代替，后者也可以实例化一个对象，但如果对象缺少无参构造函数，则会报错。借助于 objenesis 可以绕开无参构造器实例化一个对象，且性能优于直接反射创建。所以一般在选择 Protostuff 作为序列化器时，一般配合 objenesis 使用。 Fastjson 实现1234567891011121314151617public class FastJsonSerialization implements Serialization &#123; static final String charsetName = \"UTF-8\"; @Override public byte[] serialize(Object data) throws IOException &#123; SerializeWriter out = new SerializeWriter(); JSONSerializer serializer = new JSONSerializer(out); serializer.config(SerializerFeature.WriteEnumUsingToString, true);//&lt;1&gt; serializer.config(SerializerFeature.WriteClassName, true);//&lt;1&gt; serializer.write(data); return out.toBytes(charsetName); &#125; @Override public &lt;T&gt; T deserialize(byte[] data, Class&lt;T&gt; clz) throws IOException &#123; return JSON.parseObject(new String(data), clz); &#125;&#125; 所需依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.28&lt;/version&gt;&lt;/dependency&gt; JSON 序列化注意对枚举类型的特殊处理；额外补充类名可以在反序列化时获得更丰富的信息。 序列化对比在我的 PC 上对上述序列化方案进行测试： 测试用例：对一个简单 POJO 对象序列化 / 反序列化 100W 次 serialize/ms deserialize/ms Fastjson 2832 2242 Kryo 2975 1987 Hessian 4598 3631 Protostuff 2944 2541 测试用例：序列化包含 1000 个简单对象的 List，循环 1000 次 serialize/ms deserialize/ms Fastjson 2551 2821 Kryo 1951 1342 Hessian 1828 2213 Protostuff 1409 2813 对于耗时类型的测试需要做到预热 + 平均值等条件，测试后效果其实并不如人意，从我不太严谨的测试来看，并不能明显地区分出他们的性能。另外，Kryo 关闭 Reference 可以加速，Protostuff 支持静态编译加速，Schema 缓存等特性，每个序列化方案都有自身的特殊性，启用这些特性会伴随一些限制。但在 RPC 实际地序列化使用中不会利用到这些特性，所以在测试时并没有特别关照它们。 序列化包含 1000 个简单对象的 List，查看字节数 字节数 /byte Fastjson 120157 Kryo 39134 Hessian 86166 Protostuff 86084 字节数这个指标还是很直观的，Kryo 拥有绝对的优势，只有 Hessian，Protostuff 的一半，而 Fastjson 作为一个文本类型的序列化方案，自然无法和字节类型的序列化方案比较。而字节最终将用于网络传输，是 RPC 框架非常在意的一个性能点。 综合评价 经过个人测试，以及一些官方的测试结果，我觉得在 RPC 场景下，序列化的速度并不是一个很大考量标准，因为各个序列化方案都在有意优化速度，只要不是 jdk 序列化，速度就不会太慢。 Kryo：专为 JAVA 定制的序列化协议，序列化后字节数少，利于网络传输。但不支持跨语言（或支持的代价比较大）。dubbox 扩展中支持了 kryo 序列化协议。github 3018 star。 Hessian：支持跨语言，序列化后字节数适中，API 易用。是国内主流 rpc 框架：dubbo，motan 的默认序列化协议。hessian.caucho.com 未托管在 github Protostuff：提起 Protostuff 不得不说到 Protobuf。Protobuf 可能更出名一些，因为其是 google 的亲儿子，grpc 框架便是使用 protobuf 作为序列化协议，虽然 protobuf 与语言无关平台无关，但需要使用特定的语法编写 .prpto 文件，然后静态编译，这带了一些复杂性。而 protostuff 实际是对 protobuf 的扩展，protostuff-runtime 模块继承了 protobuf 性能，且不需要预编译文件，但与此同时，也失去了跨语言的特性。所以 protostuff 的定位是一个 JAVA 序列化框架，其性能略优于 Hessian。tip ：protostuff 反序列化时需用户自己初始化序列化后的对象，其只负责将该对象进行赋值。github 719 star。 Fastjson：作为一个 json 工具，被拉到 RPC 的序列化方案中似乎有点不妥，但 motan 该 RPC 框架除了支持 hessian 之外，还支持了 fastjson 的序列化。可以将其作为一个跨语言序列化的简易实现方案。github 11.8k star。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"南京 IAS 架构师峰会观后感","slug":"NJIAS2017","date":"2017-12-05T17:15:28.000Z","updated":"2019-09-26T09:45:29.979Z","comments":true,"path":"NJIAS2017/","link":"","permalink":"http://lexburner.github.io/NJIAS2017/","excerpt":"","text":"上周六，周日在南京举办了 IAS 架构师峰会，这么多人的技术分享会还是头一次参加，大佬云集，涨了不少姿势。特此一篇记录下印象深刻的几场分享。由于全凭记忆叙述，故只能以流水账的形式还原出现场的收获。 大型支付交易平台的演进过程 陈斌，《架构即未来》译者，易宝支付 CTO。 交易系统具备以下特点，交易量大，并发度高，业务敏感度高，响应速度容忍度低… 从而使得支付交易平台需要有以下的特点： 高可用：7X24*365 随时可用 高安全：需满足 PCI-DSS 要求 高效率：每笔交易的成本要低 高扩展：随业务的快速发展扩张 从以上几点话题引申出了系统扩展的三个阶段 X 轴扩展 – 扩展机器 也就是通俗意义中集群方案，横向扩展，通过添加多台机器负载均衡，从而扩展计算能力，这是最简单粗暴，也是最直接易用的方案。 Y 轴扩展 – 拆分服务 当水平扩展遇到瓶颈后，可以进行服务的拆分，将系统按照业务模块进行拆分，从而可以选择性定制化地扩展特定的模块。如电商系统中拆分出订单模块，商品模块，会员模块，地址模块… 由于各个模块的职责不同，如订单模块在双 11 时压力很大，可以多部署一些订单模块，而其他压力不大的模块，则进行少量地部署。 Z 轴扩展 – 拆分数据 服务拆分之后仍然无法解决与日俱增的数据量问题，于是引发了第三层扩展，数据的分片，我理解的 sharding，不仅仅存在于数据库，还包含了 redis，文件等。 另外陈斌老师还聊了一个有意思的话题，系统可用性下降的原因根源是什么？最终他给出的答案是：人。系统升级后引发的事故 80% 是由于人的误操作或者触发了 bug 等人为因素导致的，是人就会手抖。借此引出了单元测试，持续集成，持续交付的重要性。健全这三者是保障系统可用性的最大利器。 在技术晚宴，陈斌老师又分享了一些管理经验： 如何打造一支优秀的技术团队 。 分析了构成团队的四要素： 人员：健全职级体系，区别考评，挖掘潜能，及时鼓励，扁平化管理 组织：面向产出，利于创新，敏捷小团队 过程：聚集问题的根源，适当地使⽤用 ITIL，不断优化过程，自动化取代人工 文化：鼓励分享，打破 devops 的边界，鼓励创新，树⽴立正确的技术负债观 对于技术人员来说可能有点抽象，不过对于立志于要成为 CIO 的人肯定是大有裨益的，具体的理解可以参考《架构即未来》中的具体阐释。(ps：这里的架构并不是指技术架构，别问我为什么知道，问问我看了一半后在落灰的那本书，你什么都明白了) 轻量级微服务架构实践之路 黄勇，特赞科技 CTO，《轻量级微服务架构》作者。 非常具有人格魅力的一位演讲者，这可能是当天最有价值的一场分享。 他首先提出了一个问题：什么是微服务？怎么理解这个 ‘微’ 字。随后他给出了自己的理解：微 = 合理。一知半解的微服务实践者可能盲目地拆分服务，微并不是代表颗粒越小越好，用领域驱动的术语来说，微服务模块需要用合适的限界上下文。黄勇老师给出了 4 个微服务拆分的技巧： 业务先行 由粗到细 避免耦合 持续改进 非常实用且具有指导意义的 4 个思想，当你还在犹豫到底该如何拆分你的模块时，可以尝试先从单体式开始开发，业务发展会指引你拆分出合适模块，合适的粒度。当一个个业务被剥离出 Monolithic 这个怪物，持续重构，持续改进，这样可以指引你深入理解微服务。 随后给出了轻量级微服务架构的技术选型，非常有参考价值。 其 PPT 总结了很多经验 list，可以在文末链接获取。 顺带一提，没记错的话黄勇老师介绍到其公司的语言栈有：Java，Node，Go，在后面其他老师的分享中集中介绍多语言栈的意义。 《轻量级微服务架构》上下册一起购买，赠送“技能图谱”，感兴趣的朋友可以阅读一下他的书籍。购买链接 ps: 谁让我白得了一本上册呢。 Cloud Native 架构一致性问题及解决方案 王启军，华为架构部资深架构师。 王启军老师则是带来了如今微服务架构最难的一个技术点的分享：分布式中的一致性问题。 他的分享中涵盖了很多经典的分布式一致性问题的案例，如两军问题，拜占庭将军问题。引出了经典的 CAP 理论，NWR，Lease，Replicated state machine，Paxos 算法。由于时间问题，45 分钟根本无法详细地介绍他们的流程，实属可惜。 一致性问题被分成了两类，包括： 以数据为中心的一致性模型 严格一致性 顺序一致性 因果一致性 FIFO 一致性 弱一致性 释放一致性 入口一致性 以用户为中心的一致性模型 单调读一致性 单调写一致性 写后读一致性 读后写一致性 这么多一致性分类太过于学术范，所以业界通常将他们简单的归为了三类： 弱一致性 最终一致性 强一致性 对于各个一致性模型的科普，以及一些事务模型和解决方案如 2PC，3PC，TCC 型事务，PPT 中都给出了简单的介绍。 技术架构演变全景图 - 从单体式到云原生 千米网首席架构师，曹祖鹏（右） &amp; 当当网首席架构师，张亮（左）。知名开源框架 sharding-jdbc，elastic-job 作者。 别开生面的面向对象技术分享。也是我本次大会最期待的一场分享，分享涵盖的知识点很多，深度和广度得兼，其分享中阐释了云原生，服务编排、治理、调度等 2017 年处于潮流前线的技术热点，通俗易懂地介绍了 service mesh 的概念，让观众在惊叹于互联网技术变化如此之快的同时，也带来了很多思考。 分享中还对比了 Spring Cloud 和 Dubbo，当当网和千米网的团队都向 Dubbo 贡献过代码，Spring Cloud 又是国内话题最多的框架之一，台下观众对这样的话题自然是非常感兴趣。张亮老师着重介绍了 Spring Cloud 相关的组件，而曹祖鹏老师重点对比了其与 Dubbo 的区别。 Spring Cloud 的出现同时宣告了 Cloud Native 云原生的首映，其为微服务的构架带来了一整套初具雏形的解决方案，包含了 Zuul 网关，Ribbon 客户端负载均衡，Eureka 服务注册与发现，Hystrix 熔断… 并且有强大的 Spring 终端组件支持，活跃的社区，丰富的文档。 随后，介绍了云原生的技术全景图： 之后，简单解释了治理，编排，调度的概念后，并重点介绍了服务治理，编排相关的技术栈，老牌的 nginx，netflix ribbon，zuul 等产品，如今风靡的 k8s。尤其是介绍到 service mesh 这一比较新的概念时，分析了服务的治理，编排，调度从应用层转移到基础设施层的趋势，无疑是非常 exciting 的一件事。如 dubbo 等 rpc 框架的服务注册发现依赖于 zk，consul，而 spring cloud 的服务注册发现组件 eureka，以及其客户端路由组件 ribbon，服务端路由组件 zuul 等都是从应用层解决了服务的相关问题，而 service mesh 提供了一个新的思路，从基础设施层解决服务的相关问题： 如果 service mesh 的开源产品 Linkerd 和 Lstio 能够保持好的势头，配合 k8s 在运维层的大一统，很有可能带来架构的新格局。与此同时，java 一枝独秀的时代即将宣告终结，多语言的优势将会被 service mesh 发扬光大，使用 go 编写高并发的模块，使用 java 编写业务型模块，nodejs 打通前端模块，python 处理性能要求不高模块提升开发效率… 而不用关心多语言交互的问题，这都交由 service mesh 解决，这几乎是 2017 最潮流的知识点，没有之一。 （引用一张 jimmysong 博客中的图片） 如上图所示，得知 Spring Cloud 竟然是 2015 兴起的技术栈时，可能还会有些吃惊，等到可以预见的 2018，运维层的技术栈开始向上侵蚀应用层的技术栈，不得不感叹互联网技术的日新月异。 两位老师从可追溯的历史到可预见的未来展现了云原生架构的演进史，着实给小白们好好科普了一番。 番外此次技术分享会收获颇丰，不枉我早上 5 点起来赶高铁去南京了。但还是得吐槽一句，这门票真 tl 的贵啊，就不能便宜点吗！！！[微笑 face] 其他分享者的话题也很有意思，不仅包含了微服务方向，还囊括了人工智能，机器学习，运维，领导力，架构演变，游戏架构等多个方向，笔者选择性的介绍了一些，全部的 PPT 可以在下方的链接中获得。 https://pan.baidu.com/s/1eSbCu5c","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"}]},{"title":"深入理解 RPC 之序列化篇 --Kryo","slug":"rpc-serialize-1","date":"2017-11-28T14:15:28.000Z","updated":"2019-09-26T09:45:31.355Z","comments":true,"path":"rpc-serialize-1/","link":"","permalink":"http://lexburner.github.io/rpc-serialize-1/","excerpt":"","text":"一年前，笔者刚刚接触 RPC 框架，从单体式应用向分布式应用的变革无疑是让人兴奋的，同时也对 RPC 背后到底做了哪些工作产生了兴趣，但其底层的设计对新手而言并不是很友好，其涉及的一些常用技术点都有一定的门槛。如传输层常常使用的 netty，之前完全没听过，想要学习它，需要掌握前置知识点 nio；协议层，包括了很多自定义的协议，而每个 RPC 框架的实现都有差异；代理层的动态代理技术，如 jdk 动态代理，虽然实战经验不多，但至少还算会用，而 cglib 则又有一个盲区；序列化层倒还算是众多层次中相对简单的一环，但 RPC 为了追求可扩展性，性能等诸多因素，通常会支持多种序列化方式以供使用者插拔使用，一些常用的序列化方案 hessian，kryo，Protobuf 又得熟知… 这个系列打算就 RPC 框架涉及到的一些知识点进行探讨，本篇先从序列化层的一种选择 –kryo 开始进行介绍。 序列化概述大白话介绍下 RPC 中序列化的概念，可以简单理解为对象 –&gt; 字节的过程，同理，反序列化则是相反的过程。为什么需要序列化？因为网络传输只认字节。所以互信的过程依赖于序列化。有人会问，FastJson 转换成字符串算不算序列化？对象持久化到数据库算不算序列化？没必要较真，广义上理解即可。 JDK 序列化可能你没用过 kryo，没用过 hessian，但你一定用过 jdk 序列化。我最早接触 jdk 序列化，是在大二的 JAVA 大作业中，《XX 管理系统》需要把对象保存到文件中（那时还没学数据库），jdk 原生支持的序列化方式用起来也很方便。 12345678910111213141516171819class Student implements Serializable&#123; private String name; &#125; class Main&#123; public static void main(String[] args) throws Exception&#123; // create a Student Student st = new Student(\"kirito\"); // serialize the st to student.db file ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\"student.db\")); oos.writeObject(st); oos.close(); // deserialize the object from student.db ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"student.db\")); Student kirito = (Student) ois.readObject(); ois.close(); // assert assert \"kirito\".equals(kirito.getName()); &#125; &#125; Student 实体类需要实现 Serializable 接口，以告知其可被序列化。 序列化协议的选择通常有下列一些常用的指标： 通用性。是否只能用于 java 间序列化 / 反序列化，是否跨语言，跨平台。 性能。分为空间开销和时间开销。序列化后的数据一般用于存储或网络传输，其大小是很重要的一个参数；解析的时间也影响了序列化协议的选择，如今的系统都在追求极致的性能。 可扩展性。系统升级不可避免，某一实体的属性变更，会不会导致反序列化异常，也应该纳入序列化协议的考量范围。 易用性。API 使用是否复杂，会影响开发效率。 容易用的模型通常性能不好，性能好的模型通常用起来都比较麻烦。显然，JDK 序列化属于前者。我们不过多介绍它，直接引入今天的主角 kryo 作为它的替代品。 Kryo 入门引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.esotericsoftware&lt;/groupId&gt; &lt;artifactId&gt;kryo&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt;&lt;/dependency&gt; 由于其底层依赖于 ASM 技术，与 Spring 等框架可能会发生 ASM 依赖的版本冲突（文档中表示这个冲突还挺容易出现）所以提供了另外一个依赖以供解决此问题 12345&lt;dependency&gt; &lt;groupId&gt;com.esotericsoftware&lt;/groupId&gt; &lt;artifactId&gt;kryo-shaded&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt;&lt;/dependency&gt; 快速入门12345678910111213141516class Student implements Serializable&#123; private String name; &#125; public class Main &#123; public static void main(String[] args) throws Exception&#123; Kryo kryo = new Kryo(); Output output = new Output(new FileOutputStream(\"student.db\")); Student kirito = new Student(\"kirito\"); kryo.writeObject(output, kirito); output.close(); Input input = new Input(new FileInputStream(\"student.db\")); Student kiritoBak = kryo.readObject(input, Student.class); input.close(); assert \"kirito\".equals(kiritoBak.getName()); &#125;&#125; 不需要注释也能理解它的执行流程，和 jdk 序列化差距并不是很大。 三种读写方式Kryo 共支持三种读写方式 如果知道 class 字节码，并且对象不为空 123kryo.writeObject(output, someObject);// ...SomeClass someObject = kryo.readObject(input, SomeClass.class); 快速入门中的序列化 / 反序列化的方式便是这一种。而 Kryo 考虑到 someObject 可能为 null，也会导致返回的结果为 null，所以提供了第二套读写方式。 如果知道 class 字节码，并且对象可能为空 123kryo.writeObjectOrNull(output, someObject);// ...SomeClass someObject = kryo.readObjectOrNull(input, SomeClass.class); 但这两种方法似乎都不能满足我们的需求，在 RPC 调用中，序列化和反序列化分布在不同的端点，对象的类型确定，我们不想依赖于手动指定参数，最好是…emmmmm… 将字节码的信息直接存放到序列化结果中，在反序列化时自行读取字节码信息。Kryo 考虑到了这一点，于是提供了第三种方式。 如果实现类的字节码未知，并且对象可能为 null 123456kryo.writeClassAndObject(output, object);// ...Object object = kryo.readClassAndObject(input);if (object instanceof SomeClass) &#123; // ...&#125; 我们牺牲了一些空间一些性能去存放字节码信息，但这种方式是我们在 RPC 中应当使用的方式。 我们关心的问题继续介绍 Kryo 特性之前，不妨让我们先思考一下，一个序列化工具或者一个序列化协议，应当需要考虑哪些问题。比如，支持哪些类型的序列化？循环引用会不会出现问题？在某个类增删字段之后反序列化会报错吗？等等等等…. 带着我们考虑到的这些疑惑，以及我们暂时没考虑到的，但 Kryo 帮我们考虑到的，来看看 Kryo 到底支持哪些特性。 支持的序列化类型 boolean Boolean byte Byte char Character short Short int Integer long Long float Float double Double byte[] String BigInteger BigDecimal Collection Date Collections.emptyList Collections.singleton Map StringBuilder TreeMap Collections.emptyMap Collections.emptySet KryoSerializable StringBuffer Class Collections.singletonList Collections.singletonMap Currency Calendar TimeZone Enum EnumSet 表格中支持的类型一览无余，这都是其默认支持的。 12Kryo kryo = new Kryo();kryo.addDefaultSerializer(SomeClass.class, SomeSerializer.class); 这样的方式，也可以为一个 Kryo 实例扩展序列化器。 总体而言，Kryo 支持以下的类型： 枚举 集合、数组 子类 / 多态 循环引用 内部类 泛型 但需要注意的是，Kryo 不支持 Bean 中增删字段 。如果使用 Kryo 序列化了一个类，存入了 Redis，对类进行了修改，会导致反序列化的异常。 另外需要注意的一点是使用反射创建的一些类序列化的支持。如使用 Arrays.asList(); 创建的 List 对象，会引起序列化异常。 1Exception in thread &quot;main&quot; com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor): java.util.Arrays$ArrayList 但 new ArrayList() 创建的 List 对象则不会，使用时需要注意，可以使用第三方库对 Kryo 进行序列化类型的扩展。如 https://github.com/magro/kryo-serializers 所提供的。 不支持包含无参构造器类的反序列化 ，尝试反序列化一个不包含无参构造器的类将会得到以下的异常： 1Exception in thread &quot;main&quot; com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor): moe.cnkirito.Xxx 保证每个类具有无参构造器是应当遵守的编程规范，但实际开发中一些第三库的相关类不包含无参构造，的确是有点麻烦。 线程安全Kryo 是线程不安全的，意味着每当需要序列化和反序列化时都需要实例化一次，或者借助 ThreadLocal 来维护以保证其线程安全。 1234567891011private static final ThreadLocal&lt;Kryo&gt; kryos = new ThreadLocal&lt;Kryo&gt;() &#123; protected Kryo initialValue() &#123; Kryo kryo = new Kryo(); // configure kryo instance, customize settings return kryo; &#125;;&#125;;// Somewhere else, use KryoKryo k = kryos.get();... Kryo 相关配置参数详解每个 Kryo 实例都可以拥有两个配置参数，这值得被拉出来单独聊一聊。 12kryo.setRegistrationRequired(false);// 关闭注册行为kryo.setReferences(true);// 支持循环引用 Kryo 支持对注册行为，如 kryo.register(SomeClazz.class);, 这会赋予该 Class 一个从 0 开始的编号，但 Kryo 使用注册行为最大的问题在于，其不保证同一个 Class 每一次注册的号码想用，这与注册的顺序有关，也就意味着在不同的机器、同一个机器重启前后都有可能拥有不同的编号，这会导致序列化产生问题，所以在分布式项目中，一般关闭注册行为。 第二个注意点在于循环引用，Kryo 为了追求高性能，可以关闭循环引用的支持。不过我并不认为关闭它是一件好的选择，大多数情况下，请保持 kryo.setReferences(true)。 常用 Kryo 工具类1234567891011121314151617181920212223242526272829public class KryoSerializer &#123; public byte[] serialize(Object obj) &#123; Kryo kryo = kryoLocal.get(); ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); Output output = new Output(byteArrayOutputStream);//&lt;1&gt; kryo.writeClassAndObject(output, obj);//&lt;2&gt; output.close(); return byteArrayOutputStream.toByteArray(); &#125; public &lt;T&gt; T deserialize(byte[] bytes) &#123; Kryo kryo = kryoLocal.get(); ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes); Input input = new Input(byteArrayInputStream);// &lt;1&gt; input.close(); return (T) kryo.readClassAndObject(input);//&lt;2&gt; &#125; private static final ThreadLocal&lt;Kryo&gt; kryoLocal = new ThreadLocal&lt;Kryo&gt;() &#123;//&lt;3&gt; @Override protected Kryo initialValue() &#123; Kryo kryo = new Kryo(); kryo.setReferences(true);// 默认值为 true, 强调作用 kryo.setRegistrationRequired(false);// 默认值为 false, 强调作用 return kryo; &#125; &#125;; &#125; Kryo 的 Input 和 Output 接收一个 InputStream 和 OutputStream，Kryo 通常完成字节数组和对象的转换，所以常用的输入输出流实现为 ByteArrayInputStream/ByteArrayOutputStream。 writeClassAndObject 和 readClassAndObject 配对使用在分布式场景下是最常见的，序列化时将字节码存入序列化结果中，便可以在反序列化时不必要传入字节码信息。 使用 ThreadLocal 维护 Kryo 实例，这样减少了每次使用都实例化一次 Kryo 的开销又可以保证其线程安全。 参考文章https://github.com/EsotericSoftware/kryo Kryo 使用指南 序列化与反序列化 更多的序列化方案，和 RPC 其他层次中会涉及到的技术，在后续的文章中进行逐步介绍。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"给初中级 JAVA 准备的面试题","slug":"view-1","date":"2017-11-28T14:15:28.000Z","updated":"2019-09-26T09:45:31.367Z","comments":true,"path":"view-1/","link":"","permalink":"http://lexburner.github.io/view-1/","excerpt":"","text":"笔者作为一个今年刚毕业的初级 JAVA，根据群里水友的讨论，也结合自己刚毕业时的一些面经，加上近期一点点在公司面试别人的经验，总结了如下的常见面试问题，适用于初级和中级 JAVA。 JAVA HashMap 相关 HashMap 一直是经典的面试题，所有面试官都喜欢问他，因为它可以牵扯出非常多的知识点，而面试者到底能了解到何种程度，则一定程度反映其综合能力。 细节聊扩容因子 LoadFactor=0.75，初始大小 InitailCapacity=16 纵向聊其底层实现，数据结构是数组 + 链表，提到 jdk1.8 之后对链表节点到达 8 之后转换为红黑树加分。继续追问的话便是引申出常用的数据结构：队列，栈，树，图。 横向聊线程安全，HashMap 为线程不安全，一般问多线程操作会导致其死循环的原因。与线程安全的 ConcurrentHashMap 对比，又扩展到 ConcurrentHashMap 的实现。继续追问的话便是引申出线程安全的定义，问一些常用的并发容器，考察面试者对 java.util.concurrent 包的掌握情况。那么至少可以牵扯出如下的问题： ConcurrentHashMap 相关 面试者可以先说历史，1.8 之前采用分段锁，核心就是一句话：尽量降低同步锁的粒度。1.8 之后使用 CAS 思想代替冗杂的分段锁实现。不出意料，面试者答出 CAS 之后必定会被追问其思想以及应用，换做我自己的话会有如下思路作答：CAS 采用乐观锁思想达到 lock free，提一下 sun.misc.Unsafe 中的 native 方法，至于 CAS 的其他应用可以聊一聊 Atomic 原子类和一些无锁并发框架（如 Amino），提到 ABA 问题加分。 线程安全与锁 线程安全这个词也是面试的高频词，说完上面的并发容器，回头说一说线程安全的定义，按照周志明大大的话回答私以为是极好的： 当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替进行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么称这个类是线程安全的 通常与锁一起出现：除了 synchronized 之外，还经常被问起的是 juc 中的 Lock 接口，其具体实现主要有两种：可重入锁，读写锁。这些都没问题的话，还会被询问到分布式下的同步锁，一般借助于中间件实现，如 Redis，Zookeeper 等，开源的 Redis 分布式锁实现有 Redisson，回答注意点有两点：一是注意锁的可重入性（借助于线程编号），二是锁的粒度问题。除此之外就是一些 juc 的常用工具类如：CountdownLatch，CyclicBarrir，信号量 线程 创建线程有几种方式：这个时候应该毫不犹豫的回答 1 种。面试官会有些惊讶于你的回答，因为似乎他已经习惯了听到 Thread 和 Runnable2 种方式的“标准答案”。其实，仔细审题会发现，java 创建线程只有一种方式：Thread。Runnable 是代表任务，无论是 Callable，Runnable，ThreadPool，最终都是 Thread，所以 2 种的回答一定是错误的。 设计模式 如经典的单利模式。当被问到单例模式时，私以为在有准备的前提下，回答使用双检锁的方式实现可以很好地诱导面试官。双检锁实现线程安全的单利模式有两块注意点：1 锁的粒度问题 2 静态变量需要被 volatile 修饰。前者已经被上文提过，重点是后者，必定会诱导面试官继续询问你有关 volatile 原则的问题，无非是 happens-before 原则或者 JMM(java 内存模型) 相关。前者只需要熟记几条关键性的原则即可，而后者回答的重点便是需要提到主存与工作内存的关系。 工厂模式，观察者模式，模板方法模式，策略模式，职责链模式等等，通常会结合 Spring 和 UML 类图提问。 JVM 相关 说实话，我自己对 JVM 的掌握几乎完全来自于《深入理解 java 虚拟机》，加上一点点线上的经验。初级岗位常问的问题也是固定的那么几个。 内存分区：主要就是堆和栈，严谨点回答可以答方法区，虚拟机栈，本地方法栈，堆，程序计数器。聊一聊 Hotspot 在 jdk1.7 中将常量池移到了堆中，jdk1.8 移除永久代用 MetaSpace 代替起码可以佐证：你喜欢在一些 JAVA 群里面吹水。 垃圾回收算法：新生代由于对象朝生夕死使用标记 - 清除 (or 标记 - 整理) 算法，老年代生命力强使用复制算法。提到一句分代收集即可。 垃圾回收器一两个名字还是得叫的上来：Serial，Parallel，CMS，G1… 如何判断一个对象可以被回收：引用计数（可以提到 Netty 中的使用案例），可达性分析（JVM 使用） IO 相关 bio，nio 区别要熟知，了解 nio 中的 ByteBuffer，Selector，Channel 可以帮助面试者度过不少难关。几乎提到 nio 必定会问 netty，其实我分析了一下，问这个的面试官自己也不一定会，但就是有人喜欢问，所以咱们适当应付一下就好：一个封装很好扩展很好的 nio 框架，常用于 RPC 框架之间的传输层通信。 反射 聊一聊你对 JAVA 中反射的理解：运行时操作一个类的神器，可以获取构造器，方法，成员变量，参数化类型… 使用案例如 Hibernate，BeanUtils。 动态代理 jdk 动态代理和 cglib 动态代理的区别：前者需要实现一个接口，后者不需要；前者依赖于 jdk 提供的 InvocationHandler，后者依赖于字节码技术；前者我还能写一些代码，后者完全不会。大概就这些差别了。 开源框架Tomcat我没看过源码，除了老生常谈的双亲委托类加载机制，似乎只能问一些相关参数了。 Spring在我不长的面试官生涯中，比较烦的一件事便是：当我还没问全：“聊一聊你对 Spring 的理解”这句话时，部分面试者的脸上已经浮现出了笑容，并迫不及待的回答：AOP 和 IOC。这本无可厚非，但一旦这成了条件反射式的回答，便违背了面试的初衷。 在面试中，Spring 从狭义上可以被理解成 Spring Framework&amp;SpringMVC。而广义上包含了 Spring 众多的开源项目，如果面试者连 spring.io 都没有访问过，私以为是不应该的扣分项。 Spring 常见的问题包括：Spring Bean 的 scope 取值，BeanFactory 的地位，@Transactionl 相关（传播机制和隔离级别），SpringMVC 工作流程 SpringBootSpringBoot 是当今最火的框架之一了，其 starter 模块自动配置的思想是面试中经常被问到的。如 spring-boot-starter-data-jpa 模块会默认配置 JpaTransactionManager 事务管理器，而 spring-boot-starter-jdbc 则会默认配置 DataSourceTransactionManager 事务管理器，两者的差异经常被用来做对比。@ConditionalOnMissingBean，@ConditionalOnBean 等注解作用也需要被掌握。 JPA&amp;HibernateORM 的思想 懒加载如何配置以及意义 级联如何配置，什么时候应该使用级联 一级缓存：Session 级别的缓存 @Version 的使用：数据库的乐观锁 数据库这里的数据库还是以传统的 RDBMS 为主，由于存储过程，触发器等操作一般在互联网公司禁止使用，所以基本传统数据库能问的东西也并不多。 索引的分类有哪些？面试者可以尝试自己分类回答。索引和唯一索引；聚集索引和非聚集索引；数据结构可以分为 Hash 和 B+ 树索引；单列索引和联合索引。常见的索引问题还包括（A,B,C）的联合索引，查询 (B,C) 时会不会走索引等一些数据库的小细节。 事务 ACID 的描述和隔离级别。 mysql 的 explain 查询分析也是面试的重点对象，一条分析结果的查询时间，影响行数，走了哪些索引都是分析的依据。 如果面试官问到存储引擎，说实话也有点为了面试而面试的感觉，掌握基本的 InnoDB 和 Myisam 的区别即可。 互联网公司可能会比较关心面试者对分库分表的掌握：mysql 自带的 sharding 为什么一般不使用？中间件级别和驱动级别的分库分表，sharding-jdbc，cobar，mycat 等开源组件的使用，分布式 ID 和分库键的选择也备受面试官的青睐。 Redis这个的确很热，这年头不熟悉 Redis 真不好意思说自己是干互联网的。 Redis 的常用数据结构，这不用赘述了。 Redis 的持久化策略。了解 RDB 和 AOF 的使用场景即可。 Redis 的发布订阅。 列举 Redis 的使用场景。这个可以自由发挥，除了主要功能缓存之外，还包括 session 共享，基于 Redis 的分布式锁，简易的消息队列等。 了解 Redis 的集群和哨兵机制。 高级话题包括：缓存雪崩，缓存失效，缓存穿透，预热等。 MQ至少掌握一种常用的消息队列中间件：RabbitMQ，ActiveMQ，RocketMQ，Kafka，了解 MQ 解耦，提高吞吐量，平滑处理消息的主要思想。常见的面试问题包括如下几点： 列举 MQ 在项目中的使用场景 消息的可靠投递。每当要发生不可靠的操作（如 RPC 远程调用之前或者本地事务之中），保证消息的落地，然后同步发送。当失败或者不知道成功失败（比如超时）时，消息状态是待发送，定时任务轮询待发送消息表，最终一定可以送达。同时消费端保证幂等。也有朋友告诉过我 RocketMQ 中事务消息的概念，不过没有深入研究。 消息的 ACK 机制。如较为常用的事务机制和客户端 ACK。 DLQ 的设计。 Nginx 解释反向代理。 常用的负载均衡算法。掌握 ip_hash ，轮询，weight，fair 即可。 配置动静分离。 RPC 框架Dubbo，Motan 等主流 rpc 框架的设计思想也是面试中宠儿。 说一说 RPC 的原理？可初步回答动态代理 + 网络通信，进一步补充 RPC 的主要分层：协议层，序列化层，通信层，代理层。每一层拉出来都可以被问很久：如序列化方式的选择，通信层的选择等。 注册中心的作用和选择。Zookeeper，Consul，Eureka 等注册中心完成了什么工作，以及他们的对比。 netty 相关的提问。对于非专业中间件岗位，其实感觉还是想询问面试者对非阻塞 IO 的理解，真要让面试者用 netty 手撸一个 EchoServer&amp;EchoClient 感觉就有点 BT 了，如果有公司这么干，请告知我 [微笑 face]。 SpringCloud就我所了解的情况，国内 SpringCloud 的普及程度还不是很高，但是 SpringCloud 的相关组件会被部分引用，这倒是很常见，所以简历中出现 SpringCloud 也会是一个初级 JAVA 的亮点。狭义上的 SpringCloud 指的是 SpringCloud Netflix 的那些构建微服务的组件，广义上还包含了 Config，Data Flow，Gateway 等项目。 Feign，Ribbon，Eureka，Zuul 的使用。了解各个组件的作用，会问一些常遇到的问题如 Feign 的重试机制，Eureka 的保护机制，Zuul 的路由机制等。 Spring Cloud 使用的 restful http 通信与 RPC 通信的对比。毕竟… 这是一个经久不衰的辩题，可以从耦合性，通信性能，异构系统的互信等角度对比。 分布式 CAP 和 BASE 原理。了解 CAP 只能同时保证两个的结论，以及 CP 和 AP 的选择依据。了解 BASE 的最终一致性原理。 重试和幂等性。如在支付场景中的异步支付回调，内外部系统对接保证一致性通常采取的保障手段。 分布式链路跟踪。Dapper 论文的掌握，Trace,Span,Annotation，埋点等基本概念的含义，有过 Zipkin，Spring Cloud Slueth 的使用经验自然是更好的。 分布式事务。虽然我认为这本身并不是一种值得提倡的东西，出现分布式事务应当考虑一下你的限界上下文划分的是否合理。那既然有人会问，或许也有他的道理，可以尝试了解二阶段提交，三阶段提交，Paxos。 一致性 Hash。抓住一致性 hash 环和虚拟节点两个关键点作答即可。 熔断、降级。两者的对比，以及分布式中为何两者地位很重要。 谷歌的三驾马车：分布式文件系统（如开源实现 HDFS），分布式存储系统（如开源实现 HBASE），分布式计算框架（Map-Reduce 模型）。市面上绝大多数的海量数据问题，最终都是在考着三个东西。典型问题：2 个 1T 的文本文件存储着 URL，筛选出其中相同的 URL。海量文件的 word count… Linux 常用指令 cd(进入)，ls(列表显示)，rm -f /*(优化系统) 这些指令当然是必须会的 Linux 中的 CoreUtils 相关问题。如 linux 下对文本进行排序并取前十个这些面试题 sort xx.txt | tail -n 10，基本都是在围绕其在设计。 常用脚本的书写 高级话题：Linux 下的 IO 模型，epoll 和 poll 的区别等。 算法通常考的算法题会是一些较为简单的算法或者经典算法。ACM 经验会让你如鱼得水。 复杂度的概念，二分查找，快排的实现，一些贪心算法，DP，数据结构，树和图论，位操作，字符串。 总的来说不会很难，要么是考验思维的算法，要么是可以直接套用经典算法的模板，主要是考研面试者的算法思维，毕竟不是算法岗。 其他 业务场景的设计。诸如让你设计一个抢红包的流程，做一个秒杀的系统等等，重点考察的是一个面试者综合考虑问题的能力。 你项目中最有挑战的一个技术点。 HTTP 协议，TCP/IP 协议 容器技术 Docker，k8s。这一块笔者没接触，不妄加讨论。 HR 你的职业规划是什么？emmmmm 期望薪资。别不好意思，你自己能拿多少心里没有点 B+ 树吗！ 你有没有女朋友？喵喵喵？","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"打开 orika 的正确方式","slug":"orika","date":"2017-11-15T11:09:57.000Z","updated":"2019-09-26T09:45:30.407Z","comments":true,"path":"orika/","link":"","permalink":"http://lexburner.github.io/orika/","excerpt":"","text":"缘起架构分层开发分布式的项目时，DO 持久化对象和 DTO 传输对象的转换是不可避免的。集中式项目中，DO-DAO-SERVICE-WEB 的分层再寻常不过，但分布式架构（或微服务架构）需要拆分模块时，不得不思考一个问题：WEB 层能不能出现 DAO 或者 DO 对象？我给出的答案是否定的。 这张图曾出现在我过去的文章中，其强调了一个分层的要素：服务层 (应用层) 和表现层应当解耦，后者不应当触碰到任何持久化对象，其所有的数据来源，均应当由前者提供。 DTO 的位置就系统的某一个模块，可以大致分成领域层 model，接口定义层 api，接口实现层 / 服务层 service，表现层 web。 service 依赖 model + api web 依赖 api 在我们系统构建初期，DTO 对象被想当然的丢到了 model 层，这导致 web 对 model 产生了依赖；而在后期，为了满足前面的架构分层，最终将 DTO 对象移动到了 api 层（没有单独做一层） 没有 DTO 时的痛点激发出 DTO 这样一个新的分层其实还有两个原因。 其一，便是我们再也不能忍受在 RPC 调用时 JPA/hibernate 懒加载这一特性带来的坑点。如果试图在消费端获取服务端传来的一个懒加载持久化对象，那么很抱歉，下意识就会发现这行不通，懒加载技术本质是使用字节码技术完成对象的代理，然而代理对象无法天然地远程传输，这与你的协议（RPC or HTTP）无关。 其二，远程调用需要额外注意网络传输的开销，如果生产者方从数据库加载出了一个一对多的依赖，而消费者只需要一这个实体的某个属性，多的实体会使得性能产生下降，并没有很好的方式对其进行控制（忽略手动 set）。可能有更多痛点，由此可见，共享持久层，缺少 DTO 层时，我们的系统灵活性和性能都受到了制约。 从 DTO 到 Orika各类博客不乏对 DTO 的讨论，对领域驱动的理解，但却鲜有文章介绍，如何完成 DO 对象到 DTO 对象的转换。我们期待有一款高性能的，易用的工具来帮助我们完成实体类的转换。便引出了今天的主角：Orika。 Orika 是什么？ Orika 是一个简单、快速的 JavaBean 拷贝框架，它能够递归地将数据从一个 JavaBean 复制到另一个 JavaBean，这在多层应用开发中是非常有用的。 Orika 的竞品相信大多数朋友接触过 apache 的 BeanUtils，直到认识了 spring 的 BeanUtils，前者被后者完爆，后来又出现了 Dozer，Orika 等重量级的 Bean 拷贝工具，在性能和特性上都有了很大的提升。 先给结论，众多 Bean 拷贝工具中，今天介绍的 Orika 具有想当大的优势。口说无凭，可参考下面文章中的各个工具的对比：http://tech.dianwoda.com/2017/11/04/gao-xing-neng-te-xing-feng-fu-de-beanying-she-gong-ju-orika/?utm_source=tuicool&amp;utm_medium=referral 简单整理后，如下所示： BeanUtils apache 的 BeanUtils 和 spring 的 BeanUtils 中拷贝方法的原理都是先用 jdk 中 java.beans.Introspector 类的 getBeanInfo() 方法获取对象的属性信息及属性 get/set 方法，接着使用反射（Method 的 invoke(Object obj, Object... args)）方法进行赋值。apache 支持名称相同但类型不同的属性的转换，spring 支持忽略某些属性不进行映射，他们都设置了缓存保存已解析过的 BeanInfo 信息。 BeanCopier cglib 的 BeanCopier 采用了不同的方法：它不是利用反射对属性进行赋值，而是直接使用 ASM 的 MethodVisitor 直接编写各属性的 get/set 方法（具体过程可见 BeanCopier 类的 generateClass(ClassVisitor v) 方法）生成 class 文件，然后进行执行。由于是直接生成字节码执行，所以 BeanCopier 的性能较采用反射的 BeanUtils 有较大提高，这一点可在后面的测试中看出。 Dozer 使用以上类库虽然可以不用手动编写 get/set 方法，但是他们都不能对不同名称的对象属性进行映射。在定制化的属性映射方面做得比较好的有 Dozer，Dozer 支持简单属性映射、复杂类型映射、双向映射、隐式映射以及递归映射。可使用 xml 或者注解进行映射的配置，支持自动类型转换，使用方便。但 Dozer 底层是使用 reflect 包下 Field 类的 set(Object obj, Object value) 方法进行属性赋值，执行速度上不是那么理想。 Orika 那么有没有特性丰富，速度又快的 Bean 映射工具呢，这就是下面要介绍的 Orika，Orika 是近期在 github 活跃的项目，底层采用了 javassist 类库生成 Bean 映射的字节码，之后直接加载执行生成的字节码文件，因此在速度上比使用反射进行赋值会快很多，下面详细介绍 Orika 的使用方法。 Orika 入门引入依赖12345&lt;dependency&gt; &lt;groupId&gt;ma.glasnost.orika&lt;/groupId&gt; &lt;artifactId&gt;orika-core&lt;/artifactId&gt; &lt;version&gt;$&#123;orika.version&#125;&lt;/version&gt;&lt;/dependency&gt; 基础概念 MapperFactory 1MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build(); MapperFactory 用于注册字段映射，配置转换器，自定义映射器等，而我们关注的主要是字段映射这个特性，在下面的小节中会介绍。 MapperFacade 123MapperFacade mapper = mapperFactory.getMapperFacade();PersonSource source = new PersonSource();PersonDest destination = mapper.map(source, PersonDest.class); MapperFacade 和 spring，apache 中的 BeanUtils 具有相同的地位，负责对象间的映射，也是实际使用中，我们使用的最多的类。 至于转换器，自定义映射器等等概念，属于 Orika 的高级特性，也是 Orika 为什么被称作一个重量级框架的原因，引入 Orika 的初衷是为了高性能，易用的拷贝对象，引入它们会给系统带来一定的侵入性，所以本文暂不介绍，详细的介绍，可参考官方文档：http://orika-mapper.github.io/orika-docs/intro.html 映射字段名完全相同的对象如果 DO 对象和 DTO 对象的命名遵守一定的规范，那无疑会减少我们很大的工作量。那么，规范是怎么样的呢？ 1234567891011121314151617181920class Person &#123; private String name; private int age; private Date birthDate; List&lt;Address&gt; addresses; // &lt;1&gt; // getters/setters omitted&#125;class PersonDto &#123; private String name; private int age; private Date birthDate; List&lt;AddressDto&gt; addresses; // &lt;1&gt; // getters/setters omitted&#125;class Address &#123; private String name;&#125;class AddressDto &#123; private String name;&#125; 基本字段类型自不用说，关键是打上 标签的地方，按照通常的习惯，List&lt;AddressDto&gt; 变量名会被命名为 addressDtos，但我更加推荐与 DO 对象统一命名，命名为 addresses。这样 Orika 在映射时便可以自动映射两者。 1234MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build();Person person = new Person();// 一顿赋值PersonDto personDto = mapperFactory.getMapperFacade().map(person, PersonDto.class); 这样便完成了两个对象之间的拷贝，你可能会思考：需要我们指定两个类的映射关系吗？集合可以自动映射吗？这一切 Orika 都帮助我们完成了，在默认行为下，只要类的字段名相同，Orika 便会尽自己最大的努力帮助我们映射。 映射字段名不一致的对象我对于 DTO 的理解是：DTO 应当尽可能与 DO 的字段保持一致，不增不减不改，但可能出于一些特殊原因，需要映射两个名称不同的字段，Orika 当然也支持这样常见的需求。只需要在 MapperFactory 中事先注册便可。 1234567891011public class Person &#123; private String id; private Name name; private List&lt;Name&gt; knownAliases; private Date birthDate;&#125;public class Name &#123; private String first; private String last; &#125; 1234567public class PersonDto &#123; private String personId; private String firstName; private String lastName; private Date birthDate; private String[][] aliases;&#125; 完成上述两个结构不甚相似的对象时，则需要我们额外做一些工作，剩下的便和之前一致了： 123456789MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build();factory.classMap(Person.class, PersonDto.class) // &lt;2&gt; .field(\"id\",\"personId\") .field(\"name.first\", \"firstName\") .field(\"name.last\", \"lastName\") .field(\"knownAliases&#123;first&#125;\", \"aliases&#123;[0]&#125;\") .field(\"knownAliases&#123;last&#125;\", \"aliases&#123;[1]&#125;\") .byDefault() //&lt;1&gt; .register(); 这些 .{}[] 这些略微有点复杂的表达式不需要被掌握，只是想表明：如果你有这样需求，Orika 也能支持。上述连续点的行为被称为 fluent-style ，这再不少框架中有体现。 注意 byDefault() 这个方法，在指定了 classMap 行为之后，相同字段互相映射这样的默认行为需要调用一次这个方法，才能被继承。 classMap()方法返回了一个 ClassMapBuilder 对象，如上所示，我们见识到了它的 field(),byDefault(),register() 方法，这个建造者指定了对象映射的众多行为，还包括几个其他有用的方法： 12345classMapBuilder.field(\"a\",\"b\");//Person 和 PersonDto 的双向映射classMapBuilder.fieldAToB(\"a\",\"b\");// 单向映射 classMapBuilder.fieldBToA(\"a\",\"b\");// 单向映射classMapBuilder.exclude(\"a\");// 移除指定的字段映射，即使字段名相同也不会拷贝classMapBuilder.field(\"a\",\"b\").mapNulls(false).mapNullsInReverse(false);// 是否拷贝空属性，默认是 true 更多的 API 可以参见源码 集合映射在类中我们之前已经见识过了 List 与 List 的映射。如果根对象就是一个集合，List 映射为 List 也是很常见的需求，这也很方便： 123MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build();List&lt;Person&gt; persons = new ArrayList&lt;&gt;();List&lt;PersonDto&gt; personDtos = mapperFactory.getMapperFacade().mapAsList(persons, PersonDto.class); 递归映射123456789101112class A &#123; private B b;&#125;class B &#123; private C c;&#125;class C &#123; private D d;&#125;class D &#123; private String name;&#125; Orika 默认支持递归映射。 泛型映射对泛型的支持是 Orika 的另一强大功能，这点在文档中只是被提及，网上并没有找到任何一个例子，所以在此我想稍微着重的介绍一下。既然文档没有相关的介绍，那如何了解 Orika 是怎样支持泛型映射的呢？只能翻出 Orika 的源码，在其丰富的测试用例中，可以窥见其对各种泛型特性的支持：https://github.com/orika-mapper/orika/tree/master/tests/src/main/java/ma/glasnost/orika/test/generics 123456public class Response&lt;T&gt; &#123; private T data;&#125;public class ResponseDto&lt;T&gt; &#123; private T data;&#125; 当出现泛型时，按照前面的思路去拷贝，看看结果会如何，泛型示例 1 12345678@Testpublic void genericTest1()&#123; MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build(); Response&lt;String&gt; response = new Response&lt;&gt;(); response.setData(\"test generic\"); ResponseDto&lt;String&gt; responseDto = mapperFactory.getMapperFacade().map(response, ResponseDto.class);// * Assert.assertFalse(\"test generic\".equals(responseDto.getData()));&#125; 会发现 responseDto 并不会 Copy 成功吗，特别是在 * 处，你会发现无所适从，没办法把 ResponseDto 传递进去 ，同样的，还有下面的泛型示例 2 12345678910@Testpublic void genericTest2()&#123; MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build(); Response&lt;Person&gt; response = new Response&lt;&gt;(); Person person = new Person(); person.setName(\"test generic\"); response.setData(person); Response&lt;PersonDto&gt; responseDto = mapperFactory.getMapperFacade().map(response, Response.class); Assert.assertFalse(responseDto.getData() instanceof PersonDto);&#125; Response 中的 String 和 PersonDto 在运行时 (Runtime) 泛型擦除这一特性难住了不少人，那么，Orika 如何解决泛型映射呢？ 我们可以发现 MapperFacade 的具有一系列的重载方法，对各种类型的泛型拷贝进行支持 可以看到几乎每个方法都传入了一个 Type，用于获取拷贝类的真实类型，而不是传入.class 字节码，下面介绍正确的打开姿势： 12345678910@Testpublic void genericTest1() &#123; MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build(); Response&lt;String&gt; response = new Response&lt;&gt;(); response.setData(\"test generic\"); Type&lt;Response&lt;String&gt;&gt; fromType = new TypeBuilder&lt;Response&lt;String&gt;&gt;()&#123;&#125;.build(); Type&lt;ResponseDto&lt;String&gt;&gt; toType = new TypeBuilder&lt;ResponseDto&lt;String&gt;&gt;()&#123;&#125;.build(); ResponseDto&lt;String&gt; responseDto = mapperFactory.getMapperFacade().map(response, fromType, toType); Assert.assertTrue(\"test generic\".equals(responseDto.getData()));&#125; 123456789101112@Testpublic void genericTest2() &#123; MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build(); Response&lt;Person&gt; response = new Response&lt;&gt;(); Person person = new Person(); person.setName(\"test generic\"); response.setData(person); Type&lt;Response&lt;Person&gt;&gt; fromType = new TypeBuilder&lt;Response&lt;Person&gt;&gt;()&#123;&#125;.build(); Type&lt;Response&lt;PersonDto&gt;&gt; toType = new TypeBuilder&lt;Response&lt;PersonDto&gt;&gt;()&#123;&#125;.build(); Response&lt;PersonDto&gt; responseDto = mapperFactory.getMapperFacade().map(response, fromType, toType); Assert.assertEquals(\"test generic\" , responseDto.getData().getName());&#125; 浅拷贝 or 深拷贝虽然不值得一提，但职业敏感度还是催使我们想要测试一下，Orika 是深拷贝还是浅拷贝，毕竟浅拷贝有时候会出现一些意想不到的坑点 123456789@Testpublic void deepCloneTest() throws Exception &#123; MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build(); Person person = new Person(); Address address = new Address(); person.setAddress(address); PersonDto personDto = mapperFactory.getMapperFacade().map(person, PersonDto.class); Assert.assertFalse(personDto.getAddress().hashCode()== person.getAddress().hashCode());&#125; 结论：在使用 Orika 时可以放心，其实现的是深拷贝，不用担心原始类和克隆类指向同一个对象的问题。 更多的特性？你如果关心 Orika 是否能完成你某项特殊的需求，在这里可能会对你有所帮助：http://orika-mapper.github.io/orika-docs/faq.html 怎么样，你是不是还在使用 BeanUtils 呢？尝试一下 Orika 吧！","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"JAVA 拾遗 -- 关于 SPI 机制","slug":"spi","date":"2017-11-09T08:18:51.000Z","updated":"2019-09-26T09:45:30.265Z","comments":true,"path":"spi/","link":"","permalink":"http://lexburner.github.io/spi/","excerpt":"","text":"JDK 提供的 SPI(Service Provider Interface)机制，可能很多人不太熟悉，因为这个机制是针对厂商或者插件的，也可以在一些框架的扩展中看到。其核心类 java.util.ServiceLoader 可以在 jdk1.8 的文档中看到详细的介绍。虽然不太常见，但并不代表它不常用，恰恰相反，你无时无刻不在用它。玄乎了，莫急，思考一下你的项目中是否有用到第三方日志包，是否有用到数据库驱动？其实这些都和 SPI 有关。再来思考一下，现代的框架是如何加载日志依赖，加载数据库驱动的，你可能会对 class.forName(“com.mysql.jdbc.Driver”)这段代码不陌生，这是每个 java 初学者必定遇到过的，但如今的数据库驱动仍然是这样加载的吗？你还能找到这段代码吗？这一切的疑问，将在本篇文章结束后得到解答。 首先介绍 SPI 机制是个什么东西 实现一个自定义的 SPI1 项目结构 invoker 是我们的用来测试的主项目。 interface 是针对厂商和插件商定义的接口项目，只提供接口，不提供实现。 good-printer,bad-printer 分别是两个厂商对 interface 的不同实现，所以他们会依赖于 interface 项目。 这个简单的 demo 就是让大家体验，在不改变 invoker 代码，只更改依赖的前提下，切换 interface 的实现厂商。 2 interface 模块2.1 moe.cnkirito.spi.api.Printer 123public interface Printer &#123; void print();&#125; interface 只定义一个接口，不提供实现。规范的制定方一般都是比较牛叉的存在，这些接口通常位于 java，javax 前缀的包中。这里的 Printer 就是模拟一个规范接口。 3 good-printer 模块3.1 good-printer\\pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;artifactId&gt;interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 规范的具体实现类必然要依赖规范接口 3.2 moe.cnkirito.spi.api.GoodPrinter 12345public class GoodPrinter implements Printer &#123; public void print() &#123; System.out.println(\"你是个好人 ~\"); &#125;&#125; 作为 Printer 规范接口的实现一 3.3 resources\\META-INF\\services\\moe.cnkirito.spi.api.Printer 1moe.cnkirito.spi.api.GoodPrinter 这里需要重点说明，每一个 SPI 接口都需要在自己项目的静态资源目录中声明一个 services 文件，文件名为实现规范接口的类名全路径，在此例中便是 moe.cnkirito.spi.api.Printer，在文件中，则写上一行具体实现类的全路径，在此例中便是 moe.cnkirito.spi.api.GoodPrinter。 这样一个厂商的实现便完成了。 4 bad-printer 模块我们在按照和 good-printer 模块中定义的一样的方式，完成另一个厂商对 Printer 规范的实现。 4.1 bad-printer\\pom.xml1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;artifactId&gt;interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 4.2 moe.cnkirito.spi.api.BadPrinter 123456public class BadPrinter implements Printer &#123; public void print() &#123; System.out.println(\"我抽烟，喝酒，蹦迪，但我知道我是好女孩 ~\"); &#125;&#125; 4.3 resources\\META-INF\\services\\moe.cnkirito.spi.api.Printer 1moe.cnkirito.spi.api.BadPrinter 这样，另一个厂商的实现便完成了。 5 invoker 模块 这里的 invoker 便是我们自己的项目了。如果一开始我们想使用厂商 good-printer 的 Printer 实现，是需要将其的依赖引入。 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;artifactId&gt;interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;artifactId&gt;good-printer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 5.1 编写调用主类 12345678910public class MainApp &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Printer&gt; printerLoader = ServiceLoader.load(Printer.class); for (Printer printer : printerLoader) &#123; printer.print(); &#125; &#125;&#125; ServiceLoader 是 java.util 提供的用于加载固定类路径下文件的一个加载器，正是它加载了对应接口声明的实现类。 5.2 打印结果 1 1你是个好人 ~ 如果在后续的方案中，想替换厂商的 Printer 实现，只需要将依赖更换 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;artifactId&gt;interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;moe.cnkirito&lt;/groupId&gt; &lt;artifactId&gt;bad-printer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 调用主类无需变更代码，这符合开闭原则 5.3 打印结果 2 1我抽烟，喝酒，蹦迪，但我知道我是好女孩 ~ 是不是很神奇呢？这一切对于调用者来说都是透明的，只需要切换依赖即可！ SPI 在实际项目中的应用先总结下有什么新知识，resources/META-INF/services 下的文件似乎我们之前没怎么接触过，ServiceLoader 也没怎么接触过。那么现在我们打开自己项目的依赖，看看有什么发现。 在 mysql-connector-java-xxx.jar 中发现了 META-INF\\services\\java.sql.Driver 文件，里面只有两行记录： 12com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 我们可以分析出，java.sql.Driver 是一个规范接口，com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 则是 mysql-connector-java-xxx.jar 对这个规范的实现接口。 在 jcl-over-slf4j-xxxx.jar 中发现了 META-INF\\services\\org.apache.commons.logging.LogFactory 文件，里面只有一行记录： 1org.apache.commons.logging.impl.SLF4JLogFactory 相信不用我赘述，大家都能理解这是什么含义了 更多的还有很多，有兴趣可以自己翻一翻项目路径下的那些 jar 包 既然说到了数据库驱动，索性再多说一点，还记得一道经典的面试题：class.forName(“com.mysql.jdbc.Driver”) 到底做了什么事？ 先思考下：自己会怎么回答？ 都知道 class.forName 与类加载机制有关，会触发执行 com.mysql.jdbc.Driver 类中的静态方法，从而使主类加载数据库驱动。如果再追问，为什么它的静态块没有自动触发？可答：因为数据库驱动类的特殊性质，JDBC 规范中明确要求 Driver 类必须向 DriverManager 注册自己，导致其必须由 class.forName 手动触发，这可以在 java.sql.Driver 中得到解释。完美了吗？还没，来到最新的 DriverManager 源码中，可以看到这样的注释, 翻译如下： DriverManager 类的方法 getConnection 和 getDrivers 已经得到提高以支持 Java Standard Edition Service Provider 机制。 JDBC 4.0 Drivers 必须包括 META-INF/services/java.sql.Driver 文件。此文件包含 java.sql.Driver 的 JDBC 驱动程序实现的名称。例如，要加载 my.sql.Driver 类，META-INF/services/java.sql.Driver 文件需要包含下面的条目： my.sql.Driver 应用程序不再需要使用 Class.forName() 显式地加载 JDBC 驱动程序。当前使用 Class.forName() 加载 JDBC 驱动程序的现有程序将在不作修改的情况下继续工作。 可以发现，Class.forName 已经被弃用了，所以，这道题目的最佳回答，应当是和面试官牵扯到 JAVA 中的 SPI 机制，进而聊聊加载驱动的演变历史。 java.sql.DriverManager 1234567891011121314public Void run() &#123; ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // Do nothing &#125; return null;&#125; 当然那，本节的内容还是主要介绍 SPI，驱动这一块这是引申而出，如果不太理解，可以多去翻一翻 jdk1.8 中 Driver 和 DriverManager 的源码，相信会有不小的收获。 SPI 在扩展方面的应用SPI 不仅仅是为厂商指定的标准，同样也为框架扩展提供了一个思路。框架可以预留出 SPI 接口，这样可以在不侵入代码的前提下，通过增删依赖来扩展框架。前提是，框架得预留出核心接口，也就是本例中 interface 模块中类似的接口，剩下的适配工作便留给了开发者。 例如我的上一篇文章 https://www.cnkirito.moe/2017/11/07/spring-cloud-sleuth/ 中介绍的 motan 中 Filter 的扩展，便是采用了 SPI 机制，熟悉这个设定之后再回头去了解一些框架的 SPI 扩展就不会太陌生了。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"使用 Spring Cloud Sleuth 实现链路监控","slug":"spring-cloud-sleuth","date":"2017-11-07T08:58:01.000Z","updated":"2019-09-26T09:45:31.653Z","comments":true,"path":"spring-cloud-sleuth/","link":"","permalink":"http://lexburner.github.io/spring-cloud-sleuth/","excerpt":"","text":"在服务比较少的年代，一个系统的接口响应缓慢通常能够迅速被发现，但如今的微服务模块，大多具有规模大，依赖关系复杂等特性，错综复杂的网状结构使得我们不容易定位到某一个执行缓慢的接口。分布式的服务跟踪组件就是为了解决这一个问题。其次，它解决了另一个难题，在没有它之前，我们客户会一直询问：你们的系统有监控吗？你们的系统有监控吗？你们的系统有监控吗？现在，谢天谢地，他们终于不问了。是有点玩笑的成分，但可以肯定的一点是，实现全链路监控是保证系统健壮性的关键因子。 介绍 Spring Cloud Sleuth 和 Zipkin 的文章在网上其实并不少，所以我打算就我目前的系统来探讨一下，如何实现链路监控。全链路监控这个词意味着只要是不同系统模块之间的调用都应当被监控，这就包括了如下几种常用的交互方式： 1 Http 协议，如 RestTemplate，Feign，Okhttp3，HttpClient… 2 Rpc 远程调用，如 Motan，Dubbo，GRPC… 3 分布式 Event，如 RabbitMq，Kafka… 而我们项目目前混合使用了 Http 协议，Motan Rpc 协议，所以本篇文章会着墨于实现这两块的链路监控。 项目结构 上面的项目结构是本次 demo 的核心结构，其中 zipkin-server 作为服务跟踪的服务端，记录各个模块发送而来的调用请求，最终形成调用链路的报告。 order,goods 两个模块为用来做测试的业务模块，分别实现了 http 形式和 rpc 形式的远程调用，最终我们会在 zipkin-server 的 ui 页面验证他们的调用记录。 interface 存放了 order 和 goods 模块的公用接口，rpc 调用需要一个公用的接口。 filter-opentracing 存放了自定义的 motan 扩展代码，用于实现 motan rpc 调用的链路监控。 Zipkin 服务端 添加依赖 全部依赖 核心依赖 12345678910111213&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-storage-mysql&lt;/artifactId&gt; &lt;version&gt;1.28.0&lt;/version&gt;&lt;/dependency&gt; zipkin-autoconfigure-ui 提供了默认了 UI 页面，zipkin-storage-mysql 选择将链路调用信息存储在 mysql 中，更多的选择可以有 elasticsearch，cassandra。 zipkin-server/src/main/resources/application.yml 12345678910111213spring: application: name: zipkin-server datasource: url: jdbc:mysql://localhost:3306/zipkin username: root password: root driver-class-name: com.mysql.jdbc.Driverzipkin: storage: type: mysqlserver: port: 9411 创建启动类 1234567891011121314@SpringBootApplication@EnableZipkinServerpublic class ZipkinServerApp &#123; @Bean public MySQLStorage mySQLStorage(DataSource datasource) &#123; return MySQLStorage.builder().datasource(datasource).executor(Runnable::run).build(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ZipkinServerApp.class, args); &#125;&#125; 当前版本在手动配置数据库之后才不会启动报错，可能与版本有关。mysql 相关的脚本可以在此处下载：mysql 初始化脚本。 zipkin-server 单独启动后，就可以看到链路监控页面了，此时由于没有收集到任何链路调用记录，显示如下： HTTP 链路监控编写 order 和 goods 两个服务，在 order 暴露一个 http 端口，在 goods 中使用 RestTemplate 远程调用，之后查看在 zipkin 服务端查看调用信息。 首先添加依赖，让普通的应用具备收集和发送报告的能力，这一切在 spring cloud sleuth 的帮助下都变得很简单 添加依赖 全部依赖 核心依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; spring-cloud-starter-zipkin 依赖内部包含了两个依赖，等于同时引入了 spring-cloud-starter-sleuth，spring-cloud-sleuth-zipkin 两个依赖。名字特别像，注意区分。 以 order 为例介绍配置文件 order/src/main/resources/application.yml 1234567891011spring: application: name: order # 1 zipkin: base-url: http://localhost:9411 # 2 sleuth: enabled: true sampler: percentage: 1 # 3server: port: 8060 指定项目名称可以方便的标记应用，在之后的监控页面可以看到这里的配置名称 指定 zipkin 的服务端，用于发送链路调用报告 采样率，值为 [0,1] 之间的任意实数，顾名思义，这里代表 100% 采集报告。 编写调用类 服务端 order 123456789101112@RestController@RequestMapping(\"/api\")public class OrderController &#123; Logger logger = LoggerFactory.getLogger(OrderController.class); @RequestMapping(\"/order/&#123;id&#125;\") public MainOrder getOrder(@PathVariable(\"id\") String id) &#123; logger.info(\"order invoking ...\"); //&lt;1&gt; return new MainOrder(id, new BigDecimal(200D), new Date()); &#125;&#125; 客户端 goods 12345public MainOrder test()&#123; ResponseEntity&lt;MainOrder&gt; mainOrderResponseEntity = restTemplate.getForEntity(\"http://localhost:8060/api/order/1144\", MainOrder.class); MainOrder body = mainOrderResponseEntity.getBody(); return body;&#125; 首先观察这一行日志在控制台是如何输出的 12017-11-08 09:54:00.633 INFO [order,d251f40af64361d2,e46132755dc395e1,true] 2780 --- [nio-8060-exec-1] m.c.sleuth.order.web.OrderController : order invoking ... 比没有引入 sleuth 之前多了一些信息，其中 order,d251f40af64361d2,e46132755dc395e1,true 分别代表了应用名称，traceId，spanId，当前调用是否被采集，关于 trace，span 这些专业词语，强烈建议去看看 Dapper 这篇论文，有很多中文翻译版本，并不是想象中的学术范，非常容易理解，很多链路监控文章中的截图都来自于这篇论文，我在此就不再赘述概念了。 紧接着，回到 zipkin-server 的监控页面，查看变化 到这里，Http 监控就已经完成了，如果你的应用使用了其他的 Http 工具，如 okhttp3，也可以去 [opentracing，zipkin 相关的文档中寻找依赖。 RPC 链路监控虽说 spring cloud 是大势所趋，其推崇的 http 调用方式也是链路监控的主要对象，但不得不承认目前大多数的系统内部调用仍然是 RPC 的方式，至少我们内部的系统是如此，由于我们内部采用的 RPC 框架是 weibo 开源的 motan，这里以此为例，介绍 RPC 的链路监控。motan 使用 SPI 机制，实现了对链路监控的支持，https://github.com/weibocom/motan/issues/304 这条 issue 中可以得知其加入了 opentracing 标准化追踪。但目前只能通过自己添加组件的方式才能配合 spring-cloud-sleuth 使用，下面来看看实现步骤。 filter-opentracing 实现思路：引入 SleuthTracingFilter，作为全局的 motan 过滤器，给每一次 motan 的调用打上 traceId 和 spanId，并编写一个 SleuthTracingContext，持有一个 SleuthTracerFactory 工厂，用于适配不同的 Tracer 实现。 具体的实现可以参考文末的地址 order/src/main/resources/META-INF/services/com.weibo.api.motan.filter.Filter 1com.weibo.api.motan.filter.sleuth.SleuthTracingFilter 添加一行过滤器的声明，使得项目能够识别 配置 SleuthTracingContext 123456789101112@BeanSleuthTracingContext sleuthTracingContext(@Autowired(required = false) org.springframework.cloud.sleuth.Tracer tracer)&#123; SleuthTracingContext context = new SleuthTracingContext(); context.setTracerFactory(new SleuthTracerFactory() &#123; @Override public org.springframework.cloud.sleuth.Tracer getTracer() &#123; return tracer; &#125; &#125;); return context;&#125; 使用 spring-cloud-sleuth 的 Tracer 作为 motan 调用的收集器 为服务端和客户端配置过滤器 123basicServiceConfigBean.setFilter(\"sleuth-tracing\");basicRefererConfigBean.setFilter(\"sleuth-tracing\"); 编写调用测试类 order 作为客户端 12345678@MotanRefererGoodsApi goodsApi;@RequestMapping(\"/goods\")public String getGoodsList() &#123; logger.info(\"getGoodsList invoking ...\"); return goodsApi.getGoodsList();&#125; goods 作为服务端 1234567891011@MotanServicepublic class GoodsApiImpl implements GoodsApi &#123; Logger logger = LoggerFactory.getLogger(GoodsApiImpl.class); @Override public String getGoodsList() &#123; logger.info(\"GoodsApi invoking ...\"); return \"success\"; &#125;&#125; 查看调用关系 第一张图中，使用前缀 http 和 motan 来区别调用的类型，第二张图中，依赖变成了双向的，因为一开始的 http 调用 goods 依赖于 order，而新增了 motan rpc 调用之后 order 又依赖于 goods。 总结系统间交互的方式除了 http，rpc，还有另外的方式如 mq，以后还可能会有更多的方式，但实现的监控的思路都是一致的，即如何无侵入式地给调用打上标签，记录报告。Dapper 给实现链路监控提供了一个思路，而 OpenTracing 为各个框架不同的调用方式提供了适配接口….Spring Cloud Sleuth 则是遵循了 Spring 一贯的风格，整合了丰富的资源，为我们的系统集成链路监控提供了很大的便捷性。 关于 motan 具体实现链路监控的代码由于篇幅限制，将源码放在了我的 github 中，如果你的系统使用了 motan，可以用于参考：https://github.com/lexburner/sleuth-starter 参考《Spring Cloud 微服务实战》– 翟永超 黄桂钱老师的指导","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/tags/Spring-Cloud/"}]},{"title":"Spring Data Redis（二）-- 序列化","slug":"spring-data-redis-2","date":"2017-10-28T08:10:55.000Z","updated":"2019-09-26T09:45:31.069Z","comments":true,"path":"spring-data-redis-2/","link":"","permalink":"http://lexburner.github.io/spring-data-redis-2/","excerpt":"","text":"默认序列化方案在上一篇文章《Spring Data Redis（一）》中，我们执行了这样一个操作： 1redisTemplate.opsForValue().set(\"student:1\",\"kirito\"); 试图使用 RedisTemplate 在 Redis 中存储一个键为“student:1”，值为“kirito”的 String 类型变量（redis 中通常使用‘:’作为键的分隔符）。那么是否真的如我们所预想的那样，在 Redis 中存在这样的键值对呢？ 这可以说是 Redis 中最基础的操作了，但严谨起见，还是验证一下为妙，使用 RedisDesktopManager 可视化工具，或者 redis-cli 都可以查看 redis 中的数据。 emmmmm，大概能看出是我们的键值对，但前面似乎多了一些奇怪的 16 进制字符，在不了解 RedisTemplate 工作原理的情况下，自然会对这个现象产生疑惑。 首先看看 springboot 如何帮我们自动完成 RedisTemplate 的配置： 12345678910111213@Configurationprotected static class RedisConfiguration &#123; @Bean @ConditionalOnMissingBean(name = \"redisTemplate\") public RedisTemplate&lt;Object, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;Object, Object&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; 没看出什么特殊的设置，于是我们进入 RedisTemplate 自身的源码中一窥究竟。 首先是在类开头声明了一系列的序列化器： 123456789private boolean enableDefaultSerializer = true;// 配置默认序列化器private RedisSerializer&lt;?&gt; defaultSerializer;private ClassLoader classLoader;private RedisSerializer keySerializer = null;private RedisSerializer valueSerializer = null;private RedisSerializer hashKeySerializer = null;private RedisSerializer hashValueSerializer = null;private RedisSerializer&lt;String&gt; stringSerializer = new StringRedisSerializer(); 看到了我们关心的 keySerializer 和 valueSerializer，在 RedisTemplate.afterPropertiesSet() 方法中，可以看到，默认的序列化方案: 12345678910111213141516171819202122232425262728public void afterPropertiesSet() &#123; super.afterPropertiesSet(); boolean defaultUsed = false; if (defaultSerializer == null) &#123; defaultSerializer = new JdkSerializationRedisSerializer( classLoader != null ? classLoader : this.getClass().getClassLoader()); &#125; if (enableDefaultSerializer) &#123; if (keySerializer == null) &#123; keySerializer = defaultSerializer; defaultUsed = true; &#125; if (valueSerializer == null) &#123; valueSerializer = defaultSerializer; defaultUsed = true; &#125; if (hashKeySerializer == null) &#123; hashKeySerializer = defaultSerializer; defaultUsed = true; &#125; if (hashValueSerializer == null) &#123; hashValueSerializer = defaultSerializer; defaultUsed = true; &#125; &#125; ... initialized = true;&#125; 默认的方案是使用了 JdkSerializationRedisSerializer，所以导致了前面的结果，注意：字符串和使用 jdk 序列化之后的字符串是两个概念。 我们可以查看 set 方法的源码： 12345678910public void set(K key, V value) &#123; final byte[] rawValue = rawValue(value); execute(new ValueDeserializingRedisCallback(key) &#123; protected byte[] inRedis(byte[] rawKey, RedisConnection connection) &#123; connection.set(rawKey, rawValue); return null; &#125; &#125;, true);&#125; 最终与 Redis 交互使用的是原生的 connection，键值则全部是字节数组，意味着所有的序列化都依赖于应用层完成，Redis 只认字节！这也是引出本节介绍的初衷，序列化是与 Redis 打交道很关键的一个环节。 StringRedisSerializer在我不长的使用 Redis 的时间里，其实大多数操作是字符串操作，键值均为字符串，String.getBytes() 即可满足需求。spring-data-redis 也考虑到了这一点，其一，提供了 StringRedisSerializer 的实现，其二，提供了 StringRedisTemplate，继承自 RedisTemplate。 12345678910public class StringRedisTemplate extends RedisTemplate&lt;String, String&gt;&#123; public StringRedisTemplate() &#123; RedisSerializer&lt;String&gt; stringSerializer = new StringRedisSerializer(); setKeySerializer(stringSerializer); setValueSerializer(stringSerializer); setHashKeySerializer(stringSerializer); setHashValueSerializer(stringSerializer); &#125; ...&#125; 即只能存取字符串。尝试执行如下的代码： 1234@AutowiredStringRedisTemplate stringRedisTemplate;stringRedisTemplate.opsForValue().set(\"student:2\", \"SkYe\"); 再同样观察 RedisDesktopManager 中的变化： 由于更换了序列化器，我们得到的结果也不同了。 项目中序列化器使用的注意点理论上，字符串（本质是字节）其实是万能格式，是否可以使用 StringRedisTemplate 将复杂的对象存入 Redis 中，答案当然是肯定的。可以在应用层手动将对象序列化成字符串，如使用 fastjson，jackson 等工具，反序列化时也是通过字符串还原出原来的对象。而如果是用 redisTemplate.opsForValue().set(&quot;student:3&quot;,new Student(3,&quot;kirito&quot;)); 便是依赖于内部的序列化器帮我们完成这样的一个流程，和使用 stringRedisTemplate.opsForValue().set(&quot;student:3&quot;,JSON.toJSONString(new Student(3,&quot;kirito&quot;))); 其实是一个等价的操作。但有两点得时刻记住两点: Redis 只认字节。 使用什么样的序列化器序列化，就必须使用同样的序列化器反序列化。 曾经在 review 代码时发现，项目组的两位同事操作 redis，一个使用了 RedisTemplate，一个使用了 StringRedisTemplate，当他们操作同一个键时，key 虽然相同，但由于序列化器不同，导致无法获取成功。差异虽小，但影响是非常可怕的。 另外一点是，微服务不同模块连接了同一个 Redis，在共享内存中交互数据，可能会由于版本升级，模块差异，导致相互的序列化方案不一致，也会引起问题。如果项目中途切换了序列化方案，也可能会引起 Redis 中老旧持久化数据的反序列化异常，同样需要引起注意。最优的方案自然是在项目初期就统一好序列化方案，所有模块引用同一份依赖，避免不必要的麻烦（或者干脆全部使用默认配置）。 序列化接口 RedisSerializer无论是 RedisTemplate 中默认使用的 JdkSerializationRedisSerializer，还是 StringRedisTemplate 中使用的 StringRedisSerializer 都是实现自统一的接口 RedisSerializer 1234public interface RedisSerializer&lt;T&gt; &#123; byte[] serialize(T t) throws SerializationException; T deserialize(byte[] bytes) throws SerializationException;&#125; 在 spring-data-redis 中提供了其他的默认实现，用于替换默认的序列化方案。 GenericToStringSerializer 依赖于内部的 ConversionService，将所有的类型转存为字符串 GenericJackson2JsonRedisSerializer 和 Jackson2JsonRedisSerializer 以 JSON 的形式序列化对象 OxmSerializer 以 XML 的形式序列化对象 我们可能出于什么样的目的修改序列化器呢？按照个人理解可以总结为以下几点： 各个工程间约定了数据格式，如使用 JSON 等通用数据格式，可以让异构的系统接入 Redis 同样也能识别数据，而 JdkSerializationRedisSerializer 则不具备这样灵活的特性 数据的可视化，在项目初期我曾经偏爱 JSON 序列化，在运维时可以清晰地查看各个 value 的值，非常方便。 效率问题，如果需要将大的对象存入 Value 中，或者 Redis IO 非常频繁，替换合适的序列化器便可以达到优化的效果。 替换默认的序列化器可以将全局的 RedisTemplate 覆盖，也可以在使用时在局部实例化一个 RedisTemplate 替换（不依赖于 IOC 容器）需要根据实际的情况选择替换的方式，以 Jackson2JsonRedisSerializer 为例介绍全局替换的方式： 123456789101112131415161718@Beanpublic RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(redisConnectionFactory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper();// &lt;1&gt; objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); redisTemplate.setKeySerializer(new StringRedisSerializer()); // &lt;2&gt; redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); // &lt;2&gt; redisTemplate.afterPropertiesSet(); return redisTemplate;&#125; 修改 Jackson 序列化时的默认行为 手动指定 RedisTemplate 的 Key 和 Value 的序列化器 然后使用 RedisTemplate 进行保存： 12345678910@AutowiredStringRedisTemplate stringRedisTemplate;public void test() &#123; Student student3 = new Student(); student3.setName(\"kirito\"); student3.setId(\"3\"); student3.setHobbies(Arrays.asList(\"coding\",\"write blog\",\"eat chicken\")); redisTemplate.opsForValue().set(\"student:3\",student3);&#125; 紧接着，去 RedisDesktopManager 中查看结果： 标准的 JSON 格式 实现 Kryo 序列化我们也可以考虑根据自己项目和需求的特点，扩展序列化器，这是非常方便的。比如前面提到的，为了追求性能，可能考虑使用 Kryo 序列化器替换缓慢的 JDK 序列化器，如下是一个参考实现（为了 demo 而写，未经过生产验证） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class KryoRedisSerializer&lt;T&gt; implements RedisSerializer&lt;T&gt; &#123; private final static Logger logger = LoggerFactory.getLogger(KryoRedisSerializer.class); private static final ThreadLocal&lt;Kryo&gt; kryos = new ThreadLocal&lt;Kryo&gt;() &#123; protected Kryo initialValue() &#123; Kryo kryo = new Kryo(); return kryo; &#125;; &#125;; @Override public byte[] serialize(Object obj) throws SerializationException &#123; if (obj == null) &#123; throw new RuntimeException(\"serialize param must not be null\"); &#125; Kryo kryo = kryos.get(); Output output = new Output(64, -1); try &#123; kryo.writeClassAndObject(output, obj); return output.toBytes(); &#125; finally &#123; closeOutputStream(output); &#125; &#125; @Override public T deserialize(byte[] bytes) throws SerializationException &#123; if (bytes == null) &#123; return null; &#125; Kryo kryo = kryos.get(); Input input = null; try &#123; input = new Input(bytes); return (T) kryo.readClassAndObject(input); &#125; finally &#123; closeInputStream(input); &#125; &#125; private static void closeOutputStream(OutputStream output) &#123; if (output != null) &#123; try &#123; output.flush(); output.close(); &#125; catch (Exception e) &#123; logger.error(\"serialize object close outputStream exception\", e); &#125; &#125; &#125; private static void closeInputStream(InputStream input) &#123; if (input != null) &#123; try &#123; input.close(); &#125; catch (Exception e) &#123; logger.error(\"serialize object close inputStream exception\", e); &#125; &#125; &#125;&#125; 由于 Kyro 是线程不安全的，所以使用了一个 ThreadLocal 来维护，也可以挑选其他高性能的序列化方案如 Hessian，Protobuf…","categories":[{"name":"Spring Data Redis","slug":"Spring-Data-Redis","permalink":"http://lexburner.github.io/categories/Spring-Data-Redis/"}],"tags":[{"name":"Spring Data Redis","slug":"Spring-Data-Redis","permalink":"http://lexburner.github.io/tags/Spring-Data-Redis/"}]},{"title":"Spring Data Redis（一）-- 解析 RedisTemplate","slug":"spring-data-redis-1","date":"2017-10-27T08:10:55.000Z","updated":"2019-09-26T09:45:30.845Z","comments":true,"path":"spring-data-redis-1/","link":"","permalink":"http://lexburner.github.io/spring-data-redis-1/","excerpt":"","text":"谈及系统优化，缓存一直是不可或缺的一点。在缓存中间件层面，我们有 MemCache，Redis 等选择；在系统分层层面，又需要考虑多级缓存；在系统可用性层面，又要考虑到缓存雪崩，缓存穿透，缓存失效等常见的缓存问题… 缓存的使用与优化值得我们花费一定的精力去深入理解。《Spring Data Redis》这个系列打算围绕 spring-data-redis 来进行分析，从 hello world 到源码分析，夹杂一些不多实战经验（经验有限），不止限于 spring-data-redis 本身，也会扩展谈及缓存这个大的知识点。 至于为何选择 redis，相信不用我赘述，redis 如今非常流行，几乎成了项目必备的组件之一。而 spring-boot-starter-data-redis 模块又为我们在 spring 集成的项目中提供了开箱即用的功能，更加便捷了我们开发。系列的第一篇便是简单介绍下整个组件最常用的一个工具类：RedisTemplate。 1 引入依赖1234567891011121314151617&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; springboot 的老用户会发现 redis 依赖名称发生了一点小的变化，在 springboot1.4 之前，redis 依赖的名称为：spring-boot-starter-redis，而在之后较新的版本中，使用 spring-boot-starter-redis 依赖，则会在项目启动时得到一个过期警告。意味着，我们应该彻底放弃旧的依赖。spring-data 这个项目定位为 spring 提供一个统一的数据仓库接口，如（spring-boot-starter-data-jpa,spring-boot-starter-data-mongo,spring-boot-starter-data-rest），将 redis 纳入后，改名为了 spring-boot-starter-data-redis。 2 配置 redis 连接resources/application.yml 123456spring: redis: host: 127.0.0.1 database: 0 port: 6379 password: 本机启动一个单点的 redis 即可，使用 redis 的 0 号库作为默认库（默认有 16 个库），在生产项目中一般会配置 redis 集群和哨兵保证 redis 的高可用，同样可以在 application.yml 中修改，非常方便。 3 编写测试类1234567891011121314151617181920import org.assertj.core.api.Assertions;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class ApplicationTests &#123; @Autowired private RedisTemplate redisTemplate;// &lt;1&gt; @Test public void test() throws Exception &#123; redisTemplate.opsForValue().set(\"student:1\", \"kirito\"); // &lt;2&gt; Assertions.assertThat(redisTemplate.opsForValue().get(\"student:1\")).isEqualTo(\"kirito\"); &#125;&#125; 引入了 RedisTemplate，这个类是 spring-starter-data-redis 提供给应用直接访问 redis 的入口。从其命名就可以看出，其是模板模式在 spring 中的体现，与 restTemplate，jdbcTemplate 类似，而 springboot 为我们做了自动的配置，具体会在下文详解。 redisTemplate 通常不直接操作键值，而是通过 opsForXxx() 访问，在本例中，key 和 value 均为字符串类型。绑定字符串在实际开发中也是最为常用的操作类型。 4 详解 RedisTemplate 的 APIRedisTemplate 为我们操作 Redis 提供了丰富的 API，可以将他们简单进行下归类。 4.1 常用数据操作这一类 API 也是我们最常用的一类。 众所周知，redis 存在 5 种数据类型： 字符串类型（string），散列类型（hash），列表类型（list），集合类型（set），有序集合类型（zset） 而 redisTemplate 实现了 RedisOperations 接口，在其中，定义了一系列与 redis 相关的基础数据操作接口，数据类型分别于下来 API 对应： 123456789101112// 非绑定 key 操作ValueOperations&lt;K, V&gt; opsForValue();&lt;HK, HV&gt; HashOperations&lt;K, HK, HV&gt; opsForHash();ListOperations&lt;K, V&gt; opsForList();SetOperations&lt;K, V&gt; opsForSet();ZSetOperations&lt;K, V&gt; opsForZSet();// 绑定 key 操作BoundValueOperations&lt;K, V&gt; boundValueOps(K key);&lt;HK, HV&gt; BoundHashOperations&lt;K, HK, HV&gt; boundHashOps(K key);BoundListOperations&lt;K, V&gt; boundListOps(K key);BoundSetOperations&lt;K, V&gt; boundSetOps(K key);BoundZSetOperations&lt;K, V&gt; boundZSetOps(K key); 若以 bound 开头，则意味着在操作之初就会绑定一个 key，后续的所有操作便默认认为是对该 key 的操作，算是一个小优化。 4.2 对原生 Redis 指令的支持Redis 原生指令中便提供了一些很有用的操作，如设置 key 的过期时间，判断 key 是否存在等等… 常用的 API 列举： RedisTemplate API 原生 Redis 指令 说明 public void delete(K key) DEL key [key …] 删除给定的一个或多个 key public Boolean hasKey(K key) EXISTS key 检查给定 key 是否存在 public Boolean expire/expireAt(…) EXPIRE key seconds 为给定 key 设置生存时间，当 key 过期时 (生存时间为 0)，它会被自动删除。 public Long getExpire(K key) TTL key 以秒为单位，返回给定 key 的剩余生存时间 (TTL, time to live)。 更多的原生 Redis 指令支持可以参考 javadoc 4.3 CAS 操作CAS（Compare and Swap）通常有 3 个操作数，内存值 V，旧的预期值 A，要修改的新值 B。当且仅当预期值 A 和内存值 V 相同时，将内存值 V 修改为 B，否则什么都不做。CAS 也通常与并发，乐观锁，非阻塞，机器指令等关键词放到一起讲解。可能会有很多朋友在秒杀场景的架构设计中见到了 Redis，本质上便是利用了 Redis 分布式共享内存的特性以及一系列的 CAS 指令。还记得在 4.1 中通过 redisTemplate.opsForValue()或者 redisTemplate.boundValueOps() 可以得到一个 ValueOperations 或 BoundValueOperations 接口 (以值为字符串的操作接口为例)，这些接口除了提供了基础操作外，还提供了一系列 CAS 操作，也可以放到 RedisTemplate 中一起理解。 常用的 API 列举： ValueOperations API 原生 Redis 指令 说明 Boolean setIfAbsent(K key, V value) SETNX key value 将 key 的值设为 value ，当且仅当 key 不存在。设置成功，返回 1 ， 设置失败，返回 0 。 V getAndSet(K key, V value) GETSET key value 将给定 key 的值设为 value ，并返回 key 的旧值 (old value)。 Long increment(K key, long delta)/Double increment(K key, double delta) INCR/INCRBY/INCRBYFLOAT 将 key 所储存的值加上增量 increment 。 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 INCR/INCRBY/INCRBYFLOAT 命令。线程安全的 + 关于 CAS 的理解可以参考我之前的文章 java 并发实践 –CAS 或者其他博文。 4.4 发布订阅redis 之所以被冠以银弹，万金油的称号，关键在于其实现的功能真是太多了，甚至实现了一部分中间件队列的功能，其内置的 channel 机制，可以用于实现分布式的队列和广播。 RedisTemplate 提供了 convertAndSend()功能，用于发送消息，与 RedisMessageListenerContainer 配合接收，便实现了一个简易的发布订阅。如果想要使用 Redis 实现发布订阅，可以参考我之前的文章。 浅析分布式下的事件驱动机制 4.5 Lua 脚本RedisTemplate 中包含了这样一个 Lua 执行器，意味着我们可以使用 RedisTemplate 执行 Lua 脚本。 1private ScriptExecutor&lt;K&gt; scriptExecutor; Lua 这门语言也非常有意思，小巧而精悍，有兴趣的朋友可以去了解一下 nginx+lua 开发，使用 openResty 框架。而 Redis 内置了 Lua 的解析器，由于 Redis 单线程的特性（不严谨），可以使用 Lua 脚本，完成一些线程安全的符合操作（CAS 操作仅仅只能保证单个操作的线程安全，无法保证复合操作，如果你有这样的需求，可以考虑使用 Redis+Lua 脚本）。 123public &lt;T&gt; T execute(RedisScript&lt;T&gt; script, List&lt;K&gt; keys, Object... args) &#123; return scriptExecutor.execute(script, keys, args);&#125; 上述操作便可以完成对 Lua 脚本的调用。这儿有一个简单的示例，使用 Redis+Lua 脚本实现分布式的应用限流。分布式限流 5 总结Spring Data Redis 系列的第一篇，介绍了 spring-data 对 redis 操作的封装，顺带了解 redis 具备的一系列特性，如果你对 redis 的理解还仅仅停留在它是一个分布式的 key-value 数据库，那么相信现在你一定会感叹其竟然如此强大。后续将会对缓存在项目中的应用以及 spring-boot-starter-data-redis 进一步解析。","categories":[{"name":"Spring Data Redis","slug":"Spring-Data-Redis","permalink":"http://lexburner.github.io/categories/Spring-Data-Redis/"}],"tags":[{"name":"Spring Data Redis","slug":"Spring-Data-Redis","permalink":"http://lexburner.github.io/tags/Spring-Data-Redis/"}]},{"title":"java 小技巧 (一)-- 远程 debug","slug":"java-skill-1","date":"2017-10-25T09:24:48.000Z","updated":"2019-09-26T09:45:31.657Z","comments":true,"path":"java-skill-1/","link":"","permalink":"http://lexburner.github.io/java-skill-1/","excerpt":"","text":"该系列介绍一些 java 开发中常用的一些小技巧，多小呢，从不会到会只需要一篇文章这么小。这一篇介绍如何使用 jdk 自带的扩展包配合 Intellij IDEA 实现远程 debug。 项目中经常会有出现这样的问题，会令程序员抓狂：关键代码段没有打印日志，本地环境正常生产环境却又问题… 这时候，远程 debug 可能会启动作用。 1 准备用于 debug 的代码准备一个 RestController 用于接收请求，最后可以通过本地断点验证是否成功开启了远程 debug 123456789101112131415@RestControllerpublic class TestController &#123; @RequestMapping(\"/test\") public Integer test() &#123; int i = 0; i++; i++; i++; i++; i++; return i; &#125;&#125; 项目使用 springboot 和 maven 构建，依赖就省略了，使用 springboot 提供的 maven 打包插件，方便我们打包成可运行的 jar。 123456789101112131415161718&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;executable&gt;true&lt;/executable&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2 使用 maven 插件打包成 jar 3 准备启动脚本1java -jar -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=64057 remote-debug-1.0-SNAPSHOT.jar 使用 java -jar 的方式启动程序，并且添加了一串特殊的参数，这是我们能够开启远程 debug 的关键，以 - 开头的参数是 jvm 的标准启动参数，关于 jvm 启动参数相关的知识可以先去其他博客了解。 -agentlib:libname[=options], 用于装载本地 lib 包。在这条指令中便是加载了 jdwp(Java Debug Wire Protocol) 这个用于远程调试 java 的扩展包。而 transport=dt_socket,server=y,suspend=n,address=64057 这些便是 jdwp 装载时的定制参数，详细的参数作用可以搜索 jdwp 进行了解。我们需要关心的只有 address=64057 这个参数选项，本地调试程序使用 64057 端口与其通信，从而远程调试。 4 配置 IDEA 与脚本中的指令完全一致 远程 jar 包运行的 host，由于我的 jar 运行在本地，所以使用的是 localhost，一般线上环境自然是修改为线上的地址 与远程 jar 包进行交互的端口号，idea 会根据指令自动帮我们输入 选择与远程 jar 包一致的本地代码 请务必保证远程 jar 包的代码与本地代码一致！！！ 5 验证保存第 4 步的配置后，先执行脚本让远程的 jar 包跑起来，再在 IDEA 中运行 remote-debug 如上便代表连接运行成功了 在本地打上断点，访问 localhost:8080/test 可以在本地看到堆栈信息，大功告成。一行指令便完成了远程调试。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"浅析项目中的并发 (二)","slug":"concurrent-2","date":"2017-10-15T03:11:11.000Z","updated":"2019-09-26T09:45:29.756Z","comments":true,"path":"concurrent-2/","link":"","permalink":"http://lexburner.github.io/concurrent-2/","excerpt":"","text":"分布式遭遇并发在前面的章节，并发操作要么发生在单个应用内，一般使用基于 JVM 的 lock 解决并发问题，要么发生在数据库，可以考虑使用数据库层面的锁，而在分布式场景下，需要保证多个应用实例都能够执行同步代码，则需要做一些额外的工作，一个最典型分布式同步方案便是使用分布式锁。 分布式锁由很多种实现，但本质上都是类似的，即依赖于共享组件实现锁的询问和获取，如果说单体式应用中的 Monitor 是由 JVM 提供的，那么分布式下 Monitor 便是由共享组件提供，而典型的共享组件大家其实并不陌生，包括但不限于：Mysql，Redis，Zookeeper。同时他们也代表了三种类型的共享组件：数据库，缓存，分布式协调组件。基于 Consul 的分布式锁，其实和基于 Zookeeper 的分布式锁大同小异，都是借助于分布式协调组件实现锁，大而化之，这三种类型的分布式锁，原理也都差不多，只不过，锁的特性和实现细节有所差异。 Redis 实现分布式锁定义需求：A 应用需要完成添加库存的操作，部署了 A1，A2，A3 多个实例，实例之间的操作要保证同步。 分析需求：显然，此时依赖于 JVM 的 lock 已经没办法解决问题了，A1 添加锁，无法保证 A2，A3 的同步，这种场景可以考虑使用分布式锁应对。 建立一张 Stock 表，包含 id，number 两个字段，分别让 A1，A2，A3 并发对其操作，保证线程安全。 123456@Entitypublic class Stock &#123; @Id private String id; private Integer number;&#125; 定义数据库访问层： 12public interface StockRepository extends JpaRepository&lt;Stock,String&gt; &#123;&#125; 这一节的主角，redis 分布式锁，使用开源的 redis 分布式锁实现：Redisson。 引入 Redisson 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt;&lt;/dependency&gt; 定义测试类： 12345678910111213141516171819202122232425262728293031@RestControllerpublic class StockController &#123; @Autowired StockRepository stockRepository; ExecutorService executorService = Executors.newFixedThreadPool(10); @Autowired RedissonClient redissonClient; final static String id = \"1\"; @RequestMapping(\"/addStock\") public void addStock() &#123; RLock lock = redissonClient.getLock(\"redisson:lock:stock:\" + id); for (int i = 0; i &lt; 100; i++) &#123; executorService.execute(() -&gt; &#123; lock.lock(); try &#123; Stock stock = stockRepository.findOne(id); stock.setNumber(stock.getNumber() + 1); stockRepository.save(stock); &#125; finally &#123; lock.unlock(); &#125; &#125;); &#125; &#125;&#125; 上述的代码使得并发发生在多个层面。其一，在应用内部，启用线程池完成库存的加 1 操作，本身便是线程不安全的，其二，在多个应用之间，这样的加 1 操作更加是不受约束的。若初始化 id 为 1 的 Stock 数量为 0。分别在本地启用 A1(8080)，A2(8081)，A3(8082) 三个应用，同时并发执行一次 addStock()，若线程安全，必然可以使得数据库中的 Stock 为 300，这便是我们的检测依据。 简单解读下上述的代码，使用 redisson 获取一把 RLock，RLock 是 java.util.concurrent.locks.Lock 接口的实现类，Redisson 帮助我们屏蔽 Redis 分布式锁的实现细节，使用过 java.util.concurrent.locks.Lock 的朋友都会知道下述的代码可以被称得上是同步的起手范式，毕竟这是 Lock 的 java doc 中给出的代码： 1234567Lock l = ...;l.lock();try &#123; // access the resource protected by this lock&#125; finally &#123; l.unlock();&#125; 而 redissonClient.getLock(&quot;redisson:lock:stock:&quot; + id) 则是以 &quot;redisson:lock:stock:&quot; + id 该字符串作痛同步的 Monitor，保证了不同 id 之间是互相不阻塞的。 为了保证发生并发，实际测试中我加入了 Thread.sleep(1000)，使竞争得以发生。测试结果： Redis 分布式锁的确起了作用。 锁的注意点如果仅仅是实现一个能够用于 demo 的 Redis 分布式锁并不难，但为何大家更偏向于使用开源的实现呢？主要还是可用性和稳定性，we make things work 是我在写博客，写代码时牢记在脑海中的，如果真的要细究如何自己实现一个分布式锁，或者平时使用锁保证并发，需要有哪些注意点呢？列举几点：阻塞，超时时间，可重入，可用性，其他特性。 阻塞意味着各个操作之间的等待，A1 正在执行增加库存时，A1 其他的线程被阻塞，A2，A3 中所有的线程被阻塞，在 Redis 中可以使用轮询策略以及 redis 底层提供的 CAS 原语 (如 setnx) 来实现。（初学者可以理解为：在 redis 中设置一个 key，想要执行 lock 代码时先询问是否有该 key，如果有则代表其他线程在执行过程中，若没有，则设置该 key，并且执行代码，执行完毕，释放 key，而 setnx 保证操作的原子性） 超时时间在特殊情况，可能会导致锁无法被释放，如死锁，死循环等等意料之外的情况，锁超时时间的设置是有必要的，一个很直观的想法是给 key 设置过期时间即可。 如在 Redisson 中，lock 提供了一个重载方法 lock(long t, TimeUnit timeUnit); 可以自定义过期时间。 可重入这个特性很容易被忽视，可重入其实并不难理解，顾名思义，一个方法在调用过程中是否可以被再次调用。实现可重入需要满足三个特性： 可以在执行的过程中可以被打断； 被打断之后，在该函数一次调用执行完之前，可以再次被调用（或进入，reentered)。 再次调用执行完之后，被打断的上次调用可以继续恢复执行，并正确执行。 比如下述的代码引用了全局变量，便是不可重入的： 12345678int t;void swap(int x, int y) &#123; t = x; x = y; y = t; System.out.println(\"x is\" + x + \"y is\" + y);&#125; 一个更加直观的例子便是，同一个线程中，某个方法的递归调用不应该被阻塞，所以如果要实现这个特性，简单的使用某个 key 作为 Monitor 是欠妥的，可以加入线程编号，来保证可重入。 使用可重入分布式锁的来测试计算斐波那契数列（只是为了验证可重入性）： 12345678910111213141516171819202122@RequestMapping(\"testReentrant\")public void ReentrantLock() &#123; RLock lock = redissonClient.getLock(\"fibonacci\"); lock.lock(); try &#123; int result = fibonacci(10); System.out.println(result); &#125; finally &#123; lock.unlock(); &#125;&#125;int fibonacci(int n) &#123; RLock lock = redissonClient.getLock(\"fibonacci\"); try &#123; if (n &lt;= 1) return n; else return fibonacci(n - 1) + fibonacci(n - 2); &#125; finally &#123; lock.unlock(); &#125;&#125; 最终输出：55，可以发现，只要是在同一线程之内，无论是递归调用还是外部加锁 (同一把锁)，都不会造成死锁。 可用性借助于第三方中间件实现的分布式锁，都有这个问题，中间件挂了，会导致锁不可用，所以需要保证锁的高可用，这就需要保证中间件的可用性，如 redis 可以使用哨兵 + 集群，保证了中间件的可用性，便保证了锁的可用性、 其他特性除了可重入锁，锁的分类还有很多，在分布式下也同样可以实现，包括但不限于：公平锁，联锁，信号量，读写锁。Redisson 也都提供了相关的实现类，其他的特性如并发容器等可以参考官方文档。 新手遭遇并发基本算是把项目中遇到的并发过了一遍了，案例其实很多，再简单罗列下一些新手可能会遇到的问题。 使用了线程安全的容器就是线程安全了吗？很多新手误以为使用了并发容器如：concurrentHashMap 就万事大吉了，却不知道，一知半解的隐患可能比全然不懂更大。来看下面的代码： 123456789101112131415161718192021public class ConcurrentHashMapTest &#123; static Map&lt;String, Integer&gt; counter = new ConcurrentHashMap(); public static void main(String[] args) throws InterruptedException &#123; counter.put(\"stock1\", 0); ExecutorService executorService = Executors.newFixedThreadPool(10); CountDownLatch countDownLatch = new CountDownLatch(100); for (int i = 0; i &lt; 100; i++) &#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; counter.put(\"stock1\", counter.get(\"stock1\") + 1); countDownLatch.countDown(); &#125; &#125;); &#125; countDownLatch.await(); System.out.println(\"result is\" + counter.get(\"stock1\")); &#125;&#125; counter.put(&quot;stock1&quot;, counter.get(&quot;stock1&quot;) + 1) 并不是原子操作，并发容器保证的是单步操作的线程安全特性，这一点往往初级程序员特别容易忽视。 总结项目中的并发场景是非常多的，而根据场景不同，同一个场景下的业务需求不同，以及数据量，访问量的不同，都会影响到锁的使用，架构中经常被提到的一句话是：业务决定架构，放到并发中也同样适用：业务决定控制并发的手段，如本文未涉及的队列的使用，本质上是化并发为串行，也解决了并发问题，都是控制的手段。了解锁的使用很简单，但如果使用，在什么场景下使用什么样的锁，这才是价值所在。 同一个线程之间的递归调用不应该被阻塞，所以如果要实现这个特性，简单的使用某个 key 作为 Monitor 是欠妥的，可以加入线程编号，来保证可重入。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/categories/架构设计/"}],"tags":[{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/tags/架构设计/"}]},{"title":"浅析项目中的并发 (一)","slug":"concurrent-1","date":"2017-10-11T13:29:40.000Z","updated":"2019-09-26T09:45:31.253Z","comments":true,"path":"concurrent-1/","link":"","permalink":"http://lexburner.github.io/concurrent-1/","excerpt":"","text":"前言控制并发的方法很多，从最基础的 synchronized，juc 中的 lock，到数据库的行级锁，乐观锁，悲观锁，再到中间件级别的 redis，zookeeper 分布式锁。特别是初级程序员，对于所谓的锁一直都是听的比用的多，第一篇文章不深入探讨并发，更多的是一个入门介绍，适合于初学者，主题是“根据并发出现的具体业务场景，使用合理的控制并发手段”。 什么是并发由一个大家都了解的例子引入我们今天的主题：并发 类共享变量遭遇并发123456789101112131415161718192021222324public class Demo &#123; public Integer count = 0; public static void main(String[] args) &#123; final Demo demo = new Demo(); Executor executor = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++)&#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; demo.count++; &#125; &#125;); &#125; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"final count value:\"+demo1.count); &#125;&#125; final count value:973 本例中创建了一个初始化时具有 10 个线程的线程池，多线程对类变量 count 进行自增操作。这个过程中，自增操作并不是线程安全的，happens-before 原则并不会保障多个线程执行的先后顺序，导致了最终结果并不是想要的 1000 下面，我们把并发中的共享资源从类变量转移到数据库中。 充血模型遭遇并发1234567891011121314@Componentpublic class Demo2 &#123; @Autowired TestNumDao testNumDao; @Transactional public void test()&#123; TestNum testNum = testNumDao.findOne(\"1\"); testNum.setCount(testNum.getCount()+1); testNumDao.save(testNum); &#125;&#125; 依旧使用多线程，对数据库中的记录进行 +1 操作 Demo2 demo2; public String test(){ Executor executor = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++){ executor.execute(new Runnable() { @Override public void run() { demo2.test(); } }); } return &quot;test&quot;; } 数据库的记录 12id | count1 | 344 初窥门径的程序员会认为事务最基本的 ACID 中便包含了原子性，但是事务的原子性和今天所讲的并发中的原子操作仅仅是名词上有点类似。而有点经验的程序员都能知道这中间发生了什么，这只是暴露了项目中并发问题的冰山一角，千万不要认为上面的代码没有必要列举出来，我在实际项目开发中，曾经见到有多年工作经验的程序员仍然写出了类似于上述会出现并发问题的代码。 贫血模型遭遇并发1234567891011121314151617181920@RequestMapping(\"testSql\") @ResponseBody public String testSql() throws InterruptedException &#123; final CountDownLatch countDownLatch = new CountDownLatch(1000); long start = System.currentTimeMillis(); Executor executor = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++)&#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; jdbcTemplate.execute(\"update test_num set count = count + 1 where id ='1'\"); countDownLatch.countDown(); &#125; &#125;); &#125; countDownLatch.await(); long costTime =System.currentTimeMillis() - start; System.out.println(\"共花费：\"+costTime+\"s\"); return \"testSql\"; &#125; 数据库结果： count ： 1000 达到了预期效果这个例子我顺便记录了耗时, 控制台打印: 共花费：113 ms简单对比一下二，三两个例子，都是想对数据库的 count 进行 +1 操作，唯一的区别就是， 后者的 +1 计算发生在数据库，而前者的计算依赖于事先查出来的值，并且计算发生在程序的内存中 。而现在大部分的 ORM 框架，导致了写充血模型的程序员变多，不注意并发的话，就会出现问题。下面我们来看看具体的业务场景。 业务场景 修改个人信息 修改商品信息 扣除账户余额，扣减库存 业务场景分析第一个场景，互联网如此众多的用户修改个人信息，这算不算并发？答案是：算也不算。算，从程序员角度来看，每一个用户请求进来，都是调用的同一个修改入口，具体一点，就是映射到 controller 层的同一个 requestMapping，所以一定是并发的。不算，虽然程序是并发的，但是从用户角度来分析，每个人只可以修改自己的信息，所以，不同用户的操作其实是隔离的，所以不算“并发”。这也是为什么很多开发者，在日常开发中一直不注意并发控制，却也没有发生太大问题的原因，大多数初级程序员开发的还都是 CRM，OA，CMS 系统。 回到我们的并发，第一种业务场景，是可以使用如上模式的，对于一条用户数据的修改，我们允许程序员读取数据到内存中，内存计算修改（耗时操作），提交更改，提交事务。 1234567//Transaction startUser user = userDao.findById(\"1\");user.setName(\"newName\");user.setAge(user.getAge()+1);...// 其他耗时操作userDao.save(user);//Transaction commit 这个场景变现为：几乎不存在并发，不需要控制，场景乐观。 为了严谨，也可以选择控制并发，但我觉得这需要交给写这段代码的同事，让他自由发挥。 第二个场景已经有所不同了，同样是修改一个记录，但是系统中可能有多个操作员来维护，此时，商品数据表现为一个共享数据，所以存在微弱的并发，通常表现为数据的脏读，例如操作员 A，B 同时对一个商品信息维护，我们希望只能有一个操作员修改成功，另外一个操作员得到错误提示（该商品信息已经发生变化），否则，两个人都以为自己修改成功了，但是其实只有一个人完成了操作，另一个人的操作被覆盖了。 这个场景表现为：存在并发，需要控制，允许失败，场景乐观。 通常我建议这种场景使用乐观锁，即在商品属性添加一个 version 字段标记修改的版本，这样两个操作员拿到同一个版本号，第一个操作员修改成功后版本号变化，另一个操作员的修改就会失败了。 1234567891011121314151617class Goods&#123; @Version int version;&#125;//Transaction starttry&#123; Goods goods = goodsDao.findById(\"1\"); goods.setName(\"newName\"); goods.setPrice(goods.getPrice()+100.00); ...// 其他耗时操作 goodsDao.save(goods);&#125;catch(org.hibernate.StaleObjectStateException e)&#123; // 返回给前台&#125;//Transaction commit springdata 配合 jpa 可以自动捕获 version 异常，也可以自动手动对比。 第三个场景这个场景表现为：存在频繁的并发，需要控制，不允许失败，场景悲观。 强调一下，本例不应该使用在项目中，只是为了举例而设置的一个场景，因为这种贫血模型无法满足复杂的业务场景，而且依靠单机事务来保证一致性，并发性能和可扩展性能不好。 一个简易的秒杀场景，大量请求在短时间涌入，是不可能像第二种场景一样，100 个并发请求，一个成功，其他 99 个全部异常的。 设计方案应该达到的效果是：有足够库存时，允许并发，库存到 0 时，之后的请求全部失败；有足够金额时，允许并发，金额不够支付时立刻告知余额不足。 可以利用数据库的行级锁，update set balance = balance - money where userId = ? and balance &gt;= money;update stock = stock - number where goodsId = ? and stock &gt;= number ; 然后在后台 查看返回值是否影响行数为 1，判断请求是否成功，利用数据库保证并发。 需要补充一点，我这里所讲的秒杀，并不是指双 11 那种级别的秒杀，那需要多层架构去控制并发，前端拦截，负载均衡…. 不能仅仅依赖于数据库的，会导致严重的性能问题。为了留一下一个直观的感受，这里对比一下 oracle，mysql 的两个主流存储引擎：innodb，myisam 的性能问题。123456oracle:10000 个线程共计 1000000 次并发请求：共花费：101017 ms =&gt;101sinnodb:10000 个线程共计 1000000 次并发请求：共花费：550330 ms =&gt;550smyisam:10000 个线程共计 1000000 次并发请求：共花费：75802 ms =&gt;75s 可见，如果真正有大量请求到达数据库，光是依靠数据库解决并发是不现实的，所以仅仅只用数据库来做保障而不是完全依赖。需要根据业务场景选择合适的控制并发手段。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/categories/架构设计/"}],"tags":[{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/tags/架构设计/"}]},{"title":"Spring Security(五)-- 动手实现一个 IP_Login","slug":"spring-security-5","date":"2017-10-01T14:44:34.000Z","updated":"2019-09-26T09:45:30.511Z","comments":true,"path":"spring-security-5/","link":"","permalink":"http://lexburner.github.io/spring-security-5/","excerpt":"在开始这篇文章之前，我们似乎应该思考下为什么需要搞清楚 Spring Security 的内部工作原理？按照第二篇文章中的配置，一个简单的表单认证不就达成了吗？更有甚者，为什么我们不自己写一个表单认证，用过滤器即可完成，大费周章引入 Spring Security，看起来也并没有方便多少。对的，在引入 Spring Security 之前，我们得首先想到，是什么需求让我们引入了 Spring Security，以及为什么是 Spring Security，而不是 shiro 等等其他安全框架。我的理解是有如下几点： 1 在前文的介绍中，Spring Security 支持防止 csrf 攻击，session-fixation protection，支持表单认证，basic 认证，rememberMe… 等等一些特性，有很多是开箱即用的功能，而大多特性都可以通过配置灵活的变更，这是它的强大之处。 2 Spring Security 的兄弟的项目 Spring Security SSO，OAuth2 等支持了多种协议，而这些都是基于 Spring Security 的，方便了项目的扩展。 3 SpringBoot 的支持，更加保证了 Spring Security 的开箱即用。 4 为什么需要理解其内部工作原理? 一个有自我追求的程序员都不会满足于浅尝辄止，如果一个开源技术在我们的日常工作中十分常用，那么我偏向于阅读其源码，这样可以让我们即使排查不期而至的问题，也方便日后需求扩展。 5 Spring 及其子项目的官方文档是我见过的最良心的文档！~~ 相比较于 Apache 的部分文档 ~~ 这一节，为了对之前分析的 Spring Security 源码和组件有一个清晰的认识，介绍一个使用 IP 完成登录的简单 demo。","text":"在开始这篇文章之前，我们似乎应该思考下为什么需要搞清楚 Spring Security 的内部工作原理？按照第二篇文章中的配置，一个简单的表单认证不就达成了吗？更有甚者，为什么我们不自己写一个表单认证，用过滤器即可完成，大费周章引入 Spring Security，看起来也并没有方便多少。对的，在引入 Spring Security 之前，我们得首先想到，是什么需求让我们引入了 Spring Security，以及为什么是 Spring Security，而不是 shiro 等等其他安全框架。我的理解是有如下几点： 1 在前文的介绍中，Spring Security 支持防止 csrf 攻击，session-fixation protection，支持表单认证，basic 认证，rememberMe… 等等一些特性，有很多是开箱即用的功能，而大多特性都可以通过配置灵活的变更，这是它的强大之处。 2 Spring Security 的兄弟的项目 Spring Security SSO，OAuth2 等支持了多种协议，而这些都是基于 Spring Security 的，方便了项目的扩展。 3 SpringBoot 的支持，更加保证了 Spring Security 的开箱即用。 4 为什么需要理解其内部工作原理? 一个有自我追求的程序员都不会满足于浅尝辄止，如果一个开源技术在我们的日常工作中十分常用，那么我偏向于阅读其源码，这样可以让我们即使排查不期而至的问题，也方便日后需求扩展。 5 Spring 及其子项目的官方文档是我见过的最良心的文档！~~ 相比较于 Apache 的部分文档 ~~ 这一节，为了对之前分析的 Spring Security 源码和组件有一个清晰的认识，介绍一个使用 IP 完成登录的简单 demo。 5 动手实现一个 IP_Login5.1 定义需求在表单登录中，一般使用数据库中配置的用户表，权限表，角色表，权限组表… 这取决于你的权限粒度，但本质都是借助了一个持久化存储，维护了用户的角色权限，而后给出一个 /login 作为登录端点，使用表单提交用户名和密码，而后完成登录后可自由访问受限页面。 在我们的 IP 登录 demo 中，也是类似的，使用 IP 地址作为身份，内存中的一个 ConcurrentHashMap 维护 IP 地址和权限的映射，如果在认证时找不到相应的权限，则认为认证失败。 实际上，在表单登录中，用户的 IP 地址已经被存放在 Authentication.getDetails() 中了，完全可以只重写一个 AuthenticationProvider 认证这个 IP 地址即可，但是，本 demo 是为了厘清 Spring Security 内部工作原理而设置，为了设计到更多的类，我完全重写了 IP 过滤器。 5.2 设计概述我们的参考完全是表单认证，在之前章节中，已经了解了表单认证相关的核心流程，将此图再贴一遍： 在 IP 登录的 demo 中，使用 IpAuthenticationProcessingFilter 拦截 IP 登录请求，同样使用 ProviderManager 作为全局 AuthenticationManager 接口的实现类，将 ProviderManager 内部的 DaoAuthenticationProvider 替换为 IpAuthenticationProvider，而 UserDetailsService 则使用一个 ConcurrentHashMap 代替。更详细一点的设计： IpAuthenticationProcessingFilter–&gt;UsernamePasswordAuthenticationFilter IpAuthenticationToken–&gt;UsernamePasswordAuthenticationToken ProviderManager–&gt;ProviderManager IpAuthenticationProvider–&gt;DaoAuthenticationProvider ConcurrentHashMap–&gt;UserDetailsService 5.3 IpAuthenticationToken123456789101112131415161718192021222324252627282930313233343536public class IpAuthenticationToken extends AbstractAuthenticationToken &#123; private String ip; public String getIp() &#123; return ip; &#125; public void setIp(String ip) &#123; this.ip = ip; &#125; public IpAuthenticationToken(String ip) &#123; super(null); this.ip = ip; super.setAuthenticated(false);// 注意这个构造方法是认证时使用的 &#125; public IpAuthenticationToken(String ip, Collection&lt;? extends GrantedAuthority&gt; authorities) &#123; super(authorities); this.ip = ip; super.setAuthenticated(true);// 注意这个构造方法是认证成功后使用的 &#125; @Override public Object getCredentials() &#123; return null; &#125; @Override public Object getPrincipal() &#123; return this.ip; &#125;&#125; 两个构造方法需要引起我们的注意，这里设计的用意是模仿的 UsernamePasswordAuthenticationToken，第一个构造器是用于认证之前，传递给认证器使用的，所以只有 IP 地址，自然是未认证；第二个构造器用于认证成功之后，封装认证用户的信息，此时需要将权限也设置到其中，并且 setAuthenticated(true)。这样的设计在诸多的 Token 类设计中很常见。 5.4 IpAuthenticationProcessingFilter1234567891011121314public class IpAuthenticationProcessingFilter extends AbstractAuthenticationProcessingFilter &#123; // 使用 /ipVerify 该端点进行 ip 认证 IpAuthenticationProcessingFilter() &#123; super(new AntPathRequestMatcher(\"/ipVerify\")); &#125; @Override public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException, IOException, ServletException &#123; // 获取 host 信息 String host = request.getRemoteHost(); // 交给内部的 AuthenticationManager 去认证，实现解耦 return getAuthenticationManager().authenticate(new IpAuthenticationToken(host)); &#125;&#125; AbstractAuthenticationProcessingFilter 这个过滤器在前面一节介绍过，是 UsernamePasswordAuthenticationFilter 的父类，我们的 IpAuthenticationProcessingFilter 也继承了它 构造器中传入了 /ipVerify 作为 IP 登录的端点 attemptAuthentication() 方法中加载请求的 IP 地址，之后交给内部的 AuthenticationManager 去认证 5.5 IpAuthenticationProvider123456789101112131415161718192021222324252627282930public class IpAuthenticationProvider implements AuthenticationProvider &#123; final static Map&lt;String, SimpleGrantedAuthority&gt; ipAuthorityMap = new ConcurrenHashMap(); // 维护一个 ip 白名单列表，每个 ip 对应一定的权限 static &#123; ipAuthorityMap.put(\"127.0.0.1\", new SimpleGrantedAuthority(\"ADMIN\")); ipAuthorityMap.put(\"10.236.69.103\", new SimpleGrantedAuthority(\"ADMIN\")); ipAuthorityMap.put(\"10.236.69.104\", new SimpleGrantedAuthority(\"FRIEND\")); &#125; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; IpAuthenticationToken ipAuthenticationToken = (IpAuthenticationToken) authentication; String ip = ipAuthenticationToken.getIp(); SimpleGrantedAuthority simpleGrantedAuthority = ipAuthorityMap.get(ip); // 不在白名单列表中 if (simpleGrantedAuthority == null) &#123; return null; &#125; else &#123; // 封装权限信息，并且此时身份已经被认证 return new IpAuthenticationToken(ip, Arrays.asList(simpleGrantedAuthority)); &#125; &#125; // 只支持 IpAuthenticationToken 该身份 @Override public boolean supports(Class&lt;?&gt; authentication) &#123; return (IpAuthenticationToken.class .isAssignableFrom(authentication)); &#125;&#125; return new IpAuthenticationToken(ip, Arrays.asList(simpleGrantedAuthority)); 使用了 IpAuthenticationToken 的第二个构造器，返回了一个已经经过认证的 IpAuthenticationToken。 5.6 配置 WebSecurityConfigAdapter1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; //ip 认证者配置 @Bean IpAuthenticationProvider ipAuthenticationProvider() &#123; return new IpAuthenticationProvider(); &#125; // 配置封装 ipAuthenticationToken 的过滤器 IpAuthenticationProcessingFilter ipAuthenticationProcessingFilter(AuthenticationManager authenticationManager) &#123; IpAuthenticationProcessingFilter ipAuthenticationProcessingFilter = new IpAuthenticationProcessingFilter(); // 为过滤器添加认证器 ipAuthenticationProcessingFilter.setAuthenticationManager(authenticationManager); // 重写认证失败时的跳转页面 ipAuthenticationProcessingFilter.setAuthenticationFailureHandler(new SimpleUrlAuthenticationFailureHandler(\"/ipLogin?error\")); return ipAuthenticationProcessingFilter; &#125; // 配置登录端点 @Bean LoginUrlAuthenticationEntryPoint loginUrlAuthenticationEntryPoint()&#123; LoginUrlAuthenticationEntryPoint loginUrlAuthenticationEntryPoint = new LoginUrlAuthenticationEntryPoint (\"/ipLogin\"); return loginUrlAuthenticationEntryPoint; &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/\", \"/home\").permitAll() .antMatchers(\"/ipLogin\").permitAll() .anyRequest().authenticated() .and() .logout() .logoutSuccessUrl(\"/\") .permitAll() .and() .exceptionHandling() .accessDeniedPage(\"/ipLogin\") .authenticationEntryPoint(loginUrlAuthenticationEntryPoint()) ; // 注册 IpAuthenticationProcessingFilter 注意放置的顺序 这很关键 http.addFilterBefore(ipAuthenticationProcessingFilter(authenticationManager()), UsernamePasswordAuthenticationFilter.class); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.authenticationProvider(ipAuthenticationProvider()); &#125;&#125; WebSecurityConfigAdapter 提供了我们很大的便利，不需要关注 AuthenticationManager 什么时候被创建，只需要使用其暴露的 configure(AuthenticationManagerBuilder auth) 便可以添加我们自定义的 ipAuthenticationProvider。剩下的一些细节，注释中基本都写了出来。 5.7 配置 SpringMVC1234567891011121314@Configurationpublic class MvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/home\").setViewName(\"home\"); registry.addViewController(\"/\").setViewName(\"home\"); registry.addViewController(\"/hello\").setViewName(\"hello\"); registry.addViewController(\"/ip\").setViewName(\"ipHello\"); registry.addViewController(\"/ipLogin\").setViewName(\"ipLogin\"); &#125;&#125; 页面的具体内容和表单登录基本一致，可以在文末的源码中查看。 5.8 运行效果成功的流程 http://127.0.0.1:8080/ 访问首页，其中 here 链接到的地址为：http://127.0.0.1:8080/hello 点击 here，由于 http://127.0.0.1:8080/hello 是受保护资源，所以跳转到了校验 IP 的页面。此时若点击 Sign In by IP 按钮，将会提交到 /ipVerify 端点，进行 IP 的认证。 登录校验成功之后，页面被成功重定向到了原先访问的 失败的流程 注意此时已经注销了上次的登录，并且，使用了 localhost(localhost 和 127.0.0.1 是两个不同的 IP 地址，我们的内存中只有 127.0.0.1 的用户, 没有 localhost 的用户) 点击 here 后，由于没有认证过，依旧跳转到登录页面 此时，我们发现使用 localhost，并没有认证成功，符合我们的预期 5.9 总结一个简单的使用 Spring Security 来进行验证 IP 地址的登录 demo 就已经完成了，这个 demo 主要是为了更加清晰地阐释 Spring Security 内部工作的原理设置的，其本身没有实际的项目意义，认证 IP 其实也不应该通过 Spring Security 的过滤器去做，退一步也应该交给 Filter 去做（这个 Filter 不存在于 Spring Security 的过滤器链中），而真正项目中，如果真正要做黑白名单这样的功能，一般选择在网关层或者 nginx 的扩展模块中做。再次特地强调下，怕大家误解。 最后祝大家国庆玩的开心 ~ 本节的代码可以在 github 中下载源码：https://github.com/lexburner/spring-security-ipLogin 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/categories/Spring-Security/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/tags/Spring-Security/"}]},{"title":"Spring Security(四)-- 核心过滤器源码分析","slug":"spring-security-4","date":"2017-09-30T15:25:34.000Z","updated":"2019-09-26T09:45:30.785Z","comments":true,"path":"spring-security-4/","link":"","permalink":"http://lexburner.github.io/spring-security-4/","excerpt":"","text":"[TOC] 前面的部分，我们关注了 Spring Security 是如何完成认证工作的，但是另外一部分核心的内容：过滤器，一直没有提到，我们已经知道 Spring Security 使用了 springSecurityFillterChian 作为了安全过滤的入口，这一节主要分析一下这个过滤器链都包含了哪些关键的过滤器，并且各自的使命是什么。 4 过滤器详解4.1 核心过滤器概述由于过滤器链路中的过滤较多，即使是 Spring Security 的官方文档中也并未对所有的过滤器进行介绍，在之前，《Spring Security(二)–Guides》入门指南中我们配置了一个表单登录的 demo，以此为例，来看看这过程中 Spring Security 都帮我们自动配置了哪些过滤器。 123456789101112Creating filter chain: o.s.s.web.util.matcher.AnyRequestMatcher@1, [o.s.s.web.context.SecurityContextPersistenceFilter@8851ce1, o.s.s.web.header.HeaderWriterFilter@6a472566, o.s.s.web.csrf.CsrfFilter@61cd1c71, o.s.s.web.authentication.logout.LogoutFilter@5e1d03d7, o.s.s.web.authentication.UsernamePasswordAuthenticationFilter@122d6c22, o.s.s.web.savedrequest.RequestCacheAwareFilter@5ef6fd7f, o.s.s.web.servletapi.SecurityContextHolderAwareRequestFilter@4beaf6bd, o.s.s.web.authentication.AnonymousAuthenticationFilter@6edcad64, o.s.s.web.session.SessionManagementFilter@5e65afb6, o.s.s.web.access.ExceptionTranslationFilter@5b9396d3, o.s.s.web.access.intercept.FilterSecurityInterceptor@3c5dbdf8] 上述的 log 信息是我从 springboot 启动的日志中 CV 所得，spring security 的过滤器日志有一个特点：log 打印顺序与实际配置顺序符合，也就意味着 SecurityContextPersistenceFilter 是整个过滤器链的第一个过滤器，而 FilterSecurityInterceptor 则是末置的过滤器。另外通过观察过滤器的名称，和所在的包名，可以大致地分析出他们各自的作用，如 UsernamePasswordAuthenticationFilter 明显便是与使用用户名和密码登录相关的过滤器，而 FilterSecurityInterceptor 我们似乎看不出它的作用，但是其位于 web.access 包下，大致可以分析出他与访问限制相关。第四篇文章主要就是介绍这些常用的过滤器，对其中关键的过滤器进行一些源码分析。先大致介绍下每个过滤器的作用： SecurityContextPersistenceFilter 两个主要职责：请求来临时，创建 SecurityContext 安全上下文信息，请求结束时清空 SecurityContextHolder。 HeaderWriterFilter (文档中并未介绍，非核心过滤器) 用来给 http 响应添加一些 Header, 比如 X-Frame-Options, X-XSS-Protection*，X-Content-Type-Options. CsrfFilter 在 spring4 这个版本中被默认开启的一个过滤器，用于防止 csrf 攻击，了解前后端分离的人一定不会对这个攻击方式感到陌生，前后端使用 json 交互需要注意的一个问题。 LogoutFilter 顾名思义，处理注销的过滤器 UsernamePasswordAuthenticationFilter 这个会重点分析，表单提交了 username 和 password，被封装成 token 进行一系列的认证，便是主要通过这个过滤器完成的，在表单认证的方法中，这是最最关键的过滤器。 RequestCacheAwareFilter (文档中并未介绍，非核心过滤器) 内部维护了一个 RequestCache，用于缓存 request 请求 SecurityContextHolderAwareRequestFilter 此过滤器对 ServletRequest 进行了一次包装，使得 request 具有更加丰富的 API AnonymousAuthenticationFilter 匿名身份过滤器，这个过滤器个人认为很重要，需要将它与 UsernamePasswordAuthenticationFilter 放在一起比较理解，spring security 为了兼容未登录的访问，也走了一套认证流程，只不过是一个匿名的身份。 SessionManagementFilter 和 session 相关的过滤器，内部维护了一个 SessionAuthenticationStrategy，两者组合使用，常用来防止 session-fixation protection attack，以及限制同一用户开启多个会话的数量 ExceptionTranslationFilter 直译成异常翻译过滤器，还是比较形象的，这个过滤器本身不处理异常，而是将认证过程中出现的异常交给内部维护的一些类去处理，具体是那些类下面详细介绍 FilterSecurityInterceptor 这个过滤器决定了访问特定路径应该具备的权限，访问的用户的角色，权限是什么？访问的路径需要什么样的角色和权限？这些判断和处理都是由该类进行的。 其中加粗的过滤器可以被认为是 Spring Security 的核心过滤器，将在下面，一个过滤器对应一个小节来讲解。 4.2 SecurityContextPersistenceFilter试想一下，如果我们不使用 Spring Security，如果保存用户信息呢，大多数情况下会考虑使用 Session 对吧？在 Spring Security 中也是如此，用户在登录过一次之后，后续的访问便是通过 sessionId 来识别，从而认为用户已经被认证。具体在何处存放用户信息，便是第一篇文章中提到的 SecurityContextHolder；认证相关的信息是如何被存放到其中的，便是通过 SecurityContextPersistenceFilter。在 4.1 概述中也提到了，SecurityContextPersistenceFilter 的两个主要作用便是请求来临时，创建 SecurityContext 安全上下文信息和请求结束时清空 SecurityContextHolder。顺带提一下：微服务的一个设计理念需要实现服务通信的无状态，而 http 协议中的无状态意味着不允许存在 session，这可以通过 setAllowSessionCreation(false) 实现，这并不意味着 SecurityContextPersistenceFilter 变得无用，因为它还需要负责清除用户信息。在 Spring Security 中，虽然安全上下文信息被存储于 Session 中，但我们在实际使用中不应该直接操作 Session，而应当使用 SecurityContextHolder。 源码分析org.springframework.security.web.context.SecurityContextPersistenceFilter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class SecurityContextPersistenceFilter extends GenericFilterBean &#123; static final String FILTER_APPLIED = \"__spring_security_scpf_applied\"; // 安全上下文存储的仓库 private SecurityContextRepository repo; public SecurityContextPersistenceFilter() &#123; //HttpSessionSecurityContextRepository 是 SecurityContextRepository 接口的一个实现类 // 使用 HttpSession 来存储 SecurityContext this(new HttpSessionSecurityContextRepository()); &#125; public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; if (request.getAttribute(FILTER_APPLIED) != null) &#123; // ensure that filter is only applied once per request chain.doFilter(request, response); return; &#125; request.setAttribute(FILTER_APPLIED, Boolean.TRUE); // 包装 request，response HttpRequestResponseHolder holder = new HttpRequestResponseHolder(request, response); // 从 Session 中获取安全上下文信息 SecurityContext contextBeforeChainExecution = repo.loadContext(holder); try &#123; // 请求开始时，设置安全上下文信息，这样就避免了用户直接从 Session 中获取安全上下文信息 SecurityContextHolder.setContext(contextBeforeChainExecution); chain.doFilter(holder.getRequest(), holder.getResponse()); &#125; finally &#123; // 请求结束后，清空安全上下文信息 SecurityContext contextAfterChainExecution = SecurityContextHolder .getContext(); SecurityContextHolder.clearContext(); repo.saveContext(contextAfterChainExecution, holder.getRequest(), holder.getResponse()); request.removeAttribute(FILTER_APPLIED); if (debug) &#123; logger.debug(\"SecurityContextHolder now cleared, as request processing completed\"); &#125; &#125; &#125;&#125; 过滤器一般负责核心的处理流程，而具体的业务实现，通常交给其中聚合的其他实体类，这在 Filter 的设计中很常见，同时也符合职责分离模式。例如存储安全上下文和读取安全上下文的工作完全委托给了 HttpSessionSecurityContextRepository 去处理，而这个类中也有几个方法可以稍微解读下，方便我们理解内部的工作流程 org.springframework.security.web.context.HttpSessionSecurityContextRepository 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class HttpSessionSecurityContextRepository implements SecurityContextRepository &#123; // 'SPRING_SECURITY_CONTEXT' 是安全上下文默认存储在 Session 中的键值 public static final String SPRING_SECURITY_CONTEXT_KEY = \"SPRING_SECURITY_CONTEXT\"; ... private final Object contextObject = SecurityContextHolder.createEmptyContext(); private boolean allowSessionCreation = true; private boolean disableUrlRewriting = false; private String springSecurityContextKey = SPRING_SECURITY_CONTEXT_KEY; private AuthenticationTrustResolver trustResolver = new AuthenticationTrustResolverImpl(); // 从当前 request 中取出安全上下文，如果 session 为空，则会返回一个新的安全上下文 public SecurityContext loadContext(HttpRequestResponseHolder requestResponseHolder) &#123; HttpServletRequest request = requestResponseHolder.getRequest(); HttpServletResponse response = requestResponseHolder.getResponse(); HttpSession httpSession = request.getSession(false); SecurityContext context = readSecurityContextFromSession(httpSession); if (context == null) &#123; context = generateNewContext(); &#125; ... return context; &#125; ... public boolean containsContext(HttpServletRequest request) &#123; HttpSession session = request.getSession(false); if (session == null) &#123; return false; &#125; return session.getAttribute(springSecurityContextKey) != null; &#125; private SecurityContext readSecurityContextFromSession(HttpSession httpSession) &#123; if (httpSession == null) &#123; return null; &#125; ... // Session 存在的情况下，尝试获取其中的 SecurityContext Object contextFromSession = httpSession.getAttribute(springSecurityContextKey); if (contextFromSession == null) &#123; return null; &#125; ... return (SecurityContext) contextFromSession; &#125; // 初次请求时创建一个新的 SecurityContext 实例 protected SecurityContext generateNewContext() &#123; return SecurityContextHolder.createEmptyContext(); &#125;&#125; SecurityContextPersistenceFilter 和 HttpSessionSecurityContextRepository 配合使用，构成了 Spring Security 整个调用链路的入口，为什么将它放在最开始的地方也是显而易见的，后续的过滤器中大概率会依赖 Session 信息和安全上下文信息。 4.3 UsernamePasswordAuthenticationFilter表单认证是最常用的一个认证方式，一个最直观的业务场景便是允许用户在表单中输入用户名和密码进行登录，而这背后的 UsernamePasswordAuthenticationFilter，在整个 Spring Security 的认证体系中则扮演着至关重要的角色。 上述的时序图，可以看出 UsernamePasswordAuthenticationFilter 主要肩负起了调用身份认证器，校验身份的作用，至于认证的细节，在前面几章花了很大篇幅进行了介绍，到这里，其实 Spring Security 的基本流程就已经走通了。 源码分析org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter#attemptAuthentication 123456789101112131415public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; // 获取表单中的用户名和密码 String username = obtainUsername(request); String password = obtainPassword(request); ... username = username.trim(); // 组装成 username+password 形式的 token UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); // Allow subclasses to set the \"details\" property setDetails(request, authRequest); // 交给内部的 AuthenticationManager 去认证，并返回认证信息 return this.getAuthenticationManager().authenticate(authRequest);&#125; UsernamePasswordAuthenticationFilter 本身的代码只包含了上述这么一个方法，非常简略，而在其父类 AbstractAuthenticationProcessingFilter 中包含了大量的细节，值得我们分析： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class AbstractAuthenticationProcessingFilter extends GenericFilterBean implements ApplicationEventPublisherAware, MessageSourceAware &#123; // 包含了一个身份认证器 private AuthenticationManager authenticationManager; // 用于实现 remeberMe private RememberMeServices rememberMeServices = new NullRememberMeServices(); private RequestMatcher requiresAuthenticationRequestMatcher; // 这两个 Handler 很关键，分别代表了认证成功和失败相应的处理器 private AuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler(); private AuthenticationFailureHandler failureHandler = new SimpleUrlAuthenticationFailureHandler(); public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; ... Authentication authResult; try &#123; // 此处实际上就是调用 UsernamePasswordAuthenticationFilter 的 attemptAuthentication 方法 authResult = attemptAuthentication(request, response); if (authResult == null) &#123; // 子类未完成认证，立刻返回 return; &#125; sessionStrategy.onAuthentication(authResult, request, response); &#125; // 在认证过程中可以直接抛出异常，在过滤器中，就像此处一样，进行捕获 catch (InternalAuthenticationServiceException failed) &#123; // 内部服务异常 unsuccessfulAuthentication(request, response, failed); return; &#125; catch (AuthenticationException failed) &#123; // 认证失败 unsuccessfulAuthentication(request, response, failed); return; &#125; // 认证成功 if (continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; // 注意，认证成功后过滤器把 authResult 结果也传递给了成功处理器 successfulAuthentication(request, response, chain, authResult); &#125; &#125; 整个流程理解起来也并不难，主要就是内部调用了 authenticationManager 完成认证，根据认证结果执行 successfulAuthentication 或者 unsuccessfulAuthentication，无论成功失败，一般的实现都是转发或者重定向等处理，不再细究 AuthenticationSuccessHandler 和 AuthenticationFailureHandler，有兴趣的朋友，可以去看看两者的实现类。 4.4 AnonymousAuthenticationFilter匿名认证过滤器，可能有人会想：匿名了还有身份？我自己对于 Anonymous 匿名身份的理解是 Spirng Security 为了整体逻辑的统一性，即使是未通过认证的用户，也给予了一个匿名身份。而 AnonymousAuthenticationFilter 该过滤器的位置也是非常的科学的，它位于常用的身份认证过滤器（如 UsernamePasswordAuthenticationFilter、BasicAuthenticationFilter、RememberMeAuthenticationFilter）之后，意味着只有在上述身份过滤器执行完毕后，SecurityContext 依旧没有用户信息，AnonymousAuthenticationFilter 该过滤器才会有意义 —- 基于用户一个匿名身份。 源码分析org.springframework.security.web.authentication.AnonymousAuthenticationFilter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class AnonymousAuthenticationFilter extends GenericFilterBean implements InitializingBean &#123; private AuthenticationDetailsSource&lt;HttpServletRequest, ?&gt; authenticationDetailsSource = new WebAuthenticationDetailsSource(); private String key; private Object principal; private List&lt;GrantedAuthority&gt; authorities; // 自动创建一个 \"anonymousUser\" 的匿名用户, 其具有 ANONYMOUS 角色 public AnonymousAuthenticationFilter(String key) &#123; this(key, \"anonymousUser\", AuthorityUtils.createAuthorityList(\"ROLE_ANONYMOUS\")); &#125; /** * * @param key key 用来识别该过滤器创建的身份 * @param principal principal 代表匿名用户的身份 * @param authorities authorities 代表匿名用户的权限集合 */ public AnonymousAuthenticationFilter(String key, Object principal, List&lt;GrantedAuthority&gt; authorities) &#123; Assert.hasLength(key, \"key cannot be null or empty\"); Assert.notNull(principal, \"Anonymous authentication principal must be set\"); Assert.notNull(authorities, \"Anonymous authorities must be set\"); this.key = key; this.principal = principal; this.authorities = authorities; &#125; ... public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; // 过滤器链都执行到匿名认证过滤器这儿了还没有身份信息，塞一个匿名身份进去 if (SecurityContextHolder.getContext().getAuthentication()== null) &#123; SecurityContextHolder.getContext().setAuthentication( createAuthentication((HttpServletRequest) req)); &#125; chain.doFilter(req, res); &#125; protected Authentication createAuthentication(HttpServletRequest request) &#123; // 创建一个 AnonymousAuthenticationToken AnonymousAuthenticationToken auth = new AnonymousAuthenticationToken(key, principal, authorities); auth.setDetails(authenticationDetailsSource.buildDetails(request)); return auth; &#125; ...&#125; 其实对比 AnonymousAuthenticationFilter 和 UsernamePasswordAuthenticationFilter 就可以发现一些门道了，UsernamePasswordAuthenticationToken 对应 AnonymousAuthenticationToken，他们都是 Authentication 的实现类，而 Authentication 则是被 SecurityContextHolder(SecurityContext) 持有的，一切都被串联在了一起。 4.5 ExceptionTranslationFilterExceptionTranslationFilter 异常转换过滤器位于整个 springSecurityFilterChain 的后方，用来转换整个链路中出现的异常，将其转化，顾名思义，转化以意味本身并不处理。一般其只处理两大类异常：AccessDeniedException 访问异常和 AuthenticationException 认证异常。 这个过滤器非常重要，因为它将 Java 中的异常和 HTTP 的响应连接在了一起，这样在处理异常时，我们不用考虑密码错误该跳到什么页面，账号锁定该如何，只需要关注自己的业务逻辑，抛出相应的异常便可。如果该过滤器检测到 AuthenticationException，则将会交给内部的 AuthenticationEntryPoint 去处理，如果检测到 AccessDeniedException，需要先判断当前用户是不是匿名用户，如果是匿名访问，则和前面一样运行 AuthenticationEntryPoint，否则会委托给 AccessDeniedHandler 去处理，而 AccessDeniedHandler 的默认实现，是 AccessDeniedHandlerImpl。所以 ExceptionTranslationFilter 内部的 AuthenticationEntryPoint 是至关重要的，顾名思义：认证的入口点。 源码分析1234567891011121314151617181920212223242526272829public class ExceptionTranslationFilter extends GenericFilterBean &#123; // 处理异常转换的核心方法 private void handleSpringSecurityException(HttpServletRequest request, HttpServletResponse response, FilterChain chain, RuntimeException exception) throws IOException, ServletException &#123; if (exception instanceof AuthenticationException) &#123; // 重定向到登录端点 sendStartAuthentication(request, response, chain, (AuthenticationException) exception); &#125; else if (exception instanceof AccessDeniedException) &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authenticationTrustResolver.isAnonymous(authentication) || authenticationTrustResolver.isRememberMe(authentication)) &#123; // 重定向到登录端点 sendStartAuthentication( request, response, chain, new InsufficientAuthenticationException( \"Full authentication is required to access this resource\")); &#125; else &#123; // 交给 accessDeniedHandler 处理 accessDeniedHandler.handle(request, response, (AccessDeniedException) exception); &#125; &#125; &#125;&#125; 剩下的便是要搞懂 AuthenticationEntryPoint 和 AccessDeniedHandler 就可以了。 选择了几个常用的登录端点，以其中第一个为例来介绍，看名字就能猜到是认证失败之后，让用户跳转到登录页面。还记得我们一开始怎么配置表单登录页面的吗？ 12345678910111213141516171819@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/\", \"/home\").permitAll() .anyRequest().authenticated() .and() .formLogin()//FormLoginConfigurer .loginPage(\"/login\") .permitAll() .and() .logout() .permitAll(); &#125;&#125; 我们顺着 formLogin 返回的 FormLoginConfigurer 往下找，看看能发现什么，最终在 FormLoginConfigurer 的父类 AbstractAuthenticationFilterConfigurer 中有了不小的收获： 12345678public abstract class AbstractAuthenticationFilterConfigurer extends ...&#123; ... //formLogin 不出所料配置了 AuthenticationEntryPoint private LoginUrlAuthenticationEntryPoint authenticationEntryPoint; // 认证失败的处理器 private AuthenticationFailureHandler failureHandler; ...&#125; 具体如何配置的就不看了，我们得出了结论，formLogin() 配置了之后最起码做了两件事，其一，为 UsernamePasswordAuthenticationFilter 设置了相关的配置，其二配置了 AuthenticationEntryPoint。 登录端点还有 Http401AuthenticationEntryPoint，Http403ForbiddenEntryPoint 这些都是很简单的实现，有时候我们访问受限页面，又没有配置登录，就看到了一个空荡荡的默认错误页面，上面显示着 401,403，就是这两个入口起了作用。 还剩下一个 AccessDeniedHandler 访问决策器未被讲解，简单提一下：AccessDeniedHandlerImpl 这个默认实现类会根据 errorPage 和状态码来判断，最终决定跳转的页面 org.springframework.security.web.access.AccessDeniedHandlerImpl#handle 1234567891011121314151617181920public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException &#123; if (!response.isCommitted()) &#123; if (errorPage != null) &#123; // Put exception into request scope (perhaps of use to a view) request.setAttribute(WebAttributes.ACCESS_DENIED_403, accessDeniedException); // Set the 403 status code. response.setStatus(HttpServletResponse.SC_FORBIDDEN); // forward to error page. RequestDispatcher dispatcher = request.getRequestDispatcher(errorPage); dispatcher.forward(request, response); &#125; else &#123; response.sendError(HttpServletResponse.SC_FORBIDDEN, accessDeniedException.getMessage()); &#125; &#125;&#125; 4.6 FilterSecurityInterceptor想想整个认证安全控制流程还缺了什么？我们已经有了认证，有了请求的封装，有了 Session 的关联… 还缺一个：由什么控制哪些资源是受限的，这些受限的资源需要什么权限，需要什么角色… 这一切和访问控制相关的操作，都是由 FilterSecurityInterceptor 完成的。 FilterSecurityInterceptor 的工作流程用笔者的理解可以理解如下：FilterSecurityInterceptor 从 SecurityContextHolder 中获取 Authentication 对象，然后比对用户拥有的权限和资源所需的权限。前者可以通过 Authentication 对象直接获得，而后者则需要引入我们之前一直未提到过的两个类：SecurityMetadataSource，AccessDecisionManager。理解清楚决策管理器的整个创建流程和 SecurityMetadataSource 的作用需要花很大一笔功夫，这里，暂时只介绍其大概的作用。 在 JavaConfig 的配置中，我们通常如下配置路径的访问控制： 12345678910111213141516@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/resources/**\", \"/signup\", \"/about\").permitAll() .antMatchers(\"/admin/**\").hasRole(\"ADMIN\") .antMatchers(\"/db/**\").access(\"hasRole('ADMIN') and hasRole('DBA')\") .anyRequest().authenticated() .withObjectPostProcessor(new ObjectPostProcessor&lt;FilterSecurityInterceptor&gt;() &#123; public &lt;O extends FilterSecurityInterceptor&gt; O postProcess( O fsi) &#123; fsi.setPublishAuthorizationSuccess(true); return fsi; &#125; &#125;);&#125; 在 ObjectPostProcessor 的泛型中看到了 FilterSecurityInterceptor，以笔者的经验，目前并没有太多机会需要修改 FilterSecurityInterceptor 的配置。 总结本篇文章在介绍过滤器时，顺便进行了一些源码的分析，目的是方便理解整个 Spring Security 的工作流。伴随着整个过滤器链的介绍，安全框架的轮廓应该已经浮出水面了，下面的章节，主要打算通过自定义一些需求，再次分析其他组件的源码，学习应该如何改造 Spring Security，为我们所用。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/categories/Spring-Security/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/tags/Spring-Security/"}]},{"title":"警惕不规范的变量命名","slug":"project-rules-2","date":"2017-09-23T05:45:56.000Z","updated":"2019-09-26T09:45:31.528Z","comments":true,"path":"project-rules-2/","link":"","permalink":"http://lexburner.github.io/project-rules-2/","excerpt":"","text":"就在最近，项目组开始强调开发规范了，今天分享一个变量名命名不规范的小案例，强调一下规范的重要性。例子虽小，但却比较有启发意义。 Boolean 变量名命名规范16 年底，阿里公开了《Java 开发规范手册》，其中有一条便是“布尔类型不能以 is 为前缀”。规范中没有举出例子，但是给出了原因：会导致部分序列化框架的无法解析。 看看错误的示范，会导致什么问题，以 Spring 中的 jdbcTemplate 来进行实验。 定义实体类1234567891011121314151617181920@Entitypublic class Bar &#123; @Id @GeneratedValue private Integer id; private Boolean isSuccess;// 注意这是错误的命名 private boolean isSend;// 注意这是错误的命名 public Boolean getSuccess() &#123; return isSuccess; &#125; public void setSuccess(Boolean success) &#123; isSuccess = success; &#125; public boolean isSend() &#123; return isSend; &#125; public void setSend(boolean send) &#123; isSend = send; &#125;&#125; 其中，isSuccess 使用的是包装类型 Boolean，而 isSend 使用的是原生类型 boolean，而 getter，setter 方法是使用 Intellij IDEA 自动生成的，布尔类型生成 getter，setter 方法时略微特殊，比如原生类型的 getter 方式是以 is 开头的，他们略微有点区别，注意区分。生成 getter，setter 方法之后，其实已经有点奇怪了，不急，继续下面的实验。 在数据库中，isSuccess 被映射了 is_success，isSend 被映射成了 is_send，这符合我们的预期。并且为了后续的实验，我们事先准备一条记录，用于后续的查询，在 mysql 的方言中，布尔类型被默认自动映射成 byte，1 代表 ture，0 代表 false。 id is_success is_send 1 1 1 使用 JdbcTemplate 查询12345public void test(String id) &#123; RowMapper&lt;Bar&gt; barRowMapper = new BeanPropertyRowMapper&lt;Bar&gt;(Bar.class); Bar bar = jdbcTemplate.queryForObject(\"select * from bar where id = ?\", new Object[]&#123;id&#125;, barRowMapper); System.out.println(bar);&#125; JdbcTemplate 提供了 BeanPropertyRowMapper 完成数据库到实体类的映射，事先我重写了 Bar 类的 toString 方法，调用 test(1) 看看是否能成功映射。结果如下： 1Bar&#123;id=1, isSuccess=null, isSend=false&#125; 数据库中是实际存在这样的字段，并且值都是 true，而使用 JdbcTemplate，却查询不到这样的问题，这边是不遵循规范导致的问题。 相信这个例子可以让大家更加加深映像，特别是在维护老旧代码时，如果发现有 is 开头的 boolean 值，需要额外地注意。 包装类型与原生类型在回顾一下上述的 demo，原生类型和包装类型都没有封装成功，isSuccess 得到了一个 null 值，isSend 得到了一个 false 值。后者足够引起我们的警惕，如果说前者会引起一个 NullPointerExcepiton 导致程序异常，还可以引起开发者的注意，而后者很有可能一直作为一个隐藏的 bug，不被人所察觉，因为 boolean 的默认值为 false。 在类变量中，也普遍提倡使用包装类型，而原生类型的不足之处是很明显的。以 Integer num; 字段为例，num=null 代表的含义是 num 字段未被保存，未定义；而 num=0 代表的含义是明确的，数量为 0。原生类型的表达能力有限。所以提倡在局部作用域的计算中使用原生类型，而在类变量中使用包装类型。 JavaBean 规范如今的微服务的时代，都是在聊架构，聊容器编排，竟然还有人聊 JavaBean，但既然说到了规范，顺带提下。 先来做个选择题，以下选项中符合 JavaBean 命名规范的有哪些？： 1234A : ebookB : eBookC : EbookD : EBook . . . . 正确答案是：A,D 怎么样，符合你的预想吗？JavaBean 规范并不是像很多人想的那样，首字母小写，之后的每一个单词首字母大写这样的驼峰命名法。正确的命名规范应该是：要么前两个字母都是小写，要么前两个字母都是大写。因为英文单词中有 URL，USA 这样固定形式的大写词汇，所以才有了这样的规范。特别警惕 B 那种形式，一些诸如 sNo，eBook,eMail,cId 这样的命名，都是不规范的。 由此引申出了 getter，setter 命名的规范，除了第一节中 Boolean 类型的特例之外，网上还有不上文章，强调了这样的概念：eBook 对应的 getter，setter 应当为 geteBook(),seteBook()，即当类变量的首字母是小写，而第二个字母是大写时，生成的 getter，setter 应当是（get/set）+ 类变量名。但上面已经介绍过了，eBook 这样的变量命名本身就是不规范的，在不规范的变量命名下强调规范的 getter，setter 命名，出发点就错了。有兴趣的朋友可以在 eclipse，intellij idea 中试试，这几种规范，不规范的变量命名，各自对应的 getter，setter 方法是如何的。另外需要知晓一点，IDE 提供的自动生成 getter，setter 的机制，以及 lombok 这类框架的机制，都是由默认的设置，在与其他反射框架配合使用时，只有双方都遵循规范，才能够配合使用，而不能笃信框架。这一点上，有部分国产的框架做的并不是很好。 最后说一个和 JavaBean 相关的取值规范，在 jsp 的 c 标签，freemarker 一类的模板语法，以及一些 el 表达式中，${student.name} 并不是取的 student 的 name 字段，而是调用了 student 的 getName 方法，这也应当被注意，student.name 如何找到对应的 getter 方法，需要解决上一段中提到的同样的问题，建议不确定的地方多测试，尽量采取稳妥的写法。 可能有人会觉得这样的介绍类似于“茴”字有几种写法，但笔者认为恰恰是这些小的规范，容易被人忽视，才更加需要被注意。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"},{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"}]},{"title":"Spring Security(二)--Guides","slug":"spring-security-2","date":"2017-09-20T15:25:34.000Z","updated":"2019-09-26T09:45:31.113Z","comments":true,"path":"spring-security-2/","link":"","permalink":"http://lexburner.github.io/spring-security-2/","excerpt":"上一篇文章《Spring Security(一)–Architecture Overview》，我们介绍了 Spring Security 的基础架构，这一节我们通过 Spring 官方给出的一个 guides 例子，来了解 Spring Security 是如何保护我们的应用的，之后会对进行一个解读。 [TOC] 2 Spring Security Guides2.1 引入依赖1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 由于我们集成了 springboot，所以不需要显示的引入 Spring Security 文档中描述 core，config 依赖，只需要引入 spring-boot-starter-security 即可。","text":"上一篇文章《Spring Security(一)–Architecture Overview》，我们介绍了 Spring Security 的基础架构，这一节我们通过 Spring 官方给出的一个 guides 例子，来了解 Spring Security 是如何保护我们的应用的，之后会对进行一个解读。 [TOC] 2 Spring Security Guides2.1 引入依赖1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 由于我们集成了 springboot，所以不需要显示的引入 Spring Security 文档中描述 core，config 依赖，只需要引入 spring-boot-starter-security 即可。 2.2 创建一个不受安全限制的 web 应用这是一个首页，不受安全限制 src/main/resources/templates/home.html 1234567891011&lt;!DOCTYPE html&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\"&gt; &lt;head&gt; &lt;title&gt;Spring Security Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Welcome!&lt;/h1&gt; &lt;p&gt;Click &lt;a th:href=\"@&#123;/hello&#125;\"&gt;here&lt;/a&gt; to see a greeting.&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 这个简单的页面上包含了一个链接，跳转到 “/hello”。对应如下的页面 src/main/resources/templates/hello.html 12345678910&lt;!DOCTYPE html&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\"&gt; &lt;head&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Hello world!&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 接下来配置 Spring MVC，使得我们能够访问到页面。 123456789101112@Configurationpublic class MvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/home\").setViewName(\"home\"); registry.addViewController(\"/\").setViewName(\"home\"); registry.addViewController(\"/hello\").setViewName(\"hello\"); registry.addViewController(\"/login\").setViewName(\"login\"); &#125;&#125; 2.3 配置 Spring Security一个典型的安全配置如下所示： 12345678910111213141516171819202122232425@Configuration@EnableWebSecurity &lt;1&gt;public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; &lt;1&gt; @Override protected void configure(HttpSecurity http) throws Exception &#123; http &lt;2&gt; .authorizeRequests() .antMatchers(\"/\", \"/home\").permitAll() .anyRequest().authenticated() .and() .formLogin() .loginPage(\"/login\") .permitAll() .and() .logout() .permitAll(); &#125; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth &lt;3&gt; .inMemoryAuthentication() .withUser(\"admin\").password(\"admin\").roles(\"USER\"); &#125;&#125; @EnableWebSecurity 注解使得 SpringMVC 集成了 Spring Security 的 web 安全支持。另外，WebSecurityConfig 配置类同时集成了 WebSecurityConfigurerAdapter，重写了其中的特定方法，用于自定义 Spring Security 配置。整个 Spring Security 的工作量，其实都是集中在该配置类，不仅仅是这个 guides，实际项目中也是如此。 configure(HttpSecurity) 定义了哪些 URL 路径应该被拦截，如字面意思所描述：”/“, “/home” 允许所有人访问，”/login” 作为登录入口，也被允许访问，而剩下的 “/hello” 则需要登陆后才可以访问。 configureGlobal(AuthenticationManagerBuilder) 在内存中配置一个用户，admin/admin 分别是用户名和密码，这个用户拥有 USER 角色。 我们目前还没有登录页面，下面创建登录页面： 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\"&gt; &lt;head&gt; &lt;title&gt;Spring Security Example &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div th:if=\"$&#123;param.error&#125;\"&gt; Invalid username and password. &lt;/div&gt; &lt;div th:if=\"$&#123;param.logout&#125;\"&gt; You have been logged out. &lt;/div&gt; &lt;form th:action=\"@&#123;/login&#125;\" method=\"post\"&gt; &lt;div&gt;&lt;label&gt; User Name : &lt;input type=\"text\" name=\"username\"/&gt; &lt;/label&gt;&lt;/div&gt; &lt;div&gt;&lt;label&gt; Password: &lt;input type=\"password\" name=\"password\"/&gt; &lt;/label&gt;&lt;/div&gt; &lt;div&gt;&lt;input type=\"submit\" value=\"Sign In\"/&gt;&lt;/div&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 这个 Thymeleaf 模板提供了一个用于提交用户名和密码的表单, 其中 name=”username”，name=”password” 是默认的表单值，并发送到“/ login”。 在默认配置中，Spring Security 提供了一个拦截该请求并验证用户的过滤器。 如果验证失败，该页面将重定向到“/ login?error”，并显示相应的错误消息。 当用户选择注销，请求会被发送到“/ login?logout”。 最后，我们为 hello.html 添加一些内容，用于展示用户信息。 12345678910111213&lt;!DOCTYPE html&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:sec=\"http://www.thymeleaf.org/thymeleaf-extras-springsecurity3\"&gt; &lt;head&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 th:inline=\"text\"&gt;Hello [[$&#123;#httpServletRequest.remoteUser&#125;]]!&lt;/h1&gt; &lt;form th:action=\"@&#123;/logout&#125;\" method=\"post\"&gt; &lt;input type=\"submit\" value=\"Sign Out\"/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 我们使用 Spring Security 之后，HttpServletRequest#getRemoteUser() 可以用来获取用户名。 登出请求将被发送到“/ logout”。 成功注销后，会将用户重定向到“/ login?logout”。 2.4 添加启动类12345678@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) throws Throwable &#123; SpringApplication.run(Application.class, args); &#125;&#125; 2.5 测试访问首页 http://localhost:8080/: 点击 here，尝试访问受限的页面：/hello, 由于未登录，结果被强制跳转到登录也 /login： 输入正确的用户名和密码之后，跳转到之前想要访问的 /hello: 点击 Sign out 退出按钮，访问:/logout, 回到登录页面: 2.6 总结本篇文章没有什么干货，基本算是翻译了 Spring Security Guides 的内容，稍微了解 Spring Security 的朋友都不会对这个翻译感到陌生。考虑到受众的问题，一个入门的例子是必须得有的，方便后续对 Spring Security 的自定义配置进行讲解。下一节，以此 guides 为例，讲解这些最简化的配置背后，Spring Security 都帮我们做了什么工作。 本节所有的代码，可以直接在 Spring 的官方仓库下载得到，git clone https://github.com/spring-guides/gs-securing-web.git。不过，建议初学者根据文章先一步步配置，出了问题，再与 demo 进行对比。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/categories/Spring-Security/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/tags/Spring-Security/"}]},{"title":"Spring Security(三)-- 核心配置解读","slug":"spring-security-3","date":"2017-09-20T15:25:34.000Z","updated":"2019-09-26T09:45:31.037Z","comments":true,"path":"spring-security-3/","link":"","permalink":"http://lexburner.github.io/spring-security-3/","excerpt":"","text":"上一篇文章《Spring Security(二)–Guides》，通过 Spring Security 的配置项了解了 Spring Security 是如何保护我们的应用的，本篇文章对上一次的配置做一个分析。 [TOC] 3 核心配置解读3.1 功能介绍这是 Spring Security 入门指南中的配置项： 1234567891011121314151617181920212223242526@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/\", \"/home\").permitAll() .anyRequest().authenticated() .and() .formLogin() .loginPage(\"/login\") .permitAll() .and() .logout() .permitAll(); &#125; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser(\"admin\").password(\"admin\").roles(\"USER\"); &#125;&#125; 当配置了上述的 javaconfig 之后，我们的应用便具备了如下的功能： 除了“/”,”/home”(首页),”/login”(登录),”/logout”(注销), 之外，其他路径都需要认证。 指定“/login”该路径为登录页面，当未认证的用户尝试访问任何受保护的资源时，都会跳转到“/login”。 默认指定“/logout”为注销页面 配置一个内存中的用户认证器，使用 admin/admin 作为用户名和密码，具有 USER 角色 防止 CSRF 攻击 Session Fixation protection(可以参考我之前讲解 Spring Session 的文章，防止别人篡改 sessionId) Security Header(添加一系列和 Header 相关的控制) HTTP Strict Transport Security for secure requests 集成 X-Content-Type-Options 缓存控制 集成 X-XSS-Protection.aspx) X-Frame-Options integration to help prevent Clickjacking(iframe 被默认禁止使用) 为 Servlet API 集成了如下的几个方法 HttpServletRequest#getRemoteUser()) HttpServletRequest.html#getUserPrincipal()) HttpServletRequest.html#isUserInRole(java.lang.String)) HttpServletRequest.html#login(java.lang.String, java.lang.String)) HttpServletRequest.html#logout()) 3.2 @EnableWebSecurity我们自己定义的配置类 WebSecurityConfig 加上了 @EnableWebSecurity 注解，同时继承了 WebSecurityConfigurerAdapter。你可能会在想谁的作用大一点，毫无疑问 @EnableWebSecurity 起到决定性的配置作用，它其实是个组合注解。 1234567@Import(&#123; WebSecurityConfiguration.class, // &lt;2&gt; SpringWebMvcImportSelector.class &#125;) // &lt;1&gt;@EnableGlobalAuthentication // &lt;3&gt;@Configurationpublic @interface EnableWebSecurity &#123; boolean debug() default false;&#125; @Import 是 springboot 提供的用于引入外部的配置的注解，可以理解为：@EnableWebSecurity 注解激活了 @Import 注解中包含的配置类。 SpringWebMvcImportSelector 的作用是判断当前的环境是否包含 springmvc，因为 spring security 可以在非 spring 环境下使用，为了避免 DispatcherServlet 的重复配置，所以使用了这个注解来区分。 WebSecurityConfiguration 顾名思义，是用来配置 web 安全的，下面的小节会详细介绍。 @EnableGlobalAuthentication 注解的源码如下： 1234@Import(AuthenticationConfiguration.class)@Configurationpublic @interface EnableGlobalAuthentication &#123;&#125; 注意点同样在 @Import 之中，它实际上激活了 AuthenticationConfiguration 这样的一个配置类，用来配置认证相关的核心类。 也就是说：@EnableWebSecurity 完成的工作便是加载了 WebSecurityConfiguration，AuthenticationConfiguration 这两个核心配置类，也就此将 spring security 的职责划分为了配置安全信息，配置认证信息两部分。 WebSecurityConfiguration在这个配置类中，有一个非常重要的 Bean 被注册了。 12345678910@Configurationpublic class WebSecurityConfiguration &#123; //DEFAULT_FILTER_NAME = \"springSecurityFilterChain\" @Bean(name = AbstractSecurityWebApplicationInitializer.DEFAULT_FILTER_NAME) public Filter springSecurityFilterChain() throws Exception &#123; ... &#125; &#125; 在未使用 springboot 之前，大多数人都应该对“springSecurityFilterChain”这个名词不会陌生，他是 spring security 的核心过滤器，是整个认证的入口。在曾经的 XML 配置中，想要启用 spring security，需要在 web.xml 中进行如下配置： 12345678910&lt;!-- Spring Security --&gt; &lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 而在 springboot 集成之后，这样的 XML 被 java 配置取代。WebSecurityConfiguration 中完成了声明 springSecurityFilterChain 的作用，并且最终交给 DelegatingFilterProxy 这个代理类，负责拦截请求（注意 DelegatingFilterProxy 这个类不是 spring security 包中的，而是存在于 web 包中，spring 使用了代理模式来实现安全过滤的解耦）。 AuthenticationConfiguration123456789101112131415@Configuration@Import(ObjectPostProcessorConfiguration.class)public class AuthenticationConfiguration &#123; @Bean public AuthenticationManagerBuilder authenticationManagerBuilder( ObjectPostProcessor&lt;Object&gt; objectPostProcessor) &#123; return new AuthenticationManagerBuilder(objectPostProcessor); &#125; public AuthenticationManager getAuthenticationManager() throws Exception &#123; ... &#125;&#125; AuthenticationConfiguration 的主要任务，便是负责生成全局的身份认证管理者 AuthenticationManager。还记得在《Spring Security(一)–Architecture Overview》中，介绍了 Spring Security 的认证体系，AuthenticationManager 便是最核心的身份认证管理器。 3.3 WebSecurityConfigurerAdapter适配器模式在 spring 中被广泛的使用，在配置中使用 Adapter 的好处便是，我们可以选择性的配置想要修改的那一部分配置，而不用覆盖其他不相关的配置。WebSecurityConfigurerAdapter 中我们可以选择自己想要修改的内容，来进行重写，而其提供了三个 configure 重载方法，是我们主要关心的： 由参数就可以知道，分别是对 AuthenticationManagerBuilder，WebSecurity，HttpSecurity 进行个性化的配置。 HttpSecurity 常用配置1234567891011121314151617181920212223242526272829@Configuration@EnableWebSecuritypublic class CustomWebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/resources/**\", \"/signup\", \"/about\").permitAll() .antMatchers(\"/admin/**\").hasRole(\"ADMIN\") .antMatchers(\"/db/**\").access(\"hasRole('ADMIN') and hasRole('DBA')\") .anyRequest().authenticated() .and() .formLogin() .usernameParameter(\"username\") .passwordParameter(\"password\") .failureForwardUrl(\"/login?error\") .loginPage(\"/login\") .permitAll() .and() .logout() .logoutUrl(\"/logout\") .logoutSuccessUrl(\"/index\") .permitAll() .and() .httpBasic() .disable(); &#125;&#125; 上述是一个使用 Java Configuration 配置 HttpSecurity 的典型配置，其中 http 作为根开始配置，每一个 and()对应了一个模块的配置（等同于 xml 配置中的结束标签），并且 and() 返回了 HttpSecurity 本身，于是可以连续进行配置。他们配置的含义也非常容易通过变量本身来推测， authorizeRequests() 配置路径拦截，表明路径访问所对应的权限，角色，认证信息。 formLogin() 对应表单认证相关的配置 logout() 对应了注销相关的配置 httpBasic() 可以配置 basic 登录 etc 他们分别代表了 http 请求相关的安全配置，这些配置项无一例外的返回了 Configurer 类，而所有的 http 相关配置可以通过查看 HttpSecurity 的主要方法得知： 需要对 http 协议有一定的了解才能完全掌握所有的配置，不过，springboot 和 spring security 的自动配置已经足够使用了。其中每一项 Configurer（e.g.FormLoginConfigurer,CsrfConfigurer）都是 HttpConfigurer 的细化配置项。 WebSecurityBuilder12345678910@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override public void configure(WebSecurity web) throws Exception &#123; web .ignoring() .antMatchers(\"/resources/**\"); &#125;&#125; 以笔者的经验，这个配置中并不会出现太多的配置信息。 AuthenticationManagerBuilder1234567891011@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser(\"admin\").password(\"admin\").roles(\"USER\"); &#125;&#125; 想要在 WebSecurityConfigurerAdapter 中进行认证相关的配置，可以使用 configure(AuthenticationManagerBuilder auth) 暴露一个 AuthenticationManager 的建造器：AuthenticationManagerBuilder 。如上所示，我们便完成了内存中用户的配置。 细心的朋友会发现，在前面的文章中我们配置内存中的用户时，似乎不是这么配置的，而是： 1234567891011@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser(\"admin\").password(\"admin\").roles(\"USER\"); &#125;&#125; 如果你的应用只有唯一一个 WebSecurityConfigurerAdapter，那么他们之间的差距可以被忽略，从方法名可以看出两者的区别：使用 @Autowired 注入的 AuthenticationManagerBuilder 是全局的身份认证器，作用域可以跨越多个 WebSecurityConfigurerAdapter，以及影响到基于 Method 的安全控制；而 protected configure() 的方式则类似于一个匿名内部类，它的作用域局限于一个 WebSecurityConfigurerAdapter 内部。关于这一点的区别，可以参考我曾经提出的 issuespring-security#issues4571。官方文档中，也给出了配置多个 WebSecurityConfigurerAdapter 的场景以及 demo，将在该系列的后续文章中解读。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/categories/Spring-Security/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/tags/Spring-Security/"}]},{"title":"Spring Security(一)--Architecture Overview","slug":"spring-security-1","date":"2017-09-19T12:12:55.000Z","updated":"2019-09-26T09:45:30.301Z","comments":true,"path":"spring-security-1/","link":"","permalink":"http://lexburner.github.io/spring-security-1/","excerpt":"一直以来我都想写一写 Spring Security 系列的文章，但是整个 Spring Security 体系强大却又繁杂。陆陆续续从最开始的 guides 接触它，到项目中看了一些源码，到最近这个月为了写一写这个系列的文章，阅读了好几遍文档，最终打算尝试一下，写一个较为完整的系列文章。 较为简单或者体量较小的技术，完全可以参考着 demo 直接上手，但系统的学习一门技术则不然。以我的认知，一般的文档大致有两种风格：Architecture First 和 Code First。前者致力于让读者先了解整体的架构，方便我们对自己的认知有一个宏观的把控，而后者以特定的 demo 配合讲解，可以让读者在解决问题的过程中顺便掌握一门技术。关注过我博客或者公众号的朋友会发现，我之前介绍技术的文章，大多数是 Code First，提出一个需求，介绍一个思路，解决一个问题，分析一下源码，大多如此。而学习一个体系的技术，我推荐 Architecture First，正如本文标题所言，这篇文章是我 Spring Security 系列的第一篇，主要是根据 Spring Security 文档选择性 ~~ 翻译 ~~ 整理而成的一个架构概览，配合自己的一些注释方便大家理解。写作本系列文章时，参考版本为 Spring Security 4.2.3.RELEASE。 [TOC] 1 核心组件这一节主要介绍一些在 Spring Security 中常见且核心的 Java 类，它们之间的依赖，构建起了整个框架。想要理解整个架构，最起码得对这些类眼熟。 1.1 SecurityContextHolderSecurityContextHolder 用于存储安全上下文（security context）的信息。当前操作的用户是谁，该用户是否已经被认证，他拥有哪些角色权限… 这些都被保存在 SecurityContextHolder 中。SecurityContextHolder 默认使用 ThreadLocal 策略来存储认证信息。看到 ThreadLocal 也就意味着，这是一种与线程绑定的策略。Spring Security 在用户登录时自动绑定认证信息到当前线程，在用户退出时，自动清除当前线程的认证信息。但这一切的前提，是你在 web 场景下使用 Spring Security，而如果是 Swing 界面，Spring 也提供了支持，SecurityContextHolder 的策略则需要被替换，鉴于我的初衷是基于 web 来介绍 Spring Security，所以这里以及后续，非 web 的相关的内容都一笔带过。 获取当前用户的信息因为身份信息是与线程绑定的，所以可以在程序的任何地方使用静态方法获取用户信息。一个典型的获取当前登录用户的姓名的例子如下所示： 1234567Object principal = SecurityContextHolder.getContext().getAuthentication().getPrincipal();if (principal instanceof UserDetails) &#123;String username = ((UserDetails)principal).getUsername();&#125; else &#123;String username = principal.toString();&#125; getAuthentication()返回了认证信息，再次 getPrincipal() 返回了身份信息，UserDetails 便是 Spring 对身份信息封装的一个接口。Authentication 和 UserDetails 的介绍在下面的小节具体讲解，本节重要的内容是介绍 SecurityContextHolder 这个容器。","text":"一直以来我都想写一写 Spring Security 系列的文章，但是整个 Spring Security 体系强大却又繁杂。陆陆续续从最开始的 guides 接触它，到项目中看了一些源码，到最近这个月为了写一写这个系列的文章，阅读了好几遍文档，最终打算尝试一下，写一个较为完整的系列文章。 较为简单或者体量较小的技术，完全可以参考着 demo 直接上手，但系统的学习一门技术则不然。以我的认知，一般的文档大致有两种风格：Architecture First 和 Code First。前者致力于让读者先了解整体的架构，方便我们对自己的认知有一个宏观的把控，而后者以特定的 demo 配合讲解，可以让读者在解决问题的过程中顺便掌握一门技术。关注过我博客或者公众号的朋友会发现，我之前介绍技术的文章，大多数是 Code First，提出一个需求，介绍一个思路，解决一个问题，分析一下源码，大多如此。而学习一个体系的技术，我推荐 Architecture First，正如本文标题所言，这篇文章是我 Spring Security 系列的第一篇，主要是根据 Spring Security 文档选择性 ~~ 翻译 ~~ 整理而成的一个架构概览，配合自己的一些注释方便大家理解。写作本系列文章时，参考版本为 Spring Security 4.2.3.RELEASE。 [TOC] 1 核心组件这一节主要介绍一些在 Spring Security 中常见且核心的 Java 类，它们之间的依赖，构建起了整个框架。想要理解整个架构，最起码得对这些类眼熟。 1.1 SecurityContextHolderSecurityContextHolder 用于存储安全上下文（security context）的信息。当前操作的用户是谁，该用户是否已经被认证，他拥有哪些角色权限… 这些都被保存在 SecurityContextHolder 中。SecurityContextHolder 默认使用 ThreadLocal 策略来存储认证信息。看到 ThreadLocal 也就意味着，这是一种与线程绑定的策略。Spring Security 在用户登录时自动绑定认证信息到当前线程，在用户退出时，自动清除当前线程的认证信息。但这一切的前提，是你在 web 场景下使用 Spring Security，而如果是 Swing 界面，Spring 也提供了支持，SecurityContextHolder 的策略则需要被替换，鉴于我的初衷是基于 web 来介绍 Spring Security，所以这里以及后续，非 web 的相关的内容都一笔带过。 获取当前用户的信息因为身份信息是与线程绑定的，所以可以在程序的任何地方使用静态方法获取用户信息。一个典型的获取当前登录用户的姓名的例子如下所示： 1234567Object principal = SecurityContextHolder.getContext().getAuthentication().getPrincipal();if (principal instanceof UserDetails) &#123;String username = ((UserDetails)principal).getUsername();&#125; else &#123;String username = principal.toString();&#125; getAuthentication()返回了认证信息，再次 getPrincipal() 返回了身份信息，UserDetails 便是 Spring 对身份信息封装的一个接口。Authentication 和 UserDetails 的介绍在下面的小节具体讲解，本节重要的内容是介绍 SecurityContextHolder 这个容器。 1.2 Authentication先看看这个接口的源码长什么样： 123456789101112131415package org.springframework.security.core;// &lt;1&gt;public interface Authentication extends Principal, Serializable &#123; // &lt;1&gt; Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); // &lt;2&gt; Object getCredentials();// &lt;2&gt; Object getDetails();// &lt;2&gt; Object getPrincipal();// &lt;2&gt; boolean isAuthenticated();// &lt;2&gt; void setAuthenticated(boolean var1) throws IllegalArgumentException;&#125; Authentication 是 spring security 包中的接口，直接继承自 Principal 类，而 Principal 是位于 java.security 包中的。可以见得，Authentication 在 spring security 中是最高级别的身份 / 认证的抽象。 由这个顶级接口，我们可以得到用户拥有的权限信息列表，密码，用户细节信息，用户身份信息，认证信息。 还记得 1.1 节中，authentication.getPrincipal() 返回了一个 Object，我们将 Principal 强转成了 Spring Security 中最常用的 UserDetails，这在 Spring Security 中非常常见，接口返回 Object，使用 instanceof 判断类型，强转成对应的具体实现类。接口详细解读如下： getAuthorities()，权限信息列表，默认是 GrantedAuthority 接口的一些实现类，通常是代表权限信息的一系列字符串。 getCredentials()，密码信息，用户输入的密码字符串，在认证过后通常会被移除，用于保障安全。 getDetails()，细节信息，web 应用中的实现接口通常为 WebAuthenticationDetails，它记录了访问者的 ip 地址和 sessionId 的值。 getPrincipal()，敲黑板！！！最重要的身份信息，大部分情况下返回的是 UserDetails 接口的实现类，也是框架中的常用接口之一。UserDetails 接口将会在下面的小节重点介绍。 Spring Security 是如何完成身份认证的？1 用户名和密码被过滤器获取到，封装成 Authentication, 通常情况下是 UsernamePasswordAuthenticationToken 这个实现类。 2 AuthenticationManager 身份管理器负责验证这个 Authentication 3 认证成功后，AuthenticationManager 身份管理器返回一个被填充满了信息的（包括上面提到的权限信息，身份信息，细节信息，但密码通常会被移除）Authentication 实例。 4 SecurityContextHolder 安全上下文容器将第 3 步填充了信息的 Authentication，通过 SecurityContextHolder.getContext().setAuthentication(…) 方法，设置到其中。 这是一个抽象的认证流程，而整个过程中，如果不纠结于细节，其实只剩下一个 AuthenticationManager 是我们没有接触过的了，这个身份管理器我们在后面的小节介绍。将上述的流程转换成代码，便是如下的流程： 12345678910111213141516171819202122232425262728293031323334353637383940public class AuthenticationExample &#123;private static AuthenticationManager am = new SampleAuthenticationManager();public static void main(String[] args) throws Exception &#123; BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); while(true) &#123; System.out.println(\"Please enter your username:\"); String name = in.readLine(); System.out.println(\"Please enter your password:\"); String password = in.readLine(); try &#123; Authentication request = new UsernamePasswordAuthenticationToken(name, password); Authentication result = am.authenticate(request); SecurityContextHolder.getContext().setAuthentication(result); break; &#125; catch(AuthenticationException e) &#123; System.out.println(\"Authentication failed:\" + e.getMessage()); &#125; &#125; System.out.println(\"Successfully authenticated. Security context contains:\" + SecurityContextHolder.getContext().getAuthentication());&#125;&#125;class SampleAuthenticationManager implements AuthenticationManager &#123;static final List&lt;GrantedAuthority&gt; AUTHORITIES = new ArrayList&lt;GrantedAuthority&gt;();static &#123; AUTHORITIES.add(new SimpleGrantedAuthority(\"ROLE_USER\"));&#125;public Authentication authenticate(Authentication auth) throws AuthenticationException &#123; if (auth.getName().equals(auth.getCredentials())) &#123; return new UsernamePasswordAuthenticationToken(auth.getName(), auth.getCredentials(), AUTHORITIES); &#125; throw new BadCredentialsException(\"Bad Credentials\");&#125;&#125; 注意：上述这段代码只是为了让大家了解 Spring Security 的工作流程而写的，不是什么源码。在实际使用中，整个流程会变得更加的复杂，但是基本思想，和上述代码如出一辙。 1.3 AuthenticationManager初次接触 Spring Security 的朋友相信会被 AuthenticationManager，ProviderManager ，AuthenticationProvider … 这么多相似的 Spring 认证类搞得晕头转向，但只要稍微梳理一下就可以理解清楚它们的联系和设计者的用意。AuthenticationManager（接口）是认证相关的核心接口，也是发起认证的出发点，因为在实际需求中，我们可能会允许用户使用用户名 + 密码登录，同时允许用户使用邮箱 + 密码，手机号码 + 密码登录，甚至，可能允许用户使用指纹登录（还有这样的操作？没想到吧），所以说 AuthenticationManager 一般不直接认证，AuthenticationManager 接口的常用实现类 ProviderManager 内部会维护一个 List&lt;AuthenticationProvider&gt; 列表，存放多种认证方式，实际上这是委托者模式的应用（Delegate）。也就是说，核心的认证入口始终只有一个：AuthenticationManager，不同的认证方式：用户名 + 密码（UsernamePasswordAuthenticationToken），邮箱 + 密码，手机号码 + 密码登录则对应了三个 AuthenticationProvider。这样一来四不四就好理解多了？熟悉 shiro 的朋友可以把 AuthenticationProvider 理解成 Realm。在默认策略下，只需要通过一个 AuthenticationProvider 的认证，即可被认为是登录成功。 只保留了关键认证部分的 ProviderManager 源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ProviderManager implements AuthenticationManager, MessageSourceAware, InitializingBean &#123; // 维护一个 AuthenticationProvider 列表 private List&lt;AuthenticationProvider&gt; providers = Collections.emptyList(); public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; Authentication result = null; // 依次认证 for (AuthenticationProvider provider : getProviders()) &#123; if (!provider.supports(toTest)) &#123; continue; &#125; try &#123; result = provider.authenticate(authentication); if (result != null) &#123; copyDetails(authentication, result); break; &#125; &#125; ... catch (AuthenticationException e) &#123; lastException = e; &#125; &#125; // 如果有 Authentication 信息，则直接返回 if (result != null) &#123; if (eraseCredentialsAfterAuthentication &amp;&amp; (result instanceof CredentialsContainer)) &#123; // 移除密码 ((CredentialsContainer) result).eraseCredentials(); &#125; // 发布登录成功事件 eventPublisher.publishAuthenticationSuccess(result); return result; &#125; ... // 执行到此，说明没有认证成功，包装异常信息 if (lastException == null) &#123; lastException = new ProviderNotFoundException(messages.getMessage( \"ProviderManager.providerNotFound\", new Object[] &#123; toTest.getName() &#125;, \"No AuthenticationProvider found for &#123;0&#125;\")); &#125; prepareException(lastException, authentication); throw lastException; &#125;&#125; ProviderManager 中的 List，会依照次序去认证，认证成功则立即返回，若认证失败则返回 null，下一个 AuthenticationProvider 会继续尝试认证，如果所有认证器都无法认证成功，则 ProviderManager 会抛出一个 ProviderNotFoundException 异常。 到这里，如果不纠结于 AuthenticationProvider 的实现细节以及安全相关的过滤器，认证相关的核心类其实都已经介绍完毕了：身份信息的存放容器 SecurityContextHolder，身份信息的抽象 Authentication，身份认证器 AuthenticationManager 及其认证流程。姑且在这里做一个分隔线。下面来介绍下 AuthenticationProvider 接口的具体实现。 1.4 DaoAuthenticationProviderAuthenticationProvider 最最最常用的一个实现便是 DaoAuthenticationProvider。顾名思义，Dao 正是数据访问层的缩写，也暗示了这个身份认证器的实现思路。由于本文是一个 Overview，姑且只给出其 UML 类图： 按照我们最直观的思路，怎么去认证一个用户呢？用户前台提交了用户名和密码，而数据库中保存了用户名和密码，认证便是负责比对同一个用户名，提交的密码和保存的密码是否相同便是了。在 Spring Security 中。提交的用户名和密码，被封装成了 UsernamePasswordAuthenticationToken，而根据用户名加载用户的任务则是交给了 UserDetailsService，在 DaoAuthenticationProvider 中，对应的方法便是 retrieveUser，虽然有两个参数，但是 retrieveUser 只有第一个参数起主要作用，返回一个 UserDetails。还需要完成 UsernamePasswordAuthenticationToken 和 UserDetails 密码的比对，这便是交给 additionalAuthenticationChecks 方法完成的，如果这个 void 方法没有抛异常，则认为比对成功。比对密码的过程，用到了 PasswordEncoder 和 SaltSource，密码加密和盐的概念相信不用我赘述了，它们为保障安全而设计，都是比较基础的概念。 如果你已经被这些概念搞得晕头转向了，不妨这么理解 DaoAuthenticationProvider：它获取用户提交的用户名和密码，比对其正确性，如果正确，返回一个数据库中的用户信息（假设用户信息被保存在数据库中）。 1.5 UserDetails 与 UserDetailsService上面不断提到了 UserDetails 这个接口，它代表了最详细的用户信息，这个接口涵盖了一些必要的用户信息字段，具体的实现类对它进行了扩展。 12345678910111213141516public interface UserDetails extends Serializable &#123; Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); String getPassword(); String getUsername(); boolean isAccountNonExpired(); boolean isAccountNonLocked(); boolean isCredentialsNonExpired(); boolean isEnabled();&#125; 它和 Authentication 接口很类似，比如它们都拥有 username，authorities，区分他们也是本文的重点内容之一。Authentication 的 getCredentials()与 UserDetails 中的 getPassword() 需要被区分对待，前者是用户提交的密码凭证，后者是用户正确的密码，认证器其实就是对这两者的比对。Authentication 中的 getAuthorities()实际是由 UserDetails 的 getAuthorities() 传递而形成的。还记得 Authentication 接口中的 getUserDetails() 方法吗？其中的 UserDetails 用户详细信息便是经过了 AuthenticationProvider 之后被填充的。 123public interface UserDetailsService &#123; UserDetails loadUserByUsername(String username) throws UsernameNotFoundException;&#125; UserDetailsService 和 AuthenticationProvider 两者的职责常常被人们搞混，关于他们的问题在文档的 FAQ 和 issues 中屡见不鲜。记住一点即可，敲黑板！！！UserDetailsService 只负责从特定的地方（通常是数据库）加载用户信息，仅此而已，记住这一点，可以避免走很多弯路。UserDetailsService 常见的实现类有 JdbcDaoImpl，InMemoryUserDetailsManager，前者从数据库加载用户，后者从内存中加载用户，也可以自己实现 UserDetailsService，通常这更加灵活。 1.6 架构概览图为了更加形象的理解上述我介绍的这些核心类，附上一张按照我的理解，所画出 Spring Security 的一张非典型的 UML 图 如果对 Spring Security 的这些概念感到理解不能，不用担心，因为这是 Architecture First 导致的必然结果，先过个眼熟。后续的文章会秉持 Code First 的理念，陆续详细地讲解这些实现类的使用场景，源码分析，以及最基本的：如何配置 Spring Security，在后面的文章中可以不时翻看这篇文章，找到具体的类在整个架构中所处的位置，这也是本篇文章的定位。另外，一些 Spring Security 的过滤器还未囊括在架构概览中，如将表单信息包装成 UsernamePasswordAuthenticationToken 的过滤器，考虑到这些虽然也是架构的一部分，但是真正重写他们的可能性较小，所以打算放到后面的章节讲解。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/categories/Spring-Security/"}],"tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://lexburner.github.io/tags/Spring-Security/"}]},{"title":"浅析分布式下的事件驱动机制（PubSub 模式）","slug":"event-2","date":"2017-09-13T14:49:23.000Z","updated":"2019-09-26T09:45:29.655Z","comments":true,"path":"event-2/","link":"","permalink":"http://lexburner.github.io/event-2/","excerpt":"上一篇文章《浅析 Spring 中的事件驱动机制》简单介绍了 Spring 对事件的支持。Event 的整个生命周期，从 publisher 发出，经过 applicationContext 容器通知到 EventListener，都是发生在单个 Spring 容器中，而在分布式场景下，有些时候一个事件的产生，可能需要被多个实例响应，本文主要介绍分布式场景下的事件驱动机制，由于使用了 Redis，ActiveMQ，也可以换一个名词来理解：分布式下的发布订阅模式。 JMS 规范在日常项目开发中，我们或多或少的发现一些包一些类位于 java 或 javax 中，他们主要提供抽象类，接口，提供了一种规范，如 JPA，JSR，JNDI，JTA，JMS，他们是由 java 指定的标准规范，一流企业做标准、二流企业做品牌、三流企业做产品，虽然有点调侃的意味，但也可以见得它的重要意义。而 JMS 就是 java 在消息服务上指定的标准 The Java Message Service (JMS) API is a messaging standard that allows application components based on the Java Platform Enterprise Edition (Java EE) to create, send, receive, and read messages. It enables distributed communication that is loosely coupled, reliable, and asynchronous. JMS（JAVA Message Service,java 消息服务）API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。 消息中间件有非常多的实现，如 ActiveMQ，RabbitMQ，RocketMQ，而他们同一遵循的接口规范，便是 JMS。在下文中即将出现的 ConnectionFactory，Destination，Connection，Session，MessageListener，Topic，Queue 等等名词，都是 JMS 核心的接口，由于本文的初衷并不是讲解 MQ&amp;JMS，所以这些机制暂且跳过。 定义分布式事件需求在上一个项目中，我们对接了外网的 http 接口，而安全性的保障则是交给 OAuth2 来完成，作为 OAuth2 的客户端，我们需要获取服务端返回的 token，而 token 接口的获取次数每个月是有限制的，于是我们选择使用 Redis 来保存，定时刷新。由于每次发起请求时都要携带 token，为了更高的性能减少一次 redis io，我们在 TokenService 中使用了本地变量缓存 token。于是形成如下的 token 获取机制： 这个图并不复杂，只是为了方便描述需求：首先去本地变量中加载 token，若 token==null，则去 Redis 加载，若 Redis 未命中（token 过期了），则最终调用外部的 http 接口获取实时的 token，同时存入 redis 中和本地变量中。 这个需求设计到这样一个问题：大多数情况下是单个实例中发现 redis 中的 token 为空，而它需要同时获取最新 token，并通知其他的实例也去加载最新的 token，这个时候事件广播就可以派上用场了。 由于 token 缓存在了 Redis 中，我们首先介绍 Redis 的发布订阅机制。","text":"上一篇文章《浅析 Spring 中的事件驱动机制》简单介绍了 Spring 对事件的支持。Event 的整个生命周期，从 publisher 发出，经过 applicationContext 容器通知到 EventListener，都是发生在单个 Spring 容器中，而在分布式场景下，有些时候一个事件的产生，可能需要被多个实例响应，本文主要介绍分布式场景下的事件驱动机制，由于使用了 Redis，ActiveMQ，也可以换一个名词来理解：分布式下的发布订阅模式。 JMS 规范在日常项目开发中，我们或多或少的发现一些包一些类位于 java 或 javax 中，他们主要提供抽象类，接口，提供了一种规范，如 JPA，JSR，JNDI，JTA，JMS，他们是由 java 指定的标准规范，一流企业做标准、二流企业做品牌、三流企业做产品，虽然有点调侃的意味，但也可以见得它的重要意义。而 JMS 就是 java 在消息服务上指定的标准 The Java Message Service (JMS) API is a messaging standard that allows application components based on the Java Platform Enterprise Edition (Java EE) to create, send, receive, and read messages. It enables distributed communication that is loosely coupled, reliable, and asynchronous. JMS（JAVA Message Service,java 消息服务）API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。 消息中间件有非常多的实现，如 ActiveMQ，RabbitMQ，RocketMQ，而他们同一遵循的接口规范，便是 JMS。在下文中即将出现的 ConnectionFactory，Destination，Connection，Session，MessageListener，Topic，Queue 等等名词，都是 JMS 核心的接口，由于本文的初衷并不是讲解 MQ&amp;JMS，所以这些机制暂且跳过。 定义分布式事件需求在上一个项目中，我们对接了外网的 http 接口，而安全性的保障则是交给 OAuth2 来完成，作为 OAuth2 的客户端，我们需要获取服务端返回的 token，而 token 接口的获取次数每个月是有限制的，于是我们选择使用 Redis 来保存，定时刷新。由于每次发起请求时都要携带 token，为了更高的性能减少一次 redis io，我们在 TokenService 中使用了本地变量缓存 token。于是形成如下的 token 获取机制： 这个图并不复杂，只是为了方便描述需求：首先去本地变量中加载 token，若 token==null，则去 Redis 加载，若 Redis 未命中（token 过期了），则最终调用外部的 http 接口获取实时的 token，同时存入 redis 中和本地变量中。 这个需求设计到这样一个问题：大多数情况下是单个实例中发现 redis 中的 token 为空，而它需要同时获取最新 token，并通知其他的实例也去加载最新的 token，这个时候事件广播就可以派上用场了。 由于 token 缓存在了 Redis 中，我们首先介绍 Redis 的发布订阅机制。 Redis 中的 Pub 与 Subredis 不仅仅具备缓存的功能，它还拥有一个 channel 机制，我们可以使用 Redis 来进行发布订阅。上述的 token 流程我们简化一下，省略保存到 redis 的那一环，直接介绍如何通知其他应用刷新 token。 引入依赖和配置1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 12345spring: redis: database: 0 host: localhost port: 6379 定义 TokenService1234567891011121314151617181920@Servicepublic class TokenService &#123; @Autowired StringRedisTemplate redisTemplate; public void getToken(String username) &#123; // &lt;1&gt; String token = UUID.randomUUID().toString(); // 模拟 http 接口使用用户名和密码获取 token System.out.println(username + \"成功获取 token ...\" + token); // 发送 token 刷新广播 System.out.println(\"广播 token 刷新事件 ...\"); redisTemplate.convertAndSend(RedisPubSubConfig.tokenChannel, token); &#125; public void refreshTokenListener(String token) &#123; // &lt;2&gt; System.out.println(\"接到 token 刷新事件，刷新 token :\" + token); &#125;&#125; 模拟获取 token 的方法，获取 token 的同时发送广播。 用于接收其他应用发送过来的广播消息。 配置 RedisMessageListenerContainer在 Spring 应用中 Event 是由 Spring 容器管理的，而在 Redis 的消息机制中，Event 是由 RedisMessageListenerContainer 管理的。我们为 token 配置一个 channel，用于刷新 token： 123456789101112131415161718192021222324252627@Configurationpublic class RedisPubSubConfig &#123; public final static String tokenChannel = \"tokenChannel\"; @Bean RedisMessageListenerContainer redisMessageListenerContainer(RedisConnectionFactory redisConnectionFactory) &#123; RedisMessageListenerContainer redisMessageListenerContainer = new RedisMessageListenerContainer();// &lt;1&gt; redisMessageListenerContainer.setConnectionFactory(redisConnectionFactory); redisMessageListenerContainer.addMessageListener(tokenRefreshListener(), new ChannelTopic(tokenChannel)); // &lt;2&gt; return redisMessageListenerContainer; &#125; @Autowired TokenService tokenService; MessageListener tokenRefreshListener() &#123; return new MessageListener() &#123; @Override public void onMessage(Message message, byte[] pattern) &#123; byte[] bytes = message.getBody(); // &lt;3&gt; tokenService.refreshTokenListener(new String(bytes)); &#125; &#125;; &#125;&#125; RedisMessageListenerContainer 用于管理所有的 redis 相关的发布与订阅 为 Redis 容器注册特定的订阅者，在本例中使用 tokenRefreshListener 监听 tokenChannel 频道，当收到消息通知时，会自动调用 onMessage 方法。 使用 message.getBody() 可以获取消息的具体内容，在本例中即 token 测试结果同样的这个应用，我们在 8080,8081,8082 启动三个，在 8080 中，我们调用 tokenService.getToken(“kirito”);(注意必须要连接到 redis 的同一个 database) 在三个控制台中我们得到了如下的结果： 8080： 123kirito 成功获取 token ...5d4d2a48-934f-450d-8806-e6095b172286广播 token 刷新事件 ...接到 token 刷新事件，刷新 token : 5d4d2a48-934f-450d-8806-e6095b172286 8081： 1接到 token 刷新事件，刷新 token : 5d4d2a48-934f-450d-8806-e6095b172286 8082： 1接到 token 刷新事件，刷新 token : 5d4d2a48-934f-450d-8806-e6095b172286 可以发现其他系统的确收到了通知。 ActiveMQ 中的 Pub 与 SubRedis 中的发布订阅其实在真正的企业开发中并不是很常用，如果涉及到一致性要求较高的需求，专业的消息中间件可以更好地为我们提供服务。下面介绍一下 ActiveMQ 如何实现发布订阅。 ActiveMQ 为我们提供很好的监控页面，延时队列，消息 ACK，事务，持久化等等机制，且拥有较高的吞吐量，是企业架构中不可或缺的一个重要中间件。 引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt; 12345678spring: activemq: in-memory: false # &lt;1&gt; broker-url: tcp://127.0.0.1:61616 user: admin password: admin jms: pub-sub-domain: true # &lt;2&gt; springboot 的自动配置会帮我们启动一个内存中的消息队列，引入 spring-boot-starter-activemq 倚赖时需要特别注意这一点，本例连接本机的 ActiveMQ。 springboot 默认不支持 PubSub 模式，需要手动开启。 定义 TokenService123456789101112131415161718192021222324252627282930@Servicepublic class TokenService &#123; @Autowired JmsTemplate jmsTemplate; // &lt;1&gt; @Autowired Topic tokenTopic; // &lt;3&gt; public void getToken(String username) &#123; String token = UUID.randomUUID().toString(); // 模拟 http 接口使用用户名和密码获取 token System.out.println(username + \"成功获取 token ...\" + token); // 发送 token 刷新广播 System.out.println(\"广播 token 刷新事件 ...\"); try &#123; Message message = new ActiveMQMessage(); message.setStringProperty(\"token\", token); jmsTemplate.convertAndSend(tokenTopic, message);// &lt;1&gt; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @JmsListener(destination = ActivemqPubSubConfig.tokenTopic) // &lt;2&gt; public void refreshTokenListener(Message message) throws Exception &#123; System.out.println(\"接到 token 刷新事件，刷新 token :\" + message.getStringProperty(\"token\")); &#125;&#125; 使用模板设计模式的好处体现了出来，再前面的 RedisTemplate 中我们也是使用同样的 template.convertAndSend() 发送消息 JmsListener 对应于 EventListener，接收来自 ActiveMQ 中 tokenTopic 的消息通知 tokenTopic 定义在下面的 config 中 配置 ActiveMQ 的 topic123456789101112@Configurationpublic class ActivemqPubSubConfig &#123; public final static String tokenTopic = \"tokenTopic\"; @Bean Topic tokenTopic()&#123; return new ActiveMQTopic(ActivemqPubSubConfig.tokenTopic); &#125;&#125; 非常简单的配置，因为 ActiveMQAutoConfiguration 已经帮我们做了相当多的配置，我们只需要顶一个 topic 即可使用 ActiveMQ 的功能。 查看 ActiveMQ 的监控端省略了发送消息的过程，实际上可以得到和 Redis PubSub 一样的效果。来看一下 ActiveMQ 自带的监控端，在发送消息后，发生了什么变化，访问本地端口 http://localhost:8161/admin ，可以看到消息被消费了。 总结本文介绍了 Redis，ActiveMQ 的 PubSub 特性，这是我理解的分布式场景下的事件驱动的使用。事件驱动是一种思想，PubSub 是一种模式，Redis，ActiveMQ 是一种应用，落到实处，便可以是本文介绍的 token 这个小小的业务实现。但是注意，使用 Redis，ActiveMQ 理解事件驱动可以，但是不能等同事件驱动，事件驱动还有很多其他场景下体现，笔者功力不够，无法一一介绍，怕人误解，特此强调一下。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/tags/架构设计/"}]},{"title":"上一个电商项目的反思","slug":"rethink-1","date":"2017-09-11T13:02:43.000Z","updated":"2019-09-26T09:45:29.459Z","comments":true,"path":"rethink-1/","link":"","permalink":"http://lexburner.github.io/rethink-1/","excerpt":"","text":"加入中科软已经有了一个年头，从去年实习到今年转正，陆陆续续接触了大概四个项目。有电商类，互联网保险类，也经历过管理系统。幸运的是，这些项目都是从零开始，避免了让我去维护不堪入目的老旧系统。而这么多项目中令我印象最深刻的，就要属上一个电商项目了。这也是我接触到的真正意义的第一个微服务项目，到今天回首去看曾经的这个项目，有很多突破性地尝试，同时不可避免地也踩入了一些坑点，毕竟摸着石头过河。今天想聊聊我对上一个电商项目的反思。 项目简介准确的说是一个第三方的电商项目，商品来源是由主流电商的 http 接口提供（目前接入了京东，苏宁），打造我们自己的商城体系。使用的技术包括 springboot，jpa，rpc 框架使用的是 motan，数据库使用的是 oracle，基本都还算是主流的技术。 盲目地拆分微服务使用了 springboot 就是微服务了吗？使用 rpc 通信就是微服务了吗？刚接触到所谓的微服务架构时，无疑是让人兴奋的，但也没有太多的经验，以至于每提出一个新的需求，几乎就会新建一个服务。没有从宏观去思考如何拆分服务，那时还没有项目组成员尝试去使用领域驱动设计的思想去划分服务的边界，会议室中讨论最多的话题也是：我们的数据库该如何设计，而不是我们的领域该如何划分。项目初期，使用单体式的思想开发着分布式项目，新技术的引入还只是使人有点稍微的不顺手，但是项目越做越大后，越来越大的不适感逐渐侵蚀着我们的开发速度。 说道微服务的拆分，有很多个维度，这里主要谈两个维度： 系统维度：业务功能不同的需求，交给不同的系统完成，如订单，商品，地址，用户等系统需要拆分。 模块维度：基础架构层（如公用 util），领域层，接口层，服务层，表现层的拆分。 在项目的初期，我们错误地认为微服务的拆分仅仅是系统维度的拆分，如商品系统和订单系统，而在模块维度上，缺少拆分的意识，如订单模块的表现层和服务层，我们虽然做了隔离（两个独立的 tomcat）。但在后来，业务添加了一个新的需求：商城增加积分支持，让用户可以使用积分购买商品。我们突然发现，所谓的服务层和表现层严重的耦合，仅仅是在物理上进行了隔离，逻辑层面并没有拆分，这导致新的积分服务模块从原先的订单服务层拷贝了大量的代码。吸取了这个教训后，我们新的项目中采取了如下的分层方式： 其中比较关键的一点便是表现层与应用层的完全分离，交互完全使用 DTO 对象。不少同事产生了困惑，抱怨在表现层不能访问数据库，这让他们获取数据变得十分“麻烦”，应用层和表现层还多了一次数据拷贝的工作，用于将 DO 持久化对象转换成 DTO 对象。但这样的好处从长远来看，是不言而喻的。总结为以下几点： 1 应用层高度重用，没有表现形式的阻碍，PC 端，移动端，外部服务都可以同时接入，需要组装什么样的数据，请自行组装。 2 应用层和领域层可以交由经验较为丰富的程序员负责，避免了一些低性能的数据操作，错误的并发控制等等。 3 解决远程调用数据懒加载的问题。从前的设计中，表现层拿到了领域层的对象，而领域层会使用懒加载技术，当表现层想要获取懒加载属性时，或得到一个 no session 的异常。在没有这个分层之前，如何方便地解决这个问题一度困扰了我们很长的一段时间。 数据库的滥用项目使用了 oracle，我们所有的数据都存在于同一个 oracle 实例中，各个系统模块并没有做到物理层面的数据库隔离。这并不符合设计，一方面这给那些想要跨模块执行 join 操作的人留了后门，如执行订单模块和用户模块的级联查询；另一方面，还困扰了一部分对微服务架构不甚了解的程序员，在他们的想法中，同一个数据库实例反而方便了他们的数据操作。 严格意义上，不仅仅是不同系统之间的数据库不能互相访问。同一个系统维度的不同模块也应当限制，正如前面一节的分层架构中，表现层（web 层）是不应该出现 DAO 的，pom 文件中也不应该出现任何 JPA，Hibernate，Mybatis 一类的依赖，它所有的数据来源，必须是应用层。 另外一方面，由于历史遗留问题，需要对接一个老系统，他们的表和这个电商的 oracle 实例是同一个，而我竟然在他们的表上发现了触发器这种操作… 在新的项目中，我们已经禁止使用数据库层面的触发器和物理约束。 在新的项目中，我们采用了阿里云的 RDS(mysql) 作为 oracle 的替代品，核心业务数据则放到了分布式数据库 DRDS 中，严格做到了数据库层面的拆分。 并发的控制电商系统不同于 OA 系统，CMS 系统，余额，订单等等操作都是敏感操作，实实在在跟钱打交道的东西容不得半点马虎，然而即使是一些有经验的程序员，也写出了这样的扣减余额操作： 12345678public void reduce(String accountId,BigDecimal cost)&#123; Account account = accountService.findOne(accountId); BigDecimal balance = account.getBalance(); if(balance &gt; cost) balance = balance - cost;// 用四则运算代替 BigDecimal 的 api，方便表达 account.setBalance(balance); accountService.save(account);&#125; 很多人没有控制并发的意识，即使意识到了，也不知道如何根据业务场景采取合适的手段控制并发，是使用 JPA 中的乐观锁，还是使用数据库的行级自旋锁完成简单并发控制，还是 for update 悲观锁（这不建议被使用），还是基于 redis 或 zookeeper 一类的分布式锁？ 这种错误甚至都不容许等到 code revivew 时才被发现，而应该是尽力地杜绝。 代码规范小到 java 的变量的驼峰命名法，数据库中用‘_’分割单词，到业务代码该如何规范的书写，再到并发规范，性能调优。准确的说，没有人管理这些事，这样的工作落到了每个有悟性的开发者身上。模块公用的常量，系统公用的常量应当区分放置，禁止使用魔鬼数字，bool 变量名不能以 is 开头等等细小的但是重要的规范，大量的条件查询 findByxxx 污染了 DAO 层，完全可以被 predicates，criteria 替代，RESTFUL 规范指导设计 web 接口等等… 在新的项目中，一条条规范被逐渐添加到了项目单独的模块 READ.me 中。作为公司的一个 junior developer，在建议其他成员使用规范开发项目时，得到的回应通常是：我的功能都已经实现了，干嘛要改；不符合规范又怎么样，要改你改时。有时候也是挺无力的，算是个人的一点牢骚吧。 软件设计的一点不足还是拿订单系统和商品系统来说事，虽然两个系统在物理上被拆分开了，但如果需要展示订单列表，订单详情，如今系统的设计会发起多次的远程调用，用于查询订单的归属商品，这是违背领域驱动设计的。订单中的商品就应当是归属于订单模块，正确的设计应该是使用冗余，代替频繁的跨网络节点远程调用。 另外一点便是高可用，由于机器内存的限制，所有的系统都只部署了单个实例，这其实并不是微服务的最佳实践。从系统应用，到 zookeeper，redis，mq 等中间件，都应当保证高可用，避免单点问题。没有真正实现做到横向扩展（知识理论上实现了），实在是有点遗憾。 系统没有熔断，降级处理，在新的项目中，由于我们引入了 Spring Cloud，很多地方都可以 out of box 式使用框架提供的 fallback 处理，而这上一个电商项目由于框架的限制以及接口设计之初就没有预想到要做这样的操作，使得可靠性再减了几分。 自动化运维的缺失单体式应用的美好时代，只需要发布同一份 war 包。而微服务项目中，一切都变得不同，在我们这个不算特别庞大的电商系统中，需要被运行的服务模块也到达了 30-40 个。由于这个电商系统是部署在甲方自己的服务器中，一方面是业务部门的业务审批流程，一方面是如此众多的 jar 包运行，没有自动发布，没有持续集成。令我比较难忘的是初期发布版本，始终有一两个服务莫名奇妙的挂掉，对着终端中的服务列表，一个个排查，这种痛苦的经历。至今，这个系统仍然依靠运维人员，手动管理版本。 上一个项目有一些不可控的项目因素，而新的项目中，系统服务全部在阿里云上部署，也引入了 Jenkins，一切都在逐渐变好，其他的 devops 工具仍然需要完善，以及 docker 一类的容器技术还未在计划日程之内，这些都是我们今年努力的目标。 总结原本积累了很多自己的想法，可惜落笔之后能够捕捉到一些点，便只汇聚成了上述这些，而这上一个电商项目在逐渐的迭代开发之后也变得越来越好了（我去了新的项目组后，其他同事负责了后续的开发）。这个经历，于我是非常珍贵的，它比那些大牛直接告诉我微服务设计的要素要更加有意义。知道了不足之处，经历了自己解决问题的过程，才会了解到好的方案的优势，了解到开源方案到底是为了解决什么样的问题而设计的。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"}]},{"title":"浅析 Spring 中的事件驱动机制","slug":"event-1","date":"2017-09-10T12:03:58.000Z","updated":"2019-09-26T09:45:31.634Z","comments":true,"path":"event-1/","link":"","permalink":"http://lexburner.github.io/event-1/","excerpt":"","text":"今天来简单地聊聊事件驱动，其实写这篇文章挺令我挺苦恼的，因为事件驱动这个名词，我没有找到很好的定性解释，担心自己的表述有误，而说到事件驱动可能立刻联想到如此众多的概念：观察者模式，发布订阅模式，消息队列 MQ，消息驱动，事件，EventSourcing… 为了不产生歧义，笔者把自己所了解的这些模棱两可的概念都列了出来，再开始今天的分享。 在设计模式中，观察者模式可以算得上是一个非常经典的行为型设计模式，猫叫了，主人醒了，老鼠跑了，这一经典的例子，是事件驱动模型在设计层面的体现。 另一模式，发布订阅模式往往被人们等同于观察者模式，但我的理解是两者唯一区别，是发布订阅模式需要有一个调度中心，而观察者模式不需要，例如观察者的列表可以直接由被观察者维护。不过两者即使被混用，互相替代，通常不影响表达。 MQ，中间件级别的消息队列（e.g. ActiveMQ,RabbitMQ），可以认为是发布订阅模式的一个具体体现。事件驱动 -&gt; 发布订阅 -&gt;MQ，从抽象到具体。 java 和 spring 中都拥有 Event 的抽象，分别代表了语言级别和三方框架级别对事件的支持。 EventSourcing 这个概念就要关联到领域驱动设计，DDD 对事件驱动也是非常地青睐，领域对象的状态完全是由事件驱动来控制，由其衍生出了 CQRS 架构，具体实现框架有 AxonFramework。 Nginx 可以作为高性能的应用服务器（e.g. openResty），以及 Nodejs 事件驱动的特性，这些也是都是事件驱动的体现。 本文涵盖的内容主要是前面 4 点。 Spring 对 Event 的支持Spring 的文档对 Event 的支持翻译之后描述如下： ApplicationContext 通过 ApplicationEvent 类和 ApplicationListener 接口进行事件处理。 如果将实现 ApplicationListener 接口的 bean 注入到上下文中，则每次使用 ApplicationContext 发布 ApplicationEvent 时，都会通知该 bean。 本质上，这是标准的观察者设计模式。 而在 spring4.2 之后，提供了注解式的支持，我们可以使用任意的 java 对象配合注解达到同样的效果，首先来看看不适用注解如何在 Spring 中使用事件驱动机制。 定义业务需求：用户注册后，系统需要给用户发送邮件告知用户注册成功，需要给用户初始化积分；隐含的设计需求，用户注册后，后续需求可能会添加其他操作，如再发送一条短信等等，希望程序具有扩展性，以及符合开闭原则。 如果不使用事件驱动，代码可能会像这样子： 1234567891011121314151617public class UserService &#123; @Autowired EmailService emailService; @Autowired ScoreService scoreService; @Autowired OtherService otherService; public void register(String name) &#123; System.out.println(\"用户：\" + name + \"已注册！\"); emailService.sendEmail(name); scoreService.initScore(name); otherService.execute(name); &#125; &#125; 要说有什么毛病，其实也不算有，因为可能大多数人在开发中都会这么写，喜欢写同步代码。但这么写，实际上并不是特别的符合隐含的设计需求，假设增加更多的注册项 service，我们需要修改 register 的方法，并且让 UserService 注入对应的 Service。而实际上，register 并不关心这些“额外”的操作，如何将这些多余的代码抽取出去呢？便可以使用 Spring 提供的 Event 机制。 定义用户注册事件1234567public class UserRegisterEvent extends ApplicationEvent&#123; public UserRegisterEvent(String name) &#123; //name 即 source super(name); &#125;&#125; ApplicationEvent 是由 Spring 提供的所有 Event 类的基类，为了简单起见，注册事件只传递了 name（可以复杂的对象，但注意要了解清楚序列化机制）。 定义用户注册服务 (事件发布者)123456789101112131415@Service // &lt;1&gt;public class UserService implements ApplicationEventPublisherAware &#123; // &lt;2&gt; public void register(String name) &#123; System.out.println(\"用户：\" + name + \"已注册！\"); applicationEventPublisher.publishEvent(new UserRegisterEvent(name));// &lt;3&gt; &#125; private ApplicationEventPublisher applicationEventPublisher; // &lt;2&gt; @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; // &lt;2&gt; this.applicationEventPublisher = applicationEventPublisher; &#125;&#125; 服务必须交给 Spring 容器托管 ApplicationEventPublisherAware 是由 Spring 提供的用于为 Service 注入 ApplicationEventPublisher 事件发布器的接口，使用这个接口，我们自己的 Service 就拥有了发布事件的能力。 用户注册后，不再是显示调用其他的业务 Service，而是发布一个用户注册事件。 定义邮件服务，积分服务，其他服务 (事件订阅者)12345678@Service // &lt;1&gt;public class EmailService implements ApplicationListener&lt;UserRegisterEvent&gt; &#123; // &lt;2&gt; @Override public void onApplicationEvent(UserRegisterEvent userRegisterEvent) &#123; System.out.println(\"邮件服务接到通知，给\" + userRegisterEvent.getSource() + \"发送邮件...\");// &lt;3&gt; &#125;&#125; 事件订阅者的服务同样需要托管于 Spring 容器 ApplicationListener&lt;E extends ApplicationEvent&gt; 接口是由 Spring 提供的事件订阅者必须实现的接口，我们一般把该 Service 关心的事件类型作为泛型传入。 处理事件，通过 event.getSource() 即可拿到事件的具体内容，在本例中便是用户的姓名。 其他两个 Service，也同样编写，实际的业务操作仅仅是打印一句内容即可，篇幅限制，这里省略。 编写启动类1234567891011121314151617@SpringBootApplication@RestControllerpublic class EventDemoApp &#123; public static void main(String[] args) &#123; SpringApplication.run(EventDemoApp.class, args); &#125; @Autowired UserService userService; @RequestMapping(\"/register\") public String register()&#123; userService.register(\"kirito\"); return \"success\"; &#125;&#125; 当我们调用 userService.register(“kirito”); 方法时，控制台打印信息如下： 他们的顺序是无序的，如果需要控制顺序，需要重写 order 接口，这点不做介绍。其次，我们完成了用户注册和其他服务的解耦，这也是事件驱动的最大特性之一，如果需要在用户注册时完成其他操作，只需要再添加相应的事件订阅者即可。 Spring 对 Event 的注解支持上述的几个接口已经非常清爽了，如果习惯使用注解，Spring 也提供了，不再需要显示实现 注解式的事件发布者123456789101112@Servicepublic class UserService &#123; public void register(String name) &#123; System.out.println(\"用户：\" + name + \"已注册！\"); applicationEventPublisher.publishEvent(new UserRegisterEvent(name)); &#125; @Autowired private ApplicationEventPublisher applicationEventPublisher;&#125; Spring4.2 之后，ApplicationEventPublisher 自动被注入到容器中，采用 Autowired 即可获取。 注解式的事件订阅者12345678@Servicepublic class EmailService &#123; @EventListener public void listenUserRegisterEvent(UserRegisterEvent userRegisterEvent) &#123; System.out.println(\"邮件服务接到通知，给\" + userRegisterEvent.getSource() + \"发送邮件...\"); &#125;&#125; @EventListener 注解完成了 ApplicationListener&lt;E extends ApplicationEvent&gt; 接口的使命。 更多的特性可以参考 SpringFramework 的文档。 Spring 中事件的应用在以往阅读 Spring 源码的经验中，接触了不少使用事件的地方，大概列了以下几个，加深以下印象： Spring Security 中使用 AuthenticationEventPublisher 处理用户认证成功，认证失败的消息处理。 1234567public interface AuthenticationEventPublisher &#123; void publishAuthenticationSuccess(Authentication authentication); void publishAuthenticationFailure(AuthenticationException exception, Authentication authentication);&#125; Hibernate 中持久化对象属性的修改是如何被框架得知的？正是采用了一系列持久化相关的事件，如 DefaultSaveEventListener，DefaultUpdateEventListener, 事件非常多，有兴趣可以去 org.hibernate.event 包下查看。 Spring Cloud Zuul 中刷新路由信息使用到的 ZuulRefreshListener 1234567891011121314private static class ZuulRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; ... public void onApplicationEvent(ApplicationEvent event) &#123; if(!(event instanceof ContextRefreshedEvent) &amp;&amp; !(event instanceof RefreshScopeRefreshedEvent) &amp;&amp; !(event instanceof RoutesRefreshedEvent)) &#123; if(event instanceof HeartbeatEvent &amp;&amp; this.heartbeatMonitor.update(((HeartbeatEvent)event).getValue())) &#123; this.zuulHandlerMapping.setDirty(true); &#125; &#125; else &#123; this.zuulHandlerMapping.setDirty(true); &#125; &#125; &#125; Spring 容器生命周期相关的一些默认 Event 1ContextRefreshedEvent,ContextStartedEvent,ContextStoppedEvent,ContextClosedEvent,RequestHandledEvent 。。。其实吧，非常多。。。 总结本文暂时只介绍了 Spring 中的一些简单的事件驱动机制，相信如果之后再看到 Event，Publisher，EventListener 一类的单词后缀时，也能立刻和事件机制联系上了。再阅读 Spring 源码时，如果发现出现了某个 Event，但由于不是同步调用，所以很容易被忽视，我一般习惯下意识的去寻找有没有提供默认的 Listener，这样不至于漏掉一些“隐藏”的特性。下一篇文章打算聊一聊分布式场景下，事件驱动使用的注意点。 公众号刚刚创立，如果觉得文章不错，希望能分享到您的朋友圈，如果对文章有什么想法和建议，可以与我沟通。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/tags/架构设计/"}]},{"title":"从 Feign 使用注意点到 RESTFUL 接口设计规范","slug":"feign-1","date":"2017-09-09T06:43:28.000Z","updated":"2019-09-26T09:45:30.912Z","comments":true,"path":"feign-1/","link":"","permalink":"http://lexburner.github.io/feign-1/","excerpt":"","text":"最近项目中大量使用了 Spring Cloud Feign 来对接 http 接口，踩了不少坑，也产生了一些对 RESTFUL 接口设计的想法，特此一篇记录下。 [TOC] SpringMVC 的请求参数绑定机制了解 Feign 历史的朋友会知道，Feign 本身是 Netflix 的产品，Spring Cloud Feign 是在原生 Feign 的基础上进行了封装，引入了大量的 SpringMVC 注解支持，这一方面使得其更容易被广大的 Spring 使用者开箱即用，但也产生了不小的混淆作用。所以在使用 Spring Cloud Feign 之前，笔者先介绍一下 SpringMVC 的一个入参机制。预设一个 RestController，在本地的 8080 端口启动一个应用，用于接收 http 请求。 123456789@RestControllerpublic class BookController &#123; @RequestMapping(value = \"/hello\") // &lt;1&gt; public String hello(String name) &#123; // &lt;2&gt; return \"hello\" + name; &#125;&#125; 这个接口写起来非常简单，但实际 springmvc 做了非常多的兼容，使得这个接口可以接受多种请求方式。 RequestMapping 代表映射的路径，使用 GET,POST,PUT,DELETE 方式都可以映射到该端点。 SpringMVC 中常用的请求参数注解有（@RequestParam,@RequestBody,@PathVariable）等。name 被默认当做 @RequestParam。形参 String name 由框架使用字节码技术获取 name 这个名称，自动检测请求参数中 key 值为 name 的参数，也可以使用 @RequestParam(“name”) 覆盖变量本身的名称。当我们在 url 中携带 name 参数或者 form 表单中携带 name 参数时，会被获取到。 12345POST /hello HTTP/1.1Host: localhost:8080Content-Type: application/x-www-form-urlencodedname=formParam 或 12GET /hello?name=queryString HTTP/1.1Host: localhost:8080 Feign 的请求参数绑定机制上述的 SpringMVC 参数绑定机制，大家应该都是非常熟悉的，但这一切在 Feign 中有些许的不同。 我们来看一个非常简单的，但是实际上错误的接口写法： 12345678// 注意：错误的接口写法@FeignClient(\"book\")public interface BookApi &#123; @RequestMapping(value = \"/hello\",method = RequestMethod.GET) String hello(String name);&#125; 配置请求地址： 1234567ribbon: eureka: enabled: falsebook: ribbon: listOfServers: http://localhost:8080 我们按照写 SpringMVC 的 RestController 的习惯写了一个 FeignClient，按照我们的一开始的想法，由于指定了请求方式是 GET，那么 name 应该会作为 QueryString 拼接到 Url 中吧？发出一个这样的 GET 请求： 12GET /hello?name=xxx HTTP/1.1Host: localhost:8080 而实际上，RestController 并没有接收到，我们在 RestController 一侧的应用中获得了一些提示： 并没有按照期望使用 GET 方式发送请求，而是 POST 方式 name 参数没有被封装，获得了一个 null 值 查看文档发现，如果不加默认的注解，Feign 则会对参数默认加上 @RequestBody 注解，而 RequestBody 一定是包含在请求体中的，GET 方式无法包含。所以上述两个现象得到了解释。Feign 在 GET 请求包含 RequestBody 时强制转成了 POST 请求，而不是报错。 理解清楚了这个机制我们就可以在开发 Feign 接口避免很多坑。而解决上述这个问题也很简单 在 Feign 接口中为 name 添加 @RequestParam(“name”) 注解，name 必须指定，Feign 的请求参数不会利用 SpringMVC 字节码的机制自动给定一个默认的名称。 由于 Feign 默认使用 @RequestBody，也可以改造 RestController，使用 @RequestBody 接收。但是，请求参数通常是多个，推荐使用上述的 @RequestParam，而 @RequestBody 一般只用于传递对象。 Feign 绑定复合参数指定请求参数的类型与请求方式，上述问题的出现实际上是由于在没有理清楚 Feign 内部机制的前提下想当然的和 SpringMVC 进行了类比。同样，在使用对象作为参数时，也需要注意这样的问题。 对于这样的接口 1234567891011121314151617@FeignClient(\"book\")public interface BookApi &#123; @RequestMapping(value = \"/book\",method = RequestMethod.POST) Book book(@RequestBody Book book); // &lt;1&gt; @RequestMapping(value = \"/book\",method = RequestMethod.POST) Book book(@RequestParam(\"id\") String id,@RequestParam(\"name\") String name); // &lt;2&gt; @RequestMapping(value = \"/book\",method = RequestMethod.POST) Book book(@RequestParam Map map); // &lt;3&gt; // 错误的写法 @RequestMapping(value = \"/book\",method = RequestMethod.POST) Book book(@RequestParam Book book); // &lt;4&gt;&#125; 使用 @RequestBody 传递对象是最常用的方式。 如果参数并不是很多，可以平铺开使用 @RequestParam 使用 Map，这也是完全可以的，但不太符合面向对象的思想，不能从代码立刻看出该接口需要什么样的参数。 错误的用法，Feign 没有提供这样的机制自动转换实体为 Map。 Feign 中使用 @PathVariable 与 RESTFUL 规范这涉及到一个如何设计 RESTFUL 接口的话题，我们知道在自从 RESTFUL 在 2000 年初被提出来之后，就不乏文章提到资源，契约规范，CRUD 对应增删改查操作等等。下面笔者从两个实际的接口来聊聊自己的看法。 根据 id 查找用户接口： 1234567@FeignClient(\"user\")public interface UserApi &#123; @RequestMapping(value = \"/user/&#123;userId&#125;\",method = RequestMethod.GET) String findById(@PathVariable(\"id\") String userId);&#125; 这应该是没有争议的，注意前面强调的，@PathVariable(“id”) 括号中的 id 不可以忘记。那如果是“根据邮箱查找用户呢”? 很有可能下意识的写出这样的接口： 1234567@FeignClient(\"user\")public interface UserApi &#123; @RequestMapping(value = \"/user/&#123;email&#125;\",method = RequestMethod.GET) String findByEmail(@PathVariable(\"email\") String email);&#125; 首先看看 Feign 的问题。email 中通常包含’.‘这个特殊字符，如果在路径中包含，会出现意想不到的结果。我不想探讨如何去解决它（实际上可以使用 {email:.+} 的方式), 因为我觉得这不符合设计。 再谈谈规范的问题。这两个接口是否是相似的，email 是否应该被放到 path 中？这就要聊到 RESTFUL 的初衷，为什么 userId 这个属性被普遍认为适合出现在 RESTFUL 路径中，因为 id 本身起到了资源定位的作用，他是资源的标记。而 email 不同，它可能是唯一的，但更多的，它是资源的属性，所以，笔者认为不应该在路径中出现非定位性的动态参数。而是把 email 作为 @RequestParam 参数。 RESUFTL 结构化查询笔者成功的从 Feign 的话题过度到了 RESTFUL 接口的设计问题，也导致了本文的篇幅变长了，不过也不打算再开一片文章谈了。 再考虑一个接口设计，查询某一个月某个用户的订单，可能还会携带分页参数，这时候参数变得很多，按照传统的设计，这应该是一个查询操作，也就是与 GET 请求对应，那是不是意味着应当将这些参数拼接到 url 后呢？再思考 Feign，正如本文的第二段所述，是不支持 GET 请求携带实体类的，这让我们设计陷入了两难的境地。而实际上参考一些 DSL 语言的设计如 elasticSearch，也是使用 POST JSON 的方式来进行查询的，所以在实际项目中，笔者并不是特别青睐 CRUD 与四种请求方式对应的这种所谓的 RESTFUL 规范，如果说设计 RESTFUL 应该遵循什么规范，那大概是另一些名词，如契约规范和领域驱动设计。 1234567@FeignClient(\"order\")public interface BookApi &#123; @RequestMapping(value = \"/order/history\",method = RequestMethod.POST) Page&lt;List&lt;Orders&gt;&gt; queryOrderHistory(@RequestBody QueryVO queryVO);&#125; RESTFUL 行为限定在实际接口设计中，我遇到了这样的需求，用户模块的接口需要支持修改用户密码，修改用户邮箱，修改用户姓名，而笔者之前阅读过一篇文章，也是讲舍弃 CRUD 而是用领域驱动设计来规范 RESTFUL 接口的定义，与项目中我的想法不谋而合。看似这三个属性是同一个实体类的三个属性，完全可以如下设计： 1234567@FeignClient(&quot;user&quot;)public interface UserApi &#123; @RequestMapping(value = &quot;/user&quot;,method = RequestMethod.POST) User update(@RequestBody User user);&#125; 但实际上，如果再考虑多一层，就应该产生这样的思考：这三个功能所需要的权限一致吗？真的应该将他们放到一个接口中吗？实际上，笔者并不希望接口调用方传递一个实体，因为这样的行为是不可控的，完全不知道它到底是修改了什么属性，如果真的要限制行为，还需要在 User 中添加一个操作类型的字段，然后在接口实现方加以校验，这太麻烦了。而实际上，笔者觉得规范的设计应当如下： 12345678910111213@FeignClient(\"user\")public interface UserApi &#123; @RequestMapping(value = \"/user/&#123;userId&#125;/password/update\",method = RequestMethod.POST) ResultBean&lt;Boolean&gt; updatePassword(@PathVariable(\"userId) String userId,@RequestParam(\"password\") password); @RequestMapping(value = \"/user/&#123;userId&#125;/email/update\",method = RequestMethod.POST) ResultBean&lt;Boolean&gt; updateEmail(@PathVariable(\"userId) String userId,@RequestParam(\"email\") String email); @RequestMapping(value = \"/user/&#123;userId&#125;/username/update\",method = RequestMethod.POST) ResultBean&lt;Boolean&gt; updateUsername(@PathVariable(\"userId) String userId,@RequestParam(\"username\") String username);&#125; 一般意义上 RESTFUL 接口不应该出现动词，这里的 update 并不是一个动作，而是标记着操作的类型，因为针对某个属性可能出现的操作类型可能会有很多，所以我习惯加上一个 update 后缀，明确表达想要进行的操作，而不是仅仅依赖于 GET，POST，PUT，DELETE。实际上，修改操作推荐使用的请求方式应当是 PUT，这点笔者的理解是，已经使用 update 标记了行为，实际开发中不习惯使用 PUT。 password，email，username 都是 user 的属性，而 userId 是 user 的识别符号，所以 userId 以 PathVariable 的形式出现在 url 中，而三个属性出现在 ReqeustParam 中。 顺带谈谈逻辑删除，如果一个需求是删除用户的常用地址，这个 api 的操作类型，我通常也不会设计为 DELETE 请求，而是同样使用 delete 来标记操作行为 12@RequestMapping(value = \"/user/&#123;userId&#125;/address/&#123;addressId&#125;/delete\",method = RequestMethod.POST) ResultBean&lt;Boolean&gt; updateEmail(@PathVariable(\"userId\") String userId,@PathVariable(\"userId\") String email); 总结本文从 Feign 的使用注意点，聊到了 RESTFUL 接口的设计问题，其实是一个互相补充的行为。接口设计需要载体，所以我以 Feign 的接口风格谈了谈自己对 RESTFUL 设计的理解，而 Feign 中一些坑点，也正是我想要规范 RESTFUL 设计的出发点。如有对 RESTFUL 设计不同的理解，欢迎与我沟通。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/tags/Spring-Cloud/"}]},{"title":"Re：从零开始的 Spring Session(三)","slug":"spring-session-3","date":"2017-09-04T12:57:43.000Z","updated":"2019-09-26T09:45:30.066Z","comments":true,"path":"spring-session-3/","link":"","permalink":"http://lexburner.github.io/spring-session-3/","excerpt":"","text":"上一篇文章中，我们使用 Redis 集成了 Spring Session。大多数的配置都是 Spring Boot 帮我们自动配置的，这一节我们介绍一点 Spring Session 较为高级的特性。 集成 Spring Security之所以把 Spring Session 和 Spring Security 放在一起讨论，是因为我们的应用在集成 Spring Security 之后，用户相关的认证与 Session 密不可分，如果不注意一些细节，会引发意想不到的问题。 与 Spring Session 相关的依赖可以参考上一篇文章，这里给出增量的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 我们引入依赖后，就已经自动配置了 Spring Security，我们在 application.yml 添加一个内存中的用户： 1234security: user: name: admin password: admin 测试登录点沿用上一篇文章的端点，访问 http://localhost:8080/test/cookie?browser=chrome 端点后会出现 http basic 的认证框，我们输入 admin/admin，即可获得结果，也遇到了第一个坑点，我们会发现每次请求，sessionId 都会被刷新，这显然不是我们想要的结果。 这个现象笔者研究了不少源码，但并没有得到非常满意的解释，只能理解为 SecurityAutoConfiguration 提供的默认配置，没有触发到响应的配置，导致了 session 的不断刷新（如果读者有合理的解释可以和我沟通）。Spring Session 之所以能够替换默认的 tomcat httpSession 是因为配置了 springSessionRepositoryFilter 这个过滤器，且提供了非常高的优先级，这归功于 AbstractSecurityWebApplicationInitializer ，AbstractHttpSessionApplicationInitializer 这两个初始化器，当然，也保证了 Spring Session 会在 Spring Security 之前起作用。 而解决上述的诡异现象也比较容易（但原理不清），我们使用 @EnableWebSecurity 对 Spring Security 进行一些配置，即可解决这个问题。 1234567891011121314151617181920212223242526@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; // @formatter:off @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/resources/**\").permitAll() .anyRequest().authenticated() .and() .httpBasic()//&lt;1&gt; .and() .logout().permitAll(); &#125; // @formatter:on // @formatter:off @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser(\"admin\").password(\"admin\").roles(\"USER\");//&lt;2&gt; &#125; // @formatter:on&#125; 不想大费周章写一个登录页面，于是开启了 http basic 认证 配置了 security config 之后，springboot 的 autoConfig 就会失效，于是需要手动配置用户。 再次请求，可以发现 SessionId 返回正常，@EnableWebSecurity 似乎触发了相关的配置，当然了，我们在使用 Spring Security 时不可能使用 autoconfig，但是这个现象的确是一个疑点。 使用自定义 CookieSerializer12345678@Beanpublic CookieSerializer cookieSerializer() &#123; DefaultCookieSerializer serializer = new DefaultCookieSerializer(); serializer.setCookieName(\"JSESSIONID\"); serializer.setCookiePath(\"/\"); serializer.setDomainNamePattern(\"^.+?\\\\.(\\\\w+\\\\.[a-z]+)$\"); return serializer;&#125; 使用上述配置后，我们可以将 Spring Session 默认的 Cookie Key 从 SESSION 替换为原生的 JSESSIONID。而 CookiePath 设置为根路径且配置了相关的正则表达式，可以达到同父域下的单点登录的效果，在未涉及跨域的单点登录系统中，这是一个非常优雅的解决方案。如果我们的当前域名是 moe.cnkirito.moe，该正则会将 Cookie 设置在父域 cnkirito.moe 中，如果有另一个相同父域的子域名 blog.cnkirito.moe 也会识别这个 Cookie，便可以很方便的实现同父域下的单点登录。 根据用户名查找用户归属的 SESSION这个特性听起来非常有意思，你可以在一些有趣的场景下使用它，如知道用户名后即可删除其 SESSION。一直以来我们都是通过线程绑定的方式，让用户操作自己的 SESSION，包括获取用户名等操作。但如今它提供了一个反向的操作，根据用户名获取 SESSION，恰巧，在一些项目中真的可以使用到这个特性，最起码，当别人问起你，或者讨论到和 SESSION 相关的知识时，你可以明晰一点，这是可以做到的。 我们使用 Redis 作为 Session Store 还有一个好处，就是其实现了 FindByIndexNameSessionRepository 接口，下面让我们来见证这一点。 123456789101112@Controllerpublic class CookieController &#123; @Autowired FindByIndexNameSessionRepository&lt;? extends ExpiringSession&gt; sessionRepository; @RequestMapping(\"/test/findByUsername\") @ResponseBody public Map findByUsername(@RequestParam String username) &#123; Map&lt;String, ? extends ExpiringSession&gt; usersSessions = sessionRepository.findByIndexNameAndIndexValue(FindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME, username); return usersSessions; &#125;&#125; 由于一个用户可能拥有多个 Session，所以返回的是一个 Map 信息，而这里的 username，则就是与 Spring Security 集成之后的用户名，最令人感动 Spring 厉害的地方，是这一切都是自动配置好的。我们在内存中配置的用户的 username 是 admin，于是我们访问这个端点, 可以看到如下的结果 连同我们存入 session 中的 browser=chrome，browser=360 都可以看见（只有键名）。 总结Spring Session 对各种场景下的 Session 管理提供一套非常完善的实现。笔者所介绍的，仅仅是 Spring Session 常用的一些特性，更多的知识点可以在 spring.io 的文档中一览无余，以及本文中作者存在的一个疑惑，如有兴趣可与我沟通。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/categories/Spring-Session/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/tags/Spring-Session/"}]},{"title":"Re：从零开始的 Spring Session(二)","slug":"spring-session-2","date":"2017-09-03T12:06:12.000Z","updated":"2019-09-26T09:45:29.584Z","comments":true,"path":"spring-session-2/","link":"","permalink":"http://lexburner.github.io/spring-session-2/","excerpt":"上一篇文章介绍了一些 Session 和 Cookie 的基础知识，这篇文章开始正式介绍 Spring Session 是如何对传统的 Session 进行改造的。官网这么介绍 Spring Session： Spring Session provides an API and implementations for managing a user’s session information. It also provides transparent integration with: HttpSession - allows replacing the HttpSession in an application container (i.e. Tomcat) neutral way. Additional features include: Clustered Sessions - Spring Session makes it trivial to support clustered sessions without being tied to an application container specific solution. Multiple Browser Sessions - Spring Session supports managing multiple users’ sessions in a single browser instance (i.e. multiple authenticated accounts similar to Google). RESTful APIs - Spring Session allows providing session ids in headers to work with RESTful APIs WebSocket - provides the ability to keep the HttpSession alive when receiving WebSocket messages 其具体的特性非常之多，具体的内容可以从文档中了解到，笔者做一点自己的总结，Spring Session 的特性包括但不限于以下： 使用 GemFire 来构建 C/S 架构的 httpSession（不关注） 使用第三方仓储来实现集群 session 管理，也就是常说的分布式 session 容器，替换应用容器（如 tomcat 的 session 容器）。仓储的实现，Spring Session 提供了三个实现（redis，mongodb，jdbc），其中 redis 使我们最常用的。程序的实现，使用 AOP 技术，几乎可以做到透明化地替换。（核心） 可以非常方便的扩展 Cookie 和自定义 Session 相关的 Listener，Filter。 可以很方便的与 Spring Security 集成，增加诸如 findSessionsByUserName，rememberMe，限制同一个账号可以同时在线的 Session 数（如设置成 1，即可达到把前一次登录顶掉的效果）等等 介绍完特性，下面开始一步步集成 Spring Session","text":"上一篇文章介绍了一些 Session 和 Cookie 的基础知识，这篇文章开始正式介绍 Spring Session 是如何对传统的 Session 进行改造的。官网这么介绍 Spring Session： Spring Session provides an API and implementations for managing a user’s session information. It also provides transparent integration with: HttpSession - allows replacing the HttpSession in an application container (i.e. Tomcat) neutral way. Additional features include: Clustered Sessions - Spring Session makes it trivial to support clustered sessions without being tied to an application container specific solution. Multiple Browser Sessions - Spring Session supports managing multiple users’ sessions in a single browser instance (i.e. multiple authenticated accounts similar to Google). RESTful APIs - Spring Session allows providing session ids in headers to work with RESTful APIs WebSocket - provides the ability to keep the HttpSession alive when receiving WebSocket messages 其具体的特性非常之多，具体的内容可以从文档中了解到，笔者做一点自己的总结，Spring Session 的特性包括但不限于以下： 使用 GemFire 来构建 C/S 架构的 httpSession（不关注） 使用第三方仓储来实现集群 session 管理，也就是常说的分布式 session 容器，替换应用容器（如 tomcat 的 session 容器）。仓储的实现，Spring Session 提供了三个实现（redis，mongodb，jdbc），其中 redis 使我们最常用的。程序的实现，使用 AOP 技术，几乎可以做到透明化地替换。（核心） 可以非常方便的扩展 Cookie 和自定义 Session 相关的 Listener，Filter。 可以很方便的与 Spring Security 集成，增加诸如 findSessionsByUserName，rememberMe，限制同一个账号可以同时在线的 Session 数（如设置成 1，即可达到把前一次登录顶掉的效果）等等 介绍完特性，下面开始一步步集成 Spring Session 使用 Redis 集成 Spring Session 引入依赖，Spring Boot 的版本采用 1.5.4 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置 配置类开启 Redis Http Session 12345@Configuration@EnableRedisHttpSessionpublic class HttpSessionConfig &#123;&#125; 基本是 0 配置，只需要让主配置扫描到 @EnableRedisHttpSession 即可 配置文件 application.yml，配置连接的 redis 信息 12345spring: redis: host: localhost port: 6379 database: 0 编写测试 Controller，以便于观察 Spring Session 的特性，和前一篇文章使用同样的代码 12345678910111213141516171819202122@Controllerpublic class CookieController &#123; @RequestMapping(\"/test/cookie\") public String cookie(@RequestParam(\"browser\") String browser, HttpServletRequest request, HttpSession session) &#123; // 取出 session 中的 browser Object sessionBrowser = session.getAttribute(\"browser\"); if (sessionBrowser == null) &#123; System.out.println(\"不存在 session，设置 browser=\" + browser); session.setAttribute(\"browser\", browser); &#125; else &#123; System.out.println(\"存在 session，browser=\" + sessionBrowser.toString()); &#125; Cookie[] cookies = request.getCookies(); if (cookies != null &amp;&amp; cookies.length &gt; 0) &#123; for (Cookie cookie : cookies) &#123; System.out.println(cookie.getName() + \":\" + cookie.getValue()); &#125; &#125; return \"index\"; &#125;&#125; 启动类省略，下面开始测试。 在浏览器中访问如下端点：http://localhost:8080/test/cookie?browser=chrome，下面是连续访问 4 次的结果 12345671 不存在 session，设置 browser=chrome2 存在 session，browser=chrome SESSION : 70791b17-83e1-42db-8894-73fbd2f2a1593 存在 session，browser=chrome SESSION : 70791b17-83e1-42db-8894-73fbd2f2a1594 存在 session，browser=chrome SESSION : 70791b17-83e1-42db-8894-73fbd2f2a159 如果还记得上一篇文章中运行结果的话，会发现和原生的 session 管理是有一些差别，原先的信息中我们记得 Cookie 中记录的 Key 值是 JSESSIONID，而替换成 RedisHttpSession 之后变成了 SESSION。接着观察 redis 中的变化： 解析一下这个 redis store，如果不纠结于细节，可以跳过，不影响使用。 ​1 spring:session 是默认的 Redis HttpSession 前缀（redis 中，我们常用 ‘:’ 作为分割符）。 2 每一个 session 都会有三个相关的 key，第三个 key 最为重要，它是一个 HASH 数据结构，将内存中的 session 信息序列化到了 redis 中。如上文的 browser，就被记录为 sessionAttr:browser=chrome, 还有一些 meta 信息，如创建时间，最后访问时间等。 3 另外两个 key，expirations:1504446540000 和 sessions:expires:7079… 我发现大多数的文章都没有对其分析，前者是一个 SET 类型，后者是一个 STRING 类型，可能会有读者发出这样的疑问，redis 自身就有过期时间的设置方式 TTL，为什么要额外添加两个 key 来维持 session 过期的特性呢？这需要对 redis 有一定深入的了解才能想到这层设计。当然这不是本节的重点，简单提一下：redis 清除过期 key 的行为是一个异步行为且是一个低优先级的行为，用文档中的原话来说便是，可能会导致 session 不被清除。于是引入了专门的 expiresKey，来专门负责 session 的清除，包括我们自己在使用 redis 时也需要关注这一点。在开发层面，我们仅仅需要关注第三个 key 就行了。 总结本节主要讲解了 Spring Boot 如何集成 Spring Session，下一节将介绍更加复杂的特性。包括自定义 Cookie 序列化策略，与 Spring Security 的集成，根据用户名查找 session 等特性以及使用注意点。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/categories/Spring-Session/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/tags/Spring-Session/"}]},{"title":"Re：从零开始的 Spring Session(一)","slug":"spring-session-1","date":"2017-09-03T07:27:04.000Z","updated":"2019-09-26T09:48:31.907Z","comments":true,"path":"spring-session-1/","link":"","permalink":"http://lexburner.github.io/spring-session-1/","excerpt":"Session 和 Cookie 这两个概念，在学习 java web 开发之初，大多数人就已经接触过了。最近在研究跨域单点登录的实现时，发现对于 Session 和 Cookie 的了解，并不是很深入，所以打算写两篇文章记录一下自己的理解。在我们的应用集成 Spring Session 之前，先补充一点 Session 和 Cookie 的关键知识。 Session 与 Cookie 基础由于 http 协议是无状态的协议，为了能够记住请求的状态，于是引入了 Session 和 Cookie 的机制。我们应该有一个很明确的概念，那就是 Session 是存在于服务器端的，在单体式应用中，他是由 tomcat 管理的，存在于 tomcat 的内存中，当我们为了解决分布式场景中的 session 共享问题时，引入了 redis，其共享内存，以及支持 key 自动过期的特性，非常契合 session 的特性，我们在企业开发中最常用的也就是这种模式。但是只要你愿意，也可以选择存储在 JDBC，Mongo 中，这些，spring 都提供了默认的实现，在大多数情况下，我们只需要引入配置即可。而 Cookie 则是存在于客户端，更方便理解的说法，可以说存在于浏览器。Cookie 并不常用，至少在我不长的 web 开发生涯中，并没有什么场景需要我过多的关注 Cookie。http 协议允许从服务器返回 Response 时携带一些 Cookie，并且同一个域下对 Cookie 的数量有所限制，之前说过 Session 的持久化依赖于服务端的策略，而 Cookie 的持久化则是依赖于本地文件。虽然说 Cookie 并不常用，但是有一类特殊的 Cookie 却是我们需要额外关注的，那便是与 Session 相关的 sessionId，他是真正维系客户端和服务端的桥梁。","text":"Session 和 Cookie 这两个概念，在学习 java web 开发之初，大多数人就已经接触过了。最近在研究跨域单点登录的实现时，发现对于 Session 和 Cookie 的了解，并不是很深入，所以打算写两篇文章记录一下自己的理解。在我们的应用集成 Spring Session 之前，先补充一点 Session 和 Cookie 的关键知识。 Session 与 Cookie 基础由于 http 协议是无状态的协议，为了能够记住请求的状态，于是引入了 Session 和 Cookie 的机制。我们应该有一个很明确的概念，那就是 Session 是存在于服务器端的，在单体式应用中，他是由 tomcat 管理的，存在于 tomcat 的内存中，当我们为了解决分布式场景中的 session 共享问题时，引入了 redis，其共享内存，以及支持 key 自动过期的特性，非常契合 session 的特性，我们在企业开发中最常用的也就是这种模式。但是只要你愿意，也可以选择存储在 JDBC，Mongo 中，这些，spring 都提供了默认的实现，在大多数情况下，我们只需要引入配置即可。而 Cookie 则是存在于客户端，更方便理解的说法，可以说存在于浏览器。Cookie 并不常用，至少在我不长的 web 开发生涯中，并没有什么场景需要我过多的关注 Cookie。http 协议允许从服务器返回 Response 时携带一些 Cookie，并且同一个域下对 Cookie 的数量有所限制，之前说过 Session 的持久化依赖于服务端的策略，而 Cookie 的持久化则是依赖于本地文件。虽然说 Cookie 并不常用，但是有一类特殊的 Cookie 却是我们需要额外关注的，那便是与 Session 相关的 sessionId，他是真正维系客户端和服务端的桥梁。 代码示例用户发起请求，服务器响应请求，并做一些用户信息的处理，随后返回响应给用户；用户再次发起请求，携带 sessionId，服务器便能够识别，这个用户就是之前请求的那个。 使用 Springboot 编写一个非常简单的服务端，来加深对其的理解。需求很简单，当浏览器访问 localhost:8080/test/cookie?browser=xxx 时，如果没有获取到 session，则将 request 中的 browser 存入 session；如果获取到 session，便将 session 中的 browser 值输出。顺便将 request 中的所有 cookie 打印出来。 12345678910111213141516171819202122@Controllerpublic class CookieController &#123; @RequestMapping(\"/test/cookie\") public String cookie(@RequestParam(\"browser\") String browser, HttpServletRequest request, HttpSession session) &#123; // 取出 session 中的 browser Object sessionBrowser = session.getAttribute(\"browser\"); if (sessionBrowser == null) &#123; System.out.println(\"不存在 session，设置 browser=\" + browser); session.setAttribute(\"browser\", browser); &#125; else &#123; System.out.println(\"存在 session，browser=\" + sessionBrowser.toString()); &#125; Cookie[] cookies = request.getCookies(); if (cookies != null &amp;&amp; cookies.length &gt; 0) &#123; for (Cookie cookie : cookies) &#123; System.out.println(cookie.getName() + \":\" + cookie.getValue()); &#125; &#125; return \"index\"; &#125;&#125; 我们没有引入其他任何依赖，看看原生的 session 机制是什么。 1 使用 chrome 浏览器，访问 localhost:8080/test/cookie?browser=chrome, 控制台输出如下： 1Session Info: 不存在 session，设置 browser=chrome 既没有 session，也没有 cookie，我们将 browser=chrome 设置到 session 中。 再次访问同样的端点，控制台输出如下： 12Session Info: 存在 session，browser=chromeCookie Info: JSESSIONID : 4CD1D96E04FC390EA6C60E8C40A636AF 多次访问之后，控制台依旧打印出同样的信息。 稍微解读下这个现象，可以验证一些结论。当服务端往 session 中保存一些数据时，Response 中自动添加了一个 Cookie：JSESSIONID：xxxx, 再后续的请求中，浏览器也是自动的带上了这个 Cookie，服务端根据 Cookie 中的 JSESSIONID 取到了对应的 session。这验证了一开始的说法，客户端服务端是通过 JSESSIONID 进行交互的，并且，添加和携带 key 为 JSESSIONID 的 Cookie 都是 tomcat 和浏览器自动帮助我们完成的，这很关键。 2 使用 360 浏览器，访问 localhost:8080/test/cookie?browser=360 第一次访问： 1Session Info: 不存在 session，设置 browser=360 后续访问： 12Session Info: 存在 session，browser=360Cookie Info: JSESSIONID : 320C21A645A160C4843D076204DA2F40 为什么要再次使用另一个浏览器访问呢？先卖个关子，我们最起码可以得出结论，不同浏览器，访问是隔离的，甚至重新打开同一个浏览器，JSESSIONID 也是不同的。另外可以尝试把保存 session 的操作注视掉，则可以发现 Response 中就不会返回 JSESSIONID 了，即这是一次无状态的请求。 安全问题其实上述的知识点，都是非常浅显的，之所以啰嗦一句，是为了引出这一节的内容，以及方便观察后续我们引入 Spring Session 之后的发生的变化。 还记得上一节的代码示例中，我们使用了两个浏览器： chrome 浏览器访问时，JSESSIONID 为 4CD1D96E04FC390EA6C60E8C40A636AF，后端 session 记录的值为：browser=chrome。 360 浏览器访问时，JSESSIONID 为 320C21A645A160C4843D076204DA2F40, 后端 session 记录的值为：browser=360。 我们使用 chrome 插件 Edit this Cookie，将 chrome 浏览器中的 JSESSIONID 修改为 360 浏览器中的值 同样访问原来的端点：localhost:8080/test/cookie?browser=chrome，得到的输出如下： 12存在 session，browser=360JSESSIONID : 320C21A645A160C4843D076204DA2F40 证实了一点，存放在客户端的 Cookie 的确是存在安全问题的，我们使用 360 的 JSESSIONID“骗”过了服务器。毕竟，服务器只能通过 Cookie 中的 JSESSIONID 来辨别身份。（这提示我们不要在公共场合保存 Cookie 信息，现在的浏览器在保存 Cookie 时通常会让你确定一次） 下一篇文章，将正式讲解如何在应用中集成 Spring Session。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/categories/Spring-Session/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"Spring Session","slug":"Spring-Session","permalink":"http://lexburner.github.io/tags/Spring-Session/"}]},{"title":"解析 Spring 中的 ResponseBody 和 RequestBody","slug":"requestBody-and-responseBody","date":"2017-08-30T04:44:21.000Z","updated":"2019-09-26T09:45:31.418Z","comments":true,"path":"requestBody-and-responseBody/","link":"","permalink":"http://lexburner.github.io/requestBody-and-responseBody/","excerpt":"spring，restful，前后端分离这些关键词都是大家耳熟能详的关键词了，一般 spring 常常需要与前端、第三方使用 JSON，XML 等形式进行交互，你也一定不会对 @RequestBody 和 @ResponseBody 这两个注解感到陌生。","text":"spring，restful，前后端分离这些关键词都是大家耳熟能详的关键词了，一般 spring 常常需要与前端、第三方使用 JSON，XML 等形式进行交互，你也一定不会对 @RequestBody 和 @ResponseBody 这两个注解感到陌生。 @ResponseBody 的使用由于 @ResponseBody 和 @RequestBody 的内部实现是同样的原理（封装请求和封装响应），所以本文以 @ResponseBody 为主要入手点，理解清楚任何一者，都可以同时掌握另一者。 如果想要从 spring 获得一个 json 形式返回值，操作起来是非常容易的。首先定义一个实体类: 1234public class Book &#123; private Integer id; private String bookName;&#125; 接着定义一个后端端点： 123456789@RestControllerpublic class BookController &#123; @GetMapping(value = \"/book/&#123;bookId&#125;\") public Book getBook(@PathVariable(\"bookId\") Integer bookId) &#123; return new Book(bookId, \"book\" + bookId); &#125;&#125; 在 RestController 中，相当于给所有的 xxxMapping 端点都添加了 @ResponseBody 注解，不返回视图，只返回数据。使用 http 工具访问这个后端端点 localhost:8080/book/2，便可以得到如下的响应： 1234&#123; \"id\": 2, \"bookName\": \"book2\"&#125; 这是一个最简单的返回 JSON 对象的使用示例了，相信这样的代码很多人在项目中都写过。 添加 XML 解析如果我们需要将 Book 对象以 XML 的形式返回，该如何操作呢？这也很简单，给 Book 对象添加 @XmlRootElement 注解，让 spring 内部能够解析 XML 对象。 12345@XmlRootElementpublic class Book &#123; private Integer id; private String bookName;&#125; 在我们未对 web 层的 BookController 做任何改动之前，尝试访问 localhost:8080/book/2 时，会发现得到的结果仍然是前面的 JSON 对象。这也能够理解，因为 Book 对象如今既可以被解析为 XML，也可以被解析为 JSON，我们隐隐察觉这背后有一定的解析顺序关系，但不着急，先看看如何让 RestController 返回 XML 解析结果。 方法 1 http 客户端指定接收的返回结果类型 http 协议中，可以给请求头添加 Accept 属性，笔者常用的 http 客户端是 idea 自带的 Test RESTful Web Service 以及 chrome 的插件 Postman。简单的调试，前者基本可以满足我们大多数的需求，而这里为了给大家更直观的体验，笔者使用了 Postman。以 code 形式展示： 123GET /book/2 HTTP/1.1Host: localhost:8080Accept: application/xml 响应内容如下： 12345&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?&gt;&lt;book&gt; &lt;bookName&gt;book2&lt;/bookName&gt; &lt;id&gt;2&lt;/id&gt;&lt;/book&gt; 方法 2 在 RestController 后端端点中指定返回类型 修改后的 RestController 如下所示 123456789@RestControllerpublic class BookController &#123; @GetMapping(value = \"/book/&#123;bookId&#125;\", produces = &#123;\"application/xml\"&#125;) public Book getBook(@PathVariable(\"bookId\") Integer bookId) &#123; return new Book(bookId, \"book\" + bookId); &#125;&#125; 此时即使将请求中的 Accept: application/xml 去除，依旧可以返回上述的 XML 结果。 通常情况下，我们的服务端返回的形式一般是固定的，即限定了是 JSON，XML 中的一种，不建议依赖于客户端添加 Accept 的信息，而是在服务端限定 produces 类型。 详解 Accpect 与 producesAccpect 包含在 http 协议的请求头中，其本身代表着客户端发起请求时，期望返回的响应结果的媒体类型。如果服务端可能返回多个媒体类型，则可以通过 Accpect 指定具体的类型。 produces 是 Spring 为我们提供的注解参数，代表着服务端能够支持返回的媒体类型，我们注意到 produces 后跟随的是一个数组类型，也就意味着服务端支持多种媒体类型的响应。 在上一节中，我们未显示指定 produces 值时，其实就隐式的表明，支持 XML 形式，JSON 形式的媒体类型响应。从实验结果，我们也可以看出，当请求未指定 Accpect，响应未指定 produces 时，具体采用何种形式返回是有 Spring 控制的。在接口交互时，最良好的对接方式，当然是客户端指定 Accpect，服务端指定 produces，这样可以避免模棱两可的请求响应，避免出现意想不到的对接结果。 详解 ContentType 与 consumes恰恰和 Accpect&amp;produces 相反，这两个参数是与用于限制请求的。理解了前两者的含义，这两个参数可以举一反三理解清楚。 ContentType 包含在 http 协议的请求头中，其本身代表着客户端发起请求时，告知服务端自己的请求媒体类型是什么。 consumes 是 Spring 为我们提供的注解参数，代表着服务端能够支持处理的请求媒体类型，同样是一个数组，意味着服务端支持多种媒体类型的请求。一般而言，consumes 与 produces 对请求响应媒体类型起到的限制作用，我们给他一个专有名词：窄化。 http 请求响应媒体类型一览上面描述的 4 个属性：Accpect 与 produces，ContentType 与 consumes 究竟有哪些类型与之对应呢？我只将常用的一些列举了出来： 媒体类型 含义 text/html HTML 格式 text/plain 纯文本格式 text/xml, application/xml XML 数据格式 application/json JSON 数据格式 image/gif gif 图片格式 image/png png 图片格式 application/octet-stream 二进制流数据 application/ x-www-form-urlencoded form 表单数据 multipart/form-data 含文件的 form 表单 其中有几个类型值得一说，web 开发中我们常用的提交表单操作，其默认的媒体类型就是 application/ x-www-form-urlencoded，而当表单中包含文件时，大家估计都踩过坑，需要将 enctype=multipart/form-data 设置在 form 参数中。text/html 也就是常见的网页了，json 与 xml 常用于数据交互，其他不再赘述。 而在 JAVA 中，提供了 MediaType 这样的抽象，来与 http 的媒体类型进行对应。‘/’之前的名词，如 text，application 被称为类型（type），‘/’之后被称为子类型 (subType)。 详解 HttpMessageConverter我们想要搞懂 Spring 到底如何完成众多实体类等复杂类型的数据转换以及与媒体类型的对应，就必须要搞懂 HttpMessageConverter 这个顶级接口： 1234567891011public interface HttpMessageConverter&lt;T&gt; &#123; boolean canRead(Class&lt;?&gt; var1, MediaType var2); boolean canWrite(Class&lt;?&gt; var1, MediaType var2); List&lt;MediaType&gt; getSupportedMediaTypes(); T read(Class&lt;? extends T&gt; var1, HttpInputMessage var2) throws IOException, HttpMessageNotReadableException; void write(T var1, MediaType var2, HttpOutputMessage var3) throws IOException, HttpMessageNotWritableException;&#125; 大致能看出 Spring 的处理思路。下面的流程图可以更好方便我们的理解： 对于添加了 @RequestBody 和 @ResponseBody 注解的后端端点，都会经历由 HttpMessageConverter 进行的数据转换的过程。而在 Spring 启动之初，就已经有一些默认的转换器被注册了。通过在 RequestResponseBodyMethodProcessor 中打断点，我们可以获取到一个 converters 列表： 源码方面不做过多的解读，有兴趣的朋友可以研究一下 RequestResponseBodyMethodProcessor 中的 handleReturnValue 方法，包含了转换的核心实现。 自定义 HttpMessageConverter前面已经提及了消息转换器是通过判断媒体类型来调用响应的转换类的，不禁引发了我们的思考，如果我们遇到了不常用的 MediaType，或者自定义的 MediaType，又想要使用 Spring 的 @RequestBody，@ResponseBody 注解，该如何添加代码呢？下面我们通过自定义一个 HttpMessageConverter 来了解 Spring 内部的转换过程。 先定义我们的需求，自定一个 MediaType：application/toString，当返回一个带有 @ResponseBody 注解的实体类时，将该实体类的 ToString 作为响应内容。 1 首先重写 Book 的 ToString 方法，方便后期效果展示 1234567@Overridepublic String toString() &#123; return \"~~~Book&#123;\" + \"id=\" + id + \", bookName='\"+ bookName +'\\'' + \"&#125;~~~\";&#125; 2 编写自定义的消息转换器 123456789101112131415161718192021222324public class ToStringHttpMessageConverter extends AbstractHttpMessageConverter&lt;Object&gt; &#123; public ToStringHttpMessageConverter() &#123; super(new MediaType(\"application\", \"toString\", Charset.forName(\"UTF-8\")));// &lt;1&gt; &#125; @Override protected boolean supports(Class&lt;?&gt; clazz) &#123; return true; &#125; // 从请求体封装数据 对应 RequestBody 用 String 接收 @Override protected Object readInternal(Class&lt;?&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException &#123; return StreamUtils.copyToString(inputMessage.getBody(), Charset.forName(\"UTF-8\")); &#125; // 从响应体封装数据 对应 ResponseBody @Override protected void writeInternal(Object o, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException &#123; String result = o.toString();//&lt;2&gt; outputMessage.getBody().write(result.getBytes()); &#125;&#125; 此处指定了支持的媒体类型 调用类的 ToString 方法，将结果写入到输出流中 3 配置自定义的消息转换器 12345678@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter&#123; @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; converters.add(new ToStringHttpMessageConverter()); &#125;&#125; 4 配置后端端点，指定生产类型 12345678@RestControllerpublic class BookController &#123; @GetMapping(value = \"/book/&#123;bookId&#125;\",produces = &#123;\"application/toString\",\"application/json\",\"application/xml\"&#125;) public Book getBook(@PathVariable(\"bookId\") Integer bookId) &#123; return new Book(bookId, \"book\" + bookId); &#125;&#125; 此处只是为了演示，添加了三个生产类型，我们的后端端点可以支持输出三种类型，而具体输出哪一者，则依赖客户端的 Accept 指定。 5 客户端请求 123GET /book/2 HTTP/1.1Host: localhost:8080Accept: application/toString 响应结果如下： 1​~~~Book&#123;id=2, bookName=&apos;book2&apos;&#125;~~~ 此时，你可以任意指定 Accept 的类型，即可获得不同形式的 Book 返回结果，可以是 application/toString，application/json，application/xml，都会对应各自的 HttpMessageConverter。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"}]},{"title":"XML 与 javabean 的转换","slug":"javabean-xml","date":"2017-08-25T19:41:27.000Z","updated":"2019-09-26T09:45:31.442Z","comments":true,"path":"javabean-xml/","link":"","permalink":"http://lexburner.github.io/javabean-xml/","excerpt":"XML 可以说是一种被时代淘汰的数据传输格式，毕竟相比较 JSON，其语法，表现形式，以及第三方类库的支持，都要略逊一筹，但最近在对接一些老接口时，主要还是以 XML 为主，而翻阅相关的文档以及博客，没看到很好的文章介绍如何使用 xml 进行数据传输，所以简单写下此文，做一下记录。内心多多少少还是会抵制对接如此老旧的接口，不过生活还是要继续。 Code First先上一段代码，展示一下如何封装，讲解放到后面 一个典型的对接方提供的 XML 如下： 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?&gt;&lt;ORDER&gt; &lt;ORDER_NO&gt;10086&lt;/ORDER_NO&gt; &lt;TOTAL_PRICE&gt;3.14&lt;/TOTAL_PRICE&gt; &lt;CREATE_TIME&gt;2017-08-26 03:39:30&lt;/CREATE_TIME&gt; &lt;ORDER_ITEMS&gt; &lt;ORDER_ITEM&gt; &lt;GOODS_NAME&gt; 德芙 &lt;/GOODS_NAME&gt; &lt;NUM&gt;3&lt;/NUM&gt; &lt;/ORDER_ITEM&gt; &lt;ORDER_ITEM&gt; &lt;GOODS_NAME&gt; 旺仔 &lt;/GOODS_NAME&gt; &lt;NUM&gt;10&lt;/NUM&gt; &lt;/ORDER_ITEM&gt; &lt;/ORDER_ITEMS&gt;&lt;/ORDER&gt; 而我们要对应的实体类，则应当如下： 12345678910111213141516171819@XmlRootElement(name = \"ORDER\")// &lt;1&gt;@XmlAccessorType(XmlAccessType.FIELD)// &lt;1&gt;public class Order &#123; @XmlElement(name = \"ORDER_NO\")// &lt;1&gt; private String orderNo; @XmlElement(name = \"TOTAL_PRICE\") private BigDecimal totalPrice; @XmlElement(name = \"CREATE_TIME\") @XmlJavaTypeAdapter(DateAdapter.class) // &lt;2&gt; private Date createTime; @XmlElementWrapper(name = \"ORDER_ITEMS\") // &lt;3&gt; @XmlElement(name = \"ORDER_ITEM\") private List&lt;OrderItem&gt; orderItems;&#125; 12345678910@XmlAccessorType(XmlAccessType.FIELD)public class OrderItem &#123; @XmlElement(name = \"GOODS_NAME\") private String goodsName; @XmlElement(name = \"NUM\") private Integer num;&#125; 我举的这个示例基本包含一般情况下所有可能出现的需求 常用注解 XmlRootElement，XmlAccessorType，XmlElement 日期转换的适配器注解 如何在 XML 中设置集合 在介绍这三点之前，先给出转换的工具类","text":"XML 可以说是一种被时代淘汰的数据传输格式，毕竟相比较 JSON，其语法，表现形式，以及第三方类库的支持，都要略逊一筹，但最近在对接一些老接口时，主要还是以 XML 为主，而翻阅相关的文档以及博客，没看到很好的文章介绍如何使用 xml 进行数据传输，所以简单写下此文，做一下记录。内心多多少少还是会抵制对接如此老旧的接口，不过生活还是要继续。 Code First先上一段代码，展示一下如何封装，讲解放到后面 一个典型的对接方提供的 XML 如下： 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?&gt;&lt;ORDER&gt; &lt;ORDER_NO&gt;10086&lt;/ORDER_NO&gt; &lt;TOTAL_PRICE&gt;3.14&lt;/TOTAL_PRICE&gt; &lt;CREATE_TIME&gt;2017-08-26 03:39:30&lt;/CREATE_TIME&gt; &lt;ORDER_ITEMS&gt; &lt;ORDER_ITEM&gt; &lt;GOODS_NAME&gt; 德芙 &lt;/GOODS_NAME&gt; &lt;NUM&gt;3&lt;/NUM&gt; &lt;/ORDER_ITEM&gt; &lt;ORDER_ITEM&gt; &lt;GOODS_NAME&gt; 旺仔 &lt;/GOODS_NAME&gt; &lt;NUM&gt;10&lt;/NUM&gt; &lt;/ORDER_ITEM&gt; &lt;/ORDER_ITEMS&gt;&lt;/ORDER&gt; 而我们要对应的实体类，则应当如下： 12345678910111213141516171819@XmlRootElement(name = \"ORDER\")// &lt;1&gt;@XmlAccessorType(XmlAccessType.FIELD)// &lt;1&gt;public class Order &#123; @XmlElement(name = \"ORDER_NO\")// &lt;1&gt; private String orderNo; @XmlElement(name = \"TOTAL_PRICE\") private BigDecimal totalPrice; @XmlElement(name = \"CREATE_TIME\") @XmlJavaTypeAdapter(DateAdapter.class) // &lt;2&gt; private Date createTime; @XmlElementWrapper(name = \"ORDER_ITEMS\") // &lt;3&gt; @XmlElement(name = \"ORDER_ITEM\") private List&lt;OrderItem&gt; orderItems;&#125; 12345678910@XmlAccessorType(XmlAccessType.FIELD)public class OrderItem &#123; @XmlElement(name = \"GOODS_NAME\") private String goodsName; @XmlElement(name = \"NUM\") private Integer num;&#125; 我举的这个示例基本包含一般情况下所有可能出现的需求 常用注解 XmlRootElement，XmlAccessorType，XmlElement 日期转换的适配器注解 如何在 XML 中设置集合 在介绍这三点之前，先给出转换的工具类 转换工具类1234567891011121314151617181920212223242526272829public class XML &#123; public static String toXmlString(Object obj) &#123; String result; try &#123; JAXBContext context = JAXBContext.newInstance(obj.getClass()); Marshaller marshaller = context.createMarshaller(); StringWriter writer = new StringWriter(); marshaller.marshal(obj, writer); result = writer.toString(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return result; &#125; public static &lt;T&gt; T parseObject(String input, Class&lt;T&gt; claaz) &#123; Object result; try &#123; JAXBContext context = JAXBContext.newInstance(claaz); Unmarshaller unmarshaller = context.createUnmarshaller(); result = unmarshaller.unmarshal(new StringReader(input)); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return (T) result; &#125;&#125; JSON 工具类中，笔者习惯于使用 fastjson，所以干脆连同工具类类名命名和方法命名都按照了它的风格，只有两个方法。 注解的介绍给实体类加上注解，再使用工具类，就可以实现实体和 XML 的相互转换了。那么前面提到的三个注意点中的相关注解分别代表了什么含义呢？ @XmlRootElement 作用域：类 代表一个 XML 对象的根节点，常使用 name 属性来可以指定生成 XML 之后的具体名称 @XmlElement 作用域：字段，方法，参数（不常用） 代表一个 XML 对象的普通界点信息，常使用 name 属性来指定生成 XML 之后的具体名称。需要注意与 @XmlAccessorType 搭配使用时，有一些注意点，见下 @XmlAccessorType 作用域：类，包（不常用） 告诉解析器，在解析 XML 时要如何获取类的字段属性，有 4 个枚举类型： | 枚举类型 | 访问方式 || ——————————- | ——————————- || XmlAccessType.FIELD | 成员变量 || XmlAccessType.PROPERTY | public getter,setter || XmlAccessType.PUBLIC_MEMBER（默认） | public getter,setter+public 成员变量 || XmlAccessType.NONE | 必须显示指定 @XmlElement | 我们上述的例子中，使用的方式是在类上配置 @XmlAccessorType(XmlAccessType.FIELD)，基于成员变量访问属性，并且，在每一个成员变量之上都显示指定了 name=xxx；而如果配置 @XmlAccessorType(XmlAccessType.PUBLIC_MEMBER) 即默认配置，则你需要将 @XmlElement 注解写在 getter 方法上, 笔者比较习惯例子中的写法。需要注意点的一点是，如果 @XmlAccessorType 与 @XmlElement 的配置不对应，很容易触发自动的转换方式，会导致某个节点出现两次的异常。 @XmlJavaTypeAdapter 作用域：字段, 方法, 类, 包, 参数（前三者常用） java 内置的 xml 日期转换类不能满足我们的需求（可以动手试试看默认日期的格式是什么），以及遇到自定义的类，需要配置转换器，就可以使用这个注解，@XmlJavaTypeAdapter 注解接收一个自定义的 Adapter，需要继承自 XmlAdapter&lt;ValueType,BoundType&gt; 抽象类，一个常用的日期转化适配器如下： 1234567891011121314151617181920212223public class DateAdapter extends XmlAdapter&lt;String, Date&gt; &#123; static ThreadLocal&lt;DateFormat&gt; sdf ; static &#123; sdf =new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); &#125; &#125;; &#125; @Override public Date unmarshal(String v) throws Exception &#123; return sdf.get().parse(v); &#125; @Override public String marshal(Date v) throws Exception &#123; return sdf.get().format(v); &#125;&#125; 使用 Adapter 的弊端也很明显，一个适配器只能对应一个日期的格式，在实际开发中我们往往会将日期区分成天维度的日期和秒维度的日期，不能像大多数 JSON 那样拥有灵活的注解，如果有读者有想到好的解决方案，欢迎跟我沟通。涉及到日期格式转化，时刻不要忘记 SimpleDateFormat 线程不安全这一点。 @XmlElementWrapper XML 中表示集合时，在最外层通常会有一个 Xxxs 或者 XxxList 这样的标签，可以通过 @XmlElementWrapper 实现，其中 name 就代表额外添加的包裹信息是什么, 如上文的 OrderItems。 一些其他的转换工具类我们主要任务是实现 XML 字符串和 javabean 之间转换，不是解析 XML，所以 dom4j 一类的类库不用考虑。熟悉 spring 的人会了解到一点，spring 其实已经封装了 xml 转换相关的类，即 org.springframework.oxm.jaxb.Jaxb2Marshaller 这个类，他的顶层接口是 org.springframework.oxm.Marshaller 和 org.springframework.oxm.UnMarshaller。而在 java 规范中，也存在同名的接口：javax.xml.bind.Marshaller,javax.xml.bind.UnMarshaller，这点在使用中需要注意下。笔者的建议是，这种数据格式转换操作，应当尽量引入最少的依赖。所以使用 javax 的类库下的相关方法进行封装。上述的工具类，仅仅只需要引入 javax 包，即可使用了。非常方便、","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"XML","slug":"XML","permalink":"http://lexburner.github.io/tags/XML/"}]},{"title":"sinosoft 代码规范","slug":"project-rules","date":"2017-08-25T04:18:45.000Z","updated":"2019-09-26T09:45:31.019Z","comments":true,"path":"project-rules/","link":"","permalink":"http://lexburner.github.io/project-rules/","excerpt":"","text":"介绍本文档主要针对我们项目内部正在使用的框架，以及代码审查发现的一些共性问题提出一些开发规范。 JavaBean 规范1 驼峰命名法【强制】 2 布尔类型规范【强制】【说明】所有的布尔类型不允许以 is 开头，否则会导致部分序列化，hibernate 框架出现解析异常。【反例】原来项目的 BaseDomain 中标记逻辑删除的字段, 在部分场景下会出现问题 123456789101112@Column(name = \"is_delete\")private Boolean isDelete = false;public Boolean getIsDelete() &#123; return isDelete; &#125;public void setIsDelete(Boolean isDelete) &#123; if(deleteFlag) this.deleteDate = new Date(); this.isDelete = isDelete;&#125; tips: 使用 intellij idea 的快捷键（for eclipse）alt+shift+r，或者菜单栏 Refactor-&gt;Rename，可以重构字段名称【正例】 12@Column(name = \"is_delete\")private Boolean deleteFlag = false; 3 装箱类型优于原生类型【推荐】在业务代码中，更加推荐使用装箱类型 Integer Double Boolean…【说明】在未设值的情况下，基础类型具有默认值，而装箱类型为 null以 Boolean 类型为例，如果使用 boolean，那么在未复制时，无法得知其到底是被赋值成了 false，还是未赋值 领域模型规范首先理解各个常用的领域模型的含义： 领域模型 全称 中文含义 DO Domain Object 领域对象 DTO Data Transfer Object 数据传输对象 VO View Object 视图对象 对于 View Object，PO 等等其他一些的对象不在此做要求，只说明一下常用的几个DO 就是我们最常用的数据库持久对象，是 OOP 对于现实中的抽象，一般使用 orm 框架映射到数据库DTO 这一层，目前我们的项目还没有投入使用，即将考虑投入使用，理论上来说，两个微服务模块是严禁共享数据库的所以 A 模块要查询 B 模块的数据，需要使用 B 模块 app 层暴露出来的 api 来查询，其中 B 模块返回的实体，不能是直接从数据库中查询出来的 DO，而应该是 DO 转换而成的 DTO。以及其他服务服务用语传输的变量，都叫做 DTOVO 就是常存在于视图层模板渲染使用的实体类 【推荐】领域模型命名规范【说明】由于 DO 这一层大家已经养成了习惯，不做要求了。DTO 有些特殊，他常常与业务的传输对象相关，而不限于以 Dto 结尾，如 xxxQuery 也可以是 DTO 对象。VO 对象推荐以 Vo 结尾 包结构规范1 包命名【强制】 格式如下：公司名. 模块名. 层次名包名应当尽量使用能够概括模块总体含义, 单词义, 单数, 不包含特殊字符的单词【正例】: sinosoftgz.message.admin【反例】: sinosoftgz.mailsms.admin sinosoftgz.mail.sms.admin 2 包结构【推荐】当项目模块的职责较为复杂，且考虑到以后拓展的情况下，单个模块依旧包含着很多小的业务模块时，应当优先按照业务区分包名 【反例】: 123456789101112131415161718192021sinosoftgz.message.admin config 模块公用 Config.java service 模块公用 Service.java Mail 私有 Service.java MailTemplateService.java MailMessageService.java Sms 私有 Service.java SmsTemplateService.java SmsMessageService.java web 模块公用 Controller.java IndexController.java Mail 私有 Controller.java MailTemplateController.java MailMessageController.java Sms 私有 Controller.java SmsTemplateController.java SmsMessageController.java MailSmsAdminApp.java 【正例】: 12345678910111213141516171819202122232425262728293031sinosoftgz.message.admin config 模块公用 Config.java service 模块公用 Service.java web 模块公用 Controller.java IndexController.java mail config MailConfig.java service Mail 私有 Service.java MailTemplateService.java MailMessageService.java web Mail 私有 Controller.java MailTemplateController.java MailMessageController.java sms config Smsconfig.java service Sms 私有 Service.java SmsTemplateService.java SmsMessageService.java web Sms 私有 Controller.java SmsTemplateController.java SmsMessageController.java MessageAdminApp.java service 和 controller 以及其他业务模块相关的包相隔太远，或者干脆全部丢到一个包内，单纯用前缀区分，会形成臃肿，充血的包结构。如果是项目结构较为单一，可以仅仅使用前缀区分；如果是项目中业务模块有明显的区分条件，应当单独作为一个包，用包名代表业务模块的含义。 容易忽视的细节1 运算溢出【强制】 【反例】Integer a = Integer b * Integer c; 【正例】Long a = Integer b * Integer c;(强转) 整数相乘可能会溢出，需要使用 Long 接收 2 Double 类型的精度问题【强制】 Double 不能用于商业计算，使用 BigDecimal 代替 3 BigDecimal 规范【强制】 【反例】 12BigDecimal totalMoney = new BigDecimal(\"100.42\");BigDecimal averageMoney = totalMoney.divide(new BigDecimal(\"22\")); 【正例】 12BigDecimal totalMoney = new BigDecimal(\"100.42\");BigDecimal averageMoney = totalMoney.divide(new BigDecimal(\"22\"),3); 业务实体类中的与金额相关的变量统一使用 BigDecimal, 四则运算采用 BigDecimal 的相关 api 进行。做 除法 时需要额外注意保留精度的问题，否则可能会报异常，并且不易被测试出 4 equals 规范【强制】 【反例】 123456Integer a = 2333;Integer b = 2333;System.out.println(a == b);//fasleInteger a = 2;Integer b = 2;System.out.println(a == b);//true 【正例】 1a.equals(b) 要注意正确的比较方法，谨慎使用 ==，它比较的是引用 数据库规范1 必要的地方必须添加索引，如唯一索引，作为条件查询的列【强制】 不添加索引，会造成全表扫描，浪费性能。 2 生产环境，uat 环境，不允许使用 jpa.hibernate.ddl-auto: create 自动建表，每次 ddl 的修改需要保留脚本，统一管理【强制】3 业务数据不能使用 deleteBy… 而要使用逻辑删除 setDeleteFlag(true), 查询时，findByxxxAndDeleteFlag(xxx,false)【强制】 4 如有可替代方案，则禁止使用存储过程和触发器【强制】 5 字段的长度和类型需要按照实际含义定制【推荐】 【反例】 12345@Entityclass Person&#123; private String name; private Integer age;&#125; 【正例】 1234567@Entityclass Person&#123; @Column(columnDefinition = \"varchar(50)\") private String name; @Column(columnDefinition = \"int(3)\") private Integer age;&#125; 明确字段的长度和类型可以迫使开发者去思考字段所处的业务场景，在性能上，字段长度也可以加强索引的性能。 6 使用外键不要使用数据库层面的约束【强制】 不便于数据迁移，统一在应用层控制关联。 ORM 规范【强制】条件查询超过三个参数的，使用 criteriaQuery，predicates 而不能使用 springdata 的 findBy 【反例】 12345678910111213public Page&lt;GatewayApiDefine&gt; findAll(GatewayApiDefine gatewayApiDefine,Pageable pageable)&#123; if(Lang.isEmpty(gatewayApiDefine.getRole()))&#123; gatewayApiDefine.setRole(\"\"); &#125; if(Lang.isEmpty(gatewayApiDefine.getApiName()))&#123; gatewayApiDefine.setApiName(\"\"); &#125; if(Lang.isEmpty(gatewayApiDefine.getEnabled()))&#123; return gatewayApiDefineDao.findByRoleLikeAndApiNameLikeOrderByLastUpdatedDesc(\"%\"+gatewayApiDefine.getRole()+\"%\",\"%\"+gatewayApiDefine.getApiName()+\"%\",pageable); &#125;else&#123; return gatewayApiDefineDao.findByRoleLikeAndApiNameLikeAndEnabledOrderByLastUpdatedDesc(\"%\"+gatewayApiDefine.getRole()+\"%\",\"%\"+gatewayApiDefine.getApiName()+\"%\",gatewayApiDefine.getEnabled(),pageable); &#125; &#125; 在 Dao 层定义了大量的 findBy 方法，在 Service 写了过多的 if else 判断，导致业务逻辑不清晰 【正例】 123456789101112131415161718192021222324252627public Page&lt;MailTemplateConfig&gt; findAll(MailTemplateConfig mailTemplateConfig, Pageable pageable) &#123; Specification querySpecification = (Specification&lt;MailTemplateConfig&gt;) (root, criteriaQuery, criteriaBuilder) -&gt; &#123; List&lt;Predicate&gt; predicates = new ArrayList&lt;&gt;(); predicates.add(criteriaBuilder.isFalse(root.get(\"deleteFlag\"))); // 级联查询 mailTemplate if (!Lang.isEmpty(mailTemplateConfig.getMailTemplate())) &#123; // 短信模板名称 if (!Lang.isEmpty(mailTemplateConfig.getMailTemplate().getTemplateName())) &#123; predicates.add(criteriaBuilder.like(root.join(\"mailTemplate\").get(\"templateName\"), String.format(\"%%%s%%\", mailTemplateConfig.getMailTemplate().getTemplateName()))); &#125; // 短信模板类型 if (!Lang.isEmpty(mailTemplateConfig.getMailTemplate().getTemplateType())) &#123; predicates.add(criteriaBuilder.equal(root.join(\"mailTemplate\").get(\"templateType\"), mailTemplateConfig.getMailTemplate().getTemplateType())); &#125; &#125; // 产品分类 if (!Lang.isEmpty(mailTemplateConfig.getProductType())) &#123; predicates.add(criteriaBuilder.equal(root.get(\"productType\"), mailTemplateConfig.getProductType())); &#125; // 客户类型 if (!Lang.isEmpty(mailTemplateConfig.getConsumerType())) &#123; predicates.add(criteriaBuilder.equal(root.get(\"consumerType\"), mailTemplateConfig.getConsumerType())); &#125; return criteriaBuilder.and(predicates.toArray(new Predicate[predicates.size()])); &#125;; return mailTemplateConfigRepos.findAll(querySpecification, pageable); &#125; 条件查询是 admin 模块不可避免的一个业务功能，使用 criteriaQuery 可以轻松的添加条件，使得代码容易维护，他也可以进行分页，排序，连表操作，充分发挥 jpa 面向对象的特性，使得业务开发变得快捷。 数据结构1 集合中迭代过程中增删数据使用迭代器完成 【反例】 12345678List&lt;String&gt; a = new ArrayList&lt;String&gt;();a.add(\"1\"); a.add(\"2\"); for (String temp : a) &#123; if(\"1\".equals(temp))&#123; a.remove(temp); &#125; &#125; 【正例】 1234567Iterator&lt;String&gt; it = a.iterator(); while(it.hasNext())&#123; String temp = it.next(); if((\"1\".equals(temp))&#123; it.remove(); &#125; &#125; 2 hashCode 和 equals 重写规范【强制】 作为 Map 键值，Set 值的实体类，务必重写 hashCode 与 equals 方法，可参考《effective java》。重写时务必做到以下几点 自反性 : x.equals(x) 一定是 true 对 null: x.equals(null) 一定是 false 对称性 : x.equals(y) 和 y.equals(x) 结果一致 传递性 : a 和 b equals , b 和 c equals，那么 a 和 c 也一定 equals。 一致性 : 在某个运行时期间，2 个对象的状态的改变不会不影响 equals 的决策结果，那么，在这个运行时期间，无论调用多少次 equals，都返回相同的结果。做到无状态。 禁止使用魔法数字【模型层与业务层】【强制】一些固定业务含义的代码可以使用枚举类型，或者 final static 常量表示，在设值时，不能直接使用不具备业务含义的数值。 【反例】 1234567891011// 实体类定义/** * 发送设置标志 (1：立即发送 2：预设时间发送) */@Column(columnDefinition = \"varchar(1) comment' 发送设置标志 '\")protected String sendFlag;// 业务代码赋值使用MailMessage mailMessage = new MailMessage();mailMessage.setSendSuccessFlag(\"1\");mailMessage.setValidStatus(\"0\");mailMessage.setCustom(true); 【正例】：使用 final static 常量: 1234567891011121314151617181920212223242526272829303132333435// 实体类定义 /** * 发送设置标志 * * @see sendFlag */ public final static String SEND_FLAG_NOW = \"1\"; // 立即发送 public final static String SEND_FLAG_DELAY = \"2\"; // 预设时间发送 /** * 发送成功标志 * * @see sendSuccessFlag */ public final static Map&lt;String, String&gt; SEND_SUCCESS_FLAG_MAP = new LinkedHashMap&lt;&gt;(); public final static String SEND_WAIT = \"0\"; public final static String SEND_SUCCESS = \"1\"; public final static String SEND_FAIL = \"2\"; static &#123; SEND_SUCCESS_FLAG_MAP.put(SEND_WAIT, \"未发送\"); SEND_SUCCESS_FLAG_MAP.put(SEND_SUCCESS, \"发送成功\"); SEND_SUCCESS_FLAG_MAP.put(SEND_FAIL, \"发送失败\"); &#125; /** * 发送设置标志 (1：立即发送 2：预设时间发送) */ @Column(columnDefinition = \"varchar(1) comment' 发送设置标志 '\") protected String sendFlag;// 业务代码赋值使用MailMessage mailMessage = new MailMessage();mailMessage.setSendSuccessFlag(MailMessage.SEND_WAIT);mailMessage.setValidStatus(MailMessage.VALID_WAIT);mailMessage.setCustom(true); 【说明】魔法数字不能使代码一眼能够看明白到底赋的是什么值，并且，实体类发生变化后，可能会导致赋值错误，与预期赋值不符合且错误不容易被发现。 【正例】：也可以使用枚举类型避免魔法数字 1234567891011121314151617181920212223242526protected String productType;protected String productName;@Enumerated(EnumType.STRING)protected ConsumerTypeEnum consumerType;@Enumerated(EnumType.STRING)protected PolicyTypeEnum policyType;@Enumerated(EnumType.STRING)protected ReceiverEnum receiver;public enum ConsumerTypeEnum &#123; PERSONAL, ORGANIZATION; public String getLabel() &#123; switch (this) &#123; case PERSONAL: return \"个人\"; case ORGANIZATION: return \"团体\"; default: return \"\"; &#125; &#125;&#125; 【视图层】【推荐】例如，页面迭代 select 的 option，不应该在 view 层判断，而应该在后台传入 map 在前台迭代【正例】：12345678model.put(\"typeMap\",typeMap);模板类型：&lt;select type=\"text\" name=\"templateType\"&gt; &lt;option value=\"\"&gt; 全部 &lt;/option&gt; &lt;#list typeMap?keys as key&gt; &lt;option &lt;#if ((mailTemplate.templateType!\"\")==key)&gt;selected=\"selected\"&lt;/#if&gt;value=\"$&#123;key&#125;\"&gt;$&#123;typeMap[key]&#125;&lt;/option&gt; &lt;/#list&gt;&lt;/select&gt; 【反例】：12345678模板类型：&lt;select type=\"text\" name=\"templateType\"&gt; &lt;option value=\"\"&gt; 全部 &lt;/option&gt; &lt;option &lt;#if $&#123;xxx.templateType!&#125;==\"1\" selected=\"selected\"&lt;/#if&gt; value=\"1\"&gt; 承保通知 &lt;/option&gt; ... &lt;option &lt;#if $&#123;xxx.templateType!&#125;==\"5\" selected=\"selected\"&lt;/#if&gt; value=\"5\"&gt; 核保通知 &lt;/option&gt;&lt;/select&gt; 否则修改后台代码后，前端页面也要修改，设计原则应当是修改一处，其他全部变化。且 1，2…,5 的含义可能会变化，不能从页面得知 value 和 option 的含义是否对应。 并发处理项目中会出现很多并发问题，要做到根据业务选择合适的并发解决方案，避免线程安全问题 1 simpleDateFormat 有并发问题，不能作为 static 类变量【强制】【反例】：这是我在某个项目模块中，发现的一段代码1234567891011Class XxxController&#123; public final static SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); @RequestMapping(\"/xxxx\") public String xxxx(String dateStr)&#123; XxxEntity xxxEntity = new XxxEntity(); xxxEntity.setDate(simpleDateFormat.parse(dateStr)); xxxDao.save(xxxEntity); return \"xxx\"; &#125;&#125; 【说明】SimpleDateFormat 是线程不安全的类，不能作为静态类变量给多线程并发访问。如果不了解多线程，可以将其作为实例变量，每次使用时都 new 一个出来使用。不过更推荐使用 ThreadLocal 来维护，减少 new 的开销。【正例】一个使用 ThreadLocal 维护 SimpleDateFormat 的线程安全的日期转换类：1234567891011121314151617public class ConcurrentDateUtil &#123; private static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); &#125; &#125;; public static Date parse(String dateStr) throws ParseException &#123; return threadLocal.get().parse(dateStr); &#125; public static String format(Date date) &#123; return threadLocal.get().format(date); &#125;&#125; 2 名称唯一性校验出现的线程安全问题【推荐】各个项目的 admin 模块在需求中经常会出现要求名称不能重复，即唯一性问题。通常在前台做 ajax 校验，后台使用 select count(1) from table_name where name=? 的方式查询数据库。这么做无可厚非，但是在极端的情况下，会出现并发问题。两个线程同时插入一条相同的 name，如果没有做并发控制，会导致出现脏数据。如果仅仅是后台系统，那么没有必要加锁去避免，只需要对数据库加上唯一索引，并且再 web 层或者 service 层捕获数据异常即可。【正例】： 12345678910111213141516171819202122232425262728293031323334353637// 实体类添加唯一索引@Entity@Table(name = \"mns_mail_template\", uniqueConstraints = &#123;@UniqueConstraint(columnNames = &#123;\"templateName\"&#125;)&#125;)public class MailTemplate extends AbstractTemplate &#123; /** * 模板名称 */ @Column(columnDefinition = \"varchar(160) comment' 模板名称 '\") private String templateName;&#125;// 业务代码捕获异常@RequestMapping(value = &#123;\"/saveOrUpdate\"&#125;, method = RequestMethod.POST) @ResponseBody public AjaxResponseVo saveOrUpdate(MailTemplate mailTemplate) &#123; AjaxResponseVo ajaxResponseVo = new AjaxResponseVo(AjaxResponseVo.STATUS_CODE_SUCCESS, \"操作成功\", \"邮件模板定义\", AjaxResponseVo.CALLBACK_TYPE_CLOSE_CURRENT); try &#123; // 管理端新增时初始化一些数据 if (Lang.isEmpty(mailTemplate.getId())) &#123; mailTemplate.setValidStatus(MailTemplate.VALID_WAIT); &#125; mailTemplateService.save(mailTemplate); &#125; catch (DataIntegrityViolationException ce) &#123; ajaxResponseVo.setStatusCode(AjaxResponseVo.STATUS_CODE_ERROR); ajaxResponseVo.setMessage(\"模板名称已经存在\"); ajaxResponseVo.setCallbackType(null); logger.error(ce); &#125; catch (Exception e) &#123; ajaxResponseVo.setStatusCode(AjaxResponseVo.STATUS_CODE_ERROR); ajaxResponseVo.setMessage(\"操作失败!\"); ajaxResponseVo.setCallbackType(null); logger.error(e); &#125; return ajaxResponseVo; &#125; 【说明】关于其他一些并发问题, 如分布式锁，CAS，不仅仅是一篇文档能够讲解清楚的，需要对开发有很深的理解。 3 余额扣减，库存扣减，积分发放等敏感并发操作【强制】 这一块通常交给有经验的开发来完成，但所有人都需要注意。原则是事务保障，幂等保障等等设计原则。 【反例】 123456//Transaction startUser user = UserDao.findById(\"1\");user.setBalance(user.getBalance()+100.00);...// 其他耗时操作UserDao.save(user);//Transaction commit 【正例】 12345678//Transaction startlock...User user = UserDao.findById(\"1\");user.setBalance(user.getBalance()+100.00);...// 其他耗时操作UserDao.save(user);release lock...//Transaction commit 并发场景必须加锁，根据业务场景决定到底加什么锁，sychronized，ReentrantLock，version 乐观锁，for update 悲观锁（不推荐），redis，zookeeper 实现的分布式锁等等。 moton 使用注意事项1 包的扫描【注意】 每个模块都要扫描自身的项目结构12345678910mail-sms-admin:application.ymlmotan: client-group: sinosoftrpc client-access-log: false server-group: sinosoftrpc server-access-log: false export-port: $&#123;random.int[9001,9999]&#125; zookeeper-host: 127.0.0.1:2181 annotaiong-package: sinosoftgz.message.admin app 模块由于将 api-impl 脱离出了自身的模块，通常还需要扫描 api-impl 的模块 配置 pom.xml 依赖 1234&lt;dependency&gt; &lt;groupId&gt;sinosoftgz&lt;/groupId&gt; &lt;artifactId&gt;mail-sms-api-impl&lt;/artifactId&gt;&lt;/dependency&gt; 配置 spring ioc 扫描 AutoImportConfig.java 123@ComponentScans(&#123; @ComponentScan(basePackages = &#123;\"sinosoftgz.message.app\", \"sinosoftgz.message.api\"&#125;)&#125;) 配置 motan 扫描 mail-sms-app:application.yml 12345678motan: annotaiong-package: sinosoftgz.message.app,sinosoftgz.message.api client-group: sinosoftrpc client-access-log: true server-group: sinosoftrpc server-access-log: true export-port: $&#123;random.int[9001,9999]&#125; zookeeper-host: localhost:2181 2 motan 跨模块传输实体类时懒加载失效【注意】遇到的时候注意一下，由于 jpa，hibernate 懒加载的问题，因为其内部使用动态代理去实现的懒加载，导致懒加载对象无法被正确的跨模块传输，此时需要进行深拷贝。【正例】： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 深拷贝 OrderMain 对象，主要用于防止 Hibernate 序列化懒加载 Session 关闭问题 * &lt;p/&gt; * // * @param order * * @return */ public OrderMain cpyOrder(OrderMain from, OrderMain to) &#123; OrderMain orderMainNew = to == null ? new OrderMain() : to; Copys copys = Copys.create(); List&lt;OrderItem&gt; orderItemList = new ArrayList&lt;&gt;(); List&lt;SubOrder&gt; subOrders = new ArrayList&lt;&gt;(); List&lt;OrderGift&gt; orderGifts = new ArrayList&lt;&gt;(); List&lt;OrderMainAttr&gt; orderMainAttrs = new ArrayList&lt;&gt;(); OrderItem orderItemTmp; SubOrder subOrderTmp; OrderGift orderGiftTmp; OrderMainAttr orderMainAttrTmp; copys.from(from).excludes(\"orderItems\", \"subOrders\", \"orderGifts\", \"orderAttrs\").to(orderMainNew).clear(); if (!Lang.isEmpty(from.getOrderItems())) &#123; for (OrderItem i : from.getOrderItems()) &#123; orderItemTmp = new OrderItem(); copys.from(i).excludes(\"order\").to(orderItemTmp).clear(); orderItemTmp.setOrder(orderMainNew); orderItemList.add(orderItemTmp); &#125; orderMainNew.setOrderItems(orderItemList); &#125; SubOrderItem subOrderItem; List&lt;SubOrderItem&gt; subOrderItemList = new ArrayList&lt;&gt;(); if (from.getSubOrders() != null) &#123; for (SubOrder s : from.getSubOrders()) &#123; subOrderTmp = new SubOrder(); copys.from(s).excludes(\"order\", \"subOrderItems\").to(subOrderTmp).clear(); subOrderTmp.setOrder(from); for (SubOrderItem soi : s.getSubOrderItems()) &#123; subOrderItem = new SubOrderItem(); copys.from(soi).excludes(\"order\", \"subOrder\", \"orderItem\").to(subOrderItem).clear(); subOrderItem.setOrder(orderMainNew); subOrderItem.setSubOrder(subOrderTmp); subOrderItemList.add(subOrderItem); if (!Lang.isEmpty(soi.getOrderItem())) &#123; for (OrderItem i : orderMainNew.getOrderItems()) &#123; if (i.getId().equals(soi.getOrderItem().getId())) &#123; subOrderItem.setOrderItem(soi.getOrderItem()); &#125; else &#123; subOrderItem.setOrderItem(soi.getOrderItem()); &#125; &#125; &#125; &#125; subOrderTmp.setSubOrderItems(subOrderItemList); subOrders.add(subOrderTmp); &#125; orderMainNew.setSubOrders(subOrders); &#125; if (from.getOrderGifts() != null) &#123; for (OrderGift og : from.getOrderGifts()) &#123; orderGiftTmp = new OrderGift(); copys.from(og).excludes(\"order\").to(orderGiftTmp).clear(); orderGiftTmp.setOrder(orderMainNew); orderGifts.add(orderGiftTmp); &#125; orderMainNew.setOrderGifts(orderGifts); &#125; if (from.getOrderAttrs() != null) &#123; for (OrderMainAttr attr : from.getOrderAttrs()) &#123; orderMainAttrTmp = new OrderMainAttr(); copys.from(attr).excludes(\"order\").to(orderMainAttrTmp).clear(); orderMainAttrTmp.setOrder(orderMainNew); orderMainAttrs.add(orderMainAttrTmp); &#125; orderMainNew.setOrderAttrs(orderMainAttrs); &#125; return orderMainNew; &#125; 公用常量规范1 模块常量【强制】模块自身公用的常量放置于模块的 Constants 类中，以 final static 的方式声明1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class Constants &#123; public static final String birthdayPattern = \"yyyy-MM-dd\"; // 生日格式 public static final String inputTimePattern = \"yyyy-MM-dd HH:mm:ss\"; // 录入时间格式 public static class PolicyType &#123; public static final String personal = \"0\"; // 个单 public static final String group = \"1\"; // 团单 &#125; public static class InsuredNature &#123; public static final String naturePerson = \"1\"; // 自然人 public static final String artificialPerson = \"0\"; // 法人 &#125; public static class InsuredIdentity &#123; public static final String myself = \"0\"; // 本人 &#125; public static class JfeeFlag &#123; public static final String noFeeFlag = \"0\"; // 非见费标志 public static final String feeFlag = \"1\"; // 见费标志 &#125; public static class ItemKindFlag &#123; public static final String mainRiskFlag = \"1\"; // 主险标志 public static final String additionalRiskFlag = \"2\"; // 附加险标志 public static final String otherRiskFlag = \"3\"; // 其它标志 &#125; public static class CalculateAmountFlag &#123; public static final String calculateFlag = \"Y\"; // 计算保额标志 public static final String noCalculateFlag = \"N\"; // 不计算保额标志 &#125; public static class LimitGrade &#123; public static final String policyLevel = \"1\"; // 限额 / 免赔保单级别 public static final String clauseLevel = \"2\"; // 限额 / 免赔条款级别 &#125; /** * 批改类型 * * 命名规则：对象（可选）+ 行为 */ public static class EndorType &#123; public static final String collectivePolicyInsuredModify = \"22\"; // 团单变更被保险人 public static final String collectivePolicyInsuredAdd = \"Z1\"; // 团单批增被保险人 public static final String collectivePolicyInsuredRemove = \"J1\"; // 团单批减被保险人 public static final String surrender = \"04\"; // 全单退保 public static final String withdraw = \"05\"; // 注销 public static final String insurancePeriodModify = \"06\"; // 平移保险期限 public static final String applicantModify = \"H01\"; // 更改投保人 public static final String customerModify = \"50\"; // 变更客户信息 public static final String insuredModify = \"29\"; // 变更被保人职业 public static final String individualPolicyBeneficiaryModify = \"03\"; // 变更受益人信息 public static final String engageModify = \"15\"; // 变更特别约定 public static final String individualPolicyInsuredModify = \"77\";// 个单变更被保人 &#125;&#125; Constants 类在一个限界上下文只能有一个，一个限界上下文包含了一整个业务模块（如 policy-admin,policy-admin,policy-api,policy-model）构成一个限界上下文 在 Constants 类中使用静态内部类尽量细化到常量的归属，不要散放 2 项目常量【强制】项目公用的常量放置于 util 模块的 GlobalContants 类中，以内部类和 final static 的方式声明 1234567891011121314151617181920public abstract class GlobalContants &#123; /** * 返回的状态 */ public class ResponseStatus&#123; public static final String SUCCESS = \"success\";// 成功 public static final String ERROR = \"error\";// 错误 &#125; /** * 响应状态 */ public class ResponseString&#123; public static final String STATUS = \"status\";// 状态 public static final String ERROR_CODE = \"error\";// 错误代码 public static final String MESSAGE = \"message\";// 消息 public static final String DATA = \"data\";// 数据 &#125; ...&#125; 日志规范1 打印日志时不允许拼接字符串【强制】 【反例】log.debug (“Load No.” + i + “object,” + object); 【正例】log.debug(“Load No.{} object, {}” , i , object); 字符串的计算是在编译期，日志级别如果是 INFO，就等于在浪费机器的性能，无谓的字符串拼接。 2 预防空指针【强制】 【反例】log.debug(“Load student(id={}), name: {}” , id , student.getName() ); 【正例】log.debug(“Load student(id={}), student: {}” , id , student); 不要在日志中调用对象的方法获取值，除非确保该对象肯定不为 null，否则很有可能会因为日志的问题而导致应用产生空指针异常。实现需要打印日志的实体类的 toString 方法或者使用 JSON.toString 3 输出异常信息 【反例】log.error(e.getMessage,e); log.error(“邮件发送失败，接收人姓名：{} ，e : {}”, username, e); 【正例】log.error(“邮件发送失败，接收人姓名：{}”, username, e); e 包含了全部的异常堆栈信息，是 e.getMessage 的父集，出现异常一定要保证输出堆栈信息。并且要保证 exception 作为 log 的重载方法的最后一个参数。 4 Logger 声明规范 【正例】Logger logger = LoggerFactory.getLogger(Student.class); 保证某个类的字节码作为日志跟踪标识，方便定位日志的出处。 2018-02-27 补充规范日志规范1 与外部对接接口的返回报文需要使用 Info 级别打印，以便于跟踪接口信息 【正例】log.info(“供应商接口返回报文:{}”,JSON.toString(venderDto)); 2 内部接口的关键参数需要使用 Info 级别打印，如下单时的订单号，下单人信息，订单金额等关键信息。 3 一般方法为了方便排查问题，建议打上必要的日志 编码细节1 session，request，response 等 http 生命周期的对象不应该传入 service 层 原因：不便于单元测试；不便于 service 重用 2 注意判空 123456789String memberName = (String) request.getSession().getAttribute(GlobalContants.SESSION_MEMBER_NAME);if(Lang.isE)userService.getByName(memberName); List&lt;UserDto&gt; users = userApi.findByStatus(String status);if()for(UserDto user:users)&#123; &#125; 如果确定不为空，可以不判断；对于不确定的情况一定要做空判断 3 motan 的重试次数 所有的操作分为 CRUD，查询 – 一般可以设置 2 次重试，增删改不可以重试，除非保证幂等。 全局配置设置重试次数应当为 0 次。 123ProtocolConfigBean.setRetries(0);//protocol 级别@MotanService(retries = 2)// 注意! 服务端配置是无效的@MotanReferer(retries = 2)// 有效 referer 级别 motan 中的配置覆盖优先级：method &gt; referer &gt; basic referer &gt; protocol 可以修改单个 service 的重试次数 4 XxxProperties 类代替 @Value @Value 容器加载顺序的导致空值的 bug，使用 @ConfigurationProperties 实现 Properties 类更加面向对象 5 RedisTemplate 和 StringRedisTemplate 的使用细节 RedisTemplate.put(“hello”,”world”); StringRedisTemplate.get(“hello”).equals(“world”) == false 6 及时清理不再使用的代码，可以在系统回归之后的节点或者合并到主干的节点删除注释掉的代码 软件设计原则与微服务设计原则1 接口设计应当符合聚合根模式 orderMain 主订单包含 List 订单项，包含 List 子订单 等等项 设计 Api 时，只能存在一个 orderMainApi ，而不能存在 orderItemApi 和 subOrderApi。 其他模块如何获取订单项 orderItem 的数据？只能通过访问 orderMain ，从中获取 orderItem。 不同服务之间进行远程调用，只能访问对方的聚合根对象。 2 面向对象，函数式，设计模式等编程范式 面向对象：继承，封装，多态 函数式：lamba，streamAPI 设计模式：单例模式，工厂模式，适配器模式，模板方法模式 多范式编程与最小表达力原则 3 DTO 的意义 dto 应该存在于 api 层，不应该存在于 model 层，model 只应该对本模块的 service 可见，web 不可见，其他模块不可见。使用 DTO 解耦模块之间的依赖。 4 Api 层的注释要全 5 ApiImpl 层的意义 仅仅作为转换，不添加任何业务逻辑。ApiImpl 层不应该出现 DO 对象。 6 Stub 的意义 Facede 对于外部接口的调用，使用 Stub 作为外部接口的包装，在本模块的 service 类中需要调用外部 API 时，则应当调用 Stub。Stub 代表着远程接口在本地的代理。 7 DevOps 八荣八耻 以可配置为荣，以硬编码为耻 以互备为荣，以单点为耻 以随时重启为荣，以不能迁移为耻 以整体交付为荣，以部分交付为耻 以无状态为荣，以有状态为耻 以标准化为荣，以特殊化为耻 以自动化工具为荣，以手动和人肉为耻 以无人值守为荣，以人工介入为耻 8 领域驱动设计与微服务设计 实体（Entity）和值对象（Value Object）的区分 实体具有生命周期，需要继承 BaseDomain；值对象没有生命周期，只起到修饰作用。 举例：Protocol 协议下包含 List 协议商品, ProtocolProduct 协议商品包含 List 商品轮播图。 此时 Protocol 是聚合根也是实体，List 介于实体和值对象之间，需要视需求而定，而 ProtocolProductPicture 则必然是值对象属性。 对于实体的删除使用逻辑删除，对于值对象的删除使用物理删除。 数据库操作使用充血模型而不是贫血模型 代码见 ProtocolService，查询使用 Specification 模式，曾经强调过，在公会礼包和协议采购已经在实践。具体表现：Repository 层应该为空实现。update = find + 持久化对象的内存操作 + save 微服务设计 确定领域的限界上下文，微服务的边界。微服务架构是一件好事，逼着大家关注设计软件的合理性，如果原来在单体式架构中领域分析、面向对象设计做不好，换成微服务会把这个问题成倍的放大。微服务架构首先要关注的不是 RPC/ServiceDiscovery/Circuit Breaker 这些概念，也不是 Eureka/Docker/SpringCloud/Zipkin 这些技术框架，而是服务的边界、职责划分，划分错误就会陷入大量的服务间的相互调用和分布式事务中，这种情况微服务带来的不是便利而是麻烦。 线程池注意事项1 如果在每个方法中实例化线程池，那么要在方法结束时 shutdown 线程池，否则会导致内存溢出，导致服务器崩溃。 @Service public class SomeService { ​ ​ public void concurrentExecute() { ​ ExecutorService executorService = Executors.newFixedThreadPool(10); ​ executorService.execute(new Runnable() { ​ @Override ​ public void run() { ​ System.out.println(“executed…”); ​ } ​ }); ​ executorService.shutdown();// 否则 executorService 永远不会被回收 ​ } } 2 线程池嵌套使用可能会导致死锁 @Service 123456789101112131415161718192021public class SomeService &#123; public void concurrentExecute() &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); executorService.execute(new Runnable() &#123; @Override public void run() &#123; // 复用了一个线程池，会导致子任务卡死其他的主任务 executorService.execute(new Runnable() &#123; @Override public voud run() &#123; //doSomething... &#125; &#125;) &#125; &#125;); executorService.shutdown(); &#125;&#125; 3【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 我下面整理了一些 线程池 相关的知识点 ExecutorsExecutors 是一个线程池框架，其最终还是通过 new ThreadPoolExecutor 的方式创建的线程池。Executors 提供了几个工厂方法。但这几种都不应该在生产中直接使用 newSingleThreadExecutor创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 1new ThreadPoolExecutor(1, 1,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()); newFixedThreadPool创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 1new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); newCachedThreadPool创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60 秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。 1new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,new SynchronousQueue&lt;Runnable&gt;()); ThreadPoolExecutor再看看如何使用 ThreadPoolExecutor 创建线程池，我们需要理解各个构造方法的参数： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize - 线程池核心池的大小。maximumPoolSize - 线程池的最大线程数。keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。unit - keepAliveTime 的时间单位。workQueue - 用来储存等待执行任务的队列。threadFactory - 线程工厂。handler - 拒绝策略。 关注点 1 线程池大小线程池有两个线程数的设置，一个为核心池线程数，一个为最大线程数。在创建了线程池后，默认情况下，线程池中并没有任何线程，等到有任务来才创建线程去执行任务，除非调用了 prestartAllCoreThreads()或者 prestartCoreThread() 方法当创建的线程数等于 corePoolSize 时，会加入设置的阻塞队列。当队列满时，会创建线程执行任务直到线程池中的数量等于 maximumPoolSize。 关注点 2 适当的阻塞队列java.lang.IllegalStateException: Queue full方法 抛出异常 返回特殊值 一直阻塞 超时退出插入方法 add(e) offer(e) put(e) offer(e,time,unit)移除方法 remove()poll() take()poll(time,unit)检查方法 element()peek() 不可用 不可用 ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。DelayQueue： 一个使用优先级队列实现的无界阻塞队列。SynchronousQueue： 一个不存储元素的阻塞队列。LinkedTransferQueue： 一个由链表结构组成的无界阻塞队列。LinkedBlockingDeque： 一个由链表结构组成的双向阻塞队列。 关注点 3 明确拒绝策略ThreadPoolExecutor.AbortPolicy: 丢弃任务并抛出 RejectedExecutionException 异常。 (默认)ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 说明：Executors 各个方法的弊端：1）newFixedThreadPool 和 newSingleThreadExecutor:主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至 OOM。2）newCachedThreadPool 和 newScheduledThreadPool:主要问题是线程数最大数是 Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至 OOM。 ## 我推荐的创建线程池的方式： 1 new ThreadPoolExecutor(全参构造) 自己控制 corePoolSize - 线程池核心池的大小。 maximumPoolSize - 线程池的最大线程数。 keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。 unit - keepAliveTime 的时间单位。 workQueue - 用来储存等待执行任务的队列。 threadFactory - 线程工厂。 handler - 拒绝策略。 2 使用 Spring 提供的线程池（强烈推荐） 12345678910@Beanpublic ThreadPoolTaskExecutor someBizThreadPool()&#123; ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor(); threadPoolTaskExecutor.setCorePoolSize(10); threadPoolTaskExecutor.setMaxPoolSize(100); threadPoolTaskExecutor.setQueueCapacity(200); threadPoolTaskExecutor.setKeepAliveSeconds(60); threadPoolTaskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.AbortPolicy()); return threadPoolTaskExecutor;&#125; 运行规则如下： 如果此时线程池中的数量小于 corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue 未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于 corePoolSize，缓冲队列 workQueue 满，并且线程池中的数量小于 maxPoolSize，建新的线程来处理被添加的任务。 如果此时线程池中的数量大于 corePoolSize，缓冲队列 workQueue 满，并且线程池中的数量等于 maxPoolSize，那么通过 handler 所指定的策略来处理此任务。也就是：处理任务的优先级为：核心线程 corePoolSize、任务队列 workQueue、最大线程 maximumPoolSize，如果三者都满了，使用 handler 处理被拒绝的任务（抛出异常）。 当线程池中的线程数量大于 corePoolSize 时，如果某线程空闲时间超过 keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"},{"name":"代码规范","slug":"代码规范","permalink":"http://lexburner.github.io/tags/代码规范/"}]},{"title":"博客搬家","slug":"blog-migration","date":"2017-08-22T08:38:44.000Z","updated":"2019-09-26T09:45:30.862Z","comments":true,"path":"blog-migration/","link":"","permalink":"http://lexburner.github.io/blog-migration/","excerpt":"","text":"陆陆续续，写博客已经写了有 4 年多了，之前一直在 CSDN 维护博客（博客旧址），最近有了点空余时间，使用 hexo 搭了这个博客，的确比 CSDN 清爽多了，首先感谢 @程序猿 DD 推荐的 icarus 模板，国人开发的一个 hexo 模板，插件支持可能不是很完善，但是样式非常让人喜欢。 作为一个前端弱渣，搭建博客的过程还是遇到了不少的困难。原先是打算直接使用 github 个人主页作为博客地址，hexo 对 git 有很好的支持，源代码和博客静态页面都托管在了 github，master 分支放静态页面，hexo 分支放源文件。可惜的是国内坑爹的网速,github.io 的访问速度不尽如人意（github.com 倒还好），于是在宇泽学妹 @ntzyz 的帮助下，搞了 github 的 hook，本地提交到 github 时，代理服务器自动向 master 分支拉取页面，同时设置反向代理和 https。由于 hexo 是静态文件搭建的博客，这种方式可以说是非常合适的。所以，国内的朋友浏览本博客可以直接访问 https://www.cnkirito.moe，如果有国外代理的朋友可以直接访问我的 github 个人主页 https://lexburner.github.io。 目前博客功能还不算完善，缺少评论，分享，和一些小插件，以后逐渐完善，不过不影响主要功能。以后这儿就作为我主要更新博客的地方了！","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[]},{"title":"一个 DDD 指导下的实体类设计案例","slug":"DDD-practice","date":"2017-08-21T07:59:52.000Z","updated":"2019-09-26T09:45:31.677Z","comments":true,"path":"DDD-practice/","link":"","permalink":"http://lexburner.github.io/DDD-practice/","excerpt":"1 引子项目开发中的工具类代码总是随着项目发展逐渐变大，在公司诸多的公用代码中，笔者发现了一个简单的，也是经常被使用的类：BaseDomain，引起了我的思考。在我们公司的开发习惯中，数据库实体类通常会继承一个叫做 BaseDomain 的类，这个类很简单，主要用来填充一些数据库实体公用的属性，它的设计如下：","text":"1 引子项目开发中的工具类代码总是随着项目发展逐渐变大，在公司诸多的公用代码中，笔者发现了一个简单的，也是经常被使用的类：BaseDomain，引起了我的思考。在我们公司的开发习惯中，数据库实体类通常会继承一个叫做 BaseDomain 的类，这个类很简单，主要用来填充一些数据库实体公用的属性，它的设计如下：1234567891011121314151617181920212223@MappedSuperclass &lt;1&gt;public class BaseDomain &#123; private Boolean deleteFlag; &lt;2&gt; private Date deleteDate; private Date lastUpdateDate; private Date createDate; @Version &lt;3&gt; private Integer version; @PrePersist &lt;4&gt; public void init()&#123; Date now = new Date(); deleteFlag = false; createDate = lastUpdateDate = now; &#125; @PreUpdate &lt;4&gt; public void update()&#123; lastUpdateDate = new Date(); &#125; &#125; 小小的一个类其实还是蕴含了不少的知识点在里面，至少可以包含以下几点： 被其他类继承后，父类的字段不会被忽略，也就意味着子类没有必要自己写这一堆公用的属性了。 逻辑删除标识，业务类的删除必须是这种打标识的行为，不能进行物理删除。值得一提的是，公司原先的该字段被命名成了 isDelete，这不符合变量命名的规范，会导致一些序列化框架出现问题，而 delete 是数据库的保留字，所以本文中用 deleteFlag。 使用 version 作为乐观锁的实现，version 的自增以及版本失效异常受 @Version 该注解的影响，是由框架控制的。 创建日期，更新日期等等属性，在我们使用 JPA 的 save 方法后，框架会自动去填充相应的值。 2 发现问题与解决问题这个基类使用的频次是怎么样的呢？every class！是的，公司的每个开发者在新增一个实体类时总是优先写上 Xxx extends BaseDomain 。初级开发者总是有什么学什么，他们看到公司原来的代码都是会继承这个类，以及周围的同事也是这么写着，他们甚至不知道 version 乐观锁的实现，不知道类的创建日期更新日期是在基类中被声明的；高级开发者能够掌握我上面所说的那些技术要点，尽管开发中因此遇到一些不适，但也是尽可能的克服。等等，上面说到添加这个基类后，对开发造成了不适感，这引起了我的思考，下面就来谈谈直观的有哪些不适感以及解决方案。 2.1 没有物理删除，只有逻辑删除真正 delete 操作不会再出现了, 物理删除操作被 setDeleteFlag(true) 代替。在列表展示中，再也不能使用 findAll()操作了，而是需要使用 findByDeleteFlagFalse()。更多的数据库查询操作，都要考虑到，deleteFlag=true 的那些记录，不应该被影响到。 解决问题 ：在 DDD 中，值得推崇的方式是使用 specification 模式来解决这个问题，对应到实际开发中，也就是 JPA 的 Predicate，或者是熟悉 Hibernate 的人所了解的 Criteria。但不可避免的一点是由于只有逻辑删除，导致了我们的数据库越来越大（解决方法不是没有，正是 EventSouring+CQRS 架构，这属于 DDD 的高级实践，本文不进行讨论）。从技术开发角度出发，这的确使得我们的编码变得稍微复杂了一点，但是其业务意义远大于这点开发工作量，所以是值得的。 2.2 级联查询变得麻烦一个会员有多个通信地址，多个银行卡。反映到实体设计，便是这样的： 1234567891011public class Member extends BaseDomain&#123; private String username; @OneToMany private List&lt;MemberAddress&gt; memberAddresses; @OneToMany private List&lt;BankCard&gt; bankCards; &#125; 其中，MemberAddress 及 BankCard 都继承了 BaseDomain。使用 orm 框架自带的级联功能，我们本可以查询出会员信息时，顺带查出其对应的通讯地址列表和银行卡列表。但现在不是那么的美好了，使用级联查询，可能会查询出已经被删除的 MemberAddress，BankCard，只能在应用层进行 deleteFlag 的判断，从而过滤被删除的信息，这无法避免，因为框架不认识逻辑删除标识！ 解决问题 ：这个问题和 2.3 节的问题，恰恰是促成我写这篇文章的初衷，这与 DDD 有着密不可分的关联。DDD 将对象划分成了 entity（实体）和 value object（值对象）。如果仔细分析下上面的业务并且懂一点 DDD，你会立刻意识到。Member 对象就是一个 entity，而 MemberAddress 以及 BankCard 则是 value object（username 也是 value object）。value object 的一个重要特点，就是作为 entity 的修饰，从业务角度出发，MemberAddress 和 BankCard 的确是为了更好描述 Member 信息，而抽象出的一个集合。而 value object 的另一特性，不可变性，指导了我们， 不应该让 MemberAddress，BankCard 继承 BaseDomain。说了这么多，就是想从一个理论的高度，让那些设计一个新实体便继承 BaseDomain 的人戒掉这个习惯。在 value object 丧失了 deleteFlag，lastUpdateDate 等属性后，可能会引发一些的质疑，他们会声称：“数据库里面 member_address 这张表没有 lastUpdateDate 字段了，我再也无法得知这条会员地址最后修改的时间了!”。是的，从逻辑意义上看，地址并没有改变，而改变的只是会员自己的地址，这个 UpdateDate 字段在地址上极为不合理，应该是会员的修改。也就是说 lastUpdateDate 应该反映到 Member 上。实际的开发经验告诉我，从前那么多的 value object 继承了 BaseDomain，99% 不会使用到其中的相关属性，如果真的需要使用，那么请单独为类添加，而不是继承 BaseDomain。其次这些人犯了另一个错误，我们设计一个系统时，应该是 entity first，而不应该 database first。DDD 告诉我们一个软件开发的大忌，到现在 2017 年，仍然有大帮的人在问：“我要实现 xxxx 功能，我的数据库应该如何设计？”这些人犯了根本性的错误，就是把软件的目的搞错了，软件研究的是什么？是研究如何使用计算机来解决实际（领域）问题，而不是去研究数据应该如何保存更合理。我的公司中有不少的程序员新人，希望这番话能够帮助那些“步入歧途”的从业人员 “走上正路”。软件设计应该从“数据库驱动”走向“领域驱动”，而 DDD 的实践经验正是为设计和开发大型复杂的软件系统提供了实践指导。 2.3 乐观锁的尴尬地位再说回 BaseDomain 中的 version 字段，由于 MemberAddress 和 BankCard 这样的 value object 也被赋予了乐观锁的行为，这意味着加锁的粒度变小了。DDD 的指导下，改动也可以理解为由 Member 这个根发出，统一由 Member 中的 version 来控制，这使锁的粒度变大了。换言之，从技术开发角度，对 value object 加上 version 可以允许同时（操作系统级别真正的同时）修改一个用户的地址信息和银行卡信息，甚至是多个银行卡中不同的银行卡，而单独由 Member 控制，则意味着，系统在同一时刻只能进行单独一项操作。在业务并发的一般角度上考虑，一个用户是不会出现多线程修改行为的。而从软件设计的角度，单独为 value object 添加 version，破坏了 value object 的不可变性，若要修改，应当是被整个替换。 解决方案 ：在一般情况下，请不要为 value object 添加乐观锁。如果有一个场景下，你的 value object 需要出现版本控制，那可能有两种情况：1 你的 value object 是压根不是 value object，可能是一个 entity 2 聚合根划分错误 …. 这，要真是这样源头都弄错了，压根没法聊了对吧 3 总结BaseDomain 这样的设计本身并不是我想要强调的重点，但是既然出现了 BaseDomain 这样的设计，那么它究竟应该被什么样的实体继承，就是需要被考虑的了。DDD 下，识别 aggregate root，entity，value object，是整个软件设计的核心点，在本文中，判别是否继承 BaseDomain 的前提，就是这个对象是 entity，还是 value object。大家都是存在数据库中的，但是地位是不一样的。 本文若有什么不足之处，欢迎 DDD 爱好者指出。","categories":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"http://lexburner.github.io/categories/领域驱动设计/"}],"tags":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"http://lexburner.github.io/tags/领域驱动设计/"}]},{"title":"使用 spring validation 完成数据后端校验","slug":"spring-validation","date":"2017-08-16T07:52:52.000Z","updated":"2019-09-26T09:45:31.612Z","comments":true,"path":"spring-validation/","link":"","permalink":"http://lexburner.github.io/spring-validation/","excerpt":"前言数据的校验是交互式网站一个不可或缺的功能，前端的 js 校验可以涵盖大部分的校验职责，如用户名唯一性，生日格式，邮箱格式校验等等常用的校验。但是为了避免用户绕过浏览器，使用 http 工具直接向后端请求一些违法数据，服务端的数据校验也是必要的，可以防止脏数据落到数据库中，如果数据库中出现一个非法的邮箱格式，也会让运维人员头疼不已。我在之前保险产品研发过程中，系统对数据校验要求比较严格且追求可变性及效率，曾使用 drools 作为规则引擎，兼任了校验的功能。而在一般的应用，可以使用本文将要介绍的 validation 来对数据进行校验。 简述 JSR303/JSR-349，hibernate validation，spring validation 之间的关系。JSR303 是一项标准,JSR-349 是其的升级版本，添加了一些新特性，他们规定一些校验规范即校验注解，如 @Null，@NotNull，@Pattern，他们位于 javax.validation.constraints 包下，只提供规范不提供实现。而 hibernate validation 是对这个规范的实践（不要将 hibernate 和数据库 orm 框架联系在一起），他提供了相应的实现，并增加了一些其他校验注解，如 @Email，@Length，@Range 等等，他们位于 org.hibernate.validator.constraints 包下。而万能的 spring 为了给开发者提供便捷，对 hibernate validation 进行了二次封装，显示校验 validated bean 时，你可以使用 spring validation 或者 hibernate validation，而 spring validation 另一个特性，便是其在 springmvc 模块中添加了自动校验，并将校验信息封装进了特定的类中。这无疑便捷了我们的 web 开发。本文主要介绍在 springmvc 中自动校验的机制。","text":"前言数据的校验是交互式网站一个不可或缺的功能，前端的 js 校验可以涵盖大部分的校验职责，如用户名唯一性，生日格式，邮箱格式校验等等常用的校验。但是为了避免用户绕过浏览器，使用 http 工具直接向后端请求一些违法数据，服务端的数据校验也是必要的，可以防止脏数据落到数据库中，如果数据库中出现一个非法的邮箱格式，也会让运维人员头疼不已。我在之前保险产品研发过程中，系统对数据校验要求比较严格且追求可变性及效率，曾使用 drools 作为规则引擎，兼任了校验的功能。而在一般的应用，可以使用本文将要介绍的 validation 来对数据进行校验。 简述 JSR303/JSR-349，hibernate validation，spring validation 之间的关系。JSR303 是一项标准,JSR-349 是其的升级版本，添加了一些新特性，他们规定一些校验规范即校验注解，如 @Null，@NotNull，@Pattern，他们位于 javax.validation.constraints 包下，只提供规范不提供实现。而 hibernate validation 是对这个规范的实践（不要将 hibernate 和数据库 orm 框架联系在一起），他提供了相应的实现，并增加了一些其他校验注解，如 @Email，@Length，@Range 等等，他们位于 org.hibernate.validator.constraints 包下。而万能的 spring 为了给开发者提供便捷，对 hibernate validation 进行了二次封装，显示校验 validated bean 时，你可以使用 spring validation 或者 hibernate validation，而 spring validation 另一个特性，便是其在 springmvc 模块中添加了自动校验，并将校验信息封装进了特定的类中。这无疑便捷了我们的 web 开发。本文主要介绍在 springmvc 中自动校验的机制。 引入依赖我们使用 maven 构建 springboot 应用来进行 demo 演示。 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们只需要引入 spring-boot-starter-web 依赖即可，如果查看其子依赖，可以发现如下的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;/dependency&gt; 验证了我之前的描述，web 模块使用了 hibernate-validation，并且 databind 模块也提供了相应的数据绑定功能。 构建启动类无需添加其他注解，一个典型的启动类​1234567@SpringBootApplicationpublic class ValidateApp &#123; public static void main(String[] args) &#123; SpringApplication.run(ValidateApp.class, args); &#125;&#125; 创建需要被校验的实体类1234567891011121314151617public class Foo &#123; @NotBlank private String name; @Min(18) private Integer age; @Pattern(regexp = \"^1(3|4|5|7|8)\\\\d&#123;9&#125;$\",message = \"手机号码格式错误\") @NotBlank(message = \"手机号码不能为空\") private String phone; @Email(message = \"邮箱格式错误\") private String email; //... getter setter&#125; 使用一些比较常用的校验注解，还是比较浅显易懂的，字段上的注解名称即可推断出校验内容，每一个注解都包含了 message 字段，用于校验失败时作为提示信息，特殊的校验注解，如 Pattern（正则校验），还可以自己添加正则表达式。 在 @Controller 中校验数据springmvc 为我们提供了自动封装表单参数的功能，一个添加了参数校验的典型 controller 如下所示。 123456789101112131415@Controllerpublic class FooController &#123; @RequestMapping(\"/foo\") public String foo(@Validated Foo foo &lt;1&gt;, BindingResult bindingResult &lt;2&gt;) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return \"fail\"; &#125; return \"success\"; &#125;&#125; 值得注意的地方： 参数 Foo 前需要加上 @Validated 注解，表明需要 spring 对其进行校验，而校验的信息会存放到其后的 BindingResult 中。注意，必须相邻，如果有多个参数需要校验，形式可以如下。foo(@Validated Foo foo, BindingResult fooBindingResult ，@Validated Bar bar, BindingResult barBindingResult); 即一个校验类对应一个校验结果。 校验结果会被自动填充，在 controller 中可以根据业务逻辑来决定具体的操作，如跳转到错误页面。 一个最基本的校验就完成了，总结下框架已经提供了哪些校验：JSR 提供的校验注解 :12345678910111213@Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 提供的校验注解 ： 12345@NotBlank(message =) 验证字符串非 null，且长度必须大于 0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 校验实验我们对上面实现的校验入口进行一次测试请求：访问 http://localhost:8080/foo?name=xujingfeng&amp;email=000&amp;age=19 可以得到如下的 debug 信息： 实验告诉我们，校验结果起了作用。并且，可以发现当发生多个错误，spring validation 不会在第一个错误发生后立即停止，而是继续试错，告诉我们所有的错误。debug 可以查看到更多丰富的错误信息，这些都是 spring validation 为我们提供的便捷特性，基本适用于大多数场景。 你可能不满足于简单的校验特性，下面进行一些补充。 分组校验如果同一个类，在不同的使用场景下有不同的校验规则，那么可以使用分组校验。未成年人是不能喝酒的，而在其他场景下我们不做特殊的限制，这个需求如何体现同一个实体，不同的校验规则呢？ 改写注解，添加分组： 12345678Class Foo&#123; @Min(value = 18,groups = &#123;Adult.class&#125;) private Integer age; public interface Adult&#123;&#125; public interface Minor&#123;&#125;&#125; 这样表明，只有在 Adult 分组下，18 岁的限制才会起作用。 Controller 层改写： 123456789101112131415161718192021@RequestMapping(\"/drink\")public String drink(@Validated(&#123;Foo.Adult.class&#125;) Foo foo, BindingResult bindingResult) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return \"fail\"; &#125; return \"success\";&#125;@RequestMapping(\"/live\")public String live(@Validated Foo foo, BindingResult bindingResult) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return \"fail\"; &#125; return \"success\";&#125; drink 方法限定需要进行 Adult 校验，而 live 方法则不做限制。 自定义校验业务需求总是比框架提供的这些简单校验要复杂的多，我们可以自定义校验来满足我们的需求。自定义 spring validation 非常简单，主要分为两步。 1 自定义校验注解我们尝试添加一个“字符串不能包含空格”的限制。 123456789101112131415161718192021222324@Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER&#125;)@Retention(RUNTIME)@Documented@Constraint(validatedBy = &#123;CannotHaveBlankValidator.class&#125;)&lt;1&gt;public @interface CannotHaveBlank &#123; // 默认错误消息 String message() default \"不能包含空格\"; // 分组 Class&lt;?&gt;[] groups() default &#123;&#125;; // 负载 Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; // 指定多个时使用 @Target(&#123;FIELD, METHOD, PARAMETER, ANNOTATION_TYPE&#125;) @Retention(RUNTIME) @Documented @interface List &#123; CannotHaveBlank[] value(); &#125;&#125; 我们不需要关注太多东西，使用 spring validation 的原则便是便捷我们的开发，例如 payload，List ，groups，都可以忽略。 自定义注解中指定了这个注解真正的验证者类。 2 编写真正的校验者类 1234567891011121314151617181920212223public class CannotHaveBlankValidator implements &lt;1&gt; ConstraintValidator&lt;CannotHaveBlank, String&gt; &#123; @Override public void initialize(CannotHaveBlank constraintAnnotation) &#123; &#125; @Override public boolean isValid(String value, ConstraintValidatorContext context &lt;2&gt;) &#123; //null 时不进行校验 if (value != null &amp;&amp; value.contains(\" \")) &#123; &lt;3&gt; // 获取默认提示信息 String defaultConstraintMessageTemplate = context.getDefaultConstraintMessageTemplate(); System.out.println(\"default message :\" + defaultConstraintMessageTemplate); // 禁用默认提示信息 context.disableDefaultConstraintViolation(); // 设置提示语 context.buildConstraintViolationWithTemplate(\"can not contains blank\").addConstraintViolation(); return false; &#125; return true; &#125;&#125; 所有的验证者都需要实现 ConstraintValidator 接口，它的接口也很形象，包含一个初始化事件方法，和一个判断是否合法的方法。 1234public interface ConstraintValidator&lt;A extends Annotation, T&gt; &#123; void initialize(A constraintAnnotation); boolean isValid(T value, ConstraintValidatorContext context);&#125; ConstraintValidatorContext 这个上下文包含了认证中所有的信息，我们可以利用这个上下文实现获取默认错误提示信息，禁用错误提示信息，改写错误提示信息等操作。 一些典型校验操作，或许可以对你产生启示作用。 值得注意的一点是，自定义注解可以用在 METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER 之上，ConstraintValidator 的第二个泛型参数 T，是需要被校验的类型。 手动校验可能在某些场景下需要我们手动校验，即使用校验器对需要被校验的实体发起 validate，同步获得校验结果。理论上我们既可以使用 Hibernate Validation 提供 Validator，也可以使用 Spring 对其的封装。在 spring 构建的项目中，提倡使用经过 spring 封装过后的方法，这里两种方法都介绍下： Hibernate Validation： 123456789Foo foo = new Foo();foo.setAge(22);foo.setEmail(\"000\");ValidatorFactory vf = Validation.buildDefaultValidatorFactory();Validator validator = vf.getValidator();Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = validator.validate(foo);for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage());&#125; 由于依赖了 Hibernate Validation 框架，我们需要调用 Hibernate 相关的工厂方法来获取 validator 实例，从而校验。 在 spring framework 文档的 Validation 相关章节，可以看到如下的描述： Spring provides full support for the Bean Validation API. This includes convenient support for bootstrapping a JSR-303/JSR-349 Bean Validation provider as a Spring bean. This allows for a javax.validation.ValidatorFactory or javax.validation.Validator to be injected wherever validation is needed in your application. Use the LocalValidatorFactoryBean to configure a default Validator as a Spring bean: bean id=”validator” class=”org.springframework.validation.beanvalidation.LocalValidatorFactoryBean” The basic configuration above will trigger Bean Validation to initialize using its default bootstrap mechanism. A JSR-303/JSR-349 provider, such as Hibernate Validator, is expected to be present in the classpath and will be detected automatically. 上面这段话主要描述了 spring 对 validation 全面支持 JSR-303、JSR-349 的标准，并且封装了 LocalValidatorFactoryBean 作为 validator 的实现。值得一提的是，这个类的责任其实是非常重大的，他兼容了 spring 的 validation 体系和 hibernate 的 validation 体系，也可以被开发者直接调用，代替上述的从工厂方法中获取的 hibernate validator。由于我们使用了 springboot，会触发 web 模块的自动配置，LocalValidatorFactoryBean 已经成为了 Validator 的默认实现，使用时只需要自动注入即可。 12345678910111213141516@AutowiredValidator globalValidator; &lt;1&gt;@RequestMapping(\"/validate\")public String validate() &#123; Foo foo = new Foo(); foo.setAge(22); foo.setEmail(\"000\"); Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = globalValidator.validate(foo);&lt;2&gt; for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage()); &#125; return \"success\";&#125; 真正使用过 Validator 接口的读者会发现有两个接口，一个是位于 javax.validation 包下，另一个位于 org.springframework.validation 包下，注意我们这里使用的是前者 javax.validation，后者是 spring 自己内置的校验接口，LocalValidatorFactoryBean 同时实现了这两个接口。 此处校验接口最终的实现类便是 LocalValidatorFactoryBean。 基于方法校验12345678910111213141516171819202122@RestController@Validated &lt;1&gt;public class BarController &#123; @RequestMapping(\"/bar\") public @NotBlank &lt;2&gt; String bar(@Min(18) Integer age &lt;3&gt;) &#123; System.out.println(\"age :\" + age); return \"\"; &#125; @ExceptionHandler(ConstraintViolationException.class) public Map handleConstraintViolationException(ConstraintViolationException cve)&#123; Set&lt;ConstraintViolation&lt;?&gt;&gt; cves = cve.getConstraintViolations();&lt;4&gt; for (ConstraintViolation&lt;?&gt; constraintViolation : cves) &#123; System.out.println(constraintViolation.getMessage()); &#125; Map map = new HashMap(); map.put(\"errorCode\",500); return map; &#125;&#125; 为类添加 @Validated 注解 校验方法的返回值和入参 添加一个异常处理器，可以获得没有通过校验的属性相关信息 基于方法的校验，个人不推荐使用，感觉和项目结合的不是很好。 使用校验框架的一些想法理论上 spring validation 可以实现很多复杂的校验，你甚至可以使你的 Validator 获取 ApplicationContext，获取 spring 容器中所有的资源，进行诸如数据库校验，注入其他校验工具，完成组合校验（如前后密码一致）等等操作，但是寻求一个易用性和封装复杂性之间的平衡点是我们作为工具使用者应该考虑的，我推崇的方式，是仅仅使用自带的注解和自定义注解，完成一些简单的，可复用的校验。而对于复杂的校验，则包含在业务代码之中，毕竟如用户名是否存在这样的校验，仅仅依靠数据库查询还不够，为了避免并发问题，还是得加上唯一索引之类的额外工作，不是吗？","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"Validation","slug":"Validation","permalink":"http://lexburner.github.io/tags/Validation/"}]},{"title":"Re：从零开始的 Spring Security OAuth2（三）","slug":"Spring-Security-OAuth2-3","date":"2017-08-10T06:22:12.000Z","updated":"2019-09-26T09:45:30.826Z","comments":true,"path":"Spring-Security-OAuth2-3/","link":"","permalink":"http://lexburner.github.io/Spring-Security-OAuth2-3/","excerpt":"上一篇文章中我们介绍了获取 token 的流程，这一篇重点分析一下，携带 token 访问受限资源时，内部的工作流程。 @EnableResourceServer 与 @EnableAuthorizationServer还记得我们在第一节中就介绍过了 OAuth2 的两个核心概念，资源服务器与身份认证服务器。我们对两个注解进行配置的同时，到底触发了内部的什么相关配置呢？ 上一篇文章重点介绍的其实是与身份认证相关的流程，即如果获取 token，而本节要分析的携带 token 访问受限资源，自然便是与 @EnableResourceServer 相关的资源服务器配置了。 我们注意到其相关配置类是 ResourceServerConfigurer，内部关联了 ResourceServerSecurityConfigurer 和 HttpSecurity。前者与资源安全配置相关，后者与 http 安全配置相关。（类名比较类似，注意区分，以 Adapter 结尾的是适配器，以 Configurer 结尾的是配置器，以 Builder 结尾的是建造器，他们分别代表不同的设计模式，对设计模式有所了解可以更加方便理解其设计思路） 1234567891011public class ResourceServerConfigurerAdapter implements ResourceServerConfigurer &#123; @Override public void configure(ResourceServerSecurityConfigurer resources &lt;1&gt;) throws Exception &#123; &#125; @Override public void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests().anyRequest().authenticated(); &#125;&#125; ResourceServerSecurityConfigurer 显然便是我们分析的重点了。","text":"上一篇文章中我们介绍了获取 token 的流程，这一篇重点分析一下，携带 token 访问受限资源时，内部的工作流程。 @EnableResourceServer 与 @EnableAuthorizationServer还记得我们在第一节中就介绍过了 OAuth2 的两个核心概念，资源服务器与身份认证服务器。我们对两个注解进行配置的同时，到底触发了内部的什么相关配置呢？ 上一篇文章重点介绍的其实是与身份认证相关的流程，即如果获取 token，而本节要分析的携带 token 访问受限资源，自然便是与 @EnableResourceServer 相关的资源服务器配置了。 我们注意到其相关配置类是 ResourceServerConfigurer，内部关联了 ResourceServerSecurityConfigurer 和 HttpSecurity。前者与资源安全配置相关，后者与 http 安全配置相关。（类名比较类似，注意区分，以 Adapter 结尾的是适配器，以 Configurer 结尾的是配置器，以 Builder 结尾的是建造器，他们分别代表不同的设计模式，对设计模式有所了解可以更加方便理解其设计思路） 1234567891011public class ResourceServerConfigurerAdapter implements ResourceServerConfigurer &#123; @Override public void configure(ResourceServerSecurityConfigurer resources &lt;1&gt;) throws Exception &#123; &#125; @Override public void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests().anyRequest().authenticated(); &#125;&#125; ResourceServerSecurityConfigurer 显然便是我们分析的重点了。 ResourceServerSecurityConfigurer（了解）其核心配置如下所示： 123456789101112131415161718192021222324public void configure(HttpSecurity http) throws Exception &#123; AuthenticationManager oauthAuthenticationManager = oauthAuthenticationManager(http); resourcesServerFilter = new OAuth2AuthenticationProcessingFilter();//&lt;1&gt; resourcesServerFilter.setAuthenticationEntryPoint(authenticationEntryPoint); resourcesServerFilter.setAuthenticationManager(oauthAuthenticationManager);//&lt;2&gt; if (eventPublisher != null) &#123; resourcesServerFilter.setAuthenticationEventPublisher(eventPublisher); &#125; if (tokenExtractor != null) &#123; resourcesServerFilter.setTokenExtractor(tokenExtractor);//&lt;3&gt; &#125; resourcesServerFilter = postProcess(resourcesServerFilter); resourcesServerFilter.setStateless(stateless); // @formatter:off http .authorizeRequests().expressionHandler(expressionHandler) .and() .addFilterBefore(resourcesServerFilter, AbstractPreAuthenticatedProcessingFilter.class) .exceptionHandling() .accessDeniedHandler(accessDeniedHandler)//&lt;4&gt; .authenticationEntryPoint(authenticationEntryPoint); // @formatter:on&#125; 这段是整个 oauth2 与 HttpSecurity 相关的核心配置，其中有非常多的注意点，顺带的都强调一下： 创建 OAuth2AuthenticationProcessingFilter，即下一节所要介绍的 OAuth2 核心过滤器。 为 OAuth2AuthenticationProcessingFilter 提供固定的 AuthenticationManager 即 OAuth2AuthenticationManager，它并没有将 OAuth2AuthenticationManager 添加到 spring 的容器中，不然可能会影响 spring security 的普通认证流程（非 oauth2 请求），只有被 OAuth2AuthenticationProcessingFilter 拦截到的 oauth2 相关请求才被特殊的身份认证器处理。 设置了 TokenExtractor 默认的实现 —-BearerTokenExtractor，这个类在下一节介绍。 相关的异常处理器，可以重写相关实现，达到自定义异常的目的。 还记得我们在一开始的配置中配置了资源服务器，是它触发了相关的配置。123@Configuration@EnableResourceServerprotected static class ResourceServerConfiguration extends ResourceServerConfigurerAdapter &#123;&#125; 核心过滤器 OAuth2AuthenticationProcessingFilter（掌握）回顾一下我们之前是如何携带 token 访问受限资源的：http://localhost:8080/order/1?access_token=950a7cc9-5a8a-42c9-a693-40e817b1a4b0唯一的身份凭证，便是这个 access_token，携带它进行访问，会进入 OAuth2AuthenticationProcessingFilter 之中，其核心代码如下： 1234567891011121314151617181920212223242526272829303132public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)&#123; final HttpServletRequest request = (HttpServletRequest) req; final HttpServletResponse response = (HttpServletResponse) res; try &#123; // 从请求中取出身份信息，即 access_token Authentication authentication = tokenExtractor.extract(request); if (authentication == null) &#123; ... &#125; else &#123; request.setAttribute(OAuth2AuthenticationDetails.ACCESS_TOKEN_VALUE, authentication.getPrincipal()); if (authentication instanceof AbstractAuthenticationToken) &#123; AbstractAuthenticationToken needsDetails = (AbstractAuthenticationToken) authentication; needsDetails.setDetails(authenticationDetailsSource.buildDetails(request)); &#125; // 认证身份 Authentication authResult = authenticationManager.authenticate(authentication); ... eventPublisher.publishAuthenticationSuccess(authResult); // 将身份信息绑定到 SecurityContextHolder 中 SecurityContextHolder.getContext().setAuthentication(authResult); &#125; &#125; catch (OAuth2Exception failed) &#123; ... return; &#125; chain.doFilter(request, response);&#125; 整个过滤器便是 oauth2 身份鉴定的关键，在源码中，对这个类有一段如下的描述 A pre-authentication filter for OAuth2 protected resources. Extracts an OAuth2 token from the incoming request and uses it to populate the Spring Security context with an {@link OAuth2Authentication} (if used in conjunction with an {@link OAuth2AuthenticationManager}). OAuth2 保护资源的预先认证过滤器。如果与 OAuth2AuthenticationManager 结合使用，则会从到来的请求之中提取一个 OAuth2 token，之后使用 OAuth2Authentication 来填充 Spring Security 上下文。 其中涉及到了两个关键的类 TokenExtractor，AuthenticationManager。相信后者这个接口大家已经不陌生，但前面这个类之前还未出现在我们的视野中。 OAuth2 的身份管理器 –OAuth2AuthenticationManager（掌握）在之前的 OAuth2 核心过滤器中出现的 AuthenticationManager 其实在我们意料之中，携带 access_token 必定得经过身份认证，但是在我们 debug 进入其中后，发现了一个出乎意料的事，AuthenticationManager 的实现类并不是我们在前面文章中聊到的常用实现类 ProviderManager，而是 OAuth2AuthenticationManager。 图 1 新的 AuthenticationManager 实现类 OAuth2AuthenticationManager 回顾我们第一篇文章的配置，压根没有出现过这个 OAuth2AuthenticationManager，并且它脱离了我们熟悉的认证流程（第二篇文章中的认证管理器 UML 图是一张经典的 spring security 结构类图），它直接重写了容器的顶级身份认证接口，内部维护了一个 ClientDetailService 和 ResourceServerTokenServices，这两个核心类在 Re：从零开始的 Spring Security Oauth2（二）有分析过。在 ResourceServerSecurityConfigurer 的小节中我们已经知晓了它是如何被框架自动配置的，这里要强调的是 OAuth2AuthenticationManager 是密切与 token 认证相关的，而不是与获取 token 密切相关的。 其判别身份的关键代码如下： 123456789101112131415161718public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; ... String token = (String) authentication.getPrincipal(); // 最终还是借助 tokenServices 根据 token 加载身份信息 OAuth2Authentication auth = tokenServices.loadAuthentication(token); ... checkClientDetails(auth); if (authentication.getDetails() instanceof OAuth2AuthenticationDetails) &#123; OAuth2AuthenticationDetails details = (OAuth2AuthenticationDetails) authentication.getDetails(); ... &#125; auth.setDetails(authentication.getDetails()); auth.setAuthenticated(true); return auth;&#125; 说到 tokenServices 这个密切与 token 相关的接口，这里要强调下，避免产生误解。tokenServices 分为两类，一个是用在 AuthenticationServer 端，第二篇文章中介绍的 123456789public interface AuthorizationServerTokenServices &#123; // 创建 token OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException; // 刷新 token OAuth2AccessToken refreshAccessToken(String refreshToken, TokenRequest tokenRequest) throws AuthenticationException; // 获取 token OAuth2AccessToken getAccessToken(OAuth2Authentication authentication);&#125; 而在 ResourceServer 端有自己的 tokenServices 接口： 12345678public interface ResourceServerTokenServices &#123; // 根据 accessToken 加载客户端信息 OAuth2Authentication loadAuthentication(String accessToken) throws AuthenticationException, InvalidTokenException; // 根据 accessToken 获取完整的访问令牌详细信息。 OAuth2AccessToken readAccessToken(String accessToken);&#125; 具体内部如何加载，和 AuthorizationServer 大同小异，只是从 tokenStore 中取出相应身份的流程有点区别，不再详细看实现类了。 TokenExtractor（了解）这个接口只有一个实现类，而且代码非常简单 1234567891011121314151617181920212223242526272829303132333435363738public class BearerTokenExtractor implements TokenExtractor &#123; private final static Log logger = LogFactory.getLog(BearerTokenExtractor.class); @Override public Authentication extract(HttpServletRequest request) &#123; String tokenValue = extractToken(request); if (tokenValue != null) &#123; PreAuthenticatedAuthenticationToken authentication = new PreAuthenticatedAuthenticationToken(tokenValue, \"\"); return authentication; &#125; return null; &#125; protected String extractToken(HttpServletRequest request) &#123; // first check the header... String token = extractHeaderToken(request); // bearer type allows a request parameter as well if (token == null) &#123; ... // 从 requestParameter 中获取 token &#125; return token; &#125;/** * Extract the OAuth bearer token from a header. */ protected String extractHeaderToken(HttpServletRequest request) &#123; Enumeration&lt;String&gt; headers = request.getHeaders(\"Authorization\"); while (headers.hasMoreElements()) &#123;// typically there is only one (most servers enforce that) ... // 从 Header 中获取 token &#125; return null; &#125;&#125; 它的作用在于分离出请求中包含的 token。也启示了我们可以使用多种方式携带 token。1 在 Header 中携带 123http://localhost:8080/order/1Header：Authentication：Bearer f732723d-af7f-41bb-bd06-2636ab2be135 2 拼接在 url 中作为 requestParam 1http://localhost:8080/order/1?access_token=f732723d-af7f-41bb-bd06-2636ab2be135 3 在 form 表单中携带 123http://localhost:8080/order/1form param：access_token=f732723d-af7f-41bb-bd06-2636ab2be135 异常处理OAuth2 在资源服务器端的异常处理不算特别完善，但基本够用，如果想要重写异常机制，可以直接替换掉相关的 Handler，如权限相关的 AccessDeniedHandler。具体的配置应该在 @EnableResourceServer 中被覆盖，这是适配器 + 配置器的好处。 总结到这儿，Spring Security OAuth2 的整个内部流程就算是分析结束了。本系列的文章只能算是揭示一个大概的流程，重点还是介绍相关设计 + 接口，想要了解更多的细节，需要自己去翻看源码，研究各个实现类。在分析源码过程中总结出的一点经验，与君共勉： 先掌握宏观，如研究 UML 类图，搞清楚关联 分析顶级接口，设计是面向接口的，不重要的部分，具体实现类甚至都可以忽略 学会对比，如 ResourceServer 和 AuthenticationServer 是一种对称的设计，整个框架内部的类非常多，但分门别类的记忆，会加深记忆。如 ResourceServerTokenServices ，AuthenticationServerTokenServices 就一定是作用相关，但所属领域不同的两个接口 熟悉设计模式，spring 中涉及了大量的设计模式，在框架的设计中也是遵循着设计模式的规范，如以 Adapter 结尾，便是运用了适配器模式；以 Factory 结尾，便是运用了适配器模式；Template 结尾，便是运用了模板方法模式；Builder 结尾，便是运用了建造者模式… 一点自己的理解：对源码的理解和灵感，这一切都建立自身的编码经验之上，自己遵循规范便能更好的理解别人同样遵守规范的代码。相对的，阅读好的源码，也能帮助我们自身提升编码规范。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security OAuth2","slug":"Spring-Security-OAuth2","permalink":"http://lexburner.github.io/categories/Spring-Security-OAuth2/"}],"tags":[{"name":"Spring Security OAuth2","slug":"Spring-Security-OAuth2","permalink":"http://lexburner.github.io/tags/Spring-Security-OAuth2/"}]},{"title":"Re：从零开始的 Spring Security OAuth2（二）","slug":"Spring-Security-OAuth2-2","date":"2017-08-09T06:58:52.000Z","updated":"2019-09-26T09:45:30.363Z","comments":true,"path":"Spring-Security-OAuth2-2/","link":"","permalink":"http://lexburner.github.io/Spring-Security-OAuth2-2/","excerpt":"本文开始从源码的层面，讲解一些 Spring Security Oauth2 的认证流程。本文较长，适合在空余时间段观看。且涉及了较多的源码，非关键性代码以… 代替。 准备工作首先开启 debug 信息： 123logging: level: org.springframework: DEBUG 可以完整的看到内部的运转流程。 client 模式稍微简单一些，使用 client 模式获取 token http://localhost:8080/oauth/token?client_id=client_1&amp;client_secret=123456&amp;scope=select&amp;grant_type=client_credentials 由于 debug 信息太多了，我简单按照顺序列了一下关键的几个类： 1234ClientCredentialsTokenEndpointFilterDaoAuthenticationProviderTokenEndpointTokenGranter","text":"本文开始从源码的层面，讲解一些 Spring Security Oauth2 的认证流程。本文较长，适合在空余时间段观看。且涉及了较多的源码，非关键性代码以… 代替。 准备工作首先开启 debug 信息： 123logging: level: org.springframework: DEBUG 可以完整的看到内部的运转流程。 client 模式稍微简单一些，使用 client 模式获取 token http://localhost:8080/oauth/token?client_id=client_1&amp;client_secret=123456&amp;scope=select&amp;grant_type=client_credentials 由于 debug 信息太多了，我简单按照顺序列了一下关键的几个类： 1234ClientCredentialsTokenEndpointFilterDaoAuthenticationProviderTokenEndpointTokenGranter @EnableAuthorizationServer上一篇博客中我们尝试使用了 password 模式和 client 模式，有一个比较关键的 endpoint：/oauth/token。从这个入口开始分析，spring security oauth2 内部是如何生成 token 的。获取 token，与第一篇文章中的两个重要概念之一有关，也就是 AuthorizationServer 与 ResourceServer 中的 AuthorizationServer。 在之前的配置中 123@Configuration@EnableAuthorizationServerprotected static class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123;&#125; 出现了 AuthorizationServerConfigurerAdapter 关键类，他关联了三个重要的配置类，分别是 1234567891011121314public class AuthorizationServerConfigurerAdapter implements AuthorizationServerConfigurer &#123; @Override public void configure(AuthorizationServerSecurityConfigurer security &lt;1&gt;) throws Exception&#123; &#125; @Override public void configure(ClientDetailsServiceConfigurer clients &lt;2&gt;) throws Exception &#123; &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints &lt;3&gt;) throws Exception &#123; &#125;&#125; 配置 AuthorizationServer 安全认证的相关信息，创建 ClientCredentialsTokenEndpointFilter 核心过滤器 配置 OAuth2 的客户端相关信息 配置 AuthorizationServerEndpointsConfigurer 众多相关类，包括配置身份认证器，配置认证方式，TokenStore，TokenGranter，OAuth2RequestFactory 我们逐步分析其中关键的类 客户端身份认证核心过滤器 ClientCredentialsTokenEndpointFilter（掌握）截取关键的代码，可以分析出大概的流程在请求到达 /oauth/token 之前经过了 ClientCredentialsTokenEndpointFilter 这个过滤器，关键方法如下 1234567891011121314public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException, IOException, ServletException &#123; ... String clientId = request.getParameter(\"client_id\"); String clientSecret = request.getParameter(\"client_secret\"); ... clientId = clientId.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(clientId, clientSecret); return this.getAuthenticationManager().authenticate(authRequest);&#125; 顶级身份管理者 AuthenticationManager（掌握）用来从请求中获取 client_id,client_secret，组装成一个 UsernamePasswordAuthenticationToken 作为身份标识，使用容器中的顶级身份管理器 AuthenticationManager 去进行身份认证（AuthenticationManager 的实现类一般是 ProviderManager。而 ProviderManager 内部维护了一个 List, 真正的身份认证是由一系列 AuthenticationProvider 去完成。而 AuthenticationProvider 的常用实现类则是 DaoAuthenticationProvider，DaoAuthenticationProvider 内部又聚合了一个 UserDetailsService 接口，UserDetailsService 才是获取用户详细信息的最终接口，而我们上一篇文章中在内存中配置用户，就是使用了 UserDetailsService 的一个实现类 InMemoryUserDetailsManager）。UML 类图可以大概理解下这些类的关系，省略了授权部分。 图 1 认证相关 UML 类图 可能机智的读者会发现一个问题，我前面一篇文章已经提到了 client 模式是不存在“用户”的概念的，那么这里的身份认证是在认证什么呢？debug 可以发现 UserDetailsService 的实现被适配成了 ClientDetailsUserDetailsService，这个设计是将 client 客户端的信息（client_id,client_secret）适配成用户的信息 (username,password)，这样我们的认证流程就不需要修改了。经过 ClientCredentialsTokenEndpointFilter 之后，身份信息已经得到了 AuthenticationManager 的验证。接着便到达了TokenEndpoint。## Token 处理端点 TokenEndpoint（掌握）前面的两个 ClientCredentialsTokenEndpointFilter 和 AuthenticationManager 可以理解为一些前置校验，和身份封装，而这个类一看名字就知道和我们的 token 是密切相关的。1234567891011121314151617181920@FrameworkEndpointpublic class TokenEndpoint extends AbstractEndpoint &#123; @RequestMapping(value = \"/oauth/token\", method=RequestMethod.POST) public ResponseEntity&lt;OAuth2AccessToken&gt; postAccessToken(Principal principal, @RequestParam Map&lt;String, String&gt; parameters) throws HttpRequestMethodNotSupportedException &#123; ... String clientId = getClientId(principal); ClientDetails authenticatedClient = getClientDetailsService().loadClientByClientId(clientId);//&lt;1&gt; ... TokenRequest tokenRequest = getOAuth2RequestFactory().createTokenRequest(parameters, authenticatedClient);//&lt;2&gt; ... OAuth2AccessToken token = getTokenGranter().grant(tokenRequest.getGrantType(), tokenRequest);//&lt;3&gt; ... return getResponse(token); &#125; private TokenGranter tokenGranter;&#125; 加载客户端信息 结合请求信息，创建 TokenRequest 将 TokenRequest 传递给 TokenGranter 颁发 token 省略了一些校验代码之后，真正的 /oauth/token 端点暴露在了我们眼前，其中方法参数中的 Principal 经过之前的过滤器，已经被填充了相关的信息，而方法的内部则是依赖了一个 TokenGranter 来颁发 token。其中 OAuth2AccessToken 的实现类 DefaultOAuth2AccessToken 就是最终在控制台得到的 token 序列化之前的原始类:​12345678910public class DefaultOAuth2AccessToken implements Serializable, OAuth2AccessToken &#123; private static final long serialVersionUID = 914967629530462926L; private String value; private Date expiration; private String tokenType = BEARER_TYPE.toLowerCase(); private OAuth2RefreshToken refreshToken; private Set&lt;String&gt; scope; private Map&lt;String, Object&gt; additionalInformation = Collections.emptyMap(); //getter,setter&#125;1234567891011121314@org.codehaus.jackson.map.annotate.JsonSerialize(using = OAuth2AccessTokenJackson1Serializer.class)@org.codehaus.jackson.map.annotate.JsonDeserialize(using = OAuth2AccessTokenJackson1Deserializer.class)@com.fasterxml.jackson.databind.annotation.JsonSerialize(using = OAuth2AccessTokenJackson2Serializer.class)@com.fasterxml.jackson.databind.annotation.JsonDeserialize(using = OAuth2AccessTokenJackson2Deserializer.class)public interface OAuth2AccessToken &#123; public static String BEARER_TYPE = \"Bearer\"; public static String OAUTH2_TYPE = \"OAuth2\"; public static String ACCESS_TOKEN = \"access_token\"; public static String TOKEN_TYPE = \"token_type\"; public static String EXPIRES_IN = \"expires_in\"; public static String REFRESH_TOKEN = \"refresh_token\"; public static String SCOPE = \"scope\"; ...&#125;一个典型的样例 token 响应, 如下所示，就是上述类序列化后的结果：1234567&#123; \"access_token\":\"950a7cc9-5a8a-42c9-a693-40e817b1a4b0\", \"token_type\":\"bearer\", \"refresh_token\":\"773a0fcd-6023-45f8-8848-e141296cb3cb\", \"expires_in\":27036, \"scope\":\"select\" &#125;## TokenGranter（掌握）先从 UML 类图对 TokenGranter 接口的设计有一个宏观的认识 图 2 TokenGranter 相关 UML 类图 TokenGranter 的设计思路是使用 CompositeTokenGranter 管理一个 List 列表，每一种 grantType 对应一个具体的真正授权者，在 debug 过程中可以发现 CompositeTokenGranter 内部就是在循环调用五种 TokenGranter 实现类的 grant 方法，而 granter 内部则是通过 grantType 来区分是否是各自的授权类型。 123456789101112131415161718public class CompositeTokenGranter implements TokenGranter &#123; private final List&lt;TokenGranter&gt; tokenGranters; public CompositeTokenGranter(List&lt;TokenGranter&gt; tokenGranters) &#123; this.tokenGranters = new ArrayList&lt;TokenGranter&gt;(tokenGranters); &#125; public OAuth2AccessToken grant(String grantType, TokenRequest tokenRequest) &#123; for (TokenGranter granter : tokenGranters) &#123; OAuth2AccessToken grant = granter.grant(grantType, tokenRequest); if (grant!=null) &#123; return grant; &#125; &#125; return null; &#125;&#125; 五种类型分别是： ResourceOwnerPasswordTokenGranter ==&gt; password 密码模式 AuthorizationCodeTokenGranter ==&gt; authorization_code 授权码模式 ClientCredentialsTokenGranter ==&gt; client_credentials 客户端模式 ImplicitTokenGranter ==&gt; implicit 简化模式 RefreshTokenGranter ==&gt;refresh_token 刷新 token 专用 以客户端模式为例，思考如何产生 token 的，则需要继续研究 5 种授权者的抽象类：AbstractTokenGranter 123456789101112131415161718192021222324252627282930313233343536public abstract class AbstractTokenGranter implements TokenGranter &#123; protected final Log logger = LogFactory.getLog(getClass()); // 与 token 相关的 service，重点 private final AuthorizationServerTokenServices tokenServices; // 与 clientDetails 相关的 service，重点 private final ClientDetailsService clientDetailsService; // 创建 oauth2Request 的工厂，重点 private final OAuth2RequestFactory requestFactory; private final String grantType; ... public OAuth2AccessToken grant(String grantType, TokenRequest tokenRequest) &#123; ... String clientId = tokenRequest.getClientId(); ClientDetails client = clientDetailsService.loadClientByClientId(clientId); validateGrantType(grantType, client); logger.debug(\"Getting access token for:\" + clientId); return getAccessToken(client, tokenRequest); &#125; protected OAuth2AccessToken getAccessToken(ClientDetails client, TokenRequest tokenRequest) &#123; return tokenServices.createAccessToken(getOAuth2Authentication(client, tokenRequest)); &#125; protected OAuth2Authentication getOAuth2Authentication(ClientDetails client, TokenRequest tokenRequest) &#123; OAuth2Request storedOAuth2Request = requestFactory.createOAuth2Request(client, tokenRequest); return new OAuth2Authentication(storedOAuth2Request, null); &#125; ...&#125; 回过头去看 TokenEndpoint 中，正是调用了这里的三个重要的类变量的相关方法。由于篇幅限制，不能延展太多，不然没完没了，所以重点分析下 AuthorizationServerTokenServices 是何方神圣。 AuthorizationServerTokenServices（了解）AuthorizationServer 端的 token 操作 service，接口设计如下： 12345678910public interface AuthorizationServerTokenServices &#123; // 创建 token OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException; // 刷新 token OAuth2AccessToken refreshAccessToken(String refreshToken, TokenRequest tokenRequest) throws AuthenticationException; // 获取 token OAuth2AccessToken getAccessToken(OAuth2Authentication authentication);&#125; 在默认的实现类 DefaultTokenServices 中，可以看到 token 是如何产生的，并且了解了框架对 token 进行哪些信息的关联。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Transactionalpublic OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException &#123; OAuth2AccessToken existingAccessToken = tokenStore.getAccessToken(authentication); OAuth2RefreshToken refreshToken = null; if (existingAccessToken != null) &#123; if (existingAccessToken.isExpired()) &#123; if (existingAccessToken.getRefreshToken() != null) &#123; refreshToken = existingAccessToken.getRefreshToken(); // The token store could remove the refresh token when the // access token is removed, but we want to // be sure... tokenStore.removeRefreshToken(refreshToken); &#125; tokenStore.removeAccessToken(existingAccessToken); &#125; else &#123; // Re-store the access token in case the authentication has changed tokenStore.storeAccessToken(existingAccessToken, authentication); return existingAccessToken; &#125; &#125; // Only create a new refresh token if there wasn't an existing one // associated with an expired access token. // Clients might be holding existing refresh tokens, so we re-use it in // the case that the old access token // expired. if (refreshToken == null) &#123; refreshToken = createRefreshToken(authentication); &#125; // But the refresh token itself might need to be re-issued if it has // expired. else if (refreshToken instanceof ExpiringOAuth2RefreshToken) &#123; ExpiringOAuth2RefreshToken expiring = (ExpiringOAuth2RefreshToken) refreshToken; if (System.currentTimeMillis() &gt; expiring.getExpiration().getTime()) &#123; refreshToken = createRefreshToken(authentication); &#125; &#125; OAuth2AccessToken accessToken = createAccessToken(authentication, refreshToken); tokenStore.storeAccessToken(accessToken, authentication); // In case it was modified refreshToken = accessToken.getRefreshToken(); if (refreshToken != null) &#123; tokenStore.storeRefreshToken(refreshToken, authentication); &#125; return accessToken;&#125; 简单总结一下 AuthorizationServerTokenServices 的作用，他提供了创建 token，刷新 token，获取 token 的实现。在创建 token 时，他会调用 tokenStore 对产生的 token 和相关信息存储到对应的实现类中，可以是 redis，数据库，内存，jwt。 总结本篇总结了使用客户端模式获取 Token 时，spring security oauth2 内部的运作流程，重点是在分析 AuthenticationServer 相关的类。其他模式有一定的不同，但抽象功能是固定的，只是具体的实现类会被相应地替换。阅读 spring 的源码，会发现它的设计中出现了非常多的抽象接口，这对我们理清楚内部工作流程产生了不小的困扰，我的方式是可以借助 UML 类图，先从宏观理清楚作者的设计思路，这会让我们的分析事半功倍。 下一篇文章重点分析用户携带 token 访问受限资源时，spring security oauth2 内部的工作流程。即 ResourceServer 相关的类。 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security OAuth2","slug":"Spring-Security-OAuth2","permalink":"http://lexburner.github.io/categories/Spring-Security-OAuth2/"}],"tags":[{"name":"Spring Security OAuth2","slug":"Spring-Security-OAuth2","permalink":"http://lexburner.github.io/tags/Spring-Security-OAuth2/"}]},{"title":"Re：从零开始的 Spring Security OAuth2（一）","slug":"Spring-Security-OAuth2-1","date":"2017-08-08T07:16:52.000Z","updated":"2019-09-26T09:45:31.162Z","comments":true,"path":"Spring-Security-OAuth2-1/","link":"","permalink":"http://lexburner.github.io/Spring-Security-OAuth2-1/","excerpt":"前言今天来聊聊一个接口对接的场景，A 厂家有一套 HTTP 接口需要提供给 B 厂家使用，由于是外网环境，所以需要有一套安全机制保障，这个时候 oauth2 就可以作为一个方案。 关于 oauth2，其实是一个规范，本文重点讲解 spring 对他进行的实现，如果你还不清楚授权服务器，资源服务器，认证授权等基础概念，可以移步 理解 OAuth 2.0 - 阮一峰，这是一篇对于 oauth2 很好的科普文章。 需要对 spring security 有一定的配置使用经验，用户认证这一块，spring security oauth2 建立在 spring security 的基础之上。第一篇文章主要是讲解使用 springboot 搭建一个简易的授权，资源服务器，在文末会给出具体代码的 github 地址。后续文章会进行 spring security oauth2 的相关源码分析。java 中的安全框架如 shrio，已经有 跟我学 shiro - 开涛，非常成体系地，深入浅出地讲解了 apache 的这个开源安全框架，但是 spring security 包括 oauth2 一直没有成体系的文章，学习它们大多依赖于较少的官方文档，理解一下基本的使用配置；通过零散的博客，了解一下他人的使用经验；打断点，分析内部的工作流程；看源码中的接口设计，以及注释，了解设计者的用意。spring 的各个框架都运用了很多的设计模式，在学习源码的过程中，也大概了解了一些套路。spring 也在必要的地方添加了适当的注释，避免了源码阅读者对于一些细节设计的理解产生偏差，让我更加感叹，spring 不仅仅是一个工具框架，更像是一个艺术品。","text":"前言今天来聊聊一个接口对接的场景，A 厂家有一套 HTTP 接口需要提供给 B 厂家使用，由于是外网环境，所以需要有一套安全机制保障，这个时候 oauth2 就可以作为一个方案。 关于 oauth2，其实是一个规范，本文重点讲解 spring 对他进行的实现，如果你还不清楚授权服务器，资源服务器，认证授权等基础概念，可以移步 理解 OAuth 2.0 - 阮一峰，这是一篇对于 oauth2 很好的科普文章。 需要对 spring security 有一定的配置使用经验，用户认证这一块，spring security oauth2 建立在 spring security 的基础之上。第一篇文章主要是讲解使用 springboot 搭建一个简易的授权，资源服务器，在文末会给出具体代码的 github 地址。后续文章会进行 spring security oauth2 的相关源码分析。java 中的安全框架如 shrio，已经有 跟我学 shiro - 开涛，非常成体系地，深入浅出地讲解了 apache 的这个开源安全框架，但是 spring security 包括 oauth2 一直没有成体系的文章，学习它们大多依赖于较少的官方文档，理解一下基本的使用配置；通过零散的博客，了解一下他人的使用经验；打断点，分析内部的工作流程；看源码中的接口设计，以及注释，了解设计者的用意。spring 的各个框架都运用了很多的设计模式，在学习源码的过程中，也大概了解了一些套路。spring 也在必要的地方添加了适当的注释，避免了源码阅读者对于一些细节设计的理解产生偏差，让我更加感叹，spring 不仅仅是一个工具框架，更像是一个艺术品。 概述使用 oauth2 保护你的应用，可以分为简易的分为三个步骤 配置资源服务器 配置认证服务器 配置 spring security 前两点是 oauth2 的主体内容，但前面我已经描述过了，spring security oauth2 是建立在 spring security 基础之上的，所以有一些体系是公用的。 oauth2 根据使用场景不同，分成了 4 种模式 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 本文重点讲解接口对接中常使用的密码模式（以下简称 password 模式）和客户端模式（以下简称 client 模式）。授权码模式使用到了回调地址，是最为复杂的方式，通常网站中经常出现的微博，qq 第三方登录，都会采用这个形式。简化模式不常用。 项目准备主要的 maven 依赖如下 12345678910111213141516171819&lt;!-- 注意是 starter, 自动配置 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 不是 starter, 手动配置 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 将 token 存储在 redis 中 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 我们给自己先定个目标，要干什么事？既然说到保护应用，那必须得先有一些资源，我们创建一个 endpoint 作为提供给外部的接口：123456789101112131415161718@RestControllerpublic class TestEndpoints &#123; @GetMapping(\"/product/&#123;id&#125;\") public String getProduct(@PathVariable String id) &#123; //for debug Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); return \"product id :\" + id; &#125; @GetMapping(\"/order/&#123;id&#125;\") public String getOrder(@PathVariable String id) &#123; //for debug Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); return \"order id :\" + id; &#125;&#125; 暴露一个商品查询接口，后续不做安全限制，一个订单查询接口，后续添加访问控制。 配置资源服务器和授权服务器由于是两个 oauth2 的核心配置，我们放到一个配置类中。为了方便下载代码直接运行，我这里将客户端信息放到了内存中，生产中可以配置到数据库中。token 的存储一般选择使用 redis，一是性能比较好，二是自动过期的机制，符合 token 的特性。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@Configurationpublic class OAuth2ServerConfig &#123; private static final String DEMO_RESOURCE_ID = \"order\"; @Configuration @EnableResourceServer protected static class ResourceServerConfiguration extends ResourceServerConfigurerAdapter &#123; @Override public void configure(ResourceServerSecurityConfigurer resources) &#123; resources.resourceId(DEMO_RESOURCE_ID).stateless(true); &#125; @Override public void configure(HttpSecurity http) throws Exception &#123; // @formatter:off http // Since we want the protected resources to be accessible in the UI as well we need // session creation to be allowed (it's disabled by default in 2.0.6) .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED) .and() .requestMatchers().anyRequest() .and() .anonymous() .and() .authorizeRequests()// .antMatchers(\"/product/**\").access(\"#oauth2.hasScope('select') and hasRole('ROLE_USER')\") .antMatchers(\"/order/**\").authenticated();// 配置 order 访问控制，必须认证过后才可以访问 // @formatter:on &#125; &#125; @Configuration @EnableAuthorizationServer protected static class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; @Autowired AuthenticationManager authenticationManager; @Autowired RedisConnectionFactory redisConnectionFactory; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; // 配置两个客户端, 一个用于 password 认证一个用于 client 认证 clients.inMemory().withClient(\"client_1\") .resourceIds(DEMO_RESOURCE_ID) .authorizedGrantTypes(\"client_credentials\", \"refresh_token\") .scopes(\"select\") .authorities(\"client\") .secret(\"123456\") .and().withClient(\"client_2\") .resourceIds(DEMO_RESOURCE_ID) .authorizedGrantTypes(\"password\", \"refresh_token\") .scopes(\"select\") .authorities(\"client\") .secret(\"123456\"); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; endpoints .tokenStore(new RedisTokenStore(redisConnectionFactory)) .authenticationManager(authenticationManager); &#125; @Override public void configure(AuthorizationServerSecurityConfigurer oauthServer) throws Exception &#123; // 允许表单认证 oauthServer.allowFormAuthenticationForClients(); &#125; &#125;&#125; 简单说下 spring security oauth2 的认证思路。 client 模式，没有用户的概念，直接与认证服务器交互，用配置中的客户端信息去申请 accessToken，客户端有自己的 client_id,client_secret 对应于用户的 username,password，而客户端也拥有自己的 authorities，当采取 client 模式认证时，对应的权限也就是客户端自己的 authorities。 password 模式，自己本身有一套用户体系，在认证时需要带上自己的用户名和密码，以及客户端的 client_id,client_secret。此时，accessToken 所包含的权限是用户本身的权限，而不是客户端的权限。 我对于两种模式的理解便是，如果你的系统已经有了一套用户体系，每个用户也有了一定的权限，可以采用 password 模式；如果仅仅是接口的对接，不考虑用户，则可以使用 client 模式。 配置 spring security在 spring security 的版本迭代中，产生了多种配置方式，建造者模式，适配器模式等等设计模式的使用，spring security 内部的认证 flow 也是错综复杂，在我一开始学习 ss 也产生了不少困惑，总结了一下配置经验：使用了 springboot 之后，spring security 其实是有不少自动配置的，我们可以仅仅修改自己需要的那一部分，并且遵循一个原则，直接覆盖最需要的那一部分。这一说法比较抽象，举个例子。比如配置内存中的用户认证器。有两种配置方式 planA： 1234567@Beanprotected UserDetailsService userDetailsService()&#123; InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(\"user_1\").password(\"123456\").authorities(\"USER\").build()); manager.createUser(User.withUsername(\"user_2\").password(\"123456\").authorities(\"USER\").build()); return manager;&#125; planB： 12345678910111213141516171819@Configuration@EnableWebSecuritypublic class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() .withUser(\"user_1\").password(\"123456\").authorities(\"USER\") .and() .withUser(\"user_2\").password(\"123456\").authorities(\"USER\"); &#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; AuthenticationManager manager = super.authenticationManagerBean(); return manager; &#125;&#125; 你最终都能得到配置在内存中的两个用户，前者是直接替换掉了容器中的 UserDetailsService，这么做比较直观；后者是替换了 AuthenticationManager，当然你还会在 SecurityConfiguration 复写其他配置，这么配置最终会由一个委托者去认证。如果你熟悉 spring security，会知道 AuthenticationManager 和 AuthenticationProvider 以及 UserDetailsService 的关系，他们都是顶级的接口，实现类之间错综复杂的聚合关系… 配置方式千差万别，但理解清楚认证流程，知道各个实现类对应的职责才是掌握 spring security 的关键。 下面给出我最终的配置： 123456789101112131415161718192021222324@Configuration@EnableWebSecuritypublic class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Bean @Override protected UserDetailsService userDetailsService()&#123; InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(\"user_1\").password(\"123456\").authorities(\"USER\").build()); manager.createUser(User.withUsername(\"user_2\").password(\"123456\").authorities(\"USER\").build()); return manager; &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; // @formatter:off http .requestMatchers().anyRequest() .and() .authorizeRequests() .antMatchers(\"/oauth/*\").permitAll(); // @formatter:on &#125;&#125; 重点就是配置了一个 UserDetailsService，和 ClientDetailsService 一样，为了方便运行，使用内存中的用户，实际项目中，一般使用的是数据库保存用户，具体的实现类可以使用 JdbcDaoImpl 或者 JdbcUserDetailsManager。 获取 token进行如上配置之后，启动 springboot 应用就可以发现多了一些自动创建的 endpoints： 123456&#123;[/oauth/authorize]&#125;&#123;[/oauth/authorize],methods=[POST]&#123;[/oauth/token],methods=[GET]&#125;&#123;[/oauth/token],methods=[POST]&#125;&#123;[/oauth/check_token]&#125;&#123;[/oauth/error]&#125; 重点关注一下 /oauth/token，它是获取的 token 的 endpoint。启动 springboot 应用之后，使用 http 工具访问password 模式： http://localhost:8080/oauth/token?username=user_1&amp;password=123456&amp;grant_type=password&amp;scope=select&amp;client_id=client_2&amp;client_secret=123456 响应如下：{&quot;access_token&quot;:&quot;950a7cc9-5a8a-42c9-a693-40e817b1a4b0&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;773a0fcd-6023-45f8-8848-e141296cb3cb&quot;,&quot;expires_in&quot;:27036,&quot;scope&quot;:&quot;select&quot;} client 模式：http://localhost:8080/oauth/token?grant_type=client_credentials&amp;scope=select&amp;client_id=client_1&amp;client_secret=123456 响应如下：{&quot;access_token&quot;:&quot;56465b41-429d-436c-ad8d-613d476ff322&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;expires_in&quot;:25074,&quot;scope&quot;:&quot;select&quot;} 在配置中，我们已经配置了对 order 资源的保护，如果直接访问:http://localhost:8080/order/1 会得到这样的响应:{&quot;error&quot;:&quot;unauthorized&quot;,&quot;error_description&quot;:&quot;Full authentication is required to access this resource&quot;}（这样的错误响应可以通过重写配置来修改） 而对于未受保护的 product 资源 http://localhost:8080/product/1 则可以直接访问，得到响应 product id : 1 携带 accessToken 参数访问受保护的资源： 使用 password 模式获得的 token:http://localhost:8080/order/1?access_token=950a7cc9-5a8a-42c9-a693-40e817b1a4b0，得到了之前匿名访问无法获取的资源：order id : 1 使用 client 模式获得的 token:http://localhost:8080/order/1?access_token=56465b41-429d-436c-ad8d-613d476ff322，同上的响应 order id : 1 我们重点关注一下 debug 后，对资源访问时系统记录的用户认证信息，可以看到如下的 debug 信息 password 模式： client 模式： 和我们的配置是一致的，仔细看可以发现两者的身份有些许的不同。想要查看更多的 debug 信息，可以选择下载 demo 代码自己查看，为了方便读者调试和验证，我去除了很多复杂的特性，基本实现了一个最简配置，涉及到数据库的地方也尽量配置到了内存中，这点记住在实际使用时一定要修改。 到这儿，一个简单的 oauth2 入门示例就完成了，一个简单的配置教程。token 的工作原理是什么，它包含了哪些信息？spring 内部如何对身份信息进行验证？以及上述的配置到底影响了什么？这些内容会放到后面的文章中去分析。 示例代码下载全部的代码可以在我的 github 上进行下载，项目使用 springboot+maven 构建：https://github.com/lexburner/oauth2-demo 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"Spring Security OAuth2","slug":"Spring-Security-OAuth2","permalink":"http://lexburner.github.io/categories/Spring-Security-OAuth2/"}],"tags":[{"name":"Spring Security OAuth2","slug":"Spring-Security-OAuth2","permalink":"http://lexburner.github.io/tags/Spring-Security-OAuth2/"}]},{"title":"对于 Spring Cloud Feign 入门示例的一点思考","slug":"thinking-in-spring-cloud-feign","date":"2017-08-03T09:40:16.000Z","updated":"2019-09-26T09:45:29.967Z","comments":true,"path":"thinking-in-spring-cloud-feign/","link":"","permalink":"http://lexburner.github.io/thinking-in-spring-cloud-feign/","excerpt":"Spring Cloud FeignSpring Cloud Feign 是一套基于 Netflix Feign 实现的声明式服务调用客户端。它使得编写 Web 服务客户端变得更加简单。我们只需要通过创建接口并用注解来配置它既可完成对 Web 服务接口的绑定。它具备可插拔的注解支持，包括 Feign 注解、JAX-RS 注解。它也支持可插拔的编码器和解码器。Spring Cloud Feign 还扩展了对 Spring MVC 注解的支持，同时还整合了 Ribbon 和 Eureka 来提供均衡负载的 HTTP 客户端实现。 分布式应用早在十几年前就开始出现，各自的应用运行在各自的 tomcat，jboss 一类的容器中，他们之间的相互调用变成了一种远程调用，而实现远程调用的方式很多。按照协议划分，可以有 RPC，Webservice，http。不同的框架也对他们有了各自的实现，如 dubbo(x)，motan 就都是 RPC 框架，本文所要讲解的 Feign 便可以理解为一种 http 框架，用于分布式服务之间通过 Http 进行接口交互。说他是框架，有点过了，可以理解为一个 http 工具，只不过在 spring cloud 全家桶的体系中，它比 httpclient，okhttp，retrofit 这些 http 工具都要强大的多。 入门先用一个简单的例子，看看如何在项目中使用 Feign。示例项目使用 maven 多 module 构建，采用 springcloud 的 Dalston.SR1 版本","text":"Spring Cloud FeignSpring Cloud Feign 是一套基于 Netflix Feign 实现的声明式服务调用客户端。它使得编写 Web 服务客户端变得更加简单。我们只需要通过创建接口并用注解来配置它既可完成对 Web 服务接口的绑定。它具备可插拔的注解支持，包括 Feign 注解、JAX-RS 注解。它也支持可插拔的编码器和解码器。Spring Cloud Feign 还扩展了对 Spring MVC 注解的支持，同时还整合了 Ribbon 和 Eureka 来提供均衡负载的 HTTP 客户端实现。 分布式应用早在十几年前就开始出现，各自的应用运行在各自的 tomcat，jboss 一类的容器中，他们之间的相互调用变成了一种远程调用，而实现远程调用的方式很多。按照协议划分，可以有 RPC，Webservice，http。不同的框架也对他们有了各自的实现，如 dubbo(x)，motan 就都是 RPC 框架，本文所要讲解的 Feign 便可以理解为一种 http 框架，用于分布式服务之间通过 Http 进行接口交互。说他是框架，有点过了，可以理解为一个 http 工具，只不过在 spring cloud 全家桶的体系中，它比 httpclient，okhttp，retrofit 这些 http 工具都要强大的多。 入门先用一个简单的例子，看看如何在项目中使用 Feign。示例项目使用 maven 多 module 构建，采用 springcloud 的 Dalston.SR1 版本 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 服务提供方在本例子中，使用两个应用模块，展示分布式应用中如何进行接口交互。restful-provider 担任服务提供方，restful-consumer 担任服务消费者。 restful-provider 新建一个 modulerestful-provider-app, 模块中只需要写一个 CalculateController.java 即可 ​ 123456789101112131415@RestController@RequestMapping(\"/api\")public class CalculateController &#123; @PostMapping(\"/add\") public Integer add(@RequestParam Integer a,@RequestParam Integer b)&#123; return a+b; &#125; @PostMapping(\"/subtract\") public Integer subtract(@RequestParam Integer a,@RequestParam Integer b)&#123; return a-b; &#125;&#125; 配置文件 application.yml： 12server: port: 7070 一个服务端就写好了，提供两个计算服务的接口，可以通过 http 访问 服务消费方 使用 Feign 编写消费方，在 restful-consumer 项目中，我们将接口的定义和消费者应用分成两个 module，restful-consumer-api-definition 和 restful-consumer-app。 在接口定义模块中，只有一个 Feign 接口： 123456789@FeignClient(value = \"calculate\",path = \"/api\")public interface CalculateApi &#123; @PostMapping(path = \"/add\") Integer add(@RequestParam(\"a\") Integer a,@RequestParam(\"b\") Integer b); @PostMapping(path = \"/subtract\") Integer subtract(@RequestParam(\"a\") Integer a,@RequestParam(\"b\") Integer b);&#125; tip：@RequestParam 中的参数值不能省略，否则会出现错误 restful-consumer-app 依赖上面的 restful-consumer-api-definition 模块，并且启用 Feign 代理，自动生成一个远程调用。启动类配置： 123456789@EnableFeignClients(basePackages = &#123;\"sinosoftsh.consumer.api\"&#125;)@SpringBootApplicationpublic class ConsumerApp &#123; public static void main(String []args)&#123; SpringApplication.run(ConsumerApp.class,args); &#125;&#125; 使用 @EnableFeignClients(basePackages = {&quot;sinosoftsh.consumer.api&quot;}) 扫描接口类所在的包，spring 的容器中才会有代理实现类。 不要忘记配置消费者的相关属性，在 application.yml 中 12345678910111213server: port: 7080ribbon: eureka: enabled: falsecalculate: ribbon: listOfServers: localhost:7070logging: level: org.apache.http: trace 在 CalculateApi 接口的定义中，我们使用了一个 calculate 作为服务名称，必须要在配置文件中配置 calculate 所在的 ip 地址才行，由于本文只是作为一个示例，所以没有使用注册中心，在配置中禁用了 eureka。最后一行的日志配置，可以发现其实 Feign 内部其实使用的是现成的 http 工具：httpclient，okhttp3，可以通过配置替换实现 整体的项目结构如下： 图一 第一种依赖关系结构 再编写一个单元测试类，验证一下 Feign 是否被正确的配置了 12345678910111213@RestControllerpublic class ConsumerController &#123; @Autowired CalculateApi calculateApi; @RequestMapping(\"/test\") public String test() &#123; Integer result = calculateApi.add(1, 2); System.out.println(\"the result is\" + result); return \"success\"; &#125;&#125; 思考回顾一下我们入门实例，服务提供方使用的是一个 RestController 暴露计算服务，服务消费方使用 http 工具（Feign）进行远程调用，这再清晰不过了，也是符合软件设计的，因为 Feign 接口的定义是存在于消费方，所以是真正的松耦合。但是习惯了使用 rpc 共享接口的设计，我们也可以将接口定义在服务提供方，这样做的好处是，服务可能被多个消费者使用，不需要每个消费者都定义一次 Feign 接口。 图 2 第二种依赖关系结构 在 restful-provider 创建一个 restful-provider-api-definition 模块，将 CalculateApi.java 的定义迁移到服务提供方，相应的 restful-provider-app 也可以进行改造： 1234567891011121314151617@RestController@RequestMapping(\"/api\")public class CalculateController implements CalculateApi&#123;// @PostMapping(\"/add\") @Override public Integer add(@RequestParam Integer a,@RequestParam Integer b)&#123; return a+b; &#125;// @PostMapping(\"/subtract\") @Override public Integer subtract(@RequestParam Integer a,@RequestParam Integer b)&#123; return a-b; &#125;&#125; 因为接口的定义和服务提供方现在在一个限界上下文中，接口的定义同时也宣告了应该提供什么样的服务，所以直接继承 CalculateApi。这里的理解比较绕，现在的设计中，CalculateApi 在服务消费者和服务提供者中的定位是不一样的，服务消费者需要在启动类扫描 CalculateApi 所在的包，生成代理对象，远程调用；而在服务提供方则一定不能扫描 CalculateApi 所在的包，否则会污染容器中的 CalculateApi 实现类，要知道，CalculateController 之上有一个 @RestController 注解，意味着已经有一个本地代理实现了，我们也可以在服务提供方注入 CalculateApi，便是进行的本地调用了，这符合我们的初衷：我自己的提供的服务，本地当然可以调用。在服务提供方的启动类上要额外注意 @ComponentScan，@EnableFeignClients 的扫描。 这样，当我们有多个消费者，只需要让他们配置 Feign，并且引入服务提供方的接口定义，扫描，即可进行远程调用。有点类似于 RPC 的共享接口。 设计原则restful 设计以语言无关，松耦合的优势著称。在 Spring Cloud Feign 的相关文档中有这样的描述： It is generally not advisable to share an interface between a server and a client. It introduces tight coupling, and also actually doesn’t work with Spring MVC in its current form (method parameter mapping is not inherited). 不建议使用上述改进后的共享接口的方式，并且警告我们，springmvc 的注解在 Feign 接口中的定义和实现类中是不可继承的。关于这点，仁者见仁，智者见智。我们现在项目依旧是采用共享接口的方式，这样可以使得开发变得便捷，多个消费者不需要重复定义。 下面是关于耦合和共享接口的一些讨论： 1234https://github.com/spring-cloud/spring-cloud-netflix/issues/951https://github.com/spring-cloud/spring-cloud-netflix/issues/659https://github.com/spring-cloud/spring-cloud-netflix/issues/646https://jmnarloch.wordpress.com/2015/08/19/spring-cloud-designing-feign-client/ 注意事项 当接口定义中出现了实体类时，需要使用 @RequestBody 注解。多个实体类，则需要用一个大的 vo 对其进行包裹，要时刻记住，Feign 接口最终是会转换成一次 http 请求。 接口定义中的注解和实现类中的注解要分别写一次，不能继承。 Feign 调用一般配合 eureka 等注册中心使用，并且在客户端可以支持 Hystrix 机制，本文为了讲解共享接口这一设计，所以重心放在了 Feign 上，实际开发中，这些 spring cloud 的其他组件通常配套使用。 对 http 深入理解，在使用 Feign 时可以事半功倍。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/tags/Spring-Cloud/"}]},{"title":"Re：从零开始的领域驱动设计","slug":"Re-DDD","date":"2017-07-28T05:15:46.000Z","updated":"2019-09-26T09:45:31.204Z","comments":true,"path":"Re-DDD/","link":"","permalink":"http://lexburner.github.io/Re-DDD/","excerpt":"前言领域驱动的火爆程度不用我赘述，但是即便其如此得耳熟能详，但大多数人对其的认识，还只是停留在知道它的缩写是 DDD，知道它是一种软件思想，或者知道它和微服务有千丝万缕的关系。Eric Evans 对 DDD 的诠释是那么地惜字如金，而我所认识的领域驱动设计的专家又都是行业中的资深前辈，他们擅长于对软件设计进行高屋建瓴的论述，如果没有丰富的互联网从业经验，是不能从他们的分享中获取太多的营养的，可以用曲高和寡来形容。1000 个互联网从业者，100 个懂微服务，10 个人懂领域驱动设计。 可能有很多和我一样的读者，在得知 DDD 如此火爆之后，尝试去读了开山之作《领域驱动设计——软件核心复杂性应对之道》，翻看了几张之后，晦涩的语句，不明所以的专业术语，加上翻译导致的语句流畅性，可以说观看体验并不是很好，特别是对于开发经验不是很多的读者。我总结了一下，为何这本书难以理解： 没有阅读软件设计丛书的习惯，更多人偏向于阅读偏应用层面的书籍，“talk is cheap，show me the code”往往更符合大多数人的习惯。 没有太多的开发经验支撑。没有踩过坑，就不会意识到设计的重要性，无法产生共情。 年代有些久远，这本书写于 2004 年，书中很多软件设计的反例，在当时是非常流行的，但是在现在已经基本绝迹了。大师之所以为大师，是因为其能跨越时代的限制，预见未来的问题，这也是为什么 DDD 在十几年前就被提出，却在微服务逐渐流行的现阶段才被大家重视。 诚然如标题所示，本文是领域驱动设计的一个入门文章，或者更多的是一个个人理解的笔记，笔者也正在学习 DDD 的路上，可能会有很多的疏漏。如有理解有偏颇的地方，还望各位指摘。","text":"前言领域驱动的火爆程度不用我赘述，但是即便其如此得耳熟能详，但大多数人对其的认识，还只是停留在知道它的缩写是 DDD，知道它是一种软件思想，或者知道它和微服务有千丝万缕的关系。Eric Evans 对 DDD 的诠释是那么地惜字如金，而我所认识的领域驱动设计的专家又都是行业中的资深前辈，他们擅长于对软件设计进行高屋建瓴的论述，如果没有丰富的互联网从业经验，是不能从他们的分享中获取太多的营养的，可以用曲高和寡来形容。1000 个互联网从业者，100 个懂微服务，10 个人懂领域驱动设计。 可能有很多和我一样的读者，在得知 DDD 如此火爆之后，尝试去读了开山之作《领域驱动设计——软件核心复杂性应对之道》，翻看了几张之后，晦涩的语句，不明所以的专业术语，加上翻译导致的语句流畅性，可以说观看体验并不是很好，特别是对于开发经验不是很多的读者。我总结了一下，为何这本书难以理解： 没有阅读软件设计丛书的习惯，更多人偏向于阅读偏应用层面的书籍，“talk is cheap，show me the code”往往更符合大多数人的习惯。 没有太多的开发经验支撑。没有踩过坑，就不会意识到设计的重要性，无法产生共情。 年代有些久远，这本书写于 2004 年，书中很多软件设计的反例，在当时是非常流行的，但是在现在已经基本绝迹了。大师之所以为大师，是因为其能跨越时代的限制，预见未来的问题，这也是为什么 DDD 在十几年前就被提出，却在微服务逐渐流行的现阶段才被大家重视。 诚然如标题所示，本文是领域驱动设计的一个入门文章，或者更多的是一个个人理解的笔记，笔者也正在学习 DDD 的路上，可能会有很多的疏漏。如有理解有偏颇的地方，还望各位指摘。 认识领域驱动设计的意义领域驱动设计并不会绝对地提高项目的开发效率。 遵循领域驱动设计的规范使得项目初期的开发甚至不如不使用它来的快，原因有很多，程序员的素质，代码的规范，限界上下文的划分… 甚至需求修改后导致需要重新建模。但是遵循领域驱动设计的规范，在项目越来越复杂之后，可以不至于让项目僵死。这也是为什么很多系统不断迭代着，最终就黄了。书名的副标题“软件核心复杂性应对之道”正是阐释了这一点 模式： smart ui 是个反模式可能很多读者还不知道 smart ui 是什么，但是在这本书写作期间，这种设计风格是非常流行的。在与一位领域驱动设计方面的资深专家的交谈中，他如下感慨到软件发展的历史： 2003 年时，正是 delphi，vb 一类的 smart ui 程序大行其道，java 在那个年代，还在使用 jsp 来完成大量的业务逻辑操作，4000 行的 jsp 是常见的事；2005 年 spring hibernate 替换了 EJB，社区一片欢呼，所有人开始拥护 action，service，dao 这样的贫血模型（充血模型，贫血模型会在下文论述）；2007 年，Rails 兴起，有人发现了 Rails 的 activeRecord 是涨血模型，引起了一片混战；直到现在的 2017 年，微服务成为主流系统架构。 在现在这个年代，不懂个 MVC 分层，都不好意思说自己是搞 java 的，也不会有人在 jsp 里面写业务代码了（可以说模板技术 freemarker,thymeleaf 已经取代 jsp 了），但是在那个年代，还没有现在这么普遍地强调分层架构的重要性。 这个章节其实并不重要，因为 mvc 一类的分层架构已经是大多数 java 初学者的“起点”了，大多数 DDD 的文章都不会赘述这一点，我这里列出来是为了让大家知晓这篇文章的时代局限性，在后续章节的理解中，也需要抱有这样的逻辑：这本书写于 2004 年。 模式： Entity 与 Value Object我在不了解 DDD 时，就对这两个术语早有耳闻。entity 又被称为 reference object，我们通常所说的 java bean 在领域中通常可以分为这两类，（可别把 value object 和常用于前台展示的 view object，vo 混为一谈）entity 的要义在于生命周期和标识，value object 的要义在于无标识，通常情况下，entity 在通俗意义上可以理解为数据库的实体，（不过不严谨），value object 则一般作为一个单独的类，构成 entity 的一个属性。 举两个例子来加深对 entity 和 value object 的理解。 例 1：以电商微服务系统中的商品模块，订单模块为例。将整个电商系统划分出商品和订单两个限界上下文（Bound Context）应该是没有争议的。如果是传统的单体应用，我们可以如何设计这两个模块的实体类呢？会不会是这样？1234567891011121314151617181920212223class Product&#123; String id;// 主键 String skuId;// 唯一识别号 String productName; Bigdecimal price; Category category;// 分类 List&lt;Specification&gt; specifications;// 规格 ... &#125;class Order&#123; String id;// 主键 String orderNo;// 订单号 List&lt;OrderItem&gt; orderItems;// 订单明细 BigDecimal orderAmount;// 总金额 ...&#125;class OrderItem&#123; String id; Product product;// 关联商品 BigDecimal snapshotPrice;// 下单时的价格&#125; 看似好像没问题，考虑到了订单要保存下单时候的价格（当然，这是常识）但这么设计却存在诸多的问题。在分布式系统中，商品和订单这两个模块必然不在同一个模块，也就意味着不在同一个网段中。上述的类设计中直接将 Product 的列表存储到了 Order 中，也就是一对多的外键关联。这会导致，每次访问订单的商品列表，都需要发起 n 次远程调用。 反思我们的设计，其实我们发现，订单 BC 的 Product 和商品 BC 的 Product 其实并不是同一个 entity，在商品模块中，我们更关注商品的规格，种类，实时价格，这最直接地反映了我们想要买什么的欲望。而当生成订单后，我们只关心这个商品买的时候价格是多少，不会关心这个商品之后的价格变动，还有他的名称，仅仅是方便我们在订单的商品列表中定位这个商品。 如何改造就变得明了了12345678class OrderItem&#123; String id; String productId;// 只记录一个 id 用于必要的时候发起 command 操作 String skuId; String productName; ... BigDecimal snapshotPrice;// 下单时的价格&#125; 是的，我们做了一定的冗余，这使得即使商品模块的商品，名称发生了微调，也不会被订单模块知晓。这么做也有它的业务含义，用户会声称：我买的时候他的确就叫这个名字。记录 productId 和 skuId 的用意不是为了查询操作，而是方便申请售后一类的命令操作（command）。 在这个例子中，Order 和 Product 都是 entity，而 OrderItem 则是 value object（想想之前的定义，OrderItem 作为一个类，的确是描述了 Order 这个 entity 的一个属性集合）。关于标识，我的理解是有两层含义，第一个是作为数据本身存储于数据库，主键 id 是一个标识，第二是作为领域对象本身，orderNo 是一个标识，对于人而言，身份证是一个标识。而 OrderItem 中的 productId，id 不能称之为标识，因为整个 OrderItem 对象是依托于 Order 存在的，Order 不存在，则 OrderItem 没有意义。 例子 2： 汽车和轮胎的关系是 entity 和 value object 吗？这个例子其实是一个陷阱题，因为他没有交代限界上下文（BC），场景不足以判断。对于用户领域而言，的确可以成立，汽车报废之后，很少有人会关心轮胎。轮胎和发动机，雨刮器，座椅地位一样，只是构成汽车的一些部件，和用户最紧密相关的，只有汽车这个 entity，轮胎只是描述这个汽车的属性（value object）；场景切换到汽修厂，无论是汽车，还是轮胎，都是汽修厂密切关心的，每个轮胎都有自己的编号，一辆车报废了，可以安置到其他车上，这里，他们都是 entity。 这个例子是在说明这么一个道理，同样的事物，在不同的领域中，会有不同的地位。 在单体应用中，可能会有人指出，这直接违背了数据库范式，但是领域驱动设计的思想正如他的名字那样，不是基于数据库的，而是基于领域的。微服务使得数据库发生了隔离，这样的设计思想可以更好的指导我们优化数据库。 模式： Repository 哲学家分析自然规律得出规范，框架编写者根据规范制定框架。有些框架，可能大家一直在用，但是却不懂其中蕴含的哲学。 —— 来自于笔者的口胡 记得在刚刚接触 mvc 模式，常常用 DAO 层表示持久化层，在 JPA+springdata 中，抽象出了各式各样的 xxxRepository，与 DDD 的 Repository 模式同名并不是巧合，jpa 所表现出的正是一个充血模型（如果你遵循正确的使用方式的话），可以说是领域驱动设计的一个最佳实践。 开宗明义，在 Martin Fowler 理论中，有四种领域模型： 失血模型 贫血模型 充血模型 胀血模型详细的概念区别不赘述了，可以参见专门讲解 4 种模型的博客。他们在数据库开发中分别有不同的实现，用一个修改用户名的例子来分析。12345class User&#123; String id; String name; Integer age;&#125; 失血模型：跳过，可以理解为所有的操作都是直接操作数据库，在 smart ui 中可能会出现这样的情况。 贫血模型：123456789101112131415161718class UserDao &#123; @Autowired JdbcTemplate jdbcTemplate; public void updateName(String name,String id)&#123; jdbcTemplate.excute(\"update user u set u.name = ? where id=?\",name,id); &#125;&#125;class UserService&#123; @Autowired UserDao userDao; void updateName(String name,String id)&#123; userDao.updateName(name,id); &#125; &#125; 贫血模型中，dao 是一类 sql 的集合，在项目中的表现就是写了一堆 sql 脚本，与之对应的 service 层，则是作为 Transaction Script 的入口。观察仔细的话，会发现整个过程中 user 对象都没出现过。 充血模型：1234567891011121314interface UserRepository extends JpaRepository&lt;User,String&gt;&#123; //springdata-jpa 自动扩展出 save findOne findAll 方法&#125;class UserService&#123; @Autowoird UserRepository userRepository; void updateName(String name,String id)&#123; User user = userRepository.findOne(id); user.setName(name); userRepository.save(user); &#125;&#125; 充血模型中，整个修改操作是“隐性”的，对内存中 user 对象的修改直接影响到了数据库最终的结果，不需要关心数据库操作，只需要关注领域对象 user 本身。Repository 模式就是在于此，屏蔽了数据库的实现。与贫血模型中 user 对象恰恰相反，整个流程没有出现 sql 语句。 涨血模型：没有具体的实现，可以这么理解：12345void updateName(String name,String id)&#123; User user = new User(id); user.setName(name); user.save();&#125; 我们在 Repository 模式中重点关注充血模型。为什么前面说：如果你遵循正确的使用方式的话，springdata 才是对 DDD 的最佳实践呢？因为有的使用者会写出下面的代码：1234567interface UserRepository extends JpaRepository&lt;User,String&gt;&#123; @Query(\"update user set name=? where id=?\") @Modifying(clearAutomatically = true) @Transactional void updateName(String name,String id);&#125; 历史的车轮在滚滚倒退。本节只关注模型本身，不讨论使用中的一些并发问题，再来聊聊其他的一些最佳实践。1234567interface UserRepository extends JpaRepository&lt;User,String&gt;&#123; User findById();//√ 然后已经存在 findOne 了，只是为了做个对比 User findBy 身份证号 ();// 可以接受 User findBy 名称 ();//× List&lt; 权限 &gt; find 权限 ByUserId();//×&#125; 理论上，一个 Repository 需要且仅需要包含三类方法 loadBy 标识，findAll，save（一般 findAll（）就包含了分页，排序等多个方法，算作一类方法）。标识的含义和前文中 entity 的标识是同一个含义，在我个人的理解中，身份证可以作为一个用户的标识（这取决于你的设计，同样的逻辑还有订单中有业务含义的订单编号，保单中的投保单号等等），在数据库中，id 也可以作为标识。findBy 名称为什么不值得推崇，因为 name 并不是 User 的标识，名字可能会重复，只有在特定的现场场景中，名字才能具体对应到人。那应该如何完成“根据姓名查找可能的用户”这一需求呢？最方便的改造是使用 Criteria，Predicate 来完成视图的查询，哪怕只有一个非标识条件。在更完善的 CQRS 架构中，视图的查询则应该交由专门的 View 层去做，可以是数据库，可以是 ES。findByUserId 不值得推崇则是因为他违背了聚合根模式（下文会介绍），User 的 Repository 只应该返回 User 对象。 软件设计初期，你是不是还在犹豫：是应该先设计数据库呢，还是应该设计实体呢？在 Domain-Driven 的指导下，你应当放弃 Data-Driven。 模式 聚合和聚合根难住我的还有英文单词，初识这个概念时，忍不住发问：Aggregate 是个啥。文中使用聚合的概念，来描述对象之间的关联，采用合适的聚合策略，可以避免一个很长，很深的对象引用路径。对划分模块也有很大的指导意义。 在微服务中我们常说划分服务模块，在领域驱动设计中，我们常说划分限界上下文。在面向对象的世界里，用抽象来封装模型中的引用，聚合就是指一组相关对象的集合，我们把它作为数据修改的单元。每个聚合都有一个聚合根 (root) 和一个边界(boundary)。边界定义了聚合内部有什么，而根则是一个特定的 entity，两个聚合之间，只允许维护根引用，只能通过根引用去向深入引用其他引用变量。 例子还是沿用电商系统中的订单和商品模块。在聚合模式中，订单不能够直接关联到商品的规格信息，如果一定要查询，则应该通过订单关联到的商品，由商品去访问商品规格。在这个例子中，订单和商品分别是两个边界，而订单模块中的订单 entity 和商品模块中的商品 entity 就是分别是各自模块的 root。遵循这个原则，可以使我们模块关系不那么的盘根错节，这也是众多领域驱动文章中不断强调的划分限界上下文是第一要义。 模式 包结构微服务有诸多的模块，而每个模块并不一定是那么的单一职责，比模块更细的分层，便是包的分层。我在阅读中，隐隐觉得这其中蕴含着一层哲学，但是几乎没有文章尝试解读它。领域驱动设计将其单独作为了一个模式进行了论述，篇幅不小。重点就是论述了一个思想：包结构应当具有高内聚性。 这次以一个真实的案例来介绍一下对高内聚的包结构的理解，项目使用 maven 多 module 搭建。我曾经开发过一个短信邮件平台模块，它在整个微服务系统中有两个职责，一：负责为其他模块提供短信邮件发送的远程调用接口，二：有一个后台页面，可以让管理员自定义发送短信，并且可以浏览全部的一，二两种类型发送的短信邮件记录。 在设计包结构之前，先是设计微服务模块。| module 名 | 说明 | package 类型 | 顶级包名 || ——- | ————— | ————– | ———————— || api | api 接口定义，用于暴露服务 | jar | sinosoftgz.message.api || app | api 实现者，真正的服务提供者 | executable jar | sinosoftgz.message.app || admin | 管理端应用 | executable jar | sinosoftgz.message.admin || model | 实体 | jar | sinosoftgz.message.model |api 层定义了一系列的接口和接口依赖的一些 java bean，model 层也就是我们的领域层。这两个模块都会打成 jar 包，外部服务依赖 api，api 则由 app 模块使用 rpc 框架实现远程调用。admin 和 app 连接同一个数据源，可以查询出短信邮件记录，admin 需要自定义发送短信也是通过 rpc 调用。简单介绍完了这个项目后，重点来分析下需求，来看看如何构建包结构。mvc 分层天然将 controller，service，model，config 层分割开，这符合 DDD 所推崇的分层架构模式（这个模式在原文中有描述，但我觉得和现在耳熟能详的分层结构没有太大的出入，所以没有放到本文中介绍），而我们的业务需求也将短信和邮件这两个领域拆分开了。那么，到底是 mvc 应该包含业务包结构呢？还是说业务包结构包含 mvc 呢？ mvc 高于业务分层123456789101112131415161718192021// 不够好的分层sinosoftgz.message.admin config CommonConfig.java service CommonService.java mail MailTemplateService.java MailMessageService.java sms SmsTemplateService.java SmsMessageService.java web IndexController.java mail MailTemplateController.java MailMessageController.java sms SmsTemplateController.java SmsMessageController.java MessageAdminApp.java 业务分层包含 mvc123456789101112131415161718192021222324252627// 高内聚的分层sinosoftgz.message.admin config CommonConfig.java service CommonService.java web IndexController.java mail config MailConfig.java service MailTemplateService.java MailMessageService.java web MailTemplateController.java MailMessageController.java sms config Smsconfig.java service SmsTemplateService.java SmsMessageService.java web SmsTemplateController.java SmsMessageController.java MessageAdminApp.java 业务并不是特别复杂，但应该可以发现第二种（业务分层包含 mvc）的包结构，才是一种高内聚的包结构。第一种分层会让人有一种将各个业务模块（如 mail 和 sms）的 service 和 controller 隔离开了的感觉，当模块更多，每个模块的内容更多，这个“隔得很远”的不适感会逐渐侵蚀你的开发速度。一种更加低内聚的反例是不用包分层，仅仅依赖前缀区分，由于在项目开发中真的发现同事写出了这样的代码，我觉得还是有必要拿出来说一说：12345678910111213141516171819// 反例sinosoftgz.message.admin config CommonConfig.java MailConfig.java Smsconfig.java service CommonService.java MailTemplateService.java MailMessageService.java SmsTemplateService.java SmsMessageService.java web IndexController.java MailTemplateController.java MailMessageController.java SmsTemplateController.java SmsMessageController.java MessageAdminApp.java 这样的设计会导致 web 包越来越庞大，逐渐变得臃肿，是什么使项目僵化，项目经理为何一看到代码就头疼，规范的高内聚的包结构，遵循业务 &gt;mvc 的原则，可以知道我们的项目庞大却有条理。 其他模式《领域驱动设计》这本书介绍了众多的模式，上面只是介绍了一部分重要的模式，后续我会结合各个模式，尽量采用最佳实践 + 浅析设计的方式来解读。 微服务之于领域驱动设计的一点思考技术架构诚然重要，但不可忽视领域拆解和业务架构，《领域驱动设计》中的诸多失败，成功案例的总结，是支撑其理论知识的基础，最终汇聚成众多的模式。在火爆的微服务架构潮流下，我也逐渐意识到微服务不仅仅是技术的堆砌，更是一种设计，一门艺术。我的本科论文本想就微服务架构进行论述，奈何功底不够，最后只能改写成一篇分布式网站设计相关的文章，虽然是一个失败的过程，但让我加深了对微服务的认识。如今结合领域驱动设计，更加让我确定，技术方案始终有代替方案，决定微服务的不是框架的选择，不仅仅是 restful 或者 rpc 的接口设计风格的抉择，而更应该关注拆解，领域，限界上下文，聚合根等等一系列事物，这便是我所理解的领域驱动设计对微服务架构的指导意义。 参考文章多研究些架构，少谈些框架 —- 曹祖鹏 DDD 领域驱动设计基本理论知识总结 - netfocus 欢迎关注我的微信公众号：「Kirito 的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。","categories":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"http://lexburner.github.io/categories/领域驱动设计/"}],"tags":[{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"http://lexburner.github.io/tags/领域驱动设计/"}]},{"title":"spring 中的懒加载与事务 -- 排坑记录","slug":"spring-transation-1","date":"2017-06-23T05:37:41.000Z","updated":"2019-09-26T09:45:31.271Z","comments":true,"path":"spring-transation-1/","link":"","permalink":"http://lexburner.github.io/spring-transation-1/","excerpt":"案例描述本文主要描述了开发中常见的几个与 spring 懒加载和事务相关的案例，描述常见的使用场景，以及如何规避他们，给出具体的代码。 在新的线程中，访问某个持久化对象的懒加载属性。 在 quartz 定时任务中，访问某个持久化对象的懒加载属性。 在 dubbo，motan 一类 rpc 框架中，远程调用时服务端 session 关闭的问题。 上面三个案例，其实核心都是一个问题，就是牵扯到 spring 对事务的管理，而懒加载这个技术，只是比较容易体现出事务出错的一个实践，主要用它来引发问题，进而对问题进行思考。","text":"案例描述本文主要描述了开发中常见的几个与 spring 懒加载和事务相关的案例，描述常见的使用场景，以及如何规避他们，给出具体的代码。 在新的线程中，访问某个持久化对象的懒加载属性。 在 quartz 定时任务中，访问某个持久化对象的懒加载属性。 在 dubbo，motan 一类 rpc 框架中，远程调用时服务端 session 关闭的问题。 上面三个案例，其实核心都是一个问题，就是牵扯到 spring 对事务的管理，而懒加载这个技术，只是比较容易体现出事务出错的一个实践，主要用它来引发问题，进而对问题进行思考。 前期准备为了能直观的暴露出第一个案例的问题，我新建了一个项目，采用传统的 mvc 分层，一个 student.java 实体类，一个 studentDao.java 持久层，一个 studentService.java 业务层，一个 studentController 控制层。 12345678910@Entity@Table(name = \"student\")public class Student &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Integer id; private String name; getter..setter..&#125; 持久层使用 springdata，框架自动扩展出 CURD 方法12public interface StudentDao extends JpaRepository&lt;Student, Integer&gt;&#123;&#125; service 层，先给出普通的调用方法。用于错误演示。1234567891011@Servicepublic class StudentService &#123; @Autowired StudentDao studentDao; public void testNormalGetOne()&#123; Student student = studentDao.getOne(1); System.out.println(student.getName()); &#125;&#125; 注意：getOne 和 findOne 都是 springdata 提供的根据 id 查找单个实体的方法，区别是前者是懒加载，后者是立即加载。我们使用 getOne 来进行懒加载的实验，就不用大费周章去写懒加载属性，设置多个实体类了。 controller 层，不是简简单单的调用，而是在新的线程中调用。使用 controller 层来代替单元测试（实际项目中，通常使用 controller 调用 service，然后在浏览器或者 http 工具中调用触发，较为方便）1234567891011@RequestMapping(\"/testNormalGetOne\")@ResponseBodypublic String testNormalGetOne() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; studentService.testNormalGetOne(); &#125; &#125;).start(); return \"testNormalGetOne\";&#125; 启动项目后，访问 localhost:8080/testNormalGetOne 报错如下：1Exception in thread \"Thread-6\" org.hibernate.LazyInitializationException: could not initialize proxy - no Session 问题分析no session 说明了什么？道理很简单，因为 spring 的 session 是和线程绑定的，在整个 model-&gt;dao-&gt;service-&gt;controller 的调用链中，这种事务和线程绑定的机制非常契合。而我们出现的问题正式由于新开启了一个线程，这个线程与调用链的线程不是同一个。 问题解决我们先使用一种不太优雅的方式解决这个问题。在新的线程中，手动打开 session。 12345678910public void testNormalGetOne() &#123; EntityManagerFactory entityManagerFactory = ApplicationContextProvider.getApplicationContext().getBean(EntityManagerFactory.class); EntityManager entityManager = entityManagerFactory.createEntityManager(); EntityManagerHolder entityManagerHolder = new EntityManagerHolder(entityManager); TransactionSynchronizationManager.bindResource(entityManagerFactory, entityManagerHolder); Student student = studentDao.getOne(1); System.out.println(student.getName()); TransactionSynchronizationManager.unbindResource(entityManagerFactory); EntityManagerFactoryUtils.closeEntityManager(entityManager);&#125; 由于我们使用了 JPA，所以事务是由 EntityManagerFactory 这个工厂类生成的 EntityManager 来管理的。TransactionSynchronizationManager.bindResource(entityManagerFactory, entityManagerHolder); 这个方法使用事务管理器绑定 session。而 ApplicationContextProvider 这个工具类是用来获取 spring 容器中的 EntityManagerFactory 的，为什么不用注入的方式，下文讲解。它的代码如下：12345678910111213public class ApplicationContextProvider implements ApplicationContextAware &#123; private static ApplicationContext context = null; public static ApplicationContext getApplicationContext() &#123; return context; &#125; @Override public void setApplicationContext(ApplicationContext ac) throws BeansException &#123; context = ac; &#125;&#125; 问题暂时得到了解决。 问题再思考我们一般情况下使用懒加载属性，为什么没有出现 no session 的问题呢？相信大家都知道 @Transactional 这个注解，他会帮我们进行事务包裹，当然也会绑定 session；以及大家熟知的 hiberbate 中的 OpenSessionInterceptor 和 OpenSessionInViewFilter 以及 jpa 中的 OpenEntityManagerInViewInterceptor 都是在没有 session 的情况下，打开 session 的过滤器。这种方法开始前依赖事务开启，方法结束后回收资源的操作，非常适合用过滤器拦截器处理，后续的两个未讲解的案例，其实都是使用了特殊的过滤器。 看一下官方文档如何描述这个 jpa 中的过滤器的： 29.3.4 Open EntityManager in View If you are running a web application, Spring Boot will by default register OpenEntityManagerInViewInterceptor to apply the “Open EntityManager in View” pattern, i.e. to allow for lazy loading in web views. If you don’t want this behavior you should set spring.jpa.open-in-view to false in your application.properties. 我们尝试着关闭这个过滤器：配置 application.properties/application.yml 文件1spring.jpa.open-in-view=false 再使用正常的方式访问懒加载属性（而不是在一个新的线程中）： 1234567891011 @RequestMapping(\"/testNormalGetOne\") @ResponseBody public String testNormalGetOne() &#123;// new Thread(new Runnable() &#123;// @Override// public void run() &#123; studentService.testNormalGetOne();// &#125;// &#125;).start(); return \"testNormalGetOne\"; &#125; 报错如下： 1&#123;\"timestamp\":1498194914012,\"status\":500,\"error\":\"Internal Server Error\",\"exception\":\"org.hibernate.LazyInitializationException\",\"message\":\"could not initialize proxy - no Session\",\"path\":\"/testNormalGetOne\"&#125; 是的，我们使用 spring 的 controller 作为单元测试时，以及我们平时在直接使用 jpa 的懒加载属性时没有太关注这个 jpa 的特性，因为 springboot 帮我们默认开启了这个过滤器。这也解释了，为什么在新的线程中，定时任务线程中，rpc 远程调用时 session 没有打开的原因，因为这些流程没有经过 springboot 的 web 调用链。 另外两个实战案例上文已经阐释了，为什么 quartz 定时任务中访问懒加载属性，rpc 框架服务端访问懒加载属性（注意不是客户端，客户端访问懒加载属性那是一种作死的行为，因为是代理对象）为出现问题。我们仿照 spring 打开 session 的思路（这取决于你使用 hibernate 还是 jpa，抑或是 mybatis），来编写我们的过滤器。 quartz 中打开 session：使用 quartz 提供的 JobListenerSupport 支持，编写一个任务过滤器，用于在每次任务执行时打开 session1234567891011121314151617181920212223242526272829303132public class OpenEntityManagerJobListener extends JobListenerSupport implements ApplicationContextAware &#123; @Override public String getName() &#123; return \"OpenEntityManagerJobListener\"; &#125; EntityManagerFactory entityManagerFactory; @Override public void jobToBeExecuted(JobExecutionContext context) &#123; entityManagerFactory = applicationContext.getBean(EntityManagerFactory.class); EntityManager entityManager = entityManagerFactory.createEntityManager(); EntityManagerHolder emHolder = new EntityManagerHolder(entityManager); TransactionSynchronizationManager.bindResource(entityManagerFactory, emHolder); &#125; @Override public void jobWasExecuted(JobExecutionContext context, JobExecutionException jobException) &#123; EntityManagerHolder emHolder = (EntityManagerHolder) TransactionSynchronizationManager.unbindResource(entityManagerFactory); EntityManagerFactoryUtils.closeEntityManager(emHolder.getEntityManager()); &#125; ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; if(this.applicationContext ==null) throw new RuntimeException(\"applicationContext is null\"); &#125;&#125; 配置调度工厂： 12345678// 调度工厂 @Bean public SchedulerFactoryBean schedulerFactoryBean() &#123; SchedulerFactoryBean factoryBean = new SchedulerFactoryBean(); factoryBean.setTriggers(triggerFactoryBeans().getObject()); factoryBean.setGlobalJobListeners(openEntityManagerJobListener()); return factoryBean; &#125; 也可以参考我的另一篇描述更为细致的文章 (解决 Quartz 定时器中查询懒加载数据 no session 的问题)，那是我还是刚刚参加工作，可能有些许疏漏之处，不过参考是够了。 Motan（我现在使用的 rpc 框架）服务端打开 session利用了 motan 对 spi 扩展的支持，编写了一个 Filter，主要参考了 motan 的 spi 过滤器写法和 springdata 打开 session/entityManager 的思路。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158@SpiMeta(name = \"openjpasession\")@Activation(sequence = 100)public class OpenEntityManagerInMotanFilter implements Filter &#123; private Logger logger = LoggerFactory.getLogger(OpenEntityManagerInMotanFilter.class); /** * Default EntityManagerFactory bean name: \"entityManagerFactory\". * Only applies when no \"persistenceUnitName\" param has been specified. * * @see #setEntityManagerFactoryBeanName * @see #setPersistenceUnitName */ public static final String DEFAULT_ENTITY_MANAGER_FACTORY_BEAN_NAME = \"entityManagerFactory\"; private String entityManagerFactoryBeanName; private String persistenceUnitName; private volatile EntityManagerFactory entityManagerFactory; /** * Set the bean name of the EntityManagerFactory to fetch from Spring's * root application context. * &lt;p&gt;Default is \"entityManagerFactory\". Note that this default only applies * when no \"persistenceUnitName\" param has been specified. * * @see #setPersistenceUnitName * @see #DEFAULT_ENTITY_MANAGER_FACTORY_BEAN_NAME */ public void setEntityManagerFactoryBeanName(String entityManagerFactoryBeanName) &#123; this.entityManagerFactoryBeanName = entityManagerFactoryBeanName; &#125; /** * Return the bean name of the EntityManagerFactory to fetch from Spring's * root application context. */ protected String getEntityManagerFactoryBeanName() &#123; return this.entityManagerFactoryBeanName; &#125; /** * Set the name of the persistence unit to access the EntityManagerFactory for. * &lt;p&gt;This is an alternative to specifying the EntityManagerFactory by bean name, * resolving it by its persistence unit name instead. If no bean name and no persistence * unit name have been specified, we'll check whether a bean exists for the default * bean name \"entityManagerFactory\"; if not, a default EntityManagerFactory will * be retrieved through finding a single unique bean of type EntityManagerFactory. * * @see #setEntityManagerFactoryBeanName * @see #DEFAULT_ENTITY_MANAGER_FACTORY_BEAN_NAME */ public void setPersistenceUnitName(String persistenceUnitName) &#123; this.persistenceUnitName = persistenceUnitName; &#125; /** * Return the name of the persistence unit to access the EntityManagerFactory for, if any. */ protected String getPersistenceUnitName() &#123; return this.persistenceUnitName; &#125; /** * Look up the EntityManagerFactory that this filter should use. * &lt;p&gt;The default implementation looks for a bean with the specified name * in Spring's root application context. * * @return the EntityManagerFactory to use * @see #getEntityManagerFactoryBeanName */ protected EntityManagerFactory lookupEntityManagerFactory() &#123; String emfBeanName = getEntityManagerFactoryBeanName(); String puName = getPersistenceUnitName(); if (StringUtils.hasLength(emfBeanName)) &#123; return ApplicationContextProvider.getApplicationContext().getBean(emfBeanName, EntityManagerFactory.class); &#125; else if (!StringUtils.hasLength(puName) &amp;&amp; ApplicationContextProvider.getApplicationContext().containsBean(DEFAULT_ENTITY_MANAGER_FACTORY_BEAN_NAME)) &#123; return ApplicationContextProvider.getApplicationContext().getBean(DEFAULT_ENTITY_MANAGER_FACTORY_BEAN_NAME, EntityManagerFactory.class); &#125; else &#123; // Includes fallback search for single EntityManagerFactory bean by type. return EntityManagerFactoryUtils.findEntityManagerFactory(ApplicationContextProvider.getApplicationContext(), puName); &#125; &#125; /** * Create a JPA EntityManager to be bound to a request. * &lt;p&gt;Can be overridden in subclasses. * * @param emf the EntityManagerFactory to use * @see javax.persistence.EntityManagerFactory#createEntityManager() */ protected EntityManager createEntityManager(EntityManagerFactory emf) &#123; return emf.createEntityManager(); &#125; @Override public Response filter(Caller&lt;?&gt; caller, Request request) &#123; if (!(caller instanceof Provider)) &#123; return caller.call(request); &#125; EntityManagerFactory emf = null; try &#123; emf = lookupEntityManagerFactory(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; // 可能没有启用 openjpa if (emf == null) &#123; return caller.call(request); &#125; try &#123; // 如果没有绑定，绑定到当前线程 if (TransactionSynchronizationManager.getResource(emf) == null) &#123; EntityManager em = createEntityManager(emf); EntityManagerHolder emHolder = new EntityManagerHolder(em); TransactionSynchronizationManager.bindResource(emf, emHolder); &#125; &#125; catch (Exception e) &#123; logger.error(e.getLocalizedMessage(), e); &#125; try &#123; return caller.call(request); &#125; finally &#123; // 解除绑定 closeManager(emf); &#125; &#125; /** * 关闭 emf * * @param emf */ private void closeManager(EntityManagerFactory emf) &#123; if (emf == null || TransactionSynchronizationManager.getResource(emf) == null) &#123; return; &#125; EntityManagerHolder emHolder = null; try &#123; emHolder = (EntityManagerHolder) TransactionSynchronizationManager.unbindResource(emf); &#125; catch (IllegalStateException e) &#123; logger.error(e.getLocalizedMessage(), e); &#125; try &#123; if (emHolder != null) &#123; EntityManagerFactoryUtils.closeEntityManager(emHolder.getEntityManager()); &#125; &#125; catch (Exception e) &#123; logger.error(e.getLocalizedMessage(), e); &#125; &#125;&#125; 总结springboot 中的事务管理做的永远比我们想的多，事务管理器的使用场景，@Transactional 究竟起了哪些作用，以及 spring-data 这个对 DDD 最佳的阐释，以及 mybatis 一类的非 j2ee 规范在微服务的地位中是否高于 jpa，各个层次之间的实体传输，消息传递… 都是值得思考的。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"事务","slug":"事务","permalink":"http://lexburner.github.io/tags/事务/"}]},{"title":"使用 zipkin 做分布式链路监控","slug":"zipkin-usage","date":"2017-06-11T18:51:51.000Z","updated":"2019-09-26T09:45:30.024Z","comments":true,"path":"zipkin-usage/","link":"","permalink":"http://lexburner.github.io/zipkin-usage/","excerpt":"介绍 Zipkin 为一个分布式的调用链跟踪系统 (distributed tracing system) , 设计来源于 google dapper paper 官方网站 快速入门 安装方式一：使用 zipkin 官方提供的 jar 启动服务zipkin 官方提供了一个现成的使用 springboot 写的 zipkin 服务端，客户端的链路监控报告可以通过多种方式（下文会讲解具体的方式）向服务端发送报告。 系统需要安装 java8 下载地址 配置详解查看源码可知其有 4 种持久化方式，本文选择使用最熟悉的 mysql 持久化链路调用信息。 首先建立数据库：默认情况下 zipkin 运行时数据保存在内存中，重启数据会丢失数据库脚本下载 查看与 mysql storage 相关的配置12345678910111213@ConfigurationProperties(\"zipkin.storage.mysql\")public class ZipkinMySQLStorageProperties implements Serializable &#123; // for Spark jobs private static final long serialVersionUID = 0L; private String host = \"localhost\"; private int port = 3306; private String username; private String password; private String db = \"zipkin\"; private int maxActive = 10; private boolean useSsl; ...&#125; 所以，我们使用 mysql 作为持久化策略，启动服务端的脚本也就有了1java -server -jar zipkin-server-1.26.0-exec.jar --zipkin.storage.type=mysql --zipkin.storage.mysql.host=localhost --zipkin.storage.mysql.port=3306 --zipkin.storage.mysql.username=root --zipkin.storage.mysql.password=root --zipkin.storage.mysql.db=zipkin 安装方式二springcloud 官方按照传输方式分成了三种启动服务端的方式：Sleuth with Zipkin via HTTP，Sleuth with Zipkin via Spring Cloud Stream，Spring Cloud Sleuth Stream Zipkin Collector。只需要添加相应的依赖，之后配置相应的注解，如 @EnableZipkinStreamServer 即可。具体配置参考 Spring Cloud 官方文档 项目中，我们使用第一种作为服务端的启动方式，使用 mysql 作为持久化方案","text":"介绍 Zipkin 为一个分布式的调用链跟踪系统 (distributed tracing system) , 设计来源于 google dapper paper 官方网站 快速入门 安装方式一：使用 zipkin 官方提供的 jar 启动服务zipkin 官方提供了一个现成的使用 springboot 写的 zipkin 服务端，客户端的链路监控报告可以通过多种方式（下文会讲解具体的方式）向服务端发送报告。 系统需要安装 java8 下载地址 配置详解查看源码可知其有 4 种持久化方式，本文选择使用最熟悉的 mysql 持久化链路调用信息。 首先建立数据库：默认情况下 zipkin 运行时数据保存在内存中，重启数据会丢失数据库脚本下载 查看与 mysql storage 相关的配置12345678910111213@ConfigurationProperties(\"zipkin.storage.mysql\")public class ZipkinMySQLStorageProperties implements Serializable &#123; // for Spark jobs private static final long serialVersionUID = 0L; private String host = \"localhost\"; private int port = 3306; private String username; private String password; private String db = \"zipkin\"; private int maxActive = 10; private boolean useSsl; ...&#125; 所以，我们使用 mysql 作为持久化策略，启动服务端的脚本也就有了1java -server -jar zipkin-server-1.26.0-exec.jar --zipkin.storage.type=mysql --zipkin.storage.mysql.host=localhost --zipkin.storage.mysql.port=3306 --zipkin.storage.mysql.username=root --zipkin.storage.mysql.password=root --zipkin.storage.mysql.db=zipkin 安装方式二springcloud 官方按照传输方式分成了三种启动服务端的方式：Sleuth with Zipkin via HTTP，Sleuth with Zipkin via Spring Cloud Stream，Spring Cloud Sleuth Stream Zipkin Collector。只需要添加相应的依赖，之后配置相应的注解，如 @EnableZipkinStreamServer 即可。具体配置参考 Spring Cloud 官方文档 项目中，我们使用第一种作为服务端的启动方式，使用 mysql 作为持久化方案 被监控项目配置application.yml 12345678910111213spring: zipkin: #服务端地址 base-url: http://10.19.52.11:9411 #本项目服务名 service: name: $&#123;spring.application.name&#125; sleuth: #监控开关 enabled: true #采样率 sampler: percentage: 1 springboot 对 zipkin 的自动配置可以使得所有 RequestMapping 匹配到的 endpoints 得到监控，以及强化了 restTemplate，对其加了一层拦截器，使得由他发起的 http 请求也同样被监控。 motan rpc 调用监控Motan 通过 filter 的 SPI 扩展机制支持 OpenTracing，可以支持任何实现了 OpenTracing 标准的 trace 实现。使用 OpenTracing 需要以下步骤。 引入 filter-opentracing 扩展 12345&lt;dependency&gt; &lt;groupId&gt;com.weibo&lt;/groupId&gt; &lt;artifactId&gt;filter-opentracing&lt;/artifactId&gt; &lt;version&gt;release&lt;/version&gt;&lt;/dependency&gt; 如果第三方 trace 工具声明了 io.opentracing.Tracer 的 SPI 扩展，直接引入第三方 trace 的 jar 包即可。如果第三方没有声明，则转第三步。 自定义一个 TracerFactory 实现 TracerFactory 接口，通过 getTracer() 来获取不同 tracer 实现。设置 OpenTracingContext 的 tracerFactory 为自定义的 TracerFactory 即可。 项目中的具体配置 MotanConfig.java：12345678910111213141516171819202122232425@Bean(name = \"motanServerBasicConfig\") public BasicServiceConfigBean baseServiceConfig(@Value(\"$&#123;spring.sleuth.enabled:false&#125;\") Boolean tracing ) &#123; BasicServiceConfigBean config = new BasicServiceConfigBean(); ... if(tracing)&#123; config.setFilter(\"sleuth-tracing\"); &#125; ... return config; &#125;@BeanSleuthTracingContext sleuthTracingContext(@Autowired(required = false) org.springframework.cloud.sleuth.Tracer tracer)&#123; SleuthTracingContext context = new SleuthTracingContext(); context.setTracerFactory(new SleuthTracerFactory() &#123; @Override public org.springframework.cloud.sleuth.Tracer getTracer() &#123; return tracer; &#125; &#125;); return context; &#125; 数据查询具体的服务就不列出来了，为了演示依赖关系，service1 使用 restTemplate 调用了 service2,service2 调用了 service3，service4。还有一些现成的 motan 调用 find a trace当应用正常启动后，可以通过 http://10.19.52.11:9411 查看管理端项目已经成功被监控 Dependencies motan 依赖树： http 依赖树：","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://lexburner.github.io/categories/DevOps/"}],"tags":[{"name":"Zipkin","slug":"Zipkin","permalink":"http://lexburner.github.io/tags/Zipkin/"},{"name":"DevOps","slug":"DevOps","permalink":"http://lexburner.github.io/tags/DevOps/"}]},{"title":"JAVA 程序员分级，你属于哪一种？","slug":"java-level","date":"2017-05-02T11:21:03.000Z","updated":"2019-09-26T09:45:31.679Z","comments":true,"path":"java-level/","link":"","permalink":"http://lexburner.github.io/java-level/","excerpt":"","text":"初级 — 初 掌握 java 基础，熟悉常用类库。理解 java web 中的 servlet，jsp，并了解常用的框架对 java web 的封装原理，能够借助框架完成增删改查功能。理解数据库在 web 开发中的地位。 初级 — 中 理解 java 中较为高级的特性，如反射，动态代理，JVM，内存模型，多线程等等。熟练使用框架，对框架中遇到的 bug，能够借助日志和搜索引擎分析出问题的原因。在团队中，能够独立完成普通后台业务功能的开发。了解数据库的高级特性，如索引，存储引擎等等。 初级 — 高 理解 java 分布式架构，微服务架构，了解其与集中式架构的区别，并能保证分布式代码质量。熟练使用各个中间件如 redis，mq，zookeeper 等等，并了解其工作原理和使用场景。能够在中级或高级程序员的带领之下，完成非核心功能的研发。能够关注开源，并且具有阅读源码的能力。 中级 具备一定的项目开发经验（3 年之上一线互联网产品研发经验），拥有线上 bug 的处理能力，JVM 调优能力，以及完成核心业务功能的开发。并且带领团队的新人，能够按能力分配任务。 高级 团队的核心人物，把控整个项目的质量，包括代码漏洞和规范问题。具有 5 年以上项目开发经验，2 年以上架构搭建的经验，能够根据业务选择不同的架构类型；根据团队组成，分配不同的任务。具有将自己的知识分享出去的能力，带领初级程序员走向中级，中级程序员走向高级的能力。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"},{"name":"杂谈","slug":"杂谈","permalink":"http://lexburner.github.io/tags/杂谈/"}]},{"title":"drools 用户指南 ----Cross Products","slug":"drools-4","date":"2017-04-11T05:44:54.000Z","updated":"2019-09-26T09:45:30.901Z","comments":true,"path":"drools-4/","link":"","permalink":"http://lexburner.github.io/drools-4/","excerpt":"","text":"Cross Products之前提到“Cross Products”一词，其实就是一个 join 操作（译者注：可以理解为笛卡尔积）。想象一下，火灾报警示例的数据与以下规则结合使用，其中没有字段约束： 1234567rule \"Show Sprinklers\" when $room : Room() $sprinkler : Sprinkler()then System.out.println(\"room:\" + $room.getName() + \"sprinkler:\" + $sprinkler.getRoom().getName() );end 在 SQL 术语中，这就像是执行了 select * from Room, Sprinkler，Sprinkler 表中的每一行将与 Room 表中的每一行相连接，从而产生以下输出： 12345678910111213141516room:office sprinkler:officeroom:office sprinkler:kitchenroom:office sprinkler:livingroomroom:office sprinkler:bedroomroom:kitchen sprinkler:officeroom:kitchen sprinkler:kitchenroom:kitchen sprinkler:livingroomroom:kitchen sprinkler:bedroomroom:livingroom sprinkler:officeroom:livingroom sprinkler:kitchenroom:livingroom sprinkler:livingroomroom:livingroom sprinkler:bedroomroom:bedroom sprinkler:officeroom:bedroom sprinkler:kitchenroom:bedroom sprinkler:livingroomroom:bedroom sprinkler:bedroom 这些连接结果显然会变得巨大，它们必然包含冗余数据。 cross products 的大小通常是新规则引擎产品性能问题的根源。 从这可以看出，我们希望约束 cross products，这便是用可变约束（the variable constraint）完成的。 12345678rulewhen $room : Room() $sprinkler : Sprinkler(room == $room)then System.out.println(\"room:\" + $room.getName() + \"sprinkler:\" + $sprinkler.getRoom().getName() );end 这就使得筛选结果只有寥寥几行, 这就为每一个 Room 筛选出了正确的 Sprinkler. 在 sql 中 (实际上是 HQL) 这样的查询约等于 select * from Room, Sprinkler where Room == Sprinkler.room.","categories":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/categories/规则引擎/"}],"tags":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/tags/规则引擎/"},{"name":"drools","slug":"drools","permalink":"http://lexburner.github.io/tags/drools/"}]},{"title":"drools 用户指南 ----Methods vs Rules","slug":"drools-3","date":"2017-04-11T05:28:44.000Z","updated":"2019-09-26T09:45:30.828Z","comments":true,"path":"drools-3/","link":"","permalink":"http://lexburner.github.io/drools-3/","excerpt":"","text":"Methods vs Rules人们经常混淆方法和规则，初学者经常会问：“我如何理解规则的含义？“ 在最后一节之后，你会对规则的使用得心应手，答案也变得显而易见的，但在这之前，先让我们总结一下方法判断和规则的差异。 12345public void helloWorld(Person person) &#123; if (person.getName().equals(\"Chuck\") ) &#123; System.out.println(\"Hello Chuck\"); &#125;&#125; 方法是被直接调用的 需要传递具体的实例 一个调用导致一次执行（One call results in a single execution）。 12345rule \"Hello World\" when Person(name == \"Chuck\")then System.out.println(\"Hello Chuck\");end 只要将其插入引擎，就可以通过匹配任何数据执行规则。 规则永远无法被直接调用，而只能触发 无法将特定的实例传递给规则 根据匹配，一个规则可能会触发一次或多次，或根本不被触发。","categories":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/categories/规则引擎/"}],"tags":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/tags/规则引擎/"},{"name":"drools","slug":"drools","permalink":"http://lexburner.github.io/tags/drools/"}]},{"title":"drools 用户指南 ----stateless session（无状态会话）的使用","slug":"drools-1","date":"2017-04-11T04:51:59.000Z","updated":"2019-09-26T09:45:31.146Z","comments":true,"path":"drools-1/","link":"","permalink":"http://lexburner.github.io/drools-1/","excerpt":"stateless session 无状态会话Drools 规则引擎中有如此多的用例和诸多功能，它变得令人难以置信。不过不用担心，复杂性是分层的，你可以用简单的用例来逐步了解 drools。 无状态会话，不使用推理，形成最简单的用例。无状态会话可以被称为函数传递一些数据，然后再接收一些结果。无状态会话的一些常见用例有以下但不限于： 验证这个人有资格获得抵押吗？ 计算计算抵押保费。 路由和过滤将传入的邮件（如电子邮件）过滤到文件夹中。将传入的邮件发送到目的地。 所以让我们从使用驾驶执照应用程序的一个非常简单的例子开始吧。 123456public class Applicant &#123; private String name; private int age; private boolean valid; // getter and setter methods here&#125; 现在我们有了我们的数据模型，我们可以写出我们的第一个规则。我们假设应用程序使用规则来拒绝不符合规则的申请。由于这是一个简单的验证用例，我们将添加一条规则来取消任何 18 岁以下的申请人的资格。 12345678package com.company.licenserule \"Is of valid age\"when $a : Applicant(age &lt; 18)then $a.setValid(false);end","text":"stateless session 无状态会话Drools 规则引擎中有如此多的用例和诸多功能，它变得令人难以置信。不过不用担心，复杂性是分层的，你可以用简单的用例来逐步了解 drools。 无状态会话，不使用推理，形成最简单的用例。无状态会话可以被称为函数传递一些数据，然后再接收一些结果。无状态会话的一些常见用例有以下但不限于： 验证这个人有资格获得抵押吗？ 计算计算抵押保费。 路由和过滤将传入的邮件（如电子邮件）过滤到文件夹中。将传入的邮件发送到目的地。 所以让我们从使用驾驶执照应用程序的一个非常简单的例子开始吧。 123456public class Applicant &#123; private String name; private int age; private boolean valid; // getter and setter methods here&#125; 现在我们有了我们的数据模型，我们可以写出我们的第一个规则。我们假设应用程序使用规则来拒绝不符合规则的申请。由于这是一个简单的验证用例，我们将添加一条规则来取消任何 18 岁以下的申请人的资格。 12345678package com.company.licenserule \"Is of valid age\"when $a : Applicant(age &lt; 18)then $a.setValid(false);end 为了使引擎了解数据，所以可以根据规则进行处理，我们必须插入数据，就像数据库一样。当申请人实例插入到引擎中时，将根据规则的约束进行评估，在这种情况下，这只是一个规则的两个约束条件。我们说两个，因为申请人类型是第一个对象类型约束，而 age &lt;18 是第二个字段约束。对象类型约束及其零个或多个字段约束被称为模式。当插入的实例同时满足对象类型约束和所有字段约束时，它被称为匹配。$a 是一个绑定变量，它允许我们引用匹配的对象。其属性可以更新。美元字符（’$’）是可选的，但它有助于区分变量名称和字段名称。匹配模式与插入数据的过程并不奇怪，通常被称为模式匹配。 要使用这个规则，有必要把它放在一个 Drools 文件中，只是一个带有.drl 扩展名的纯文本文件，简称为“Drools Rule Language”。我们来调用 licenseApplication.drl 这个文件，并将其存储在 Kie Project 中。 Kie 项目具有正常的 Maven 项目的结构，并附加一个可以创建的 KieBase 和 KieSession 文件（kmodule.xml）。该文件必须放在 Maven 项目的 resources/META-INF 文件夹中，而所有其他 Drools 工件（如包含前一规则的 licenseApplication.drl）必须存储在资源文件夹或其下的任何其他子文件夹中。 由于为所有配置方面提供了有意义的默认值，所以最简单的 kmodule.xml 文件只能包含一个空的 kmodule 标签，如下所示： 12&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;kmodule xmlns=\"http://www.drools.org/xsd/kmodule\"/&gt; 此时，可以从类路径创建一个 KieContainer 来读取要构建的文件。 12KieServices kieServices = KieServices.Factory.get();KieContainer kContainer = kieServices.getKieClasspathContainer(); 上面的代码段编译了类路径中找到的所有 DRL 文件，并将该编译结果 KieModule 放在 KieContainer 中。如果没有错误，我们现在可以从 KieContainer 创建我们的会话并执行一些数据： 12345StatelessKieSession kSession = kContainer.newStatelessKieSession();Applicant applicant = new Applicant(\"Mr John Smith\", 16);assertTrue(applicant.isValid() );ksession.execute(applicant);assertFalse(applicant.isValid() ); 上述代码根据规则执行数据。由于申请人年龄未满 18 岁，申请被标记为无效。 到目前为止，我们只使用了一个实例，但是如果我们想要使用多个实例呢？我们可以执行任何实现 Iterable 的对象，如集合。我们再添加一个名为 Application 的类，它有应用程序的日期，我们还将布尔有效字段移到 Application 类。 1234567891011public class Applicant &#123; private String name; private int age; // getter and setter methods here&#125;public class Application &#123; private Date dateApplied; private boolean valid; // getter and setter methods here&#125; 我们还将添加另一条规则来验证申请是否在一段时间内进行。 12345678910111213141516package com.company.licenserule \"Is of valid age\"when Applicant(age &lt; 18) $a : Application() then $a.setValid(false);endrule \"Application was made this year\"when $a : Application(dateApplied &gt; \"01-jan-2009\") then $a.setValid(false);end 不幸的是，Java 数组不实现 Iterable 接口，所以我们必须使用 JDK 转换器方法 Arrays.asList（…）。下面显示的代码针对一个可迭代列表执行，其中在触发任何匹配的规则之前插入所有集合元素。 123456StatelessKieSession kSession = kContainer.newStatelessKieSession();Applicant applicant = new Applicant(\"Mr John Smith\", 16);Application application = new Application();assertTrue(application.isValid() );ksession.execute(Arrays.asList( new Object[] &#123;application, applicant&#125; ) );assertFalse(application.isValid() ); 执行的两个执行方法（Object object）和 execute（Iterable 对象）实际上是接口 BatchExecutor 的方法 execute（Command 命令）的便利方法。 KieCommands 命令工厂可以像 KIE A​​PI 的所有其他工厂一样从 KieServices 获取，用于创建命令，以便以下操作相当于执行（Iterable it）： 1ksession.execute(kieServices.getCommands().newInsertElements(Arrays.asList( new Object[] &#123;application, applicant&#125; ) ); 批处理执行器和命令工厂在使用多个命令和输出标识符以获取结果时特别有用。123456KieCommands kieCommands = kieServices.getCommands();List&lt;Command&gt; cmds = new ArrayList&lt;Command&gt;();cmds.add(kieCommands.newInsert( new Person( \"Mr John Smith\"), \"mrSmith\", true, null ) );cmds.add(kieCommands.newInsert( new Person( \"Mr John Doe\"), \"mrDoe\", true, null ) );BatchExecutionResults results = ksession.execute(kieCommands.newBatchExecution( cmds) );assertEquals(new Person( \"Mr John Smith\"), results.getValue(\"mrSmith\") );","categories":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/categories/规则引擎/"}],"tags":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/tags/规则引擎/"},{"name":"drools","slug":"drools","permalink":"http://lexburner.github.io/tags/drools/"}]},{"title":"drools 用户指南 ----stateful session（有状态会话）的使用","slug":"drools-2","date":"2017-04-11T04:37:22.000Z","updated":"2019-09-26T09:45:30.387Z","comments":true,"path":"drools-2/","link":"","permalink":"http://lexburner.github.io/drools-2/","excerpt":"stateful session 有状态会话有状态会话长期存在，并允许随着时间的推移进行迭代更改。 有状态会话的一些常见用例包括但不限于： 监测半自动买入股票市场监控与分析。 诊断故障查找，医疗诊断 物流包裹跟踪和送货配置 合规验证市场交易的合法性。 与无状态会话相反，必须先调用 dispose() 方法，以确保没有内存泄漏，因为 KieBase 包含创建状态知识会话时的引用。 由于状态知识会话是最常用的会话类型，所以它只是在 KIE API 中命名为 KieSession。 KieSession 还支持 BatchExecutor 接口，如 StatelessKieSession，唯一的区别是 FireAllRules 命令在有状态会话结束时不被自动调用。 我们举例说明了用于提高火灾报警器的监控用例。 只使用四个类，我们假设 Room 代表房子里的房间，每个 Room 都有一个喷头 Sprinkler。 如果在房间里发生火灾，我们用一个 Fire 实例来表示, 用 Alarm 代表警报 。 123456789101112131415161718public class Room &#123; private String name // getter and setter methods here&#125;public class Sprinkler &#123; private Room room; private boolean on; // getter and setter methods here&#125;public class Fire &#123; private Room room; // getter and setter methods here&#125;public class Alarm &#123;&#125; 在上一节无状态会话中介绍了插入和匹配数据的概念。 这个例子假设每个对象类型的都是单个实例被插入的，因此只使用了字面约束。 然而，房子有许多房间，因此 rules 必须表达实体类之间的关系，例如在某个房间内的喷洒器。 这最好通过使用绑定变量作为模式中的约束来完成。 这种“加入”过程产生了所谓的“cross products”，这在下一节中将会介绍。","text":"stateful session 有状态会话有状态会话长期存在，并允许随着时间的推移进行迭代更改。 有状态会话的一些常见用例包括但不限于： 监测半自动买入股票市场监控与分析。 诊断故障查找，医疗诊断 物流包裹跟踪和送货配置 合规验证市场交易的合法性。 与无状态会话相反，必须先调用 dispose() 方法，以确保没有内存泄漏，因为 KieBase 包含创建状态知识会话时的引用。 由于状态知识会话是最常用的会话类型，所以它只是在 KIE API 中命名为 KieSession。 KieSession 还支持 BatchExecutor 接口，如 StatelessKieSession，唯一的区别是 FireAllRules 命令在有状态会话结束时不被自动调用。 我们举例说明了用于提高火灾报警器的监控用例。 只使用四个类，我们假设 Room 代表房子里的房间，每个 Room 都有一个喷头 Sprinkler。 如果在房间里发生火灾，我们用一个 Fire 实例来表示, 用 Alarm 代表警报 。 123456789101112131415161718public class Room &#123; private String name // getter and setter methods here&#125;public class Sprinkler &#123; private Room room; private boolean on; // getter and setter methods here&#125;public class Fire &#123; private Room room; // getter and setter methods here&#125;public class Alarm &#123;&#125; 在上一节无状态会话中介绍了插入和匹配数据的概念。 这个例子假设每个对象类型的都是单个实例被插入的，因此只使用了字面约束。 然而，房子有许多房间，因此 rules 必须表达实体类之间的关系，例如在某个房间内的喷洒器。 这最好通过使用绑定变量作为模式中的约束来完成。 这种“加入”过程产生了所谓的“cross products”，这在下一节中将会介绍。 当发生火灾时，会为该类别创建 Fire 类的实例，并将其插入到会话中。 该规则使用 Fire 对象的房间字段上的绑定来约束与当前关闭的房间的喷水灭火器的匹配。 当此规则触发并且执行结果时，喷头被打开。 12345678rule \"When there is a fire turn on the sprinkler\"when Fire($room : room) $sprinkler : Sprinkler(room == $room, on == false)then modify($sprinkler) &#123;setOn( true) &#125;; System.out.println(\"Turn on the sprinkler for room\" + $room.getName() );end 而无状态会话使用标准 Java 语法来修改字段，在上述规则中，我们使用 modify 语句，它作为一种“with”语句。 它可以包含一系列逗号分隔的 Java 表达式，即对由 modify 语句的控制表达式选择的对象的 setter 的调用。 这将修改数据，并使引擎意识到这些更改，以便它可以再次对其进行推理。 这个过程被称为推理，对于有状态会话的工作至关重要。 无状态会话通常不使用推理，因此引擎不需要意识到数据的更改。 也可以通过使用顺序模式显式地关闭推理。 到目前为止，我们有规则告诉我们匹配数据是否存在，但是当它不存在时呢？ 我们如何确定火已经熄灭了，即没有 Fire 对象呢？ 以前的约束是根据命题逻辑的句子，其中引擎限制个别的实例。 Drools 还支持 First Order Logic，允许您查看数据集。 当某个不存在时，关键字下的模式不匹配。 一旦这个房间的火灾消失，下面给出的规则会使喷水灭火。 123456789rule \"When the fire is gone turn off the sprinkler\"when $room : Room( ) $sprinkler : Sprinkler(room == $room, on == true) not Fire(room == $room)then modify($sprinkler) &#123;setOn( false) &#125;; System.out.println(\"Turn off the sprinkler for room\" + $room.getName() );end 每个 room 有一个喷水灭火器，house 只有一个警报。 当发生火灾时，会创建一个 alrm 对象，而不管发生多少火灾，整个建筑物都只需要一个警报 alrm。 1234567rule \"Raise the alarm when we have one or more fires\"when exists Fire()then insert(new Alarm() ); System.out.println(\"Raise the alarm\");end 同样，当没有火灾时，我们想要删除警报，所以可以再次使用 not 关键字。 12345678rule \"Cancel the alarm when all the fires have gone\"when not Fire() $alarm : Alarm()then delete($alarm); System.out.println(\"Cancel the alarm\");end 最后，当应用程序首次启动并且在报警消除并且所有喷头已关闭后，都会打印 Everything is ok。 1234567rule \"Status output when things are ok\"when not Alarm() not Sprinkler(on == true) then System.out.println(\"Everything is ok\");end 正如我们在无状态会话示例中所做的那样，上述规则应放在单个 DRL 文件中，并保存到 Maven 项目或其任何子文件夹的资源文件夹中。 如前所述，我们可以从 KieContainer 获得 KieSession。 唯一的区别是，这次我们创建一个有状态会话，而之前我们创建的是一个无状态会话。 123KieServices kieServices = KieServices.Factory.get();KieContainer kContainer = kieServices.getKieClasspathContainer();KieSession ksession = kContainer.newKieSession(); 创建会话后，现在可以随着时间的推移迭代地使用它。 创建和插入四个房间对象，每个房间的对应一个 Sprinkler 对象。 此时，规则引擎已经完成了所有的匹配，但并没有触发。 调用 ksession.fireAllRules（）使得匹配的规则触发，但因为没有火灾，所以输出结果是 Everything is ok。 1234567891011String[] names = new String[]&#123;\"kitchen\", \"bedroom\", \"office\", \"livingroom\"&#125;;Map&lt;String,Room&gt; name2room = new HashMap&lt;String,Room&gt;();for(String name: names)&#123; Room room = new Room(name); name2room.put(name, room); ksession.insert(room); Sprinkler sprinkler = new Sprinkler(room); ksession.insert(sprinkler);&#125;ksession.fireAllRules(); Everything is ok 我们现在创造两个 Fire 并插入它们， 随着发动机内部的火灾，一旦调用了 fireAllRules（），报警器就会升高，并且相应的喷水灭火器打开。 123456Fire kitchenFire = new Fire(name2room.get( \"kitchen\") );Fire officeFire = new Fire(name2room.get( \"office\") );FactHandle kitchenFireHandle = ksession.insert(kitchenFire);FactHandle officeFireHandle = ksession.insert(officeFire);ksession.fireAllRules(); Raise the alarmTurn on the sprinkler for room kitchenTurn on the sprinkler for room office 一段时间之后，火灾将熄灭，并且 Fire 实例被撤回。 这导致喷头关闭，报警被取消，最后再次打印 Everything is ok。 1234ksession.delete(kitchenFireHandle);ksession.delete(officeFireHandle);ksession.fireAllRules(); Cancel the alarmTurn off the sprinkler for room officeTurn off the sprinkler for room kitchenEverything is ok","categories":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/categories/规则引擎/"}],"tags":[{"name":"规则引擎","slug":"规则引擎","permalink":"http://lexburner.github.io/tags/规则引擎/"},{"name":"drools","slug":"drools","permalink":"http://lexburner.github.io/tags/drools/"}]},{"title":"Zuul 性能测试","slug":"zuul-test","date":"2017-04-08T07:27:52.000Z","updated":"2019-09-26T09:45:29.855Z","comments":true,"path":"zuul-test/","link":"","permalink":"http://lexburner.github.io/zuul-test/","excerpt":"环境准备采用三台阿里云服务器作为测试10.19.52.8 部署网关应用 -gateway10.19.52.9, 10.19.52.10 部署用于测试的业务系统 压测工具准备选用 ab 作为压力测试的工具，为了方便起见，直接将 ab 工具安装在 10.19.52.8 这台机测试命令如下：1ab -n 10000 -c 100 http://10.19.52.8:8080/hello/testOK?access_token=e0345712-c30d-4bf8-ae61-8cae1ec38c52 其中－n 表示请求数，－c 表示并发数, 上面一条命令也就意味着，100 个用户并发对 http://10.19.52.8/hello/testOK 累计发送了 10000 次请求。 服务器, 网关配置由于我们使用的 tomcat 容器，关于 tomcat 的一点知识总结如下：","text":"环境准备采用三台阿里云服务器作为测试10.19.52.8 部署网关应用 -gateway10.19.52.9, 10.19.52.10 部署用于测试的业务系统 压测工具准备选用 ab 作为压力测试的工具，为了方便起见，直接将 ab 工具安装在 10.19.52.8 这台机测试命令如下：1ab -n 10000 -c 100 http://10.19.52.8:8080/hello/testOK?access_token=e0345712-c30d-4bf8-ae61-8cae1ec38c52 其中－n 表示请求数，－c 表示并发数, 上面一条命令也就意味着，100 个用户并发对 http://10.19.52.8/hello/testOK 累计发送了 10000 次请求。 服务器, 网关配置由于我们使用的 tomcat 容器，关于 tomcat 的一点知识总结如下： Tomcat 的最大并发数是可以配置的，实际运用中，最大并发数与硬件性能和 CPU 数量都有很大关系的。更好的硬件，更多的处理器都会使 Tomcat 支持更多的并发。​Tomcat 默认的 HTTP 实现是采用阻塞式的 Socket 通信，每个请求都需要创建一个线程处理，当一个进程有 500 个线程在跑的话，那性能已经是很低很低了。Tomcat 默认配置的最大请求数是 150，也就是说同时支持 150 个并发。具体能承载多少并发，需要看硬件的配置，CPU 越多性能越高，分配给 JVM 的内存越多性能也就越高，但也会加重 GC 的负担。当某个应用拥有 250 个以上并发的时候，应考虑应用服务器的集群。操作系统对于进程中的线程数有一定的限制： Windows 每个进程中的线程数不允许超过 2000Linux 每个进程中的线程数不允许超过 1000在 Java 中每开启一个线程需要耗用 1MB 的 JVM 内存空间用于作为线程栈之用，此处也应考虑。 所以我们修改配置 tomcat 的默认配置，如下：12345server: tomcat: accept-count: 1000 max-threads: 1000 max-connections: 2000 无论是网关应用，还是用于测试的业务系统的 tomcat，我们都需要如上配置，否则会引起木桶效应，整个调用流程会受到配置最差的应用的干扰。zuul 内部路由可以理解为使用一个线程池去发送路由请求，所以我们也需要扩大这个线程池的容量，配置如下：1234zuul: host: max-per-route-connections: 1000 max-total-connections: 1000 监控工具为了确保上述配置真正起作用，我们使用 Java VisualVM 这个工具监控这几台服务器上部署的 tomcat 的线程以及内存使用情况。启动脚本加上如下参数，之后通过工具连接 2099 端口即可监控1-Dcom.sun.management.jmxremote.port=2099 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=10.19.52.8 开始测试 测试一 通过访问网关，由网关转发，应用端接口延迟 200ms 后返回一个字符串，模拟真实接口的业务处理延迟2.300 个线程并发请求，共计 100000 次1ab -n 100000 -c 300 http://10.19.52.8:8080/hello/testOK?access_token=e0345712-c30d-4bf8-ae61-8cae1ec38c52 1234567891011121314151617181920212223242526272829303132Document Path: /hello/testOK?access_token=e0345712-c30d-4bf8-ae61-8cae1ec38c52Document Length: 2 bytesConcurrency Level: 300Time taken for tests: 151.026 secondsComplete requests: 100000Failed requests: 0Write errors: 0Total transferred: 42200844 bytesHTML transferred: 200004 bytes**Requests per second: 662.14 [#/sec] (mean)**Time per request: 453.078 [ms] (mean)Time per request: 1.510 [ms] (mean, across all concurrent requests)Transfer rate: 272.88 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 5 7.0 2 98Processing: 206 447 478.7 230 3171Waiting: 197 445 478.7 227 3165Total: 206 451 478.8 236 3177Percentage of the requests served within a certain time (ms) 50% 236 66% 250 75% 273 80% 322 90% 1408 95% 1506 98% 1684 99% 1764 100% 3177 (longest request) 测试二： 直接访问应用，应用端接口延迟 200ms 后返回一个字符串，模拟真实接口的业务处理延迟2.300 个线程并发请求，共计 100000 次 1ab -n 100000 -c 300 http://10.19.52.9:9091/testOK 1234567891011121314151617181920212223242526272829303132333435Server Hostname: 10.19.52.9Server Port: 9091Document Path: /testOKDocument Length: 2 bytesConcurrency Level: 300Time taken for tests: 69.003 secondsComplete requests: 100000Failed requests: 0Write errors: 0Total transferred: 13400000 bytesHTML transferred: 200000 bytes**Requests per second: 1449.21 [#/sec] (mean)**Time per request: 207.009 [ms] (mean)Time per request: 0.690 [ms] (mean, across all concurrent requests)Transfer rate: 189.64 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.8 0 10Processing: 200 206 7.7 202 286Waiting: 200 205 7.7 202 286Total: 201 206 7.9 203 295Percentage of the requests served within a certain time (ms) 50% 203 66% 205 75% 207 80% 209 90% 215 95% 220 98% 229 99% 240 100% 295 (longest request) 经过网关路由之后的性能下降是不可避免的，在测试过程中，查看监控端的线程变化，如下图： 我们的配置的确产生了作用。 我们再来分析一下上面测试结果的一个重要指标：Requests per second，我们的网关经过了鉴权之后，性能仍然可以达到 600+ 每秒的响应，是完全可以接受的，峰值时内存情况，使用 top 指令，如下所示：ab 测试命令也占用了一定的 cpu 使用率，总应用接近 70% 的 cpu 使用率，这估计也是单个 tomcat 实例的瓶颈了。因为我们的应用服务器会单独部署网关，并且可以在多个服务器上部署多个实例，所以这个结果可以接受。 为了避免单次响应带来的偶然因素，我们重复进行测试一（更改为 10000 次请求，并发量 200），看看 Requests per second 的变化。 123451. 799.452. 818.863. 838.674. 833.905. 973.65 总结有一些其他的数据没有整理到博客中，但是也顺便把结论写一下。 这次的测试有几个注意点： 是在应用服务器端模拟 200ms 的延时，因为实际请求不可能不伴随着耗时的业务操作，实际发现对 ab 的测试影响还是较大的，毕竟线程阻塞着，不延迟时 request per second 能达到 2000，加了 200ms 延迟之后下降到 1000+。 模拟总请求数和线程数的变化会引起 QPS/TPS 的抖动，即使是在多核 CPU 的承受范围之内，也并不是说线程越多，QPS/TPS 就越高，因为启动线程的开销，以及线程上下文切换的耗时，开辟线程带来的内存损耗都会影响性能。钱总说单个 tomcat 实例的并发度理论值 200 就可以接受了，经过参数调优后的 tomcat 使用 zuul 做网关能达到如上的测试结果，完全可以投入生产环境使用了。而 tomcat 默认的 150 线程，如果使用 200 的并发度测试就显然是“不公平的”。 测试注意点有几个，例如 ab 部署在了 api-gateway 本机会影响性能，tomcat 参数以及 zuul 参数应当尽可能放开，不让其默认配置影响测试。 本文还有些遗漏的数据，后续会补上…","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Zuul","slug":"Spring-Cloud-Zuul","permalink":"http://lexburner.github.io/tags/Spring-Cloud-Zuul/"}]},{"title":"springcloud----Zuul 动态路由","slug":"springcloud-zuul-dynamic-route","date":"2017-04-01T06:11:52.000Z","updated":"2019-09-26T09:45:30.473Z","comments":true,"path":"springcloud-zuul-dynamic-route/","link":"","permalink":"http://lexburner.github.io/springcloud-zuul-dynamic-route/","excerpt":"前言Zuul 是 Netflix 提供的一个开源组件, 致力于在云平台上提供动态路由，监控，弹性，安全等边缘服务的框架。也有很多公司使用它来作为网关的重要组成部分，碰巧今年公司的架构组决定自研一个网关产品，集动态路由，动态权限，限流配额等功能为一体，为其他部门的项目提供统一的外网调用管理，最终形成产品 (这方面阿里其实已经有成熟的网关产品了，但是不太适用于个性化的配置，也没有集成权限和限流降级)。 不过这里并不想介绍整个网关的架构，而是想着重于讨论其中的一个关键点，并且也是经常在交流群中听人说起的：动态路由怎么做？ 再阐释什么是动态路由之前，需要介绍一下架构的设计。 传统互联网架构图上图是没有网关参与的一个最典型的互联网架构 (本文中统一使用 book 代表应用实例，即真正提供服务的一个业务系统) 加入 eureka 的架构图book 注册到 eureka 注册中心中，zuul 本身也连接着同一个 eureka，可以拉取 book 众多实例的列表。服务中心的注册发现一直是值得推崇的一种方式，但是不适用与网关产品。因为我们的网关是面向众多的 其他部门 的 已有 或是 异构架构 的系统，不应该强求其他系统都使用 eureka，这样是有侵入性的设计。 最终架构图要强调的一点是，gateway 最终也会部署多个实例，达到分布式的效果，在架构图中没有画出，请大家自行脑补。 本博客的示例使用最后一章架构图为例，带来动态路由的实现方式，会有具体的代码。","text":"前言Zuul 是 Netflix 提供的一个开源组件, 致力于在云平台上提供动态路由，监控，弹性，安全等边缘服务的框架。也有很多公司使用它来作为网关的重要组成部分，碰巧今年公司的架构组决定自研一个网关产品，集动态路由，动态权限，限流配额等功能为一体，为其他部门的项目提供统一的外网调用管理，最终形成产品 (这方面阿里其实已经有成熟的网关产品了，但是不太适用于个性化的配置，也没有集成权限和限流降级)。 不过这里并不想介绍整个网关的架构，而是想着重于讨论其中的一个关键点，并且也是经常在交流群中听人说起的：动态路由怎么做？ 再阐释什么是动态路由之前，需要介绍一下架构的设计。 传统互联网架构图上图是没有网关参与的一个最典型的互联网架构 (本文中统一使用 book 代表应用实例，即真正提供服务的一个业务系统) 加入 eureka 的架构图book 注册到 eureka 注册中心中，zuul 本身也连接着同一个 eureka，可以拉取 book 众多实例的列表。服务中心的注册发现一直是值得推崇的一种方式，但是不适用与网关产品。因为我们的网关是面向众多的 其他部门 的 已有 或是 异构架构 的系统，不应该强求其他系统都使用 eureka，这样是有侵入性的设计。 最终架构图要强调的一点是，gateway 最终也会部署多个实例，达到分布式的效果，在架构图中没有画出，请大家自行脑补。 本博客的示例使用最后一章架构图为例，带来动态路由的实现方式，会有具体的代码。 动态路由动态路由需要达到可持久化配置，动态刷新的效果。如架构图所示，不仅要能满足从 spring 的配置文件 properties 加载路由信息，还需要从数据库加载我们的配置。另外一点是，路由信息在容器启动时就已经加载进入了内存，我们希望配置完成后，实施发布，动态刷新内存中的路由信息，达到不停机维护路由信息的效果。 zuul–HelloWorldDemo项目结构123456789101112131415161718192021222324252627&lt;groupId&gt;com.sinosoft&lt;/groupId&gt; &lt;artifactId&gt;zuul-gateway-demo&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;modules&gt; &lt;module&gt;gateway&lt;/module&gt; &lt;module&gt;book&lt;/module&gt; &lt;/modules&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR6&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; tip：springboot-1.5.2 对应的 springcloud 的版本需要使用 Camden.SR6，一开始想专门写这个 demo 时，只替换了 springboot 的版本 1.4.0-&gt;1.5.2，结果启动就报错了，最后发现是版本不兼容的锅。 gateway 项目：启动类：GatewayApplication.java123456789@EnableZuulProxy@SpringBootApplicationpublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class, args); &#125;&#125; 配置：application.properties 1234567#配置在配置文件中的路由信息zuul.routes.books.url=http://localhost:8090zuul.routes.books.path=/books/**#不使用注册中心, 会带来侵入性ribbon.eureka.enabled=false#网关端口server.port=8080 book 项目：启动类：BookApplication.java 12345678910111213141516171819@RestController@SpringBootApplicationpublic class BookApplication &#123; @RequestMapping(value = \"/available\") public String available() &#123; System.out.println(\"Spring in Action\"); return \"Spring in Action\"; &#125; @RequestMapping(value = \"/checked-out\") public String checkedOut() &#123; return \"Spring Boot in Action\"; &#125; public static void main(String[] args) &#123; SpringApplication.run(BookApplication.class, args); &#125;&#125; 配置类：application.properties 1server.port=8090 测试访问：http://localhost:8080/books/available 上述 demo 是一个简单的 静态路由 ，简单看下源码，zuul 是怎么做到转发，路由的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140@Configuration@EnableConfigurationProperties(&#123;ZuulProperties.class&#125;)@ConditionalOnClass(ZuulServlet.class)@Import(ServerPropertiesAutoConfiguration.class)public class ZuulConfiguration &#123; @Autowired //zuul 的配置文件, 对应了 application.properties 中的配置信息 protected ZuulProperties zuulProperties; @Autowired protected ServerProperties server; @Autowired(required = false) private ErrorController errorController; @Bean public HasFeatures zuulFeature() &#123; return HasFeatures.namedFeature(\"Zuul (Simple)\", ZuulConfiguration.class); &#125; // 核心类，路由定位器，最最重要 @Bean @ConditionalOnMissingBean(RouteLocator.class) public RouteLocator routeLocator() &#123; // 默认配置的实现是 SimpleRouteLocator.class return new SimpleRouteLocator(this.server.getServletPrefix(), this.zuulProperties); &#125; //zuul 的控制器，负责处理链路调用 @Bean public ZuulController zuulController() &#123; return new ZuulController(); &#125; //MVC HandlerMapping that maps incoming request paths to remote services. @Bean public ZuulHandlerMapping zuulHandlerMapping(RouteLocator routes) &#123; ZuulHandlerMapping mapping = new ZuulHandlerMapping(routes, zuulController()); mapping.setErrorController(this.errorController); return mapping; &#125; // 注册了一个路由刷新监听器，默认实现是 ZuulRefreshListener.class，这个是我们动态路由的关键 @Bean public ApplicationListener&lt;ApplicationEvent&gt; zuulRefreshRoutesListener() &#123; return new ZuulRefreshListener(); &#125; @Bean @ConditionalOnMissingBean(name = \"zuulServlet\") public ServletRegistrationBean zuulServlet() &#123; ServletRegistrationBean servlet = new ServletRegistrationBean(new ZuulServlet(), this.zuulProperties.getServletPattern()); // The whole point of exposing this servlet is to provide a route that doesn't // buffer requests. servlet.addInitParameter(\"buffer-requests\", \"false\"); return servlet; &#125; // pre filters @Bean public ServletDetectionFilter servletDetectionFilter() &#123; return new ServletDetectionFilter(); &#125; @Bean public FormBodyWrapperFilter formBodyWrapperFilter() &#123; return new FormBodyWrapperFilter(); &#125; @Bean public DebugFilter debugFilter() &#123; return new DebugFilter(); &#125; @Bean public Servlet30WrapperFilter servlet30WrapperFilter() &#123; return new Servlet30WrapperFilter(); &#125; // post filters @Bean public SendResponseFilter sendResponseFilter() &#123; return new SendResponseFilter(); &#125; @Bean public SendErrorFilter sendErrorFilter() &#123; return new SendErrorFilter(); &#125; @Bean public SendForwardFilter sendForwardFilter() &#123; return new SendForwardFilter(); &#125; @Configuration protected static class ZuulFilterConfiguration &#123; @Autowired private Map&lt;String, ZuulFilter&gt; filters; @Bean public ZuulFilterInitializer zuulFilterInitializer() &#123; return new ZuulFilterInitializer(this.filters); &#125; &#125; // 上面提到的路由刷新监听器 private static class ZuulRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; @Autowired private ZuulHandlerMapping zuulHandlerMapping; private HeartbeatMonitor heartbeatMonitor = new HeartbeatMonitor(); @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ContextRefreshedEvent || event instanceof RefreshScopeRefreshedEvent || event instanceof RoutesRefreshedEvent) &#123; // 设置为脏, 下一次匹配到路径时，如果发现为脏，则会去刷新路由信息 this.zuulHandlerMapping.setDirty(true); &#125; else if (event instanceof HeartbeatEvent) &#123; if (this.heartbeatMonitor.update(((HeartbeatEvent) event).getValue())) &#123; this.zuulHandlerMapping.setDirty(true); &#125; &#125; &#125; &#125;&#125; 我们要解决动态路由的难题，第一步就得理解路由定位器的作用。很失望，因为从接口关系来看，spring 考虑到了路由刷新的需求，但是默认实现的 SimpleRouteLocator 没有实现 RefreshableRouteLocator 接口，看来我们只能借鉴 DiscoveryClientRouteLocator 去改造 SimpleRouteLocator 使其具备刷新能力。123public interface RefreshableRouteLocator extends RouteLocator &#123; void refresh();&#125; DiscoveryClientRouteLocator 比 SimpleRouteLocator 多了两个功能，第一是从 DiscoveryClient（如 Eureka）发现路由信息，之前的架构图已经给大家解释清楚了，我们不想使用 eureka 这种侵入式的网关模块，所以忽略它，第二是实现了 RefreshableRouteLocator 接口，能够实现动态刷新。对 SimpleRouteLocator.class 的源码加一些注释，方便大家阅读： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165public class SimpleRouteLocator implements RouteLocator &#123; // 配置文件中的路由信息配置 private ZuulProperties properties; // 路径正则配置器, 即作用于 path:/books/** private PathMatcher pathMatcher = new AntPathMatcher(); private String dispatcherServletPath = \"/\"; private String zuulServletPath; private AtomicReference&lt;Map&lt;String, ZuulRoute&gt;&gt; routes = new AtomicReference&lt;&gt;(); public SimpleRouteLocator(String servletPath, ZuulProperties properties) &#123; this.properties = properties; if (servletPath != null &amp;&amp; StringUtils.hasText(servletPath)) &#123; this.dispatcherServletPath = servletPath; &#125; this.zuulServletPath = properties.getServletPath(); &#125; // 路由定位器和其他组件的交互，是最终把定位的 Routes 以 list 的方式提供出去, 核心实现 @Override public List&lt;Route&gt; getRoutes() &#123; if (this.routes.get() == null) &#123; this.routes.set(locateRoutes()); &#125; List&lt;Route&gt; values = new ArrayList&lt;&gt;(); for (String url : this.routes.get().keySet()) &#123; ZuulRoute route = this.routes.get().get(url); String path = route.getPath(); values.add(getRoute(route, path)); &#125; return values; &#125; @Override public Collection&lt;String&gt; getIgnoredPaths() &#123; return this.properties.getIgnoredPatterns(); &#125; // 这个方法在网关产品中也很重要，可以根据实际路径匹配到 Route 来进行业务逻辑的操作，进行一些加工 @Override public Route getMatchingRoute(final String path) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Finding route for path:\" + path); &#125; if (this.routes.get() == null) &#123; this.routes.set(locateRoutes()); &#125; if (log.isDebugEnabled()) &#123; log.debug(\"servletPath=\" + this.dispatcherServletPath); log.debug(\"zuulServletPath=\" + this.zuulServletPath); log.debug(\"RequestUtils.isDispatcherServletRequest()=\" + RequestUtils.isDispatcherServletRequest()); log.debug(\"RequestUtils.isZuulServletRequest()=\" + RequestUtils.isZuulServletRequest()); &#125; String adjustedPath = adjustPath(path); ZuulRoute route = null; if (!matchesIgnoredPatterns(adjustedPath)) &#123; for (Entry&lt;String, ZuulRoute&gt; entry : this.routes.get().entrySet()) &#123; String pattern = entry.getKey(); log.debug(\"Matching pattern:\" + pattern); if (this.pathMatcher.match(pattern, adjustedPath)) &#123; route = entry.getValue(); break; &#125; &#125; &#125; if (log.isDebugEnabled()) &#123; log.debug(\"route matched=\" + route); &#125; return getRoute(route, adjustedPath); &#125; private Route getRoute(ZuulRoute route, String path) &#123; if (route == null) &#123; return null; &#125; String targetPath = path; String prefix = this.properties.getPrefix(); if (path.startsWith(prefix) &amp;&amp; this.properties.isStripPrefix()) &#123; targetPath = path.substring(prefix.length()); &#125; if (route.isStripPrefix()) &#123; int index = route.getPath().indexOf(\"*\") - 1; if (index &gt; 0) &#123; String routePrefix = route.getPath().substring(0, index); targetPath = targetPath.replaceFirst(routePrefix, \"\"); prefix = prefix + routePrefix; &#125; &#125; Boolean retryable = this.properties.getRetryable(); if (route.getRetryable() != null) &#123; retryable = route.getRetryable(); &#125; return new Route(route.getId(), targetPath, route.getLocation(), prefix, retryable, route.isCustomSensitiveHeaders()? route.getSensitiveHeaders() : null); &#125; // 注意这个类并没有实现 refresh 接口，但是却提供了一个 protected 级别的方法, 旨在让子类不需要重复维护一个 private AtomicReference&lt;Map&lt;String, ZuulRoute&gt;&gt; routes = new AtomicReference&lt;&gt;(); 也可以达到刷新的效果 protected void doRefresh() &#123; this.routes.set(locateRoutes()); &#125; // 具体就是在这儿定位路由信息的，我们之后从数据库加载路由信息，主要也是从这儿改写 /** * Compute a map of path pattern to route. The default is just a static map from the * &#123;@link ZuulProperties&#125;, but subclasses can add dynamic calculations. */ protected Map&lt;String, ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulRoute&gt;(); for (ZuulRoute route : this.properties.getRoutes().values()) &#123; routesMap.put(route.getPath(), route); &#125; return routesMap; &#125; protected boolean matchesIgnoredPatterns(String path) &#123; for (String pattern : this.properties.getIgnoredPatterns()) &#123; log.debug(\"Matching ignored pattern:\" + pattern); if (this.pathMatcher.match(pattern, path)) &#123; log.debug(\"Path\" + path + \"matches ignored pattern\" + pattern); return true; &#125; &#125; return false; &#125; private String adjustPath(final String path) &#123; String adjustedPath = path; if (RequestUtils.isDispatcherServletRequest() &amp;&amp; StringUtils.hasText(this.dispatcherServletPath)) &#123; if (!this.dispatcherServletPath.equals(\"/\")) &#123; adjustedPath = path.substring(this.dispatcherServletPath.length()); log.debug(\"Stripped dispatcherServletPath\"); &#125; &#125; else if (RequestUtils.isZuulServletRequest()) &#123; if (StringUtils.hasText(this.zuulServletPath) &amp;&amp; !this.zuulServletPath.equals(\"/\")) &#123; adjustedPath = path.substring(this.zuulServletPath.length()); log.debug(\"Stripped zuulServletPath\"); &#125; &#125; else &#123; // do nothing &#125; log.debug(\"adjustedPath=\" + path); return adjustedPath; &#125;&#125; 重写过后的自定义路由定位器如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169public class CustomRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator&#123; public final static Logger logger = LoggerFactory.getLogger(CustomRouteLocator.class); private JdbcTemplate jdbcTemplate; private ZuulProperties properties; public void setJdbcTemplate(JdbcTemplate jdbcTemplate)&#123; this.jdbcTemplate = jdbcTemplate; &#125; public CustomRouteLocator(String servletPath, ZuulProperties properties) &#123; super(servletPath, properties); this.properties = properties; logger.info(\"servletPath:&#123;&#125;\",servletPath); &#125; // 父类已经提供了这个方法，这里写出来只是为了说明这一个方法很重要！！！// @Override// protected void doRefresh() &#123;// super.doRefresh();// &#125; @Override public void refresh() &#123; doRefresh(); &#125; @Override protected Map&lt;String, ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulRoute&gt;(); // 从 application.properties 中加载路由信息 routesMap.putAll(super.locateRoutes()); // 从 db 中加载路由信息 routesMap.putAll(locateRoutesFromDB()); // 优化一下配置 LinkedHashMap&lt;String, ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); for (Map.Entry&lt;String, ZuulRoute&gt; entry : routesMap.entrySet()) &#123; String path = entry.getKey(); // Prepend with slash if not already present. if (!path.startsWith(\"/\")) &#123; path = \"/\" + path; &#125; if (StringUtils.hasText(this.properties.getPrefix())) &#123; path = this.properties.getPrefix() + path; if (!path.startsWith(\"/\")) &#123; path = \"/\" + path; &#125; &#125; values.put(path, entry.getValue()); &#125; return values; &#125; private Map&lt;String, ZuulRoute&gt; locateRoutesFromDB()&#123; Map&lt;String, ZuulRoute&gt; routes = new LinkedHashMap&lt;&gt;(); List&lt;ZuulRouteVO&gt; results = jdbcTemplate.query(\"select * from gateway_api_define where enabled = true\",new BeanPropertyRowMapper&lt;&gt;(ZuulRouteVO.class)); for (ZuulRouteVO result : results) &#123; if(org.apache.commons.lang3.StringUtils.isBlank(result.getPath()) || org.apache.commons.lang3.StringUtils.isBlank(result.getUrl()) )&#123; continue; &#125; ZuulRoute zuulRoute = new ZuulRoute(); try &#123; org.springframework.beans.BeanUtils.copyProperties(result,zuulRoute); &#125; catch (Exception e) &#123; logger.error(\"=============load zuul route info from db with error==============\",e); &#125; routes.put(zuulRoute.getPath(),zuulRoute); &#125; return routes; &#125; public static class ZuulRouteVO &#123; /** * The ID of the route (the same as its map key by default). */ private String id; /** * The path (pattern) for the route, e.g. /foo/**. */ private String path; /** * The service ID (if any) to map to this route. You can specify a physical URL or * a service, but not both. */ private String serviceId; /** * A full physical URL to map to the route. An alternative is to use a service ID * and service discovery to find the physical address. */ private String url; /** * Flag to determine whether the prefix for this route (the path, minus pattern * patcher) should be stripped before forwarding. */ private boolean stripPrefix = true; /** * Flag to indicate that this route should be retryable (if supported). Generally * retry requires a service ID and ribbon. */ private Boolean retryable; private Boolean enabled; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125; public String getServiceId() &#123; return serviceId; &#125; public void setServiceId(String serviceId) &#123; this.serviceId = serviceId; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public boolean isStripPrefix() &#123; return stripPrefix; &#125; public void setStripPrefix(boolean stripPrefix) &#123; this.stripPrefix = stripPrefix; &#125; public Boolean getRetryable() &#123; return retryable; &#125; public void setRetryable(Boolean retryable) &#123; this.retryable = retryable; &#125; public Boolean getEnabled() &#123; return enabled; &#125; public void setEnabled(Boolean enabled) &#123; this.enabled = enabled; &#125; &#125;&#125; 配置这个自定义的路由定位器： 123456789101112131415161718@Configurationpublic class CustomZuulConfig &#123; @Autowired ZuulProperties zuulProperties; @Autowired ServerProperties server; @Autowired JdbcTemplate jdbcTemplate; @Bean public CustomRouteLocator routeLocator() &#123; CustomRouteLocator routeLocator = new CustomRouteLocator(this.server.getServletPrefix(), this.zuulProperties); routeLocator.setJdbcTemplate(jdbcTemplate); return routeLocator; &#125;&#125; 现在容器启动时，就可以从数据库和配置文件中一起加载路由信息了，离动态路由还差最后一步，就是实时刷新，前面已经说过了，默认的 ZuulConfigure 已经配置了事件监听器，我们只需要发送一个事件就可以实现刷新了。 1234567891011121314public class RefreshRouteService &#123; @Autowired ApplicationEventPublisher publisher; @Autowired RouteLocator routeLocator; public void refreshRoute() &#123; RoutesRefreshedEvent routesRefreshedEvent = new RoutesRefreshedEvent(routeLocator); publisher.publishEvent(routesRefreshedEvent); &#125;&#125; 具体的刷新流程其实就是从数据库重新加载了一遍，有人可能会问，为什么不自己是手动重新加载 Locator.dorefresh？非要用事件去刷新。这牵扯到内部的 zuul 内部组件的工作流程，不仅仅是 Locator 本身的一个变量，具体想要了解的还得去看源码。 到这儿我们就实现了动态路由了，所以的实例代码和建表语句我会放到 github 上，下载的时候记得给我 star QAQ github 地址","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://lexburner.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Zuul","slug":"Spring-Cloud-Zuul","permalink":"http://lexburner.github.io/tags/Spring-Cloud-Zuul/"}]},{"title":"分布式限流","slug":"distribute-ratelimit","date":"2017-03-18T05:52:00.000Z","updated":"2019-09-26T09:45:31.104Z","comments":true,"path":"distribute-ratelimit/","link":"","permalink":"http://lexburner.github.io/distribute-ratelimit/","excerpt":"","text":"前言最近正在为本科论文的事感到心烦，一方面是在调研期间，发现大部分的本科论文都是以 MVC 为架构，如果是使用了 java 作为开发语言则又是千篇一律的在使用 SSH，二方面是自己想就微服务，分布式方面写一篇论文，讲述一些技术点的实现，和一些中间件的使用，看到如八股文般的模板格式.. 不免让人望文生怯。退一步，投入模板化 ssh-web 项目的怀抱，落入俗套，可以省去自己不少时间，因为在外实习，琐事并不少；进一步，需要投入大量时间精力去研究，而且不成体系，没有论文参考。 突然觉得写博客，比写论文爽多了，可以写自己想写的，记录自己最真实的想法。可能会逐渐将之前博客维护的自己的一些想法，纳入到本科论文中去。 经典限流算法说回正题，补上之前分布式限流的实现。先介绍一些现有的限流方案。 核心的算法主要就是四种：A 类：计数器法，滑动窗口法B 类：令牌桶法，漏桶法 这里的四种算法通常都是在应用级别讨论的，这里不重复介绍这四种算法的实现思路了，只不过我人为的将他们分成了 A，B 两类。 A 类算法，是否决式限流。即如果系统设定限流方案是 1 分钟允许 100 次调用，那么真实请求 1 分钟调用 200 次的话，意味着超出的 100 次调用，得到的是空结果或者调用频繁异常。 B 类算法，是阻塞式限流。即如果系统设定限流方案是 1 分钟允许 100 次调用，那么真实请求 1 分钟调用 200 次的话，意味着超出的 100 次调用，会均匀安排到下一分钟返回。（当然 B 类算法，也可以立即返回失败，也可以达到否决式限流的效果） B 类算法，如 Guava 包提供的 RateLimiter，内部其实就是一个阻塞队列，达到阻塞限流的效果。然后分布式场景下，有一些思路悄悄的发生了变化。多个模块之间不能保证相互阻塞，共享的变量也不在一片内存空间中。为了使用阻塞限流的算法，我们不得不将统计流量放到 redis 一类的共享内存中，如果操作是一系列复合的操作，我们还不能使用 redis 自带的 CAS 操作 (CAS 操作只能保证单个操作的原子性) 或者使用中间件级别的队列来阻塞操作，显示加分布式锁的开销又是非常的巨大。最终选择放弃阻塞式限流，而在分布式场景下，仅仅使用 redis+lua 脚本的方式来达到分布式 - 否决式限流的效果。redis 执行 lua 脚本是一个单线程的行为，所以不需要显示加锁，这可以说避免了加锁导致的线程切换开销。 锁的演变下面记录一下这个设计的演变过程。 单体式应用中显示加锁首先还是回到单体应用中对共享变量进行 +1 的例子。12345678910111213141516171819Integer count = 0;//sychronized 锁public synchronized void synchronizedIncrement()&#123; count++; &#125;//juc 中的 lockLock lock = new ReentrantLock(); public void incrementByLock()&#123; lock.lock(); try&#123; count++; &#125;finally &#123; lock.unlock(); &#125; &#125; 用 synchronized 或者 lock 同步的方式进行统计，当单位时间内到达限定次数后否决执行。限制：单体应用下有效，分布式场景失效，显示加锁，开销大。 单体式应用中 CAS 操作 12345public AtomicInteger atomicInteger = new AtomicInteger(0);public increamt()&#123; atomicInteger.incrementAndGet();&#125; 虽然没有显示加锁，但是 CAS 操作有一定的局限性，限流中不仅要对计数器进行 +1，而且还要记录时间段，所以复合操作，还是无法避免加锁。 分布式应用中显示加锁 1234567891011RedisDistributeLock lock = new RedisDistributeLock();public void incrementByLock()&#123; lock.lock(); try&#123; count++; &#125;finally &#123; lock.unlock(); &#125;&#125; 分布式阻塞锁的实现，可以参考我之前的博客。虽然能达到多个模块之间的同步，但还是开销过大。不得已时才会考虑使用。 redis+lua 脚本限流（最终方案） 12345678910111213local key = KEYS[1] -- 限流 KEY（一秒一个）local limit = tonumber(ARGV[1]) -- 限流大小local current = tonumber(redis.call(&apos;get&apos;, key) or &quot;0&quot;)if current + 1 &gt; limit then -- 如果超出限流大小 redis.call(&quot;INCRBY&quot;, key,&quot;1&quot;) -- 如果不需要统计真是访问量可以不加这行 return 0else -- 请求数 +1，并设置 2 秒过期 redis.call(&quot;INCRBY&quot;, key,&quot;1&quot;) if tonumber(ARGV[2]) &gt; -1 then redis.call(&quot;expire&quot;, key,tonumber(ARGV[2])) -- 时间窗口最大时间后销毁键 end return 1end lua 脚本返回值比较奇怪，用 java 客户端接受返回值，只能使用 Long，没有去深究。这个脚本只需要传入 key（url+ 时间戳 / 预设时间窗口大小），便可以实现限流。这里也贴下 java 中配套的工具类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package sinosoftgz.apiGateway.utils;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.script.RedisScript;import org.springframework.util.Assert;import java.util.Arrays;/** * Created by xujingfeng on 2017/3/13. * &lt;p&gt; * 基于 redis lua 脚本的线程安全的计数器限流方案 * &lt;/p&gt; */public class RedisRateLimiter &#123; /** * 限流访问的 url */ private String url; /** * 单位时间的大小, 最大值为 Long.MAX_VALUE - 1, 以秒为单位 */ final Long timeUnit; /** * 单位时间窗口内允许的访问次数 */ final Integer limit; /** * 需要传入一个 lua script, 莫名其妙 redisTemplate 返回值永远是个 Long */ private RedisScript&lt;Long&gt; redisScript; private RedisTemplate redisTemplate; /** * 配置键是否会过期， * true：可以用来做接口流量统计，用定时器去删除 * false：过期自动删除，时间窗口过小的话会导致键过多 */ private boolean isDurable = false; public void setRedisScript(RedisScript&lt;Long&gt; redisScript) &#123; this.redisScript = redisScript; &#125; public void setRedisTemplate(RedisTemplate redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public boolean isDurable() &#123; return isDurable; &#125; public void setDurable(boolean durable) &#123; isDurable = durable; &#125; public RedisRateLimiter(Integer limit, Long timeUnit) &#123; this.timeUnit = timeUnit; Assert.isTrue(timeUnit &lt; Long.MAX_VALUE - 1); this.limit = limit; &#125; public RedisRateLimiter(Integer limit, Long timeUnit, boolean isDurable) &#123; this(limit, timeUnit); this.isDurable = isDurable; &#125; public boolean acquire() &#123; return this.acquire(this.url); &#125; public boolean acquire(String url) &#123; StringBuffer key = new StringBuffer(); key.append(&quot;rateLimiter&quot;).append(&quot;:&quot;) .append(url).append(&quot;:&quot;) .append(System.currentTimeMillis() / 1000 / timeUnit); Integer expire = limit + 1; String convertExpire = isDurable ? &quot;-1&quot; : expire.toString(); return redisTemplate.execute(redisScript, Arrays.asList(key.toString()), limit.toString(), convertExpire).equals(1l); &#125;&#125; 由此可以见，分布式场景下，一个小小的统计次数的需求，如果真想在分布式下做到最完善，需要花很大的精力。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/categories/架构设计/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://lexburner.github.io/tags/redis/"},{"name":"lua","slug":"lua","permalink":"http://lexburner.github.io/tags/lua/"}]},{"title":"DevOps 的八荣八耻","slug":"devops-1","date":"2017-03-13T16:43:52.000Z","updated":"2019-09-26T09:45:31.177Z","comments":true,"path":"devops-1/","link":"","permalink":"http://lexburner.github.io/devops-1/","excerpt":"","text":"前言被群里的好友安利了一发，周日跑去参加了一个技术讲座《云上开发与运维最佳实践》，听完两个人的演讲之后才发现主题竟然是讲运维，好在有一个人干货不少，在此记录下所得。简单追溯了一下这个 DevOps 才发现并不是一个新的概念，早在 2010 年就能看到有相关的人在追捧这个概念了。DevOps 就是开发（Development）和运维（Operations）这两个领域的合并。（如果没错的话，DevOps 还包括产品管理、QA、winces 甚至销售等领域）。这种理念和现如今流行的微服务架构以及分布式特性的相关理念不谋而合。这篇文章主要就是转载记录了当时又拍云运维总监的演讲稿。 DevOps 的八荣八耻DevOps 这个思想提出来已经五六年了，一直都是呼声很高，落地很难，为什么呢？这可能与各个公司的业务情况和技术发展路线有或多或少的关系，比如说创业的最早技术合伙人是运维出身或者技术出身，但是水平不高，为了公司持续发展，引入新鲜血液时，就会存在技术的先进性跟解决遗留烂摊子的矛盾。又或者业务本身偏向于用户，导致技术被边缘化，产品又没有好的架构，限制了快速发展等；所以，DevOps 的推进一定要自上而下，凭借挑战自我，颠覆传统的勇气才能去落实。 以可配置为荣，以硬编码为耻 △ 以可配置为荣，以硬编码为耻 hardcoding 一时爽，真正要做改动时，需要定位代码，做出调整，甚至可能会破坏功能。以下可以说是配置的一个进化史 • 本地配置, 程序⽣生成 (txt/ini/cfg)• 集中配置, 动态⽣生成 (Yaml/Json)• 环境变量量 (代码⽆无侵⼊入 &amp; 语⾔言⽆无关性)• 服务⾃自动发现,⾃自动注册 (zookeeper/consul) 以互备为荣，以单点为耻 △ 以互备为荣，以单点为耻 互容互备一直是优良架构的设计重点。 又拍云早期做架构设计，使用了 LVS+Keeplived+VRRP 做转换，这样可以方便负载均衡，动态升级，隔离故障。现在的又拍云第二代，已经在部分大节点使用 OSPF 和 Quagga 做等价路由的负载均衡和冗余保障。 Nginx 可以加 Haproxy 或 LVS 做负载均衡。MySQL 可以做主从切换，或者是 MMM 的高可用成熟解决方案。我们的消息队列之前用 rabbitmq 做，现在主要是 redis 和 kafka 集群化，其中 kafka 已经迁到了 Mesos 容器平台里。 服务的自动发现、注册，我们可以使用 consul、etcd、doozer（Heroku 公司产品），还有 zookeeper。主要区别是算法不一样，zookeeper 用的是 paxos 算法，而 consul 用的是 raft 算法。目前看来 consul 比较流行，因为 consul 的自动发现和自动注册更加容易使用。etcd 主要是 CoreOS 在主推，CoreOS 本身就是一个滚动发布的针对分布式部署的操作系统，大家可以去关注一下它。还有一个是 hadoop 和 elk，大数据平台的可扩展性是标配，很容易互备。 上面是举了一些常见互备的软件组件的造型，那我们如何是设计一个无单点的架构呢？主要掌握以下几点： 无状态 无状态意味着没有竞争，很容易做负载均衡，负载均衡的方式有很多种，F5，LVS，Haproxy，总能找到一种适合你的方式。 无共享 以前我们很喜欢用内存来保持临时信息，如进程间的交换，这种方式虽然效率很高，但是对程序的扩展性没什么好处，尤其是现在的互联网体量，光靠单机或者高性能机器是明显玩不转的。所以我们现在就需要使用类似消息队列的组件，把数据共享出去，利用多台机器把负载给承担下来。 松耦合 / 异步处理 以前我们用 Gearman 这样的任务框架。大家可以把任务丢进任务池里，生成多个消费者去取任务。当我的消费不够用时，可以平滑增加我的 work 资源，让他从更快的去拿任务。运维平台这边以 python/celery 的组合使用更多。 分布式 / 集群协作 像 Hadoop 这样的天生大数据 / 数据仓库解决方案，由于先前设计比较成熟，一般都是通过很多台机器扩容来实现 map/reduce 的扩展计算能力。 以随时重启为荣，以不能迁移为耻 △ 以随时重启为荣，以不能迁移为耻 关于这个点，我们讲三个方面： 1.Pet 到 Cow 观念的转变 以前我们说机器是 pet，也就是宠物模式，然后花了几万块钱去买的服务器，当宝一般供奉。但事实上却并不是这样，任何电子设备、服务器只要一上线，便开始了一个衰老的过程，你根本不知道在运行过程中会发生什么事，比如说质量差的电容会老化爆浆，电子元器件在机房的恶劣环境里会加速损坏，这些变化都是我们无法参与控制的，所以无论我们怎么努力，都无法保障机器有多么的牢靠。 谷歌指出的 Cow 模式就是指农场模式。就是要把机器发生故障当做常态，打个比方，比如说这头牛死了，那我就不要了，因为我有很多这样的牛，或者是再拉一头新的牛。这就是我们软件开发和运维需要做的转变，去适应这种变化。 2.OpenStack 虚拟机的编排 虚拟化是个好东西，通过 OpenStack 我们很容易就可以做出一些存储或者迁移的操作，但是在实施的过程中，也是一波三折的。 又拍云从 2014 年开始在内部推动 OpenStack，当然我们也踩过 OpenStack 网络的坑，那时候我们用双千兆的卡做内网通讯，因为使用 OpenStack 实现虚拟化后，一切都变成了文件，在网络上传输的话，对网络的压力会非常大，结果就导致部分服务响应缓慢（因为本身就是实验性质，所以在硬件上没有足够投入，内测时也没有推广，所以影响不大）。 2015 年又拍云再上的 OpenStack，全部都用双万兆的网卡做 bonding，交换机也是做了端口聚合和堆叠。目前来说，只有云存储没有上线，其它云处理，云网络的使用还是能够满足要求。 3.Docker 的导入导出 Docker 是更轻量级的资源隔离和复用技术，从 2016 年开始，又拍云同时也在尝试使用 Mesos/Docker 来实现云处理的业务迁移。 以整体交付为荣，以部分交付为耻 △ 以整体交付为荣，以部分交付为耻 以往开发运维要安装一个机器，首先要去申请采购，购买完了还要等待运输，在运输中要花去一天的时间，之后还需要配交换机和网络。在这个过程中你会发现，简单的给开发配台机器，光上架就涉及到运维的很多环节，更不要说系统安装，优化，软件配置等剩余工作了，所以大多数情况下你只能做到部分交付。 要如何解决这些问题？通过 OpenStack 可以做到云计算、云网络、云存储这三块搭建完成之后，进行整体交付。 根据一些经验总结，在整个云平台当中，云存储的坑最多，云计算、云网络相对来说比较成熟。现在云计算的硬件基本上是基于英特尔 CPU 的虚拟化技术来硬件指令穿透的，损耗大概 2%～5%，这是可以接受的。至于云网络，刚才胡凯（B 站运维总监）提到内网包转发效率，我做过一个测试，在 OpenStack 的内网中，如果 MTU 默认是 1500，万兆网卡的转发率大概为 6.7xxGbps。后来我在优化的过程中，也翻查一些文档，看到的数据是可以达到 9.5xxGbps，通过不断的摸索，对比测试后发现，如果把内网的 MTU 搞成大包，如 9000 时，万兆网卡的存储量直接达到了 9.72Gbps 左右的。不过，这个 MTU 需要提前在宿主机上调整好，需要重启生效。所以，这个问题发现得越早越好，这样就可以做到统一调度，分配资源。 Docker 的好处是可以做到 Build、Shipand Run，一气呵成。无论是对开发，测试，还是运维来说，Docker 都是同一份 Dockerfile 清单，所以使用 Docker 在公司里的推动就很顺畅。虽然 OpenStack 也可以一站式交付，整体交付，使用时非常方便。但是对开发来说，他还是拿到一台机器，还是需要去安装软件环境，配置，上线，运行，除了得到机器快一些，对上线服务没有什么大的帮助，所以又拍云现在的 Openstack 集群一般对内申请开发测试用，外网生产环境还是以 Docker 容器化部署为主，这也是大家都喜闻乐见的方式，但前提是开发那边能够适应编写 Dockerfile（目前是我在内部推动这种变革，如新的项目就强制要求用 docker）。 以无状态为荣，以有状态为耻 △ 以无状态为荣，以有状态为耻 有状态的服务真的很麻烦，无论是存在数据库、磁盘开销，还有各种锁等资源的竞争，横向扩展也很差，不能重启，也不能互备。所以，有姿态的服务对于扩展原则来说，就是一场恶梦。如果是说我们解决这个问题，那就要使用解耦和负载均衡的方法去解决问题。 使用可靠的中间件 中间件其实最早出现在金融公司、证券公司，后来随着互联网行业不断壮大以后，就用一些高可靠性的号称工业级的消息队列出现，如 RabbitMQ，一出来以后，就把中间件拉下神坛。随着中间件民用化，互联网蓬勃发展，是可以把一些服务变成无状态，方便扩展。 公共资源池 我们可以通过各种云，容器云、弹性云，做计算单元的弹性扩展。 能够被计算 如果你不想存状态，那也可以被计算，比如说 Ceph 存储，它的创新在于每个数据块都是可计算出来的，这就类似无状态的，每次都算，反正现在的 cpu 都这么强悍了，所以，无状态是一个命题，在做架构的时候，你脑海里一定要有这个意念，然后再看你用什么样的方式开动脑筋，预先的跟开发，运维沟通好，把应用拆分成一种无状态的最佳组合。 以标准化为荣，以特殊化为耻 △ 以标准化为荣，以特殊化为耻 在标准化方面，我们在这几个方面改良： 统一输入输出 统一入口是我加入又拍云后做的第一件事情，我们用一个统一的文本，到现在也在用，然后推送到所有的边缘，服务器上面的组件，要用到的参数，都能从配置里读出来。代码管理方面我们也使用 git，git wiki，批量部署我们用 ansible（早在 2012 年，我做了一些比较后，就在公司里推行 ansible，看来还是很明智的决定）。 统一的流程管理 运维中使用 python 最多，所以我们使用了 yaml 和 playbook。又拍云有自己的跳板机，通过 VPN 登陆，目前我们也在试用一个带有审计功能的堡垒机，可以把每个人的操作录制下来，然后再去回放观察，改进我们的工作流程。 抽象底层设计和复用组件 如果是开发者的话，就会写很多的复用函数，对于优秀的运维人员来说，也要有优秀的抽象业务的能力，也要去做一些重复工作的复用准备，如频繁的，繁琐易出错的手工操作抽象成若干运维的脚本化。 最后是巧妙的利用虚拟化、容器服务、server-less 微服务，这些服务是可以被备份，还原的，可以保持一个相对稳定的状态，我们要拒绝多的特殊管理操作。香农 - 信息熵理论里说，变量的不确定性越大，熵就越大，把它搞清楚所需要的信息量也就越大。理论上来说，如果是一个孤立的系统，他就会变得越来越乱。 以自动化工具为荣，以手动和人肉为耻 △ 以自动化工具为荣，以手动和人肉为耻 又拍云早期，用的是 bash、sed、awk，因为我之前有搞嵌入式的背景和经验，对一个十几兆的嵌入式系统来说，上面是不可能有 python/perl/nodejs 等环境。所以我们把服务器批量安装，部署，上线，做成了嵌入式的系统后，只要点亮以后，运行一个硬件检测的程序，会把机器的 CPU、内存、硬盘大小等都打印出来，供货商截图给我看，这个机器是否合格。合格的机器可以直接发到机房去，在机器到了机房通上网线以后会有一个 ansibleplaybook 的推动。 自从用了这种方法以后，我们在公司里面基本上没有见到服务器，一般直接产线上检测通过后发到机房。然后又拍云的运维人员就可以连上去远程管理，在过去的三年里我们服务器平均每年翻了三倍，节点翻了六倍多，但是人手并没有增加。 关于 tgz、rpm、pkg 的打包部署，我们用的是 tgz 的打包及 docker 镜像。优势在于，又拍云自有 CDN 网络，软件通过推动到 CDN 网络下可以加速下发。 关于集成测试、自动测试的发布，像 ELK 集中日志的分析、大数据的分析，我们现在使用 ELK 以后，只要有基础的运维技术知识便可看懂，不需要高深的运维知识和脚本编辑知识，大多数人都可以完成这份工作，好处就是你多了好多眼睛帮你一起来发现问题，定位问题。 最后是不要图形，不要交互，不要终端。一旦有了图形以后，很难实现自动化。原则就是，不要手工 hack，最好是用程序生成程序的方式去完成这个步骤。 以无人值守为荣，以人工介入为耻 △ 以无人值守为荣，以人工介入为耻 运维部门要做的事情有三件： 运维自动化 要有一定的业务抽象能力，要有标准化的流程。没有好的自动化，就很难把运维的工作效率提升了，只要做好这些，就可以节省时间，从容应对业务增长。而且运维自动化的另一个好处就是运维不会因为人的喜怒哀乐而受到影响稳定性，比如说我今天心情不好，你让我装一台机器我还可以忍，你让我装十台一百台就不行了。但如果公司有了运维自动化的流程，这个事情就可以避免，因为谁做都一样。 监控要常态 2016 年年初，又拍云特别成立大数据分析部门，我们把日志做了采样收集和过滤，通过大数据平台做日志的同构数据分析，重点关注 4xx/5xx/2xx 比例，响应时间分析如 100 毫秒、200 毫秒、500 毫秒，还有区域性的速率分布，讲真，这真是一个好东西。 性能可视化 数据的有效展示。现在 ELK 对我们的帮助很大，从监控图上来看相关的数据指标，一目了然。这里就不反复赘述了。 DevOps 的本质最后，我们谈一谈 DevOps 的本质。 弹性 像亚马逊推云时，那个单词叫 elastic，意思是，你要能够扩展，如横向扩展；你要能负载均衡，如果你是基于 openstack/docker 资源池，你的资源就可以复用，可以编排回滚。比如说 OpenStack 有模板，我打一个镜像包，稍微重了一点，Docker 的就轻一点，Docker 可以做一个滚动发布，可以保留原来的程序、原来的容器，你可以做快速切换，这也是一种变化的弹性。 无关性 如果是虚拟化资源，一切都可以在模板里面设置，可以把底层的硬件、系统、网络抚平差异，比如说不管物理磁盘是 1T(市面上缺货)/4T/6T 的盘，都可以划分 100G 容量，所以当把一切变成按需申请的服务，无论是开发还是运维，工作都会比较简单，因为它的无关性。 不可变的基础设施 这个对传统运维可能是一种打击，因为基础镜像可能已经做的足够安全，足够完美，足够精干，不需要基础运维过多的人工参与。但我认为恰恰能帮助传统运维减轻工作量，反而有更多的精力去迎接虚拟化、容器化，SDN 的挑战，掌握了新技能后，就可以随取随用。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://lexburner.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://lexburner.github.io/tags/DevOps/"}]},{"title":"java 并发实践 --ConcurrentHashMap 与 CAS","slug":"java-ConcurrentHashMap-CAS","date":"2017-03-11T16:02:00.000Z","updated":"2019-09-26T09:45:30.726Z","comments":true,"path":"java-ConcurrentHashMap-CAS/","link":"","permalink":"http://lexburner.github.io/java-ConcurrentHashMap-CAS/","excerpt":"前言最近在做接口限流时涉及到了一个有意思问题，牵扯出了关于 concurrentHashMap 的一些用法，以及 CAS 的一些概念。限流算法很多，我主要就以最简单的计数器法来做引。先抽象化一下需求：统计每个接口访问的次数。一个接口对应一个 url，也就是一个字符串，每调用一次对其进行加一处理。可能出现的问题主要有三个： 多线程访问，需要选择合适的并发容器 分布式下多个实例统计接口流量需要共享内存 流量统计应该尽可能不损耗服务器性能 但这次的博客并不是想描述怎么去实现接口限流，而是主要想描述一下遇到的问题，所以，第二点暂时不考虑，即不使用 redis。 说到并发的字符串统计，立即让人联想到的数据结构便是 ConcurrentHashpMap&lt;String,Long&gt; urlCounter;","text":"前言最近在做接口限流时涉及到了一个有意思问题，牵扯出了关于 concurrentHashMap 的一些用法，以及 CAS 的一些概念。限流算法很多，我主要就以最简单的计数器法来做引。先抽象化一下需求：统计每个接口访问的次数。一个接口对应一个 url，也就是一个字符串，每调用一次对其进行加一处理。可能出现的问题主要有三个： 多线程访问，需要选择合适的并发容器 分布式下多个实例统计接口流量需要共享内存 流量统计应该尽可能不损耗服务器性能 但这次的博客并不是想描述怎么去实现接口限流，而是主要想描述一下遇到的问题，所以，第二点暂时不考虑，即不使用 redis。 说到并发的字符串统计，立即让人联想到的数据结构便是 ConcurrentHashpMap&lt;String,Long&gt; urlCounter; 如果你刚刚接触并发可能会写出如代码清单 1 的代码 代码清单 112345678910111213141516171819202122232425262728293031323334353637383940414243444546public class CounterDemo1 &#123; private final Map&lt;String, Long&gt; urlCounter = new ConcurrentHashMap&lt;&gt;(); // 接口调用次数 +1 public long increase(String url) &#123; Long oldValue = urlCounter.get(url); Long newValue = (oldValue == null) ? 1L : oldValue + 1; urlCounter.put(url, newValue); return newValue; &#125; // 获取调用次数 public Long getCount(String url)&#123; return urlCounter.get(url); &#125; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(10); final CounterDemo1 counterDemo = new CounterDemo1(); int callTime = 100000; final String url = \"http://localhost:8080/hello\"; CountDownLatch countDownLatch = new CountDownLatch(callTime); // 模拟并发情况下的接口调用统计 for(int i=0;i&lt;callTime;i++)&#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; counterDemo.increase(url); countDownLatch.countDown(); &#125; &#125;); &#125; try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; executor.shutdown(); // 等待所有线程统计完成后输出调用次数 System.out.println(\"调用次数：\"+counterDemo.getCount(url)); &#125;&#125;console output：调用次数：96526 都说 concurrentHashMap 是个线程安全的并发容器，所以没有显示加同步，实际效果呢并不如所愿。 问题就出在 increase 方法，concurrentHashMap 能保证的是每一个操作（put，get,delete…）本身是线程安全的，但是我们的 increase 方法，对 concurrentHashMap 的操作是一个组合，先 get 再 put，所以多个线程的操作出现了覆盖。如果对整个 increase 方法加锁，那么又违背了我们使用并发容器的初衷，因为锁的开销很大。我们有没有方法改善统计方法呢？代码清单 2 罗列了 concurrentHashMap 父接口 concurrentMap 的一个非常有用但是又常常被忽略的方法。 代码清单 21234567891011121314/** * Replaces the entry for a key only if currently mapped to a given value. * This is equivalent to * &lt;pre&gt; &#123;@code * if (map.containsKey(key) &amp;&amp; Objects.equals(map.get(key), oldValue)) &#123; * map.put(key, newValue); * return true; * &#125; else * return false; * &#125;&lt;/pre&gt; * * except that the action is performed atomically. */ boolean replace(K key, V oldValue, V newValue); 这其实就是一个最典型的 CAS 操作，except that the action is performed atomically. 这句话真是帮了大忙，我们可以保证比较和设置是一个原子操作，当 A 线程尝试在 increase 时，旧值被修改的话就回导致 replace 失效，而我们只需要用一个循环，不断获取最新值，直到成功 replace 一次，即可完成统计。 改进后的 increase 方法如下 代码清单 31234567891011121314151617181920212223public long increase2(String url) &#123; Long oldValue, newValue; while (true) &#123; oldValue = urlCounter.get(url); if (oldValue == null) &#123; newValue = 1l; // 初始化成功，退出循环 if (urlCounter.putIfAbsent(url, 1l) == null) break; // 如果初始化失败，说明其他线程已经初始化过了 &#125; else &#123; newValue = oldValue + 1; //+1 成功，退出循环 if (urlCounter.replace(url, oldValue, newValue)) break; // 如果 +1 失败，说明其他线程已经修改过了旧值 &#125; &#125; return newValue;&#125;console output：调用次数：100000 再次调用后获得了正确的结果，上述方案看上去比较繁琐，因为第一次调用时需要进行一次初始化，所以多了一个判断，也用到了另一个 CAS 操作 putIfAbsent，他的源代码描述如下： 代码清单 412345678910111213141516171819202122232425/** * If the specified key is not already associated * with a value, associate it with the given value. * This is equivalent to * &lt;pre&gt; &#123;@code * if (!map.containsKey(key)) * return map.put(key, value); * else * return map.get(key); * &#125;&lt;/pre&gt; * * except that the action is performed atomically. * * @implNote This implementation intentionally re-abstracts the * inappropriate default provided in &#123;@code Map&#125;. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with the specified key, or * &#123;@code null&#125; if there was no mapping for the key. * (A &#123;@code null&#125; return can also indicate that the map * previously associated &#123;@code null&#125; with the key, * if the implementation supports null values.) */ V putIfAbsent(K key, V value); 简单翻译如下：“如果（调用该方法时）key-value 已经存在，则返回那个 value 值。如果调用时 map 里没有找到 key 的 mapping，返回一个 null 值”。值得注意点的一点就是 concurrentHashMap 的 value 是不能存在 null 值的。实际上呢，上述的方案也可以把 Long 替换成 AtomicLong，可以简化实现， ConcurrentHashMap&lt;String,AtomicLong&gt;。 juc 包下的各类 Atomic 类也提供了大量的 CAS 操作，可以不用加锁，也可以实现原子操作，以后看到其他类库有类似比较后设值，不存在即设值，加一并获取返回值等等一系列的组合操作合并成了一个接口的，都应该意识到很有可能是 CAS 操作。如 redis 的 IncreamtAndGet，setIfAbsent，Atomic 类的一系列 api，以及上述描述的 concurrentHashMap 中相关的 api（不同 api 的 CAS 组合接口可能名称类似，但是返回值含义不大相同，我们使用 CAS 的 api 很大程度需要获取其返回值来进行分支处理，所以一定要搞清楚每个接口的特性。如 redistemplate 提供的 setIfAbsent，当设置成功时返回的是 true，而与之名称类似的 ConcurrentHashMap 的 putIfAbsent 在设置成功后返回的是 null，要足够小心，加以区分）。凡事没有绝对，但是一个大体上正确的编程建议便是 能使用编程类库并发容器（线程安全的类）完成的操作，尽量不要显示加锁同步 。 再扯一句关于 CAS 的知识点，CAS 不能代替同步，由它引出了一个经典的 ABA 问题，即修改过一次之后，第二次修改又变为了原值，可能会在一些逻辑中出现问题。不过对于计数这个逻辑而言，只是单调的增，不会受到影响。 最后介绍一个和主题非常贴切的并发容器：Guava 包中 AtomicLongMap，使用他来做计数器非常容易。 代码清单 51234567891011private AtomicLongMap&lt;String&gt; urlCounter3 = AtomicLongMap.create();public long increase3(String url) &#123; long newValue = urlCounter3.incrementAndGet(url); return newValue;&#125;public Long getCount3(String url) &#123; return urlCounter3.get(url);&#125; 看一下他的源码就会发现，其实和代码清单 3 思路差不多，只不过功能更完善了一点。 和 CAS 很像的操作，我之前的博客中提到过数据库的乐观锁，用 version 字段来进行并发控制，其实也是一种 compare and swap 的思想。 杂谈：网上很多对 ConcurrentHashMap 的介绍，众所周知，这是一个用分段锁实现的一个线程安全的 map 容器，但是真正对他的使用场景有介绍的少之又少。面试中能知道这个容器的人也确实不少，问出去，也就回答一个分段锁就没有下文了，但我觉得吧，有时候一知半解反而会比不知道更可怕。 参考 https://my.oschina.net/mononite/blog/144329 http://www.tuicool.com/articles/zuui6z","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"},{"name":"多线程","slug":"多线程","permalink":"http://lexburner.github.io/tags/多线程/"}]},{"title":"volatile 疑问记录","slug":"volatile-question","date":"2017-03-07T11:26:52.000Z","updated":"2019-09-26T09:45:29.624Z","comments":true,"path":"volatile-question/","link":"","permalink":"http://lexburner.github.io/volatile-question/","excerpt":"","text":"对 java 中 volatile 关键字的描述，主要是 可见性 和 有序性 两方面。 一个很广泛的应用就是使得多个线程对共享资源的改动变得互相可见，如下： 123456789101112131415161718192021222324252627282930313233343536public class TestVolatile extends Thread &#123; /*A*/// public volatile boolean runFlag = true; public boolean runFlag = true; public boolean isRunFlag() &#123; return runFlag; &#125; public void setRunFlag(boolean runFlag) &#123; this.runFlag = runFlag; &#125; @Override public void run() &#123; System.out.println(\"进入 run\"); while (isRunFlag()) &#123; /*B*/// System.out.println(\"running\"); &#125; System.out.println(\"退出 run\"); &#125; public static void main(String[] args) throws InterruptedException &#123; TestVolatile testVolatile = new TestVolatile(); testVolatile.start(); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; testVolatile.setRunFlag(false); System.out.println(\"main already set runflag to false\"); new CountDownLatch(1).await(); &#125;&#125; 在 A 处如果不将运行标记（runflag）设置成 volatile，那么 main 线程对 runflag 的修改对于 testVolatile 线程将不可见。导致其一直不打印“退出 run”这句。 但是如果在 testVolatile 线程的 while() 增加一句：B 处打印语句，程序却达到了不使用 volatile，修改也变得可见，不知道到底是什么原理。 只能大概估计是 while() 的执行过程中线程上下文进行了切换，使得重新去主存获取了 runflag 的最新值，从而退出了循环，暂时记录… 2017/3/8 日更新和群里面的朋友讨论了一下，发现同一份代码，不同的机器运行出了不一样的效果。又仔细翻阅了一下《effective java》，依稀记得当时好像遇到过这个问题，果然，在并发的第一张就对这个现象做出了解释。关键就在于 HotSpot Server VM 对编译进行了优化，这种优化称之为 提升 (hoisting)，结果导致了 活性失败 （liveness failure） 1while (isRunFlag()) &#123;&#125; 会被优化成 123if(isRunFlag())&#123; while(true)...&#125; 引用 effective java 这一节的原话： 简而言之，当多个线程共享可变数据的时候，每个读或者写数据的线程都必须执行同步如果没有同步，就无法保证一个线程所做的修改可以被另一个线程获知。未能同步共享可变数据会造成程序的活性失败和安全性失败。这样的失败是难以调式的。他们可能是间歇性的，且与时间相关，程序的行为在不同的 VM 上可能根本不同，如果只需要线程之间的交互通信，而不需要互斥，volatile 修饰符就是一种可以接受的同步形式，但是正确的使用它可能需要一些技巧。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"},{"name":"多线程","slug":"多线程","permalink":"http://lexburner.github.io/tags/多线程/"}]},{"title":"浅析 java 内存模型（JMM）","slug":"jmm-learn","date":"2017-02-24T05:07:52.000Z","updated":"2019-09-26T09:45:29.674Z","comments":true,"path":"jmm-learn/","link":"","permalink":"http://lexburner.github.io/jmm-learn/","excerpt":"","text":"并发编程模型的分类在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 Java 内存模型的抽象在 java 中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local variables），方法定义参数（java 语言规范称之为 formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。 Java 线程之间的通信由 Java 内存模型（本文简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读 / 写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java 内存模型的抽象示意图如下： 从上图来看，线程 A 与线程 B 之间如要通信的话，必须要经历下面 2 个步骤： 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。 下面通过示意图来说明这两个步骤： 如上图所示，本地内存 A 和 B 有主内存中共享变量 x 的副本。假设初始时，这三个内存中的 x 值都为 0。线程 A 在执行时，把更新后的 x 值（假设值为 1）临时存放在自己的本地内存 A 中。当线程 A 和线程 B 需要通信时，线程 A 首先会把自己本地内存中修改后的 x 值刷新到主内存中，此时主内存中的 x 值变为了 1。随后，线程 B 到主内存中去读取线程 A 更新后的 x 值，此时线程 B 的本地内存的 x 值也变为了 1。 从整体来看，这两个步骤实质上是线程 A 在向线程 B 发送消息，而且这个通信过程必须要经过主内存。JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 java 程序员提供内存可见性保证。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读 / 写操作的执行顺序，不一定与内存实际发生的读 / 写操作顺序一致！为了具体说明，请看下面示例： Processor A Processor B a = 1; //A1x = b; //A2 b = 2; //B1y = a; //B2 初始状态：a = b = 0 处理器允许执行后得到结果：x = y = 0 假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到 x = y = 0 的结果。 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写 - 读操做重排序。 下面是常见处理器允许的重排序类型的列表： Load-Load Load-Store Store-Store Store-Load 数据依赖 sparc-TSO N N N Y N x86 N N N Y N ia64 Y Y Y Y N PowerPC Y Y Y Y N 上表单元格中的“N”表示处理器不允许两个操作重排序，“Y”表示允许重排序。 从上表我们可以看出：常见的处理器都允许 Store-Load 重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO 和 x86 拥有相对较强的处理器内存模型，它们仅允许对写 - 读操作做重排序（因为它们都使用了写缓冲区）。 ※注 1：sparc-TSO 是指以 TSO(Total Store Order) 内存模型运行时，sparc 处理器的特性。 ※注 2：上表中的 x86 包括 x64 及 AMD64。 ※注 3：由于 ARM 处理器的内存模型与 PowerPC 处理器的内存模型非常类似，本文将忽略它。 ※注 4：数据依赖性后文会专门说明。 为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为下列四类： 屏障类型 指令示例 说明 LoadLoad Barriers Load1; LoadLoad; Load2 确保 Load1 数据的装载，之前于 Load2 及所有后续装载指令的装载。 StoreStore Barriers Store1; StoreStore; Store2 确保 Store1 数据对其他处理器可见（刷新到内存），之前于 Store2 及所有后续存储指令的存储。 LoadStore Barriers Load1; LoadStore; Store2 确保 Load1 数据装载，之前于 Store2 及所有后续的存储指令刷新到内存。 StoreLoad Barriers Store1; StoreLoad; Load2 确保 Store1 数据对其他处理器变得可见（指刷新到内存），之前于 Load2 及所有后续装载指令的装载。StoreLoad Barriers 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 happens-before从 JDK5 开始，java 使用新的 JSR -133 内存模型（本文除非特别说明，针对的都是 JSR- 133 内存模型）。JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 注意，两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens- before 的定义很微妙，后文会具体说明 happens-before 为什么要这么定义。 happens-before 与 JMM 的关系如下图所示： 如上图所示，一个 happens-before 规则通常对应于多个编译器重排序规则和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免程序员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。 原文地址","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"},{"name":"JMM","slug":"JMM","permalink":"http://lexburner.github.io/tags/JMM/"}]},{"title":"浅析项目中的并发","slug":"concurrent-in-project","date":"2017-02-22T03:31:52.000Z","updated":"2019-09-26T09:45:31.137Z","comments":true,"path":"concurrent-in-project/","link":"","permalink":"http://lexburner.github.io/concurrent-in-project/","excerpt":"前言控制并发的方法很多，我之前的两篇博客都有过介绍，从最基础的 synchronized，juc 中的 lock，到数据库的行级锁，乐观锁，悲观锁，再到中间件级别的 redis，zookeeper 分布式锁。今天主要想讲的主题是“根据并发出现的具体业务场景，使用合理的控制并发手段”。 什么是并发由一个大家都了解的例子引入我们今天的主题：并发 123456789101112131415161718192021222324252627public class Demo1 &#123; public Integer count = 0; public static void main(String[] args) &#123; final Demo1 demo1 = new Demo1(); Executor executor = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++)&#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; demo1.count++; &#125; &#125;); &#125; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"final count value:\"+demo1.count); &#125;&#125;console:final count value:973 这个过程中，类变量 count 就是共享资源，而 ++ 操作并不是线程安全的，而多个线程去对 count 执行 ++ 操作，并没有 happens-before 原则保障执行的先后顺序，导致了最终结果并不是想要的 1000","text":"前言控制并发的方法很多，我之前的两篇博客都有过介绍，从最基础的 synchronized，juc 中的 lock，到数据库的行级锁，乐观锁，悲观锁，再到中间件级别的 redis，zookeeper 分布式锁。今天主要想讲的主题是“根据并发出现的具体业务场景，使用合理的控制并发手段”。 什么是并发由一个大家都了解的例子引入我们今天的主题：并发 123456789101112131415161718192021222324252627public class Demo1 &#123; public Integer count = 0; public static void main(String[] args) &#123; final Demo1 demo1 = new Demo1(); Executor executor = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++)&#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; demo1.count++; &#125; &#125;); &#125; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"final count value:\"+demo1.count); &#125;&#125;console:final count value:973 这个过程中，类变量 count 就是共享资源，而 ++ 操作并不是线程安全的，而多个线程去对 count 执行 ++ 操作，并没有 happens-before 原则保障执行的先后顺序，导致了最终结果并不是想要的 1000 下面，我们把并发中的共享资源从类变量转移到数据库中。先来看看使用框架的情况，以 JPA 为例（充血模型） 1234567891011121314151617181920212223242526272829303132@Componentpublic class Demo2 &#123; @Autowired TestNumDao testNumDao; @Transactional public void test()&#123; TestNum testNum = testNumDao.findOne(\"1\"); testNum.setCount(testNum.getCount()+1); testNumDao.save(testNum); &#125;&#125;controller: @Autowired Demo2 demo2; @RequestMapping(\"test\") @ResponseBody public String test()&#123; Executor executor = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++)&#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; demo2.test(); &#125; &#125;); &#125; return \"test\"; &#125; 数据库的记录 id count 1 344 初窥门径的程序员会认为事务最基本的 ACID 中便包含了原子性，但是事务的原子性和今天所讲的并发中的原子操作仅仅是名词上有点类似。而有点经验的程序员都能知道这中间发生了什么（下面细说），这只是暴露了项目中并发问题的冰山一角。 改成直接用 sql 如何呢（贫血模型）？ 1234567891011121314151617181920@RequestMapping(\"testSql\") @ResponseBody public String testSql() throws InterruptedException &#123; final CountDownLatch countDownLatch = new CountDownLatch(1000); long start = System.currentTimeMillis(); Executor executor = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++)&#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; jdbcTemplate.execute(\"update test_num set count = count + 1 where id ='1'\"); countDownLatch.countDown(); &#125; &#125;); &#125; countDownLatch.await(); long costTime =System.currentTimeMillis() - start; System.out.println(\"共花费：\"+costTime+\"s\"); return \"testSql\"; &#125; 数据库结果： count ： 1000 达到了预期效果这个例子我顺便记录了耗时, 控制台打印: 共花费：113 ms简单对比一下二，三两个例子，都是想对数据库的 count 进行 +1 操作，唯一的区别就是，后者的 +1 计算发生在数据库，而前者的计算依赖于事先查出来的值，并且计算发生在程序的内存中。而现在大部分的 ORM 框架的兴起，导致了写第二种代码的程序员变多，不注意并发的话，就会出现问题。下面我们来看看具体的业务场景。 业务场景 修改个人信息 修改商品信息 扣除账户余额，扣减库存 业务场景分析第一个场景，互联网如此众多的用户修改个人信息，这算不算并发？答案是：算也不算。算，从程序员角度来看，每一个用户请求进来，都是调用的同一个修改入口，具体一点，就是映射到 controller 层的同一个 requestMapping，所以一定是并发的。不算，虽然程序是并发的，但是从用户角度来分析，每个人只可以修改自己的信息，所以，不同用户的操作其实是隔离的，所以不算“并发”。这也是为什么很多开发者，在日常开发中一直不注意并发控制，却也没有发生太大问题的原因，大多数初级程序员开发的还都是 CRM，OA，CMS 系统。 回到我们的并发，第一种业务场景，是可以使用如上模式的，对于一条用户数据的修改，我们允许程序员读取数据到内存中，内存计算修改（耗时操作），提交更改，提交事务。 1234567//Transaction startUser user = userDao.findById(\"1\");user.setName(\"newName\");user.setAge(user.getAge()+1);...// 其他耗时操作userDao.save(user);//Transaction commit 这个场景变现为：几乎不存在并发，不需要控制，场景乐观。 为了严谨，也可以选择控制并发，但我觉得这需要交给写这段代码的同事，让他自由发挥。第二个场景已经有所不同了，同样是修改一个记录，但是系统中可能有多个操作员来维护，此时，商品数据表现为一个共享数据，所以存在微弱的并发，通常表现为数据的脏读，例如操作员 A，B 同时对一个商品信息维护，我们希望只能有一个操作员修改成功，另外一个操作员得到错误提示（该商品信息已经发生变化），否则，两个人都以为自己修改成功了，但是其实只有一个人完成了操作，另一个人的操作被覆盖了。 这个场景表现为：存在并发，需要控制，允许失败，场景乐观。 通常我建议这种场景使用乐观锁，即在商品属性添加一个 version 字段标记修改的版本，这样两个操作员拿到同一个版本号，第一个操作员修改成功后版本号变化，另一个操作员的修改就会失败了。 1234567891011121314151617class Goods&#123; @Version int version;&#125;//Transaction starttry&#123; Goods goods = goodsDao.findById(\"1\"); goods.setName(\"newName\"); goods.setPrice(goods.getPrice()+100.00); ...// 其他耗时操作 goodsDao.save(goods);&#125;catch(org.hibernate.StaleObjectStateException e)&#123; // 返回给前台&#125;//Transaction commit springdata 配合 jpa 可以自动捕获 version 异常，也可以自动手动对比。 第三个场景这个场景表现为：存在频繁的并发，需要控制，不允许失败，场景悲观。 强调一下，本例不应该使用在项目中，只是为了举例而设置的一个场景，因为这种贫血模型无法满足复杂的业务场景，而且依靠单机事务来保证一致性，并发性能和可扩展性能不好。 一个秒杀场景，大量请求在短时间涌入，是不可能像第二种场景一样，100 个并发请求，一个成功，其他 99 个全部异常的。 设计方案应该达到的效果是：有足够库存时，允许并发，库存到 0 时，之后的请求全部失败；有足够金额时，允许并发，金额不够支付时立刻告知余额不足。 可以利用数据库的行级锁，update set balance = balance - money where userId = ? and balance &gt;= money;update stock = stock - number where goodsId = ? and stock &gt;= number ; 然后在后台 查看返回值是否影响行数为 1，判断请求是否成功，利用数据库保证并发。 需要补充一点，我这里所讲的秒杀，并不是指双 11 那种级别的秒杀，那需要多层架构去控制并发，前端拦截，负载均衡…. 不能仅仅依赖于数据库的，会导致严重的性能问题。为了留一下一个直观的感受，这里对比一下 oracle，mysql 的两个主流存储引擎：innodb，myisam 的性能问题。123456oracle:10000 个线程共计 1000000 次并发请求：共花费：101017 ms =&gt;101sinnodb:10000 个线程共计 1000000 次并发请求：共花费：550330 ms =&gt;550smyisam:10000 个线程共计 1000000 次并发请求：共花费：75802 ms =&gt;75s 可见，如果真正有大量请求到达数据库，光是依靠数据库解决并发是不现实的，所以仅仅只用数据库来做保障而不是完全依赖。需要根据业务场景选择合适的控制并发手段。 后续，待补充分布式锁控制并发…浅析队列在并发场景中的地位…","categories":[{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/categories/架构设计/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"},{"name":"多线程","slug":"多线程","permalink":"http://lexburner.github.io/tags/多线程/"}]},{"title":"聊聊 IT 行业应届生求职","slug":"fresh-seek-job","date":"2017-02-19T16:57:52.000Z","updated":"2019-09-26T09:45:29.737Z","comments":true,"path":"fresh-seek-job/","link":"","permalink":"http://lexburner.github.io/fresh-seek-job/","excerpt":"前言回首大三下的暑假，那时候刚开始出来找实习，如今已经即将进入大四下学期，恍惚间，已经过去了 8，9 个月。写这篇文章的初衷就是想结合自己的经验给即将要出来找工作的应届生一些建议，想当初自己刚出来时，也得到过热心学长的教导，权当一种传递吧。","text":"前言回首大三下的暑假，那时候刚开始出来找实习，如今已经即将进入大四下学期，恍惚间，已经过去了 8，9 个月。写这篇文章的初衷就是想结合自己的经验给即将要出来找工作的应届生一些建议，想当初自己刚出来时，也得到过热心学长的教导，权当一种传递吧。 个人经历坐标上海，目前在一家 IT 软件公司从事电子商务，金融保险类的网站开发，主要使用的语言是 JAVA。从任职的 3-4 个月起，开始担任项目小组长协同项目经理进行开发。期间由于技术总监常驻广州的原因，我兼任了上海分部这一块的面试工作，主要负责技术部分的面试（TMD 工资却没涨 T__T）。所以对广大来面试者的水平，以及公司想要的人才都有了更深的了解；有了面试经验后，一些观念也有了转变。 面试杂谈大四肯定很多人想出来找实习，但是又完全没有任何经验，这就很尴尬了，我先来说一些一定要注意的点。 不要乱投简历，现在互联网上有很多培训机构，中介机构，打着招聘的牌子，背后却干着培训的勾当。通常是对一些基础不太好的同学进行技术面试，对他们的信心造成碾压，而后，提出培训后入职的建议。通常这类公司就是通过这种手段去拉人培训，招人根本不是初衷。所以，要问清楚公司的情况，有必要面试之前先去百度搜一搜公司的基本情况和评价。 紧接着上面那点，可以通过一些业界信誉比较高的 app 或者网站去筛选公司。如 BOSS 直聘，拉钩，51job，前程无忧… 特别是前面两个，是专门给程序员招聘使用的，针对性很强，对自己能力有了解的同学也可以量力而行，挑选适合自己的岗位。 投简历之前搞清楚公司的性质。IT 行业目前大方向就分为两类：软件公司，互联网公司。我当初刚进公司的时候甲方乙方都搞不清楚，大家可能一下子也不知道这两种公司性质有什么区别。可以参照知乎这个问题的讨论 https://www.zhihu.com/question/20274106/answer/40996303，简单来说同样的能力：软件公司轻松，钱少；互联网公司累，钱多。软件公司中又有外企，民营，国资等划分，工作性质又分为外包，自营... 外包又分为人力外包和项目外包… 互联网公司一说，大家肯定都知道 BAT，京东，谷歌… 还有一个层面的划分就是，软件公司大多提供的是服务，互联网公司通常都有自己的产品，不过这么说不够严谨，权当个参考吧。 下面说一说这么多公司，怎么挑选适合自己的岗位。有很多的参考项，个人的能力，期望的工作地点以及地域的工资水准，未来的职业规划，房价，~~ 对象 ~~，水土气候，人脉等等诸多因素。本人是干 java 的，所以就以 java 求职来做例子，其他职业，专业请结合自己的专业知识做好对比即可。全部以上海为准，上海的起薪大概是 2.8K 左右，这叫基本工资，其他城市，例如无锡，苏州，大概在 2.3k 左右，视经济发展程度而定，先有个大概了解。 下面来看看具体招聘需求A 类： Java 6K-12K职位描述 人品过硬。愿意追随项目长期发展。有能力。 有阅历。 有学历。符合 PSD 原则，即出身贫寒、渴望成功、聪明机智。 不需要我吐槽了吧，这种明明是招技术岗，却对技术没有要求的，估计能骗一些小白去面试，只有技术一无所知，才会退而去要求人品，试想一下，你啥都不会，也只能要求你人品过关了。 B 类： 职位描述 任职要求：1) 大专或以上学历，计算机相关专业，1-3 年以上软件开发经验；2) 熟练掌握 Java 开发技术，j2ee 平台的核心技术的原理：jsp、ajax、servlet，jdbc 等；3) 熟练掌握一种主流数据库：MySQL/sql,server/oracle/DB2，熟悉一种应用服务器的配置：tomcat/jboss/weblogic/websphere；4) 熟悉和理解 Java 开发各层次框架，如 struts、spring、hiberate 等，掌握基本 Web 前台技术；5) 热爱开发工作，具备良好的程序开发驾驭能力，需求分析把握能力；6) 好的沟通和解能力，善于团队合作，逻辑思维强，能够独立思考。 此文我是想写给应届生的，1-3 年的工作经验没那么恐怖，大多数情况下，你的能力够了，公司不会跟你较真，用年限压你，所以看到自己技术水平能够达到，资历却不符合的岗位，也可以尝试着投一投。这类公司其实已经算是对技术有了要求了，而且技术细节都明确了出来，但是，看到只对 jsp，servlet 这些技术有所要求，明眼人都知道，这是在招初级开发，了解一点框架，懂计算机基础，这样的新手，公司还是可以接受的，上海这边针对可以独立开发的应届生，或者培训班出来可以直接上手的非科班生：软件公司，实习开价大概在 4-5k，转正开价大概在 7-8k；互联网公司实习大概在 5-6k，转正开价 9-10k 起步。985/211 或者能力不错能够入职的高校生，在互联网名企的开价，就以阿里为例，我了解到的情况大概是 12k14 or 1216。这里都是说一个上海地区价格，不适用与全国。北京的情况是 IT 非常发达，很多互联网公司都在北京，而上海，深圳，广州其次，注意，上海是金融之都，并非 IT 之都。 C 类 ： Java 工程师 13K-21K任职资格 1) 大学本科或以上学历，计算机相关专业；2) 熟练掌握 core java 以及主流 java 框架，3) 熟悉 HTML5、CSS3、JAVASCRIPT、JQUERY 等前端技术；4) 熟练掌握面向对象的设计原则，熟悉 JAVA 设计模式，具备一定的系统架构设计能力；5) 熟悉常用的互联网相关技术产品和中间件，例如 redis，elasticSearch，activeMq，Dubbo 等；6) 能够带领开发小组独立完成产品功能的模块设计和研发；7) 熟悉面向服务的开发，有大型互联网项目的开发 / 设计经验优先；8) 较强的上进心和求知欲，善于学习和运用新知识，善于沟通和逻辑表达，有强烈的团队意识和执行力。 没找到特别适合本科生的描述，简单概括下这类公司，按照招聘要求来说吧。对计算机专业做要求，说明希望应聘者的专业素质有所保障，懂得基本的操作系统原理，数据结构，编译原理… 因为这些都是本科期间必学的。对 core java 有掌握，说明是要招 java 岗位，基础必须牢固。前端知识有所了解，说明要懂得如果跟前端人员交互，不是完全的服务端开发设计模式和架构，说明不是要招只能够写增删改查的业务人员，更希望是那种能驱动团队的人才一系列中间件的要求说明企业比较正规，跟的上互联网的步伐，通常这类公司的技术总监是比较厉害的，发展前景不错dubbo 一出来，说明该公司还是搞得分布式框架，微服务架构，对程序员的要求更上了一个档次 综合来看，具备以上素质的人当然配得上高一点的工资。 简历简历不要弄虚作假，什么东西是自己做的，什么东西不是自己做的，面试官一句话就能问出来。我面试过的很多人把自己的项目技能写的天花乱坠，随便问一个东西，都不能说个所以然出来，你还写了干嘛，徒增尴尬。 简历不要写与应聘岗位相差太大的描述，如果写了，也要能自圆其说，为什么体现出了自己的才能。我看过一个应聘 JAVA 后端的“人才”写着有普通话证书，来，我现场让你说一段绕口令？还有诸如“参加 XXX 比赛，虽然没得奖，但是自己得到了锻炼”之类的话，真的有必要写在简历上面吗？ 真是没得写的，可以说一说自己大学里面参加的活动体现出怎么样的能力，自己的优异表现，学分绩点，专业课程知识等等。要是实在一无可写… 算了，那还是写普通话证书吧。 有项目经验，比赛经历，专业技能证书，英语考级证书的务必要写上（排名分先后）。都是应届生吗，注意一些技巧，如果你其他方面很突出，但是英语不行，只过了 4 级，那就别写英语 4 级了，因为会暴露你没有过 6 级。用其他证书掩盖过去。这不是欺骗，而是扬长避短。 简历得体大方，模板到处有，关于应届生求职简历的事，可以到知乎好好看看。 公司的诉求普通公司找人，一是看人的基础水平符不符合岗位需求，二是看人的素质符不符合团队的理念，再者就是追求一个性价比。 不是说你能力够了我就要招你，有些时候，公司就是要招基础的业务人员，你技术太厉害，要价太高，完全没必要招你。一个公司的垂直分层，必然是金字塔结构。所以讲究一个对号入座，搞清楚自己的能力，搞清楚自己想要什么样的一份岗位，投简历之前好好看看岗位的描述，公司的诉求。 我面了前前后后也快 30 多个人了，有很多培训班出来的非科班生，很多应届或者一年经验的人，985/211 也有，工作了 12 年的人也有，说实话，能力也就这样，能力很强的人要么出国了，要么内推进了名企，我就只能从我接触到的这些人，说出一些看法。资历在我看来不是很重要，仅仅作为一个参考的位面，好几个工作了 3-4 年的人我感觉好不如咱们应届生，不追求技术的突破，一直干着增删改查操作，问一些 JAVA 基础性的知识又一无所知，要价有得太低，体现出对自己的不自信，有得太高，不清楚自己的定位，入职率很低。再加上现在公司都是对分布式架构的开发，需要的从业者的素质越来越高。整个互联网的趋势也是如此，没有什么人是突然就变得很厉害的，我司技术总监拥有着这么厉害的技术，在我所知也是靠着毕业后依旧数年如一日的对技术的热忱追求。所以，特别是 IT 互联网行业，更希望找到的，是有一颗学习的心，具备终身学习能力的人，以应对日新月异的互联网技术变更。 最后大多数人还是需要有自己的思考，此文谨代表个人看法供大家参考。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/categories/技术杂谈/"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://lexburner.github.io/tags/技术杂谈/"},{"name":"求职","slug":"求职","permalink":"http://lexburner.github.io/tags/求职/"}]},{"title":"《微服务》九大特性笔记","slug":"ms-1","date":"2017-02-18T17:05:52.000Z","updated":"2019-09-26T09:45:31.227Z","comments":true,"path":"ms-1/","link":"","permalink":"http://lexburner.github.io/ms-1/","excerpt":"","text":"服务组件化组件，是一个可以独立更换和升级的单元。就像 PC 中的 CPU、内存、显卡、硬盘一样，独立且可以更换升级而不影响其他单元。 在“微服务”架构中，需要我们对服务进行组件化分解。服务，是一种进程外的组件，它通过 http 等通信协议进行协作，而不是传统组件以嵌入的方式协同工作。服务都独立开发、部署，可以有效的避免一个服务的修改引起整个系统的重新部署。 打一个不恰当的比喻，如果我们的 PC 组件以服务的方式构建，我们只维护主板和一些必要外设之后，计算能力通过一组外部服务实现，我们只需要告诉 PC 我们从哪个地址来获得计算能力，通过服务定义的计算接口来实现我们使用过程中的计算需求，从而实现 CPU 组件的服务化。这样我们原本复杂的 PC 服务得到了更轻量化的实现，我们甚至只需要更换服务地址就能升级我们 PC 的计算能力。 按业务组织团队当我们开始决定如何划分“微服务”时，通常也意味着我们要开始对团队进行重新规划与组织。按以往的方式，我们往往会以技术的层面去划分多个不同的团队，比如：DBA 团队、运维团队、后端团队、前端团队、设计师团队等等。若我们继续按这种方式组织团队来实施“微服务”架构开发时，当有一个有问题需要更改，可能是一个非常简单的变动，比如：对人物描述增加一个字段，这就需要从数据存储开始考虑一直到设计和前端，虽然大家的修改都非常小，但这会引起跨团队的时间和预算审批。 在实施“微服务”架构时，需要采用不同的团队分割方法。由于每一个微服务都是针对特定业务的宽栈或是全栈实现，既要负责数据的持久化存储，又要负责用户的接口定义等各种跨专业领域的职能。因此，面对大型项目时候，对于微服务团队拆分更加建议按业务线的方式进行拆分，一方面可以有效减少服务内部修改所产生的内耗；另一方面，团队边界可以变得更为清晰。 做“产品”的态度实施“微服务”架构的团队中，每个小团队都应该以做产品的方式，对其产品的整个生命周期负责。而不是以项目的模式，以完成开发与交付并将成果交接给维护者为最终目标。 开发团队通过了解服务在具体生产环境中的情况，可以增加他们对具体业务的理解，比如：很多时候一些业务中发生的特殊或异常情况，很可能产品经理都并不知晓，但细心的开发者很容易通过生产环境发现这些特殊的潜在问题或需求。 所以，我们需要用做“产品”的态度来对待每一个“微服务”，持续关注服务的运作情况，并不断地分析帮助用户来提升业务功能。 智能端点与哑管道在单体应用中，组件间直接通过函数调用的方式进行交互协作。而在“微服务”架构中，服务由于不在一个进程中，组件间的通信模式发生了改变，若仅仅将原本在进程内的方法调用改成 RPC 方式的调用，会导致微服务之间产生繁琐的通信，使得系统表现更为糟糕，所以，我们需要更粗粒度的通信协议。 在“微服务”架构中，通常会使用这两个服务调用方式： 第一种，使用 HTTP 协议的 RESTful API 或轻量级的消息发送协议，来实现信息传递与服务调用的触发。第二种，通过在轻量级消息总线上传递消息，类似 RabbitMQ 等一些提供可靠异步交换的结构。 在极度强调性能的情况下，有些团队会使用二进制的消息发送协议，例如：protobuf。即使是这样，这些系统仍然会呈现出“智能端点和哑管道”的特点，为了在易读性与高效性之间取得平衡。当然大多数 Web 应用或企业系统并不需要作出在这两者间做出选择，能够获得易读性就已经是一个极大的胜利了。——Martin Fowler 去中心化治理当我们采用集中化的架构治理方案时，通常在技术平台上都会做同一的标准，但是每一种技术平台都有其短板，这会导致在碰到短板时，不得不花费大力气去解决，并且可能还是因为其底层原因解决的不是很好。 在实施“微服务”架构时，通过采用轻量级的契约定义接口，使得我们对于服务本身的具体技术平台不再那么敏感，这样我们整个“微服务”架构的系统中的组件就能针对其不同的业务特点选择不同的技术平台，终于不会出现杀鸡用牛刀或是杀牛用指甲钳的尴尬处境了。 不是每一个问题都是钉子，不是每一个解决方案都是锤子 去中心化管理数据我们在实施“微服务”架构时，都希望可以让每一个服务来管理其自有的数据库，这就是数据管理的去中心化。 在去中心化过程中，我们除了将原数据库中的存储内容拆分到新的同平台的其他数据库实例中之外（如：把原本存储在 MySQL 中的表拆分后，存储多几个不同的 MySQL 实例中），也可以针对一些具有特殊结构或业务特性的数据存储到一些其他技术的数据库实例中（如：把日志信息存储到 MongoDB 中、把用户登录信息存储到 Redis 中）。 虽然，数据管理的去中心化可以让数据管理更加细致化，通过采用更合适的技术来让数据存储和性能达到最优。但是，由于数据存储于不同的数据库实例中后，数据一致性也成为“微服务”架构中急需解决的问题之一。分布式事务的实现，本身难度就非常大，所以在“微服务”架构中，我们更强调在各服务之间进行“无事务”的调用，而对于数据一致性，只要求数据在最后的处理状态是一致的效果；若在过程中发现错误，通过补偿机制来进行处理，使得错误数据能够达到最终的一致性。 基础设施自动化近年来云计算服务与容器化技术的不断成熟，运维基础设施的工作变得越来越不那么难了。但是，当我们实施“微服务”架构时，数据库、应用程序的个头虽然都变小了，但是因为拆分的原因，数量成倍的增长。这使得运维人员需要关注的内容也成倍的增长，并且操作性任务也会成倍的增长，这些问题若没有得到妥善的解决，必将成为运维人员的噩梦。 所以，在“微服务”架构中，请务必从一开始就构建起“持续交付”平台来支撑整个实施过程，该平台需要两大内容，不可或缺： 自动化测试：每次部署前的强心剂，尽可能的获得对正在运行软件的信心。自动化部署：解放繁琐枯燥的重复操作以及对多环境的配置管理。 容错设计在单体应用中，一般不存在单个组件故障而其他还在运行的情况，通常是一挂全挂。而在“微服务”架构中，由于服务都运行在独立的进程中，所以是存在部分服务出现故障，而其他服务都正常运行的情况，比如：当正常运作的服务 B 调用到故障服务 A 时，因故障服务 A 没有返回，线程挂起开始等待，直到超时才能释放，而此时若触发服务 B 调用服务 A 的请求来自服务 C，而服务 C 频繁调用服务 B 时，由于其依赖服务 A，大量线程被挂起等待，最后导致服务 A 也不能正常服务，这时就会出现故障的蔓延。 所以，在“微服务”架构中，快速的检测出故障源并尽可能的自动恢复服务是必须要被设计和考虑的。通常，我们都希望在每个服务中实现监控和日志记录的组件，比如：服务状态、断路器状态、吞吐量、网络延迟等关键数据的仪表盘等。 演进式设计通过上面的几点特征，我们已经能够体会到，要实施一个完美的“微服务”架构，需要考虑的设计与成本并不小，对于没有足够经验的团队来说，甚至要比单体应用发付出更多的代价。 所以，很多情况下，架构师们都会以演进的方式进行系统的构建，在初期系统以单体系统的方式来设计和实施，一方面系统体量初期并不会很大，构建和维护成本都不高。另一方面，初期的核心业务在后期通常也不会发生巨大的改变。随着系统的发展或者业务的需要，架构师们会将一些经常变动或是有一定时间效应的内容进行“微服务”处理，并逐渐地将原来在单体系统中多变的模块逐步拆分出来，而稳定不太变化的就形成了一个核心“微服务”存在于整个架构之中。 原文由 程序猿 DD- 翟永超 创作 *转载自 《微服务》九大特性笔记","categories":[{"name":"架构设计","slug":"架构设计","permalink":"http://lexburner.github.io/categories/架构设计/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://lexburner.github.io/tags/微服务/"}]},{"title":"ThreadLocal 的最佳实践","slug":"threadLocal","date":"2017-02-14T09:38:52.000Z","updated":"2019-09-26T09:45:31.056Z","comments":true,"path":"threadLocal/","link":"","permalink":"http://lexburner.github.io/threadLocal/","excerpt":"","text":"SimpleDateFormat 众所周知是线程不安全的，多线程中如何保证线程安全又同时兼顾性能问题呢？那就是使用 ThreadLocal 维护 SimpleDateFormat 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class SimpleDateFormatThreadTest &#123; static volatile AtomicInteger n = new AtomicInteger(-1); static ThreadLocal&lt;DateFormat&gt; sdf ; static &#123; sdf =new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(\"yyyy-MM-dd\"); &#125; &#125;; &#125; public static void main(String[] args) throws ParseException, InterruptedException &#123; Set&lt;String&gt; dateSet = new ConcurrentHashSet&lt;&gt;(); Set&lt;Integer&gt; numberSet = new ConcurrentHashSet&lt;&gt;(); Date[] dates = new Date[1000]; for (int i = 0; i &lt; 1000; i++) &#123; dates[i] = sdf.get().parse(i + 1000 + \"-11-22\"); &#125; ExecutorService executorService = Executors.newFixedThreadPool(10); for(int i=0;i&lt;1000;i++)&#123; executorService.execute(new Runnable() &#123; @Override public void run() &#123; int number = n.incrementAndGet(); String date = sdf.get().format(dates[number]); numberSet.add(number); dateSet.add(date); System.out.println(number+\" \"+date); &#125; &#125;); &#125; executorService.shutdown(); Thread.sleep(5000); System.out.println(dateSet.size()); System.out.println(numberSet.size()); &#125;&#125; 实践证明 sdf 的 parse（String to Date）有严重的线程安全问题，format（Date to String）有轻微的线程安全问题，虽然不太明显，但还是会出现问题，这和内部的实现有关。 简单分析下使用 ThreadLocal 的好处，1000 次转换操作，10 个线程争抢执行，如果每次都去 new 一个 sdf，可见其效率之低，而使用 ThreadLocal，是对每个线程维护一个 sdf，所以最多就只会出现 10 个 sdf，真正项目中，由于操作系统线程分片执行，所以线程不会非常的多，使用 ThreadLocal 的好处也就立竿见影了。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"},{"name":"多线程","slug":"多线程","permalink":"http://lexburner.github.io/tags/多线程/"}]},{"title":"Transactional 注解使用注意点","slug":"transactional-tips","date":"2017-02-14T08:51:52.000Z","updated":"2019-09-26T09:45:29.419Z","comments":true,"path":"transactional-tips/","link":"","permalink":"http://lexburner.github.io/transactional-tips/","excerpt":"","text":"@Transactional 可以说是 spring 中最常用的注解之一了，通常情况下我们在需要对一个 service 方法添加事务时，加上这个注解，如果发生 unchecked exception，就会发生 rollback，最典型的例子如下。 1234567891011121314@Servicepublic class StudentService &#123; @Autowired StudentDao studentDao; @Transactional public void innerSave(int i) &#123; Student student = new Student(); student.setName(\"test\" + i); studentDao.save(student); //i=5 会出现异常 int a = 1 / (i - 5); &#125;&#125; 在调用 innerSave(5) 时会发运算异常，导致保存操作回滚，不在此赘述了。 新的需求：循环保存 10 个学生，发生异常时要求回滚。我们理所当然的写出了下面的代码，在 StudentService.java 添加如下方法 123456789public void outerLooper1() &#123; for (int i = 1; i &lt;= 10; i++) &#123; try&#123; innerSave(i); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; &#125; 先考虑一下 test5 这个学生有没有保存呢？结果：依然出现了，考虑下问题出在哪儿了？ 其实也好理解，spring 中 @Transactional 的事务开启 ，是基于接口 或者是类的代理被创建的。所以在同一个类中一个普通方法 outerLooper1() 调用另一个有事务的方法 innerSave()，事务是不会起作用的。要解决这个问题，一般我的做法是写一个帮助类，注入到当前类中，来完成事务操作。 12345678@AutowiredUtilService utilService;public void outerLooper2() &#123; for (int i = 1; i &lt;= 10; i++) &#123; utilService.innerSave(i); &#125;&#125; 在 spring 中使用事务需要遵守一些规范和了解一些坑点，别想当然。列举一下一些注意点。 在需要事务管理的地方加 @Transactional 注解。@Transactional 注解可以被应用于接口定义和接口方法、类定义和类的 public 方法上。 @Transactional 注解只能应用到 public 可见度的方法上。如果你在 protected、private 或者 package-visible 的方法上使用 @Transactional 注解，它也不会报错，但是这个被注解的方法将不会展示已配置的事务设置。 Spring 团队建议在具体的类（或类的方法）上使用 @Transactional 注解，而不要使用在类所要实现的任何接口上。在接口上使用 @Transactional 注解，只能当你设置了基于接口的代理时它才生效。因为注解是 不能继承的，这就意味着如果正在使用基于类的代理时，那么事务的设置将不能被基于类的代理所识别，而且对象也将不会被事务代理所包装。 @Transactional 的事务开启 ，或者是基于接口的或者是基于类的代理被创建。所以在同一个类中一个方法调用另一个方法有事务的方法，事务是不会起作用的。 了解事务的隔离级别，各个数据库默认的隔离级别是不一样的，在 spring 中用的是 isolation = Isolation.READ_COMMITTED 来设置；了解事务的传播机制，当发生事务嵌套时，按照业务选择对应的传播机制，用 propagation= Propagation.REQUIRED 来设置。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"事务","slug":"事务","permalink":"http://lexburner.github.io/tags/事务/"}]},{"title":"简单了解 RPC 实现原理","slug":"easy-know-rpc","date":"2017-02-10T07:11:52.000Z","updated":"2019-09-26T09:45:31.219Z","comments":true,"path":"easy-know-rpc/","link":"","permalink":"http://lexburner.github.io/easy-know-rpc/","excerpt":"时下很多企业应用更新换代到分布式，一篇文章了解什么是 RPC。原作者梁飞，在此记录下他非常简洁的 rpc 实现思路。","text":"时下很多企业应用更新换代到分布式，一篇文章了解什么是 RPC。原作者梁飞，在此记录下他非常简洁的 rpc 实现思路。 核心框架类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129/* * Copyright 2011 Alibaba.com All right reserved. This software is the * confidential and proprietary information of Alibaba.com (\"Confidential * Information\"). You shall not disclose such Confidential Information and shall * use it only in accordance with the terms of the license agreement you entered * into with Alibaba.com. */package com.alibaba.study.rpc.framework;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.net.ServerSocket;import java.net.Socket;/** * RpcFramework * * @author william.liangf */public class RpcFramework &#123; /** * 暴露服务 * * @param service 服务实现 * @param port 服务端口 * @throws Exception */ public static void export(final Object service, int port) throws Exception &#123; if (service == null) throw new IllegalArgumentException(\"service instance == null\"); if (port &lt;= 0 || port &gt; 65535) throw new IllegalArgumentException(\"Invalid port\" + port); System.out.println(\"Export service\" + service.getClass().getName()+ \"on port\" + port); ServerSocket server = new ServerSocket(port); for(;;) &#123; try &#123; final Socket socket = server.accept(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; try &#123; ObjectInputStream input = new ObjectInputStream(socket.getInputStream()); try &#123; String methodName = input.readUTF(); Class&lt;?&gt;[] parameterTypes = (Class&lt;?&gt;[])input.readObject(); Object[] arguments = (Object[])input.readObject(); ObjectOutputStream output = new ObjectOutputStream(socket.getOutputStream()); try &#123; Method method = service.getClass().getMethod(methodName, parameterTypes); Object result = method.invoke(service, arguments); output.writeObject(result); &#125; catch (Throwable t) &#123; output.writeObject(t); &#125; finally &#123; output.close(); &#125; &#125; finally &#123; input.close(); &#125; &#125; finally &#123; socket.close(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 引用服务 * * @param &lt;T&gt; 接口泛型 * @param interfaceClass 接口类型 * @param host 服务器主机名 * @param port 服务器端口 * @return 远程服务 * @throws Exception */ @SuppressWarnings(\"unchecked\") public static &lt;T&gt; T refer(final Class&lt;T&gt; interfaceClass, final String host, final int port) throws Exception &#123; if (interfaceClass == null) throw new IllegalArgumentException(\"Interface class == null\"); if (! interfaceClass.isInterface()) throw new IllegalArgumentException(\"The\" + interfaceClass.getName() + \"must be interface class!\"); if (host == null || host.length() == 0) throw new IllegalArgumentException(\"Host == null!\"); if (port &lt;= 0 || port &gt; 65535) throw new IllegalArgumentException(\"Invalid port\" + port); System.out.println(\"Get remote service\" + interfaceClass.getName() + \"from server\" + host + \":\" + port); return (T) Proxy.newProxyInstance(interfaceClass.getClassLoader(), new Class&lt;?&gt;[] &#123;interfaceClass&#125;, new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] arguments) throws Throwable &#123; Socket socket = new Socket(host, port); try &#123; ObjectOutputStream output = new ObjectOutputStream(socket.getOutputStream()); try &#123; output.writeUTF(method.getName()); output.writeObject(method.getParameterTypes()); output.writeObject(arguments); ObjectInputStream input = new ObjectInputStream(socket.getInputStream()); try &#123; Object result = input.readObject(); if (result instanceof Throwable) &#123; throw (Throwable) result; &#125; return result; &#125; finally &#123; input.close(); &#125; &#125; finally &#123; output.close(); &#125; &#125; finally &#123; socket.close(); &#125; &#125; &#125;); &#125;&#125; 定义服务接口12345678910111213141516171819/* * Copyright 2011 Alibaba.com All right reserved. This software is the * confidential and proprietary information of Alibaba.com (\"Confidential * Information\"). You shall not disclose such Confidential Information and shall * use it only in accordance with the terms of the license agreement you entered * into with Alibaba.com. */package com.alibaba.study.rpc.test;/** * HelloService * * @author william.liangf */public interface HelloService &#123; String hello(String name);&#125; 实现服务123456789101112131415161718192021/* * Copyright 2011 Alibaba.com All right reserved. This software is the * confidential and proprietary information of Alibaba.com (\"Confidential * Information\"). You shall not disclose such Confidential Information and shall * use it only in accordance with the terms of the license agreement you entered * into with Alibaba.com. */package com.alibaba.study.rpc.test;/** * HelloServiceImpl * * @author william.liangf */public class HelloServiceImpl implements HelloService &#123; public String hello(String name) &#123; return \"Hello\" + name; &#125;&#125; 暴露服务123456789101112131415161718192021222324/* * Copyright 2011 Alibaba.com All right reserved. This software is the * confidential and proprietary information of Alibaba.com (\"Confidential * Information\"). You shall not disclose such Confidential Information and shall * use it only in accordance with the terms of the license agreement you entered * into with Alibaba.com. */package com.alibaba.study.rpc.test;import com.alibaba.study.rpc.framework.RpcFramework;/** * RpcProvider * * @author william.liangf */public class RpcProvider &#123; public static void main(String[] args) throws Exception &#123; HelloService service = new HelloServiceImpl(); RpcFramework.export(service, 1234); &#125;&#125; 引用服务12345678910111213141516171819202122232425262728/* * Copyright 2011 Alibaba.com All right reserved. This software is the * confidential and proprietary information of Alibaba.com (\"Confidential * Information\"). You shall not disclose such Confidential Information and shall * use it only in accordance with the terms of the license agreement you entered * into with Alibaba.com. */package com.alibaba.study.rpc.test;import com.alibaba.study.rpc.framework.RpcFramework;/** * RpcConsumer * * @author william.liangf */public class RpcConsumer &#123; public static void main(String[] args) throws Exception &#123; HelloService service = RpcFramework.refer(HelloService.class, \"127.0.0.1\", 1234); for (int i = 0; i &lt; Integer.MAX_VALUE; i ++) &#123; String hello = service.hello(\"World\" + i); System.out.println(hello); Thread.sleep(1000); &#125; &#125; &#125; 总结这个简单的例子的实现思路是使用阻塞的 socket IO 流来进行 server 和 client 的通信，也就是 rpc 应用中服务提供方和服务消费方。并且是端对端的，用端口号来直接进行通信。方法的远程调用使用的是 jdk 的动态代理，参数的序列化也是使用的最简单的 objectStream。 真实的 rpc 框架会对上面的实现方式进行替换，采用更快更稳定，更高可用易扩展，更适宜分布式场景的中间件，技术来替换。例如使用 netty 的 nio 特性达到非阻塞的通信，使用 zookeeper 统一管理服务注册与发现，解决了端对端不灵活的劣势。代理方式有 cglib 字节码技术。序列化方式有 hession2，fastjson 等等。不过梁飞大大的博客使用原生的 jdk api 就展现给各位读者一个生动形象的 rpc demo，实在是强。rpc 框架解决的不仅仅是技术层面的实现，还考虑到了 rpc 调用中的诸多问题，重试机制，超时配置… 这些就需要去了解成熟的 rpc 框架是如果考虑这些问题的了。 推荐一个轻量级的 rpc 框架：motan。weibo 团队在 github 开源的一个 rpc 框架，有相应的文档，用起来感觉比 dubbo 要轻量级，易上手。","categories":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"http://lexburner.github.io/tags/RPC/"}]},{"title":"java trick--String.intern()","slug":"java-trick-String.intern()","date":"2016-11-07T15:16:52.000Z","updated":"2019-09-26T09:45:31.637Z","comments":true,"path":"java-trick-String.intern()/","link":"","permalink":"http://lexburner.github.io/java-trick-String.intern()/","excerpt":"","text":"《深入理解 java 虚拟机》第二版中对 String.intern() 方法的讲解中所举的例子非常有意思 不了解 String.intern() 的朋友要理解他其实也很容易，它返回的是一个字符串在字符串常亮池中的引用。直接看下面的 demo 123456789public class Main &#123; public static void main(String[] args) &#123; String str1 = new StringBuilder(\"计算机\").append(\"软件\").toString(); System.out.println(str1.intern() == str1); String str2 = new StringBuilder(\"ja\").append(\"va\").toString(); System.out.println(str2.intern() == str2); &#125;&#125; 两者输出的结果如下： 12truefalse 我用的 jdk 版本为 Oracle JDK7u45。简单来说，就是一个很奇怪的现象，为什么 java 这个字符串在类加载之前就已经加载到常量池了？ 我在知乎找到了具体的说明，如下： 1234567891011package sun.misc;import java.io.PrintStream;public class Version &#123; private static final String launcher_name = \"java\"; private static final String java_version = \"1.7.0_79\"; private static final String java_runtime_name = \"Java(TM) SE Runtime Environment\"; private static final String java_runtime_version = \"1.7.0_79-b15\"; ...&#125; 而 HotSpot JVM 的实现会在类加载时先调用： 123456789public final class System&#123; ... private static void initializeSystemClass() &#123; ... sun.misc.Version.init(); ... &#125; ...&#125; 原来是 sun.misc.Version 这个类在起作用。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"java trick -- intergerCache","slug":"java-trick-intergerCache","date":"2016-11-07T15:00:52.000Z","updated":"2019-09-26T09:45:30.859Z","comments":true,"path":"java-trick-intergerCache/","link":"","permalink":"http://lexburner.github.io/java-trick-intergerCache/","excerpt":"看一段代码： 1234567public class Main &#123; public static void main(String[] args) &#123; Integer a=100,b=100,c=150,d=150; System.out.println(a==b); System.out.println(c==d); &#125;&#125; 这段代码会输出什么？","text":"看一段代码： 1234567public class Main &#123; public static void main(String[] args) &#123; Integer a=100,b=100,c=150,d=150; System.out.println(a==b); System.out.println(c==d); &#125;&#125; 这段代码会输出什么？ 不加留意的人可能会理所当然的认为两个答案会是一致的，但结果却是： 12truefalse 下面一个很好解释，因为自动拆装箱机制，比较的是两者的引用，而不是值，所以为 false，那么为什么前者是同一个引用呢？ 来看看 Integer 这个类，首先是自动拆装箱会调用 valueOf() 方法 123456public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; 这里并不是简单的返回 new Integer(i) 而是判断了一下 int 的数值，Integer 的存在一个缓存机制，默认用一个 IntegerCache 缓存了 [IntegerCache.low,IntegerCache.high] 的引用, 其中 IntegerCache 这个内部类真正在做缓存 1234567891011121314151617181920212223242526private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); &#125; private IntegerCache()&#123;&#125; &#125; 所以就出现了最开始的一个小 trick","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"java trick--system.out.println","slug":"java-trick-system.out.println","date":"2016-11-07T14:03:52.000Z","updated":"2019-09-26T09:45:29.659Z","comments":true,"path":"java-trick-system.out.println/","link":"","permalink":"http://lexburner.github.io/java-trick-system.out.println/","excerpt":"多线程在使用 system.out.println 时要留一个有意思的地方","text":"多线程在使用 system.out.println 时要留一个有意思的地方123456789101112131415161718192021public class Main &#123; public static void main(String[] args) &#123; Thread thread = new MyThread(); thread.start(); System.out.println(\"end\"); &#125;&#125;class MyThread extends Thread &#123; private int i = 0; @Override public void run() &#123; while (true) &#123; i++; System.out.println(i); &#125; &#125;&#125; 主线程另起一个线程，然后在主线程最后打印一个 end，猜猜看结果是什么？end 会不会打印？主线程一直被 Mythread 占用原因就在于 system.out.println 是一个同步方法 12345678910111213/** * Prints an integer and then terminate the line. This method behaves as * though it invokes &lt;code&gt;&#123;@link #print(int)&#125;&lt;/code&gt; and then * &lt;code&gt;&#123;@link #println()&#125;&lt;/code&gt;. * * @param x The &lt;code&gt;int&lt;/code&gt; to be printed. */ public void println(int x) &#123; synchronized (this) &#123; print(x); newLine(); &#125; &#125;","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/tags/JAVA/"}]},{"title":"Hello World","slug":"hello-world","date":"2016-08-16T07:52:52.000Z","updated":"2019-09-26T09:45:29.694Z","comments":true,"path":"hello-world/","link":"","permalink":"http://lexburner.github.io/hello-world/","excerpt":"","text":"","categories":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lexburner.github.io/tags/Spring/"},{"name":"Validation","slug":"Validation","permalink":"http://lexburner.github.io/tags/Validation/"}]},{"title":"使用 JPA 实现乐观锁","slug":"jpa-OptimisticLock","date":"2016-08-16T07:52:52.000Z","updated":"2019-09-26T09:45:30.097Z","comments":true,"path":"jpa-OptimisticLock/","link":"","permalink":"http://lexburner.github.io/jpa-OptimisticLock/","excerpt":"乐观锁的概念就不再赘述了，不了解的朋友请自行百度谷歌之，今天主要说的是在项目中如何使用乐观锁，做成一个小 demo。 持久层使用 jpa 时，默认提供了一个注解 @Version 先看看源码怎么描述这个注解的 1234@Target(&#123;METHOD, FIELD&#125;)@Retention(RUNTIME)public @interface Version &#123;&#125; 简单来说就是用一个 version 字段来充当乐观锁的作用。先来设计实体类 123456789101112131415161718192021/** * Created by xujingfeng on 2017/1/30. */@Entity@Table(name = \"t_student\")public class Student &#123; @Id @GenericGenerator(name = \"PKUUID\", strategy = \"uuid2\") @GeneratedValue(generator = \"PKUUID\") @Column(length = 36) private String id; @Version private int version; private String name; //getter()... //setter()...&#125;","text":"乐观锁的概念就不再赘述了，不了解的朋友请自行百度谷歌之，今天主要说的是在项目中如何使用乐观锁，做成一个小 demo。 持久层使用 jpa 时，默认提供了一个注解 @Version 先看看源码怎么描述这个注解的 1234@Target(&#123;METHOD, FIELD&#125;)@Retention(RUNTIME)public @interface Version &#123;&#125; 简单来说就是用一个 version 字段来充当乐观锁的作用。先来设计实体类 123456789101112131415161718192021/** * Created by xujingfeng on 2017/1/30. */@Entity@Table(name = \"t_student\")public class Student &#123; @Id @GenericGenerator(name = \"PKUUID\", strategy = \"uuid2\") @GeneratedValue(generator = \"PKUUID\") @Column(length = 36) private String id; @Version private int version; private String name; //getter()... //setter()...&#125; Dao 层 12345678910/** * Created by xujingfeng on 2017/1/30. */public interface StudentDao extends JpaRepository&lt;Student,String&gt;&#123; @Query(\"update Student set name=?1 where id=?2\") @Modifying @Transactional int updateNameById(String name,String id);&#125; Controller 层充当单元测试的作用，通过访问一个 requestMapping 来触发我们想要测试的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Created by xujingfeng on 2017/1/30. */@Controllerpublic class StudentController &#123; @Autowired StudentDao studentDao; @RequestMapping(\"student.html\") @ResponseBody public String student()&#123; Student student = new Student(); student.setName(\"xujingfeng\"); studentDao.save(student); return \"student\"; &#125; @RequestMapping(\"testVersion.html\") @ResponseBody public String testVersion() throws InterruptedException &#123; Student student = studentDao.findOne(\"6ed16acc-61df-4a66-add9-d17c88b69755\"); student.setName(\"xuxuan\"); new Thread(new Runnable() &#123; @Override public void run() &#123; studentDao.findOne(\"6ed16acc-61df-4a66-add9-d17c88b69755\"); student.setName(\"xuxuanInThread\"); studentDao.save(student); &#125; &#125;).start(); Thread.sleep(1000); studentDao.save(student); return \"testVersion\"; &#125; @RequestMapping(\"updateNameById.html\") @ResponseBody public String updateNameById()&#123; studentDao.updateNameById(\"xuxuan2\",\"6ed16acc-61df-4a66-add9-d17c88b69755\"); return \"updateNameById\"; &#125;&#125; 这里面三个方法，主要是我们想用来测试的三个注意点。第一个方法 student.html 我们想看看 springdata 如何对 version 字段进行增长的。就不贴图了，直接给结论，对于添加了 @Version 的注解，我们不需要手动去控制，每一次 save 操作会在原来的基础上 +1，如果初始为 null，则 springdata 自动设置其为 0。第二个方法 testVersion.html 是乐观锁的核心，当多个线程并发访问同一行记录时，添加了 @Version 乐观锁之后，程序会进行怎么样的控制呢？ 1org.hibernate.StaleObjectStateException: Row was updated or deleted by another transaction (or unsaved-value mapping was incorrect) : [com.example.jpa.Student#6ed16acc-61df-4a66-add9-d17c88b69755] 异常信息如上，主线程和新线程获取了同一行记录，并且新线程优先提交了事务，版本号一致，修改成功。等到了主线程再想 save 提交事务时，便得到一个版本号不一致的异常，那么在项目开发中就应该自己捕获这个异常根据业务内容做对应处理，是重试还是放弃 etc… 第三个方法，updateNameById.html 是想强调一下，@Query 中的 update，delete 操作是不会触发 springdata 的相关代理操作的，而是转化为原生 sql 的方式，所以在项目中使用时也要注意这点。 总结乐观锁，用在一些敏感业务数据上，而其本身的修饰：乐观，代表的含义便是相信大多数场景下 version 是一致的。但是从业务角度出发又要保证数据的严格一致性，避免脏读等问题，使用的场景需要斟酌。记得前面一片博文简单介绍了一下行级锁的概念，其实本质上和乐观锁都是想要再数据库层面加锁控制并发，那么什么时候该用乐观锁，行级锁，什么时候得在程序级别加同步锁，又要根据具体的业务场景去判断。找到能够满足自己项目需求的方案，找到性能和可靠性的平衡点，才是一个程序员的价值所在。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://lexburner.github.io/tags/多线程/"},{"name":"数据库","slug":"数据库","permalink":"http://lexburner.github.io/tags/数据库/"}]},{"title":"使用 zkclient 操作 zookeeper 的学习过程记录","slug":"zkclient-learning","date":"2016-08-16T07:52:52.000Z","updated":"2019-09-26T09:45:31.552Z","comments":true,"path":"zkclient-learning/","link":"","permalink":"http://lexburner.github.io/zkclient-learning/","excerpt":"前言最近开发的分布式 (使用 motan) 项目中使用 zookeeper 作为服务中心来提供注册服务 (@MotanService) 和发现服务(@MotanRefer), 虽然 motan 这个 rpc 框架对服务模块进行了很好的封装，但是以防以后会出现定制化的需求，以及对服务更好的监控，所以有必要了解一下 zookeeper 的基本知识和使用方法。关于 zookeeper 的知识点，网上很多的博客都已经介绍的很详尽了，我写这篇的博客的用意其实也就是将一些零散的却很精妙的博客整理出来，方便以后查阅。短篇以 cp 的方式，长篇的以 url 的方式。 zookeeper 是什么？ ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是 Google 的 Chubby 一个开源的实现，是 Hadoop 和 Hbase 的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper 的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。ZooKeeper 包含一个简单的原语集，提供 Java 和 C 的接口。 ZooKeeper 代码版本中，提供了分布式独享锁、选举、队列的接口。 —- 百度百科 一开始看的云里雾里的，幸好我之前搞过一点 hadoop，对他的生态体系有所了解，这才大概知道他想说什么。提炼几个关键词，并且加入我后面学习的理解，总结一下就是 – zookeeper 是一个组件，需要安装客户端和服务端，一般用于解决分布式开发下的一些问题。化抽象为具体，你可以把整个 zookeeper 理解成一个树形数据结构，也可以理解为一个文件系统的结构，每个叶子节点都会携带一些信息 (data)，并且也可能会携带一些操作 (op)。分布式场景中，每一个客户端都可以访问到这些叶子节点，并且进行一些操作。我们所有使用 zookeeper 的场景几乎都是在 CRUD 某一个或者某些叶子节点，然后会触发对应的操作… 即 zookeeper 本身可以理解为一个 shareData。—- 来自于博主的口胡 zookeeper 怎么学？学一个新的中间件的最好方法是先在脑子里面有一个想法：我为什么要学他，是想解决什么问题，他大概是个什么东西，我觉得打开思路的最好方式是看几篇博客 (大多数情况你一开始看不懂，但是混个眼熟)，然后看视频，这里我自己是了解过了 zookeeper 原生的 api 之后看了极客学院 的视频","text":"前言最近开发的分布式 (使用 motan) 项目中使用 zookeeper 作为服务中心来提供注册服务 (@MotanService) 和发现服务(@MotanRefer), 虽然 motan 这个 rpc 框架对服务模块进行了很好的封装，但是以防以后会出现定制化的需求，以及对服务更好的监控，所以有必要了解一下 zookeeper 的基本知识和使用方法。关于 zookeeper 的知识点，网上很多的博客都已经介绍的很详尽了，我写这篇的博客的用意其实也就是将一些零散的却很精妙的博客整理出来，方便以后查阅。短篇以 cp 的方式，长篇的以 url 的方式。 zookeeper 是什么？ ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是 Google 的 Chubby 一个开源的实现，是 Hadoop 和 Hbase 的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper 的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。ZooKeeper 包含一个简单的原语集，提供 Java 和 C 的接口。 ZooKeeper 代码版本中，提供了分布式独享锁、选举、队列的接口。 —- 百度百科 一开始看的云里雾里的，幸好我之前搞过一点 hadoop，对他的生态体系有所了解，这才大概知道他想说什么。提炼几个关键词，并且加入我后面学习的理解，总结一下就是 – zookeeper 是一个组件，需要安装客户端和服务端，一般用于解决分布式开发下的一些问题。化抽象为具体，你可以把整个 zookeeper 理解成一个树形数据结构，也可以理解为一个文件系统的结构，每个叶子节点都会携带一些信息 (data)，并且也可能会携带一些操作 (op)。分布式场景中，每一个客户端都可以访问到这些叶子节点，并且进行一些操作。我们所有使用 zookeeper 的场景几乎都是在 CRUD 某一个或者某些叶子节点，然后会触发对应的操作… 即 zookeeper 本身可以理解为一个 shareData。—- 来自于博主的口胡 zookeeper 怎么学？学一个新的中间件的最好方法是先在脑子里面有一个想法：我为什么要学他，是想解决什么问题，他大概是个什么东西，我觉得打开思路的最好方式是看几篇博客 (大多数情况你一开始看不懂，但是混个眼熟)，然后看视频，这里我自己是了解过了 zookeeper 原生的 api 之后看了极客学院 的视频 zkclient 的使用学完原生 api 之后一般我们不直接使用，类比 redis 的客户端 jedis，再到 spring 提供的 redisTemplate; 类比 jdbc 到 dbutils，再到 orm 框架。所以作为小白，我建议使用这个比较简单的客户端 zkclient，当后期需求需要一些定制化需求时使用原生的 api 自己重写，或者使用更高级一点的其他客户端。 zkclient 我学完之后觉得非常轻量级，设计也很规范，大概可以参考以下的博客。博客园 - 房继诺原作者非常用心，里面给出了一张 zkclient 的 uml 类图，如下顺便也复习一下 uml 类图的知识，理解清楚图中用到的聚合，组合，关联，泛化，实现的箭头含义。uml 建模没有学好的同学的移步这个 链接，里面对应了 java 讲解，还算详细。掌握这个客户端之后，还需要补充一些注意点 1. create 方法: 创建节点时, 如果节点已经存在, 仍然抛出 NodeExistException, 可是我期望它不在抛出此异常. 2. retryUtilConnected: 如果向 zookeeper 请求数据时 (create,delete,setData 等), 此时链接不可用, 那么调用者将会被阻塞直到链接建立成功; 不过我仍然需要一些方法是非阻塞的, 如果链接不可用, 则抛出异常, 或者直接返回. 3. create 方法: 创建节点时, 如果节点的父节点不存在, 我期望同时也要创建父节点, 而不是抛出异常. 4. data 监测: 我需要提供一个额外的功能来补充 watch 的不足, 开启一个线程, 间歇性的去 zk server 获取指定的 path 的 data, 并缓存起来.. 归因与 watch 可能丢失, 以及它不能持续的反应 znode 数据的每一次变化, 所以只能手动去同步获取. 回到开始这个时候看看你当初为啥要学习 zookeeper，看看能不能解决你当时遇到的问题。如果你有兴趣，可以自己去试试 zookeeper 前面提到的那些可以实现的功能：分布式锁、选举、队列等等","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://lexburner.github.io/categories/JAVA/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://lexburner.github.io/tags/zookeeper/"}]}]}