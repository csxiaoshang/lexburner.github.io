<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>徐靖峰|个人博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lexburner.github.io/"/>
  <updated>2019-02-18T07:21:48.821Z</updated>
  <id>http://lexburner.github.io/</id>
  
  <author>
    <name>徐靖峰</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一致性哈希负载均衡算法的探讨</title>
    <link href="http://lexburner.github.io/consistent-hash-lb/"/>
    <id>http://lexburner.github.io/consistent-hash-lb/</id>
    <published>2019-02-15T07:45:13.000Z</published>
    <updated>2019-02-18T07:21:48.821Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>一致性哈希算法在很多领域有应用，例如分布式缓存领域的 MemCache，Redis，负载均衡领域的 Nginx，各类 RPC 框架。不同领域场景不同，需要顾及的因素也有所差异，本文主要讨论在<strong>负载均衡</strong>中一致性哈希算法的设计。</p><p>在介绍一致性哈希算法之前，我将会介绍一些哈希算法，讨论它们的区别和使用场景。也会给出一致性哈希算法的 Java 通用实现，可以直接引用，文末会给出 github 地址。</p><blockquote><p>友情提示：阅读本文前，最好对一致性哈希算法有所了解，例如你最好听过一致性哈希环这个概念，我会在基本概念上缩短篇幅。</p></blockquote><a id="more"></a><h3 id="一致性哈希负载均衡介绍"><a href="#一致性哈希负载均衡介绍" class="headerlink" title="一致性哈希负载均衡介绍"></a>一致性哈希负载均衡介绍</h3><p>负载均衡这个概念可以抽象为：从 n 个候选服务器中选择一个进行通信的过程。负载均衡算法有多种多样的实现方式：随机、轮询、最小负载优先等，其中也包括了今天的主角：一致性哈希负载均衡。一致性哈希负载均衡需要保证的是“相同的请求尽可能落到同一个服务器上”，注意这短短的一句描述，却包含了相当大的信息量。“相同的请求” — 什么是相同的请求？一般在使用一致性哈希负载均衡时，需要指定一个 key 用于 hash 计算，可能是：</p><ol><li>请求方 IP</li><li>请求服务名称，参数列表构成的串</li><li>用户 ID</li></ol><p>“尽可能” —为什么不是一定？因为服务器可能发生上下线，所以少数服务器的变化不应该影响大多数的请求。这也呼应了算法名称中的“一致性”。</p><p>同时，一个优秀的负载均衡算法还有一个隐性要求：流量尽可能均匀分布。</p><p>综上所述，我们可以概括出一致性哈希负载均衡算法的设计思路。</p><ul><li>尽可能保证每个服务器节点均匀的分摊流量</li><li>尽可能保证服务器节点的上下线不影响流量的变更</li></ul><h3 id="哈希算法介绍"><a href="#哈希算法介绍" class="headerlink" title="哈希算法介绍"></a>哈希算法介绍</h3><p>哈希算法是一致性哈希算法中重要的一个组成部分，你可以借助 Java 中的 <code>int hashCode()</code>去理解它。 说到哈希算法，你想到了什么？Jdk 中的 hashCode、SHA-1、MD5，除了这些耳熟能详的哈希算法，还存在很多其他实现，详见 <a href="https://www.oschina.net/translate/state-of-hash-functions" target="_blank" rel="noopener">HASH 算法一览</a>。可以将他们分成三代：</p><ul><li>第一代：SHA-1（1993），MD5（1992），CRC（1975），Lookup3（2006）</li><li>第二代：MurmurHash（2008）</li><li>第三代：CityHash， SpookyHash（2011）</li></ul><p>这些都可以认为是广义上的哈希算法，你可以在 <a href="https://en.wikipedia.org/wiki/List_of_hash_functions" target="_blank" rel="noopener">wiki 百科</a> 中查看所有的哈希算法。当然还有一些哈希算法如：Ketama，专门为一致性哈希算法而设计。</p><p>既然有这么多哈希算法，那必然会有人问：当我们在讨论哈希算法时，我们再考虑哪些东西？我大概总结下有以下四点：</p><ol><li>实现复杂程度</li><li>分布均匀程度</li><li>哈希碰撞概率</li><li>性能</li></ol><p>先聊聊性能，是不是性能越高就越好呢？你如果有看过我曾经的文章 <a href="https://www.cnkirito.moe/spring-security-6/" target="_blank" rel="noopener">《该如何设计你的 PasswordEncoder?》</a> ，应该能了解到，在设计加密器这个场景下，慢 hash 算法反而有优势；而在负载均衡这个场景下，安全性不是需要考虑的因素，所以性能自然是越高越好。</p><p>优秀的算法通常比较复杂，但不足以构成评价标准，有点黑猫白猫论，所以 2，3 两点：分布均匀程度，哈希碰撞概率成了主要考虑的因素。</p><p>我挑选了几个值得介绍的哈希算法，重点介绍下。</p><ol><li><p>MurmurHash 算法：高运算性能，低碰撞率，由 Austin Appleby 创建于 2008 年，现已应用到 Hadoop、libstdc++、nginx、libmemcached 等开源系统。2011 年 Appleby 被 Google 雇佣，随后 Google 推出其变种的 CityHash 算法。官方只提供了 C 语言的实现版本。 </p><p>Java 界中 Redis，Memcached，Cassandra，HBase，Lucene 都在使用它。</p><p>在 Java 的实现，Guava 的 Hashing 类里有，上面提到的 Jedis，Cassandra 里都有相关的 Util 类。</p></li><li><p>FNV 算法：全名为 Fowler-Noll-Vo 算法，是以三位发明人 Glenn Fowler，Landon Curt Noll，Phong Vo 的名字来命名的，最早在 1991 年提出。</p><p>特点和用途：FNV 能快速 hash 大量数据并保持较小的冲突率，它的高度分散使它适用于 hash 一些非常相近的字符串，比如 URL，hostname，文件名，text，IP 地址等。</p></li><li><p>Ketama 算法：将它称之为哈希算法其实不太准确，称之为一致性哈希算法可能更为合适，其他的哈希算法有通用的一致性哈希算法实现，只不过是替换了哈希方式而已，但 Ketama 是一整套的流程，我们将在后面介绍。</p></li></ol><p>以上三者都是最合适的一致性哈希算法的强力争夺者。</p><h3 id="一致性哈希算法实现"><a href="#一致性哈希算法实现" class="headerlink" title="一致性哈希算法实现"></a>一致性哈希算法实现</h3><p><img src="https://user-gold-cdn.xitu.io/2019/2/16/168f69205ef99590?w=861&amp;h=635&amp;f=png&amp;s=59703" alt="一致性hash"></p><p>一致性哈希的概念我不做赘述，简单介绍下这个负载均衡中的一致性哈希环。首先将服务器（ip+端口号）进行哈希，映射成环上的一个节点，在请求到来时，根据指定的 hash key 同样映射到环上，并顺时针选取最近的一个服务器节点进行请求（在本图中，使用的是 userId 作为 hash key）。</p><p>当环上的服务器较少时，即使哈希算法选择得当，依旧会遇到大量请求落到同一个节点的问题，为避免这样的问题，大多数一致性哈希算法的实现度引入了虚拟节点的概念。</p><p><img src="https://user-gold-cdn.xitu.io/2019/2/16/168f6921775875f4?w=934&amp;h=639&amp;f=png&amp;s=67921" alt="一致性hash虚拟节点"></p><p>在上图中，只有两台物理服务器节点：11.1.121.1 和 11.1.121.2，我们通过添加后缀的方式，克隆出了另外三份节点，使得环上的节点分布的均匀。一般来说，物理节点越多，所需的虚拟节点就越少。</p><p>介绍完了一致性哈希换，我们便可以对负载均衡进行建模了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">LoadBalancer</span> </span>&#123;</span><br><span class="line">    <span class="function">Server <span class="title">select</span><span class="params">(List&lt;Server&gt; servers, Invocation invocation)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面直接给出通用的算法实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsistentHashLoadBalancer</span> <span class="keyword">implements</span> <span class="title">LoadBalancer</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> HashStrategy hashStrategy = <span class="keyword">new</span> JdkHashCodeStrategy();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> VIRTUAL_NODE_SIZE = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String VIRTUAL_NODE_SUFFIX = <span class="string">"&amp;&amp;"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Server <span class="title">select</span><span class="params">(List&lt;Server&gt; servers, Invocation invocation)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> invocationHashCode = hashStrategy.getHashCode(invocation.getHashKey());</span><br><span class="line">        TreeMap&lt;Integer, Server&gt; ring = buildConsistentHashRing(servers);</span><br><span class="line">        Server server = locate(ring, invocationHashCode);</span><br><span class="line">        <span class="keyword">return</span> server;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Server <span class="title">locate</span><span class="params">(TreeMap&lt;Integer, Server&gt; ring, <span class="keyword">int</span> invocationHashCode)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 向右找到第一个 key</span></span><br><span class="line">        Map.Entry&lt;Integer, Server&gt; locateEntry = ring.ceilingEntry(invocationHashCode);</span><br><span class="line">        <span class="keyword">if</span> (locateEntry == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 想象成一个环，超过尾部则取第一个 key</span></span><br><span class="line">            locateEntry = ring.firstEntry();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> locateEntry.getValue();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> TreeMap&lt;Integer, Server&gt; <span class="title">buildConsistentHashRing</span><span class="params">(List&lt;Server&gt; servers)</span> </span>&#123;</span><br><span class="line">        TreeMap&lt;Integer, Server&gt; virtualNodeRing = <span class="keyword">new</span> TreeMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Server server : servers) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VIRTUAL_NODE_SIZE; i++) &#123;</span><br><span class="line">                <span class="comment">// 新增虚拟节点的方式如果有影响，也可以抽象出一个由物理节点扩展虚拟节点的类</span></span><br><span class="line">                virtualNodeRing.put(hashStrategy.getHashCode(server.getUrl() + VIRTUAL_NODE_SUFFIX + i), server);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> virtualNodeRing;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对上述的程序做简单的解读：</p><p>Server 是对服务器的抽象，一般是 ip+port 的形式。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Server</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String url;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Invocation 是对请求的抽象，包含一个用于 hash 的 key。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Invocation</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String hashKey;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 TreeMap 作为一致性哈希环的数据结构，<code>ring.ceilingEntry</code> 可以获取环上最近的一个节点。在 <code>buildConsistentHashRing</code> 之中包含了构建一致性哈希环的过程，默认加入了 10 个虚拟节点。</p><p>计算方差，标准差的公式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StatisticsUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//方差s^2=[(x1-x)^2 +...(xn-x)^2]/n</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">variance</span><span class="params">(Long[] x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = x.length;</span><br><span class="line">        <span class="keyword">double</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;<span class="comment">//求和</span></span><br><span class="line">            sum += x[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">double</span> dAve = sum / m;<span class="comment">//求平均值</span></span><br><span class="line">        <span class="keyword">double</span> dVar = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;<span class="comment">//求方差</span></span><br><span class="line">            dVar += (x[i] - dAve) * (x[i] - dAve);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dVar / m;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//标准差σ=sqrt(s^2)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">standardDeviation</span><span class="params">(Long[] x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = x.length;</span><br><span class="line">        <span class="keyword">double</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;<span class="comment">//求和</span></span><br><span class="line">            sum += x[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">double</span> dAve = sum / m;<span class="comment">//求平均值</span></span><br><span class="line">        <span class="keyword">double</span> dVar = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;<span class="comment">//求方差</span></span><br><span class="line">            dVar += (x[i] - dAve) * (x[i] - dAve);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Math.sqrt(dVar / m);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，<code>HashStrategy</code> 是下文中重点讨论的一个内容，他是对 hash 算法的抽象，我们将会着重对比各种 hash 算法给测评结果带来的差异性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HashStrategy</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getHashCode</span><span class="params">(String origin)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="测评程序"><a href="#测评程序" class="headerlink" title="测评程序"></a>测评程序</h3><p>前面我们已经明确了一个优秀的一致性哈希算法的设计思路。这一节我们给出实际的量化指标：假设 m 次请求打到 n 个候选服务器上</p><ul><li>统计每个服务节点收到的流量，计算方差、标准差。测量流量分布均匀情况，我们可以模拟 10000 个随机请求，打到 100 个指定服务器，测试最后个节点的方差，标准差。</li><li>记录 m 次请求落到的服务器节点，下线 20% 的服务器，重放流量，统计 m 次请求中落到跟原先相同服务器的概率。测量节点上下线的情况，我们可以模拟 10000 个随机请求，打到 100 个指定服务器，之后下线 20 个服务器并重放流量，统计请求到相同服务器的比例。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoadBalanceTest</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">static</span> String[] ips = &#123;...&#125;; <span class="comment">// 100 台随机 ip</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 测试分布的离散情况</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDistribution</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        List&lt;Server&gt; servers = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (String ip : ips) &#123;</span><br><span class="line">            servers.add(<span class="keyword">new</span> Server(ip+<span class="string">":8080"</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        LoadBalancer chloadBalance = <span class="keyword">new</span> ConsistentHashLoadBalancer();</span><br><span class="line">        <span class="comment">// 构造 10000 随机请求</span></span><br><span class="line">        List&lt;Invocation&gt; invocations = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">            invocations.add(<span class="keyword">new</span> Invocation(UUID.randomUUID().toString()));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 统计分布</span></span><br><span class="line">        AtomicLongMap&lt;Server&gt; atomicLongMap = AtomicLongMap.create();</span><br><span class="line">        <span class="keyword">for</span> (Server server : servers) &#123;</span><br><span class="line">            atomicLongMap.put(server, <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (Invocation invocation : invocations) &#123;</span><br><span class="line">            Server selectedServer = chloadBalance.select(servers, invocation);</span><br><span class="line">            atomicLongMap.getAndIncrement(selectedServer);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(StatisticsUtil.variance(atomicLongMap.asMap().values().toArray(<span class="keyword">new</span> Long[]&#123;&#125;)));</span><br><span class="line">        System.out.println(StatisticsUtil.standardDeviation(atomicLongMap.asMap().values().toArray(<span class="keyword">new</span> Long[]&#123;&#125;)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 测试节点新增删除后的变化程度</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testNodeAddAndRemove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        List&lt;Server&gt; servers = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (String ip : ips) &#123;</span><br><span class="line">            servers.add(<span class="keyword">new</span> Server(ip));</span><br><span class="line">        &#125;</span><br><span class="line">        List&lt;Server&gt; serverChanged = servers.subList(<span class="number">0</span>, <span class="number">80</span>);</span><br><span class="line">        ConsistentHashLoadBalancer chloadBalance = <span class="keyword">new</span> ConsistentHashLoadBalancer();</span><br><span class="line">        <span class="comment">// 构造 10000 随机请求</span></span><br><span class="line">        List&lt;Invocation&gt; invocations = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">            invocations.add(<span class="keyword">new</span> Invocation(UUID.randomUUID().toString()));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (Invocation invocation : invocations) &#123;</span><br><span class="line">            Server origin = chloadBalance.select(servers, invocation);</span><br><span class="line">            Server changed = chloadBalance.select(serverChanged, invocation);</span><br><span class="line">            <span class="keyword">if</span> (origin.getUrl().equals(changed.getUrl())) count++;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(count / <span class="number">10000</span>D);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="不同哈希算法的实现及测评"><a href="#不同哈希算法的实现及测评" class="headerlink" title="不同哈希算法的实现及测评"></a>不同哈希算法的实现及测评</h3><p>最简单、经典的 hashCode 实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdkHashCodeStrategy</span> <span class="keyword">implements</span> <span class="title">HashStrategy</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getHashCode</span><span class="params">(String origin)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> origin.hashCode();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>FNV1_32_HASH 算法实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FnvHashStrategy</span> <span class="keyword">implements</span> <span class="title">HashStrategy</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> FNV_32_INIT = <span class="number">2166136261L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> FNV_32_PRIME = <span class="number">16777619</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getHashCode</span><span class="params">(String origin)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> p = FNV_32_PRIME;</span><br><span class="line">        <span class="keyword">int</span> hash = (<span class="keyword">int</span>) FNV_32_INIT;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; origin.length(); i++)</span><br><span class="line">            hash = (hash ^ origin.charAt(i)) * p;</span><br><span class="line">        hash += hash &lt;&lt; <span class="number">13</span>;</span><br><span class="line">        hash ^= hash &gt;&gt; <span class="number">7</span>;</span><br><span class="line">        hash += hash &lt;&lt; <span class="number">3</span>;</span><br><span class="line">        hash ^= hash &gt;&gt; <span class="number">17</span>;</span><br><span class="line">        hash += hash &lt;&lt; <span class="number">5</span>;</span><br><span class="line">        hash = Math.abs(hash);</span><br><span class="line">        <span class="keyword">return</span> hash;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>CRC 算法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CRCHashStrategy</span> <span class="keyword">implements</span> <span class="title">HashStrategy</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getHashCode</span><span class="params">(String origin)</span> </span>&#123;</span><br><span class="line">        CRC32 crc32 = <span class="keyword">new</span> CRC32();</span><br><span class="line">        crc32.update(origin.getBytes());</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) ((crc32.getValue() &gt;&gt; <span class="number">16</span>) &amp; <span class="number">0x7fff</span> &amp; <span class="number">0xffffffffL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Ketama 算法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KetamaHashStrategy</span> <span class="keyword">implements</span> <span class="title">HashStrategy</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> MessageDigest md5Digest;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            md5Digest = MessageDigest.getInstance(<span class="string">"MD5"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"MD5 not supported"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getHashCode</span><span class="params">(String origin)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] bKey = computeMd5(origin);</span><br><span class="line">        <span class="keyword">long</span> rv = ((<span class="keyword">long</span>) (bKey[<span class="number">3</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">24</span>)</span><br><span class="line">                | ((<span class="keyword">long</span>) (bKey[<span class="number">2</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">16</span>)</span><br><span class="line">                | ((<span class="keyword">long</span>) (bKey[<span class="number">1</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">8</span>)</span><br><span class="line">                | (bKey[<span class="number">0</span>] &amp; <span class="number">0xFF</span>);</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) (rv &amp; <span class="number">0xffffffffL</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Get the md5 of the given key.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] computeMd5(String k) &#123;</span><br><span class="line">        MessageDigest md5;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            md5 = (MessageDigest) md5Digest.clone();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (CloneNotSupportedException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"clone of MD5 not supported"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        md5.update(k.getBytes());</span><br><span class="line">        <span class="keyword">return</span> md5.digest();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MurmurHash 算法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MurmurHashStrategy</span> <span class="keyword">implements</span> <span class="title">HashStrategy</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getHashCode</span><span class="params">(String origin)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        ByteBuffer buf = ByteBuffer.wrap(origin.getBytes());</span><br><span class="line">        <span class="keyword">int</span> seed = <span class="number">0x1234ABCD</span>;</span><br><span class="line"></span><br><span class="line">        ByteOrder byteOrder = buf.order();</span><br><span class="line">        buf.order(ByteOrder.LITTLE_ENDIAN);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> m = <span class="number">0xc6a4a7935bd1e995L</span>;</span><br><span class="line">        <span class="keyword">int</span> r = <span class="number">47</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> h = seed ^ (buf.remaining() * m);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> k;</span><br><span class="line">        <span class="keyword">while</span> (buf.remaining() &gt;= <span class="number">8</span>) &#123;</span><br><span class="line">            k = buf.getLong();</span><br><span class="line"></span><br><span class="line">            k *= m;</span><br><span class="line">            k ^= k &gt;&gt;&gt; r;</span><br><span class="line">            k *= m;</span><br><span class="line"></span><br><span class="line">            h ^= k;</span><br><span class="line">            h *= m;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (buf.remaining() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            ByteBuffer finish = ByteBuffer.allocate(<span class="number">8</span>).order(</span><br><span class="line">                    ByteOrder.LITTLE_ENDIAN);</span><br><span class="line">            <span class="comment">// for big-endian version, do this first:</span></span><br><span class="line">            <span class="comment">// finish.position(8-buf.remaining());</span></span><br><span class="line">            finish.put(buf).rewind();</span><br><span class="line">            h ^= finish.getLong();</span><br><span class="line">            h *= m;</span><br><span class="line">        &#125;</span><br><span class="line">        h ^= h &gt;&gt;&gt; r;</span><br><span class="line">        h *= m;</span><br><span class="line">        h ^= h &gt;&gt;&gt; r;</span><br><span class="line"></span><br><span class="line">        buf.order(byteOrder);</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) (h &amp; <span class="number">0xffffffffL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测评结果：</p><table><thead><tr><th></th><th>方差</th><th>标准差</th><th>不变流量比例</th></tr></thead><tbody><tr><td><strong>JdkHashCodeStrategy</strong></td><td>29574.08</td><td>171.97</td><td>0.6784</td></tr><tr><td><strong>CRCHashStrategy</strong></td><td>3013.02</td><td>54.89</td><td>0.7604</td></tr><tr><td><strong>FnvHashStrategy</strong></td><td>961.64</td><td>31.01</td><td>0.7892</td></tr><tr><td><strong>KetamaHashStrategy</strong></td><td>1254.64</td><td>35.42</td><td>0.7986</td></tr><tr><td><strong>MurmurHashStrategy</strong></td><td>815.72</td><td>28.56</td><td>0.7971</td></tr></tbody></table><p>其中方差和标准差反映了均匀情况，越低越好，可以发现 MurmurHashStrategy，KetamaHashStrategy，FnvHashStrategy 都表现的不错。</p><p>不变流量比例体现了服务器上下线对原有请求的影响程度，不变流量比例越高越高，可以发现 KetamaHashStrategy 和 MurmurHashStrategy 表现最为优秀。</p><p>我并没有对小集群，小流量进行测试，样本偏差性较大，仅从这个常见场景来看，MurmurHashStrategy 是一个不错的选择，多次测试后发现 <strong>FnvHashStrategy</strong>，<strong>KetamaHashStrategy</strong>，<strong>MurmurHashStrategy</strong> 差距不是很大。</p><p>至于性能测试，MurmurHash 也十分的高性能，我并没有做测试（感兴趣的同学可以对几种 strategy 用 JMH 测评一下）,这里我贴一下 MurmurHash 官方的测评数据：</p><pre><code>OneAtATime - 354.163715 mb/secFNV - 443.668038 mb/secSuperFastHash - 985.335173 mb/seclookup3 - 988.080652 mb/secMurmurHash 1.0 - 1363.293480 mb/secMurmurHash 2.0 - 2056.885653 mb/sec</code></pre><blockquote><p>扩大虚拟节点可以明显降低方差和标准差，但虚拟节点的增加会加大内存占用量以及计算量</p></blockquote><h3 id="Ketama-一致性哈希算法实现"><a href="#Ketama-一致性哈希算法实现" class="headerlink" title="Ketama 一致性哈希算法实现"></a>Ketama 一致性哈希算法实现</h3><p>Ketama 算法有其专门的配套实现方式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KetamaConsistentHashLoadBalancer</span> <span class="keyword">implements</span> <span class="title">LoadBalancer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> MessageDigest md5Digest;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            md5Digest = MessageDigest.getInstance(<span class="string">"MD5"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"MD5 not supported"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> VIRTUAL_NODE_SIZE = <span class="number">12</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String VIRTUAL_NODE_SUFFIX = <span class="string">"-"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Server <span class="title">select</span><span class="params">(List&lt;Server&gt; servers, Invocation invocation)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> invocationHashCode = getHashCode(invocation.getHashKey());</span><br><span class="line">        TreeMap&lt;Long, Server&gt; ring = buildConsistentHashRing(servers);</span><br><span class="line">        Server server = locate(ring, invocationHashCode);</span><br><span class="line">        <span class="keyword">return</span> server;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Server <span class="title">locate</span><span class="params">(TreeMap&lt;Long, Server&gt; ring, Long invocationHashCode)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 向右找到第一个 key</span></span><br><span class="line">        Map.Entry&lt;Long, Server&gt; locateEntry = ring.ceilingEntry(invocationHashCode);</span><br><span class="line">        <span class="keyword">if</span> (locateEntry == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 想象成一个环，超过尾部则取第一个 key</span></span><br><span class="line">            locateEntry = ring.firstEntry();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> locateEntry.getValue();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> TreeMap&lt;Long, Server&gt; <span class="title">buildConsistentHashRing</span><span class="params">(List&lt;Server&gt; servers)</span> </span>&#123;</span><br><span class="line">        TreeMap&lt;Long, Server&gt; virtualNodeRing = <span class="keyword">new</span> TreeMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Server server : servers) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VIRTUAL_NODE_SIZE / <span class="number">4</span>; i++) &#123;</span><br><span class="line">                <span class="keyword">byte</span>[] digest = computeMd5(server.getUrl() + VIRTUAL_NODE_SUFFIX + i);</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> h = <span class="number">0</span>; h &lt; <span class="number">4</span>; h++) &#123;</span><br><span class="line">                    Long k = ((<span class="keyword">long</span>) (digest[<span class="number">3</span> + h * <span class="number">4</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">24</span>)</span><br><span class="line">                            | ((<span class="keyword">long</span>) (digest[<span class="number">2</span> + h * <span class="number">4</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">16</span>)</span><br><span class="line">                            | ((<span class="keyword">long</span>) (digest[<span class="number">1</span> + h * <span class="number">4</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">8</span>)</span><br><span class="line">                            | (digest[h * <span class="number">4</span>] &amp; <span class="number">0xFF</span>);</span><br><span class="line">                    virtualNodeRing.put(k, server);</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> virtualNodeRing;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">getHashCode</span><span class="params">(String origin)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] bKey = computeMd5(origin);</span><br><span class="line">        <span class="keyword">long</span> rv = ((<span class="keyword">long</span>) (bKey[<span class="number">3</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">24</span>)</span><br><span class="line">                | ((<span class="keyword">long</span>) (bKey[<span class="number">2</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">16</span>)</span><br><span class="line">                | ((<span class="keyword">long</span>) (bKey[<span class="number">1</span>] &amp; <span class="number">0xFF</span>) &lt;&lt; <span class="number">8</span>)</span><br><span class="line">                | (bKey[<span class="number">0</span>] &amp; <span class="number">0xFF</span>);</span><br><span class="line">        <span class="keyword">return</span> rv;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] computeMd5(String k) &#123;</span><br><span class="line">        MessageDigest md5;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            md5 = (MessageDigest) md5Digest.clone();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (CloneNotSupportedException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"clone of MD5 not supported"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        md5.update(k.getBytes());</span><br><span class="line">        <span class="keyword">return</span> md5.digest();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>稍微不同的地方便在于：Ketama 将四个节点标为一组进行了虚拟节点的设置。</p><table><thead><tr><th></th><th>方差</th><th>标准差</th><th>不变流量比例</th></tr></thead><tbody><tr><td><strong>KetamaConsistentHashLoadBalancer</strong></td><td>911.08</td><td>30.18</td><td>0.7936</td></tr></tbody></table><p>实际结果并没有太大的提升，可能和测试数据的样本规模有关。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>优秀的哈希算法和一致性哈希算法可以帮助我们在大多数场景下应用的高性能，高稳定性，但在实际使用一致性哈希负载均衡的场景中，最好针对实际的集群规模和请求哈希方式进行压测，力保流量均匀打到所有的机器上，这才是王道。</p><p>不仅仅是分布式缓存，负载均衡等等有限的场景，一致性哈希算法、哈希算法，尤其是后者，是一个用处很广泛的常见算法，了解它的经典实现是很有必要的，例如 MurmurHash，在 guava 中就有其 Java 实现，当需要高性能，分布均匀，碰撞概率小的哈希算法时，可以考虑使用它。</p><p>本文代码的 github 地址：<a href="https://github.com/lexburner/consistent-hash-algorithm" target="_blank" rel="noopener">https://github.com/lexburner/consistent-hash-algorithm</a></p><h3 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h3><p><a href="https://www.cnkirito.moe/rpc-cluster/" target="_blank" rel="noopener">深入理解 RPC 之集群篇</a></p><p><a href="https://www.cnkirito.moe/spring-security-6/" target="_blank" rel="noopener">《该如何设计你的 PasswordEncoder?》</a> </p><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><p><a href="https://sites.google.com/site/murmurhash/" target="_blank" rel="noopener">MurmurHash</a></p><p><a href="https://colobu.com/2015/04/13/consistent-hash-algorithm-in-java-memcached-client/" target="_blank" rel="noopener">memcached Java客户端spymemcached的一致性Hash算法</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;一致性哈希算法在很多领域有应用，例如分布式缓存领域的 MemCache，Redis，负载均衡领域的 Nginx，各类 RPC 框架。不同领域场景不同，需要顾及的因素也有所差异，本文主要讨论在&lt;strong&gt;负载均衡&lt;/strong&gt;中一致性哈希算法的设计。&lt;/p&gt;
&lt;p&gt;在介绍一致性哈希算法之前，我将会介绍一些哈希算法，讨论它们的区别和使用场景。也会给出一致性哈希算法的 Java 通用实现，可以直接引用，文末会给出 github 地址。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;友情提示：阅读本文前，最好对一致性哈希算法有所了解，例如你最好听过一致性哈希环这个概念，我会在基本概念上缩短篇幅。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="RPC" scheme="http://lexburner.github.io/categories/RPC/"/>
    
    
      <category term="RPC" scheme="http://lexburner.github.io/tags/RPC/"/>
    
  </entry>
  
  <entry>
    <title>定时器的几种实现方式</title>
    <link href="http://lexburner.github.io/timer/"/>
    <id>http://lexburner.github.io/timer/</id>
    <published>2019-01-24T10:47:55.000Z</published>
    <updated>2019-01-27T05:08:44.577Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h3><p>在开始正题之前，先闲聊几句。有人说，计算机科学这个学科，软件方向研究到头就是数学，硬件方向研究到头就是物理，最轻松的是中间这批使用者，可以不太懂物理，不太懂数学，依旧可以使用计算机作为自己谋生的工具。这个规律具有普适应，看看“定时器”这个例子，往应用层研究，有 Quartz，Spring Schedule 等框架；往分布式研究，又有 SchedulerX，ElasticJob 等分布式任务调度；往底层实现看，又有多种定时器实现方案的原理、工作效率、数据结构可以深究…简单上手使用一个框架，并不能体现出个人的水平，如何与他人构成区分度？我觉得至少要在某一个方向有所建树：</p><ol><li>深入研究某个现有框架的实现原理，例如：读源码</li><li>将一个传统技术在分布式领域很好地延伸，很多成熟的传统技术可能在单机 work well，但分布式场景需要很多额外的考虑。</li><li>站在设计者的角度，如果从零开始设计一个轮子，怎么利用合适的算法、数据结构，去实现它。</li></ol><p>回到这篇文章的主题，我首先会围绕第三个话题讨论：设计实现一个定时器，可以使用什么算法，采用什么数据结构。接着再聊聊第一个话题：探讨一些优秀的定时器实现方案。</p><a id="more"></a><h3 id="2-理解定时器"><a href="#2-理解定时器" class="headerlink" title="2 理解定时器"></a>2 理解定时器</h3><p>很多场景会用到定时器，例如</p><ol><li>使用 TCP 长连接时，客户端需要定时向服务端发送心跳请求。</li><li>财务系统每个月的月末定时生成对账单。</li><li>双 11 的 0 点，定时开启秒杀开关。</li></ol><p>定时器像水和空气一般，普遍存在于各个场景中，一般定时任务的形式表现为：经过固定时间后触发、按照固定频率周期性触发、在某个时刻触发。定时器是什么？可以理解为这样一个数据结构：</p><blockquote><p>存储一系列的任务集合，并且 Deadline 越接近的任务，拥有越高的执行优先级<br>在用户视角支持以下几种操作：<br>NewTask：将新任务加入任务集合<br>Cancel：取消某个任务<br>在任务调度的视角还要支持：<br>Run：执行一个到期的定时任务</p></blockquote><p>判断一个任务是否到期，基本会采用轮询的方式，<strong>每隔一个时间片</strong> 去检查 <strong>最近的任务</strong> 是否到期，并且，在 NewTask 和 Cancel 的行为发生之后，任务调度策略也会出现调整。</p><blockquote><p>说到底，定时器还是靠线程轮询实现的。</p></blockquote><h3 id="3-数据结构"><a href="#3-数据结构" class="headerlink" title="3 数据结构"></a>3 数据结构</h3><p>我们主要衡量 NewTask（新增任务），Cancel（取消任务），Run（执行到期的定时任务）这三个指标，分析他们使用不同数据结构的时间/空间复杂度。</p><h4 id="3-1-双向有序链表"><a href="#3-1-双向有序链表" class="headerlink" title="3.1 双向有序链表"></a>3.1 双向有序链表</h4><p>在 Java 中，<code>LinkedList</code> 是一个天然的双向链表</p><blockquote><p>NewTask：O(N)<br>Cancel：O(1)<br>Run：O(1)<br>N：任务数</p></blockquote><p>NewTask O(N) 很容易理解，按照 expireTime 查找合适的位置即可；Cancel O(1) ，任务在 Cancel 时，会持有自己节点的引用，所以不需要查找其在链表中所在的位置，即可实现当前节点的删除，这也是为什么我们使用双向链表而不是普通链表的原因是 ；Run O(1)，由于整个双向链表是基于 expireTime 有序的，所以调度器只需要轮询第一个任务即可。</p><h4 id="3-2-堆"><a href="#3-2-堆" class="headerlink" title="3.2 堆"></a>3.2 堆</h4><p>在 Java 中，<code>PriorityQueue</code> 是一个天然的堆，可以利用传入的 <code>Comparator</code> 来决定其中元素的优先级。</p><blockquote><p>NewTask：O(logN)<br>Cancel：O(logN)<br>Run：O(1)<br>N：任务数</p></blockquote><p>expireTime 是  <code>Comparator</code>  的对比参数。NewTask O(logN) 和 Cancel O(logN) 分别对应堆插入和删除元素的时间复杂度 ；Run O(1)，由 expireTime 形成的小根堆，我们总能在堆顶找到最快的即将过期的任务。</p><p>堆与双向有序链表相比，NewTask 和 Cancel 形成了 trade off，但考虑到现实中，定时任务取消的场景并不是很多，所以堆实现的定时器要比双向有序链表优秀。</p><h4 id="3-3-时间轮"><a href="#3-3-时间轮" class="headerlink" title="3.3 时间轮"></a>3.3 时间轮</h4><p>Netty 针对 I/O 超时调度的场景进行了优化，实现了 <code>HashedWheelTimer</code> 时间轮算法。</p><p><img src="http://kirito.iocoder.cn/201807171109599678a80c-075a-40ee-b25f-10fd82c1025c.png" alt="时间轮算法"></p><p><code>HashedWheelTimer</code> 是一个环形结构，可以用时钟来类比，钟面上有很多 bucket ，每一个 bucket 上可以存放多个任务，使用一个 List 保存该时刻到期的所有任务，同时一个指针随着时间流逝一格一格转动，并执行对应 bucket 上所有到期的任务。任务通过<code>取模</code>决定应该放入哪个 bucket 。和 HashMap 的原理类似，newTask 对应 put，使用 List 来解决 Hash 冲突。</p><p>以上图为例，假设一个 bucket 是 1 秒，则指针转动一轮表示的时间段为 8s，假设当前指针指向 0，此时需要调度一个 3s 后执行的任务，显然应该加入到 (0+3=3) 的方格中，指针再走 3 次就可以执行了；如果任务要在 10s 后执行，应该等指针走完一轮零 2 格再执行，因此应放入 2，同时将 round（1）保存到任务中。检查到期任务时只执行 round 为 0 的， bucket 上其他任务的 round 减 1。</p><p>再看图中的 bucket5，我们可以知道在 $1<em>8+5=13s$  后，有两个任务需要执行，在 $2</em>8+5=21s$ 后有一个任务需要执行。</p><blockquote><p>NewTask：O(1)<br>Cancel：O(1)<br>Run：O(M)<br>Tick：O(1)<br>M： bucket ，M ~ N/C ，其中 C 为单轮 bucket 数，Netty 中默认为 512 </p></blockquote><p>时间轮算法的复杂度可能表达有误，比较难算，仅供参考。另外，其复杂度还受到多个任务分配到同一个 bucket 的影响。并且多了一个转动指针的开销。</p><blockquote><p>传统定时器是面向任务的，时间轮定时器是面向 bucket 的。</p></blockquote><p>构造 Netty 的 <code>HashedWheelTimer</code> 时有两个重要的参数：<code>tickDuration</code> 和 <code>ticksPerWheel</code>。</p><ol><li><code>tickDuration</code>：即一个 bucket 代表的时间，默认为 100ms，Netty 认为大多数场景下不需要修改这个参数；</li><li><code>ticksPerWheel</code>：一轮含有多少个 bucket ，默认为 512 个，如果任务较多可以增大这个参数，降低任务分配到同一个 bucket 的概率。</li></ol><h4 id="3-4-层级时间轮"><a href="#3-4-层级时间轮" class="headerlink" title="3.4 层级时间轮"></a>3.4 层级时间轮</h4><p>Kafka 针对时间轮算法进行了优化，实现了层级时间轮 <code>TimingWheel</code></p><p>如果任务的时间跨度很大，数量也多，传统的 <code>HashedWheelTimer</code> 会造成任务的 <code>round</code> 很大，单个 bucket 的任务 List 很长，并会维持很长一段时间。这时可将轮盘按时间粒度分级：</p><p><img src="http://kirito.iocoder.cn/7f03c027b1de345a0b1e57239d73de74.png" alt="层级时间轮"></p><p>现在，每个任务除了要维护在当前轮盘的 <code>round</code>，还要计算在所有下级轮盘的<code>round</code>。当本层的<code>round</code>为0时，任务按下级 <code>round</code> 值被下放到下级轮子，最终在最底层的轮盘得到执行。</p><blockquote><p>NewTask：O(H)<br>Cancel：O(H)<br>Run：O(M)<br>Tick：O(1)<br>H：层级数量</p></blockquote><p>设想一下一个定时了 3 天，10 小时，50 分，30 秒的定时任务，在 tickDuration = 1s 的单层时间轮中，需要经过：$3<em>24</em>60<em>60+10</em>60<em>60+50</em>60+30$ 次指针的拨动才能被执行。但在 wheel1 tickDuration = 1 天，wheel2 tickDuration = 1 小时，wheel3 tickDuration = 1 分，wheel4 tickDuration = 1 秒 的四层时间轮中，只需要经过 $3+10+50+30$ 次指针的拨动！ </p><p>相比单层时间轮，层级时间轮在时间跨度较大时存在明显的优势。</p><h3 id="4-常见实现"><a href="#4-常见实现" class="headerlink" title="4 常见实现"></a>4 常见实现</h3><h4 id="4-1-Timer"><a href="#4-1-Timer" class="headerlink" title="4.1 Timer"></a>4.1 Timer</h4><p>JDK 中的 <code>Timer</code> 是非常早期的实现，在现在看来，它并不是一个好的设计。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 运行一个一秒后执行的定时任务</span></span><br><span class="line">Timer timer = <span class="keyword">new</span> Timer();</span><br><span class="line">timer.schedule(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// do sth</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;, <span class="number">1000</span>);</span><br></pre></td></tr></table></figure><p>使用 <code>Timer</code> 实现任务调度的核心是 <code>Timer</code> 和 <code>TimerTask</code>。其中 <code>Timer</code> 负责设定 <code>TimerTask</code> 的起始与间隔执行时间。使用者只需要创建一个 <code>TimerTask</code> 的继承类，实现自己的 <code>run</code> 方法，然后将其丢给 <code>Timer</code> 去执行即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Timer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TaskQueue queue = <span class="keyword">new</span> TaskQueue();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TimerThread thread = <span class="keyword">new</span> TimerThread(queue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 TaskQueue 是使用数组实现的一个简易的堆。另外一个值得注意的属性是 <code>TimerThread</code>，<code>Timer</code> 使用唯一的线程负责轮询并执行任务。<code>Timer</code> 的优点在于简单易用，但也因为所有任务都是由同一个线程来调度，因此整个过程是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务。</p><blockquote><p>轮询时如果发现  currentTime &lt; heapFirst.executionTime，可以 wait(executionTime - currentTime) 来减少不必要的轮询时间。这是普遍被使用的一个优化。</p></blockquote><ol><li><code>Timer</code> 只能被单线程调度</li><li><code>TimerTask</code> 中出现的异常会影响到 <code>Timer</code> 的执行。 </li></ol><p>由于这两个缺陷，JDK 1.5 支持了新的定时器方案 <code>ScheduledExecutorService</code>。</p><h4 id="4-2-ScheduledExecutorService"><a href="#4-2-ScheduledExecutorService" class="headerlink" title="4.2 ScheduledExecutorService"></a>4.2 ScheduledExecutorService</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 运行一个一秒后执行的定时任务</span></span><br><span class="line">ScheduledExecutorService service = Executors.newScheduledThreadPool(<span class="number">10</span>);</span><br><span class="line">service.scheduleA(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//do sth</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;, <span class="number">1</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure><p>相比 <code>Timer</code>，<code>ScheduledExecutorService</code> 解决了同一个定时器调度多个任务的阻塞问题，并且任务异常不会中断 <code>ScheduledExecutorService</code>。</p><p><code>ScheduledExecutorService</code> 提供了两种常用的周期调度方法 ScheduleAtFixedRate 和 ScheduleWithFixedDelay。</p><p>ScheduleAtFixedRate 每次执行时间为上一次任务开始起向后推一个时间间隔，即每次执行时间为 : $initialDelay$, $initialDelay+period$, $initialDelay+2*period$, …</p><p>ScheduleWithFixedDelay 每次执行时间为上一次任务结束起向后推一个时间间隔，即每次执行时间为：$initialDelay$, $initialDelay+executeTime+delay$, $initialDelay+2<em>executeTime+2</em>delay$, … </p><p>由此可见，ScheduleAtFixedRate 是基于固定时间间隔进行任务调度，ScheduleWithFixedDelay 取决于每次任务执行的时间长短，是基于不固定时间间隔的任务调度。</p><p><code>ScheduledExecutorService</code> 底层使用的数据结构为 <code>PriorityQueue</code>，任务调度方式较为常规，不做特别介绍。</p><h4 id="4-3-HashedWheelTimer"><a href="#4-3-HashedWheelTimer" class="headerlink" title="4.3 HashedWheelTimer"></a>4.3 HashedWheelTimer</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Timer timer = <span class="keyword">new</span> HashedWheelTimer();</span><br><span class="line"><span class="comment">//等价于 Timer timer = new HashedWheelTimer(100, TimeUnit.MILLISECONDS, 512);</span></span><br><span class="line">timer.newTimeout(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Timeout timeout)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//do sth</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;, <span class="number">1</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure><p>前面已经介绍过了 Netty 中 <code>HashedWheelTimer</code> 内部的数据结构，默认构造器会配置轮询周期为 100ms，bucket 数量为 512。其使用方法和 JDK 的 <code>Timer</code> 十分相似。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Worker worker = <span class="keyword">new</span> Worker();<span class="comment">// Runnable</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Thread workerThread;<span class="comment">// Thread</span></span><br></pre></td></tr></table></figure><p>由于篇幅限制，我并不打算做详细的源码分析，但上述两行来自 <code>HashedWheelTimer</code> 的代码阐释了一个事实：<code>HashedWheelTimer</code> 内部也同样是使用单个线程进行任务调度。与  JDK 的 <code>Timer</code> 一样，存在”前一个任务执行时间过长，影响后续定时任务执行“的问题。</p><blockquote><p>理解 HashedWheelTimer 中的 ticksPerWheel，tickDuration，对二者进行合理的配置，可以使得用户在合适的场景得到最佳的性能。</p></blockquote><h3 id="5-最佳实践"><a href="#5-最佳实践" class="headerlink" title="5 最佳实践"></a>5 最佳实践</h3><h4 id="5-1-选择合适的定时器"><a href="#5-1-选择合适的定时器" class="headerlink" title="5.1 选择合适的定时器"></a>5.1 选择合适的定时器</h4><p>毋庸置疑，JDK 的 <code>Timer</code> 使用的场景是最窄的，完全可以被后两者取代。如何在 <code>ScheduledExecutorService</code> 和 <code>HashedWheelTimer</code> 之间如何做选择，需要区分场景，做一个简单的对比：</p><ol><li><code>ScheduledExecutorService</code> 是面向任务的，当任务数非常大时，使用堆(PriorityQueue)维护任务的新增、删除会导致性能下降，而 <code>HashedWheelTimer</code> 面向 bucket，设置合理的 ticksPerWheel，tickDuration ，可以不受任务量的限制。所以在任务非常多时，<code>HashedWheelTimer</code> 可以表现出它的优势。</li><li>相反，如果任务量少，<code>HashedWheelTimer</code> 内部的 Worker 线程依旧会不停的拨动指针，虽然不是特别消耗性能，但至少不能说：<code>HashedWheelTimer</code> 一定比 <code>ScheduledExecutorService</code> 优秀。</li><li><code>HashedWheelTimer</code> 由于开辟了一个 bucket 数组，占用的内存会稍大。</li></ol><p>上述的对比，让我们得到了一个最佳实践：在任务非常多时，使用 <code>HashedWheelTimer</code> 可以获得性能的提升。例如服务治理框架中的心跳定时任务，服务实例非常多时，每一个客户端都需要定时发送心跳，每一个服务端都需要定时检测连接状态，这是一个非常适合使用 <code>HashedWheelTimer</code>  的场景。</p><h4 id="5-2-单线程与业务线程池"><a href="#5-2-单线程与业务线程池" class="headerlink" title="5.2 单线程与业务线程池"></a>5.2 单线程与业务线程池</h4><p>我们需要注意<code>HashedWheelTimer</code> 使用单线程来调度任务，如果任务比较耗时，应当设置一个业务线程池，将<code>HashedWheelTimer</code> 当做一个定时触发器，任务的实际执行，交给业务线程池。</p><blockquote><p>如果所有的任务都满足： taskNStartTime - taskN-1StartTime &gt; taskN-1CostTime，即任意两个任务的间隔时间小于先执行任务的执行时间，则无需担心这个问题。</p></blockquote><h4 id="5-3-全局定时器"><a href="#5-3-全局定时器" class="headerlink" title="5.3 全局定时器"></a>5.3 全局定时器</h4><p>实际使用 <code>HashedWheelTimer</code> 时，<strong>应当将其当做一个全局的任务调度器，例如设计成 static</strong> 。时刻谨记一点：<code>HashedWheelTimer</code> 对应一个线程，如果每次实例化 <code>HashedWheelTimer</code>，首先是线程会很多，其次是时间轮算法将会完全失去意义。</p><h4 id="5-4-为-HashedWheelTimer-设置合理的参数"><a href="#5-4-为-HashedWheelTimer-设置合理的参数" class="headerlink" title="5.4 为 HashedWheelTimer 设置合理的参数"></a>5.4 为 HashedWheelTimer 设置合理的参数</h4><p>ticksPerWheel，tickDuration 这两个参数尤为重要，ticksPerWheel 控制了时间轮中 bucket 的数量，决定了冲突发生的概率，tickDuration 决定了指针拨动的频率，一方面会影响定时的精度，一方面决定 CPU 的消耗量。当任务数量非常大时，考虑增大 ticksPerWheel；当时间精度要求不高时，可以适当加大 tickDuration，不过大多数情况下，不需要 care 这个参数。</p><h4 id="5-5-什么时候使用层级时间轮"><a href="#5-5-什么时候使用层级时间轮" class="headerlink" title="5.5 什么时候使用层级时间轮"></a>5.5 什么时候使用层级时间轮</h4><p>当时间跨度很大时，提升单层时间轮的 tickDuration 可以减少空转次数，但会导致时间精度变低，层级时间轮既可以避免精度降低，又避免了指针空转的次数。如果有时间跨度较长的定时任务，则可以交给层级时间轮去调度。此外，也可以按照定时精度实例化多个不同作用的单层时间轮，dayHashedWheelTimer、hourHashedWheelTimer、minHashedWheelTimer，配置不同的 tickDuration，此法虽 low，但不失为一个解决方案。Netty 设计的 <code>HashedWheelTimer</code> 是专门用来优化 I/O 调度的，场景较为局限，所以并没有实现层级时间轮；而在 Kafka 中定时器的适用范围则较广，所以其实现了层级时间轮，以应对更为复杂的场景。</p><h3 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6 参考资料"></a>6 参考资料</h3><p>[1] <a href="https://www.ibm.com/developerworks/cn/java/j-lo-taskschedule/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/java/j-lo-taskschedule/index.html</a></p><p>[2] <a href="http://novoland.github.io/并发/2014/07/26/定时器（Timer）的实现.html" target="_blank" rel="noopener">http://novoland.github.io/并发/2014/07/26/定时器（Timer）的实现.html</a></p><p>[3] <a href="http://www.cs.columbia.edu/~nahum/w6998/papers/sosp87-timing-wheels.pdf" target="_blank" rel="noopener">http://www.cs.columbia.edu/~nahum/w6998/papers/sosp87-timing-wheels.pdf</a></p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1 前言&quot;&gt;&lt;/a&gt;1 前言&lt;/h3&gt;&lt;p&gt;在开始正题之前，先闲聊几句。有人说，计算机科学这个学科，软件方向研究到头就是数学，硬件方向研究到头就是物理，最轻松的是中间这批使用者，可以不太懂物理，不太懂数学，依旧可以使用计算机作为自己谋生的工具。这个规律具有普适应，看看“定时器”这个例子，往应用层研究，有 Quartz，Spring Schedule 等框架；往分布式研究，又有 SchedulerX，ElasticJob 等分布式任务调度；往底层实现看，又有多种定时器实现方案的原理、工作效率、数据结构可以深究…简单上手使用一个框架，并不能体现出个人的水平，如何与他人构成区分度？我觉得至少要在某一个方向有所建树：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;深入研究某个现有框架的实现原理，例如：读源码&lt;/li&gt;
&lt;li&gt;将一个传统技术在分布式领域很好地延伸，很多成熟的传统技术可能在单机 work well，但分布式场景需要很多额外的考虑。&lt;/li&gt;
&lt;li&gt;站在设计者的角度，如果从零开始设计一个轮子，怎么利用合适的算法、数据结构，去实现它。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;回到这篇文章的主题，我首先会围绕第三个话题讨论：设计实现一个定时器，可以使用什么算法，采用什么数据结构。接着再聊聊第一个话题：探讨一些优秀的定时器实现方案。&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://lexburner.github.io/categories/JAVA/"/>
    
    
      <category term="JAVA" scheme="http://lexburner.github.io/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>提问前，请先让自己成为值得被教的人</title>
    <link href="http://lexburner.github.io/thinging-in-ask/"/>
    <id>http://lexburner.github.io/thinging-in-ask/</id>
    <published>2019-01-21T18:18:51.000Z</published>
    <updated>2019-01-24T11:15:07.445Z</updated>
    
    <content type="html"><![CDATA[<p>每一个不恰当的提问都在消耗别人对你的耐心，程序员届早已经有了诸如《提问的智慧》之类的经典文章介绍了什么是蠢问题，如何避免问蠢问题。然而，常年混迹于十几个技术交流微信群的我，发现很多小白程序员并不懂得这一点，为改善微信群的技术交流氛围，转此文，意图是让大家在担任提问者的角色时，尽可能提高提问的素质，让自己成为值得被教的人。</p><blockquote><p>原文出处：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way" target="_blank" rel="noopener">https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way</a></p></blockquote><a id="more"></a><h3 id="用清晰、正确、精准并语法正确的语句"><a href="#用清晰、正确、精准并语法正确的语句" class="headerlink" title="用清晰、正确、精准并语法正确的语句"></a>用清晰、正确、精准并语法正确的语句</h3><p>我们从经验中发现，粗心的提问者通常也会粗心的写程序与思考（我敢打包票）。回答粗心大意者的问题很不值得，我们宁愿把时间耗在别处。</p><p>正确的拼字、标点符号和大小写是很重要的。一般来说，如果你觉得这样做很麻烦，不想在乎这些，那我们也觉得麻烦，不想在乎你的提问。花点额外的精力斟酌一下字句，用不着太僵硬与正式。</p><p>更白话地说，如果你写得像是个小白，那多半得不到理睬。</p><p>如果在使用非母语的论坛提问，你可以犯点拼写和语法上的小错，但决不能在思考上马虎（没错，我们通常能弄清两者的分别）。同时，除非你知道回复者使用的语言，否则请使用英语书写。繁忙的程序员一般会直接删除用他们看不懂语言写的消息。在网络上英语是通用语言，用英语书写可以将你的问题在尚未被阅读就被直接删除的可能性降到最低。</p><p>如果英文是你的外语（Second language），提示潜在回复者你有潜在的语言困难是很好的： [译注：以下附上原文以供使用]</p><blockquote><p>English is not my native language; please excuse typing errors.</p></blockquote><ul><li>英文不是我的母语，请原谅我的错字或语法</li></ul><blockquote><p>If you speak $LANGUAGE, please email/PM me; I may need assistance translating my question.</p></blockquote><ul><li>如果你说<strong>某语言</strong>，请寄信/私讯给我；我需要有人协助我翻译我的问题</li></ul><blockquote><p>I am familiar with the technical terms, but some slang expressions and idioms are difficult for me.</p></blockquote><ul><li>我对技术名词很熟悉，但对于俗语或是特别用法比较不甚了解。</li></ul><blockquote><p>I’ve posted my question in $LANGUAGE and English. I’ll be glad to translate responses, if you only use one or the other.</p></blockquote><ul><li>我把我的问题用<strong>某语言</strong>和英文写出来，如果你只用一种语言回答，我会乐意将其翻译成另一种。</li></ul><h3 id="精确的描述问题并言之有物"><a href="#精确的描述问题并言之有物" class="headerlink" title="精确的描述问题并言之有物"></a>精确的描述问题并言之有物</h3><ul><li>仔细、清楚地描述你的问题或 Bug 的症状。</li><li>描述问题发生的环境（机器配置、操作系统、应用程序、以及相关的信息），提供经销商的发行版和版本号（如：<code>Fedora Core 4</code>、<code>Slackware 9.1</code>等）。</li><li>描述在提问前你是怎样去研究和理解这个问题的。</li><li>描述在提问前为确定问题而采取的诊断步骤。</li><li>描述最近做过什么可能相关的硬件或软件变更。</li><li>尽可能的提供一个可以<code>重现这个问题的可控环境</code>的方法。</li></ul><p>尽量去揣测一个程序员会怎样反问你，在你提问之前预先将程序员们可能遇到的问题回答一遍。</p><p>以上几点中，当你报告的是你认为可能在代码中的问题时，给程序员一个可以重现你的问题的环境尤其重要。当你这么做时，你得到有效的回答的机会和速度都会大大的提升。</p><p><a href="http://www.chiark.greenend.org.uk/~sgtatham/" target="_blank" rel="noopener">Simon Tatham</a> 写过一篇名为《<a href="http://www.chiark.greenend.org.uk/~sgtatham/bugs-tw.html" target="_blank" rel="noopener">如何有效的报告 Bug</a>》的出色文章。强力推荐你也读一读。</p><h3 id="话不在多而在精"><a href="#话不在多而在精" class="headerlink" title="话不在多而在精"></a>话不在多而在精</h3><p>你需要提供精确有内容的信息。这并不是要求你简单的把成堆的出错代码或者资料完全转录到你的提问中。如果你有庞大而复杂的测试样例能重现程序挂掉的情境，尽量将它剪裁得越小越好。</p><p>这样做的用处至少有三点。 第一，表现出你为简化问题付出了努力，这可以使你得到回答的机会增加； 第二，简化问题使你更有可能得到<strong><em>有用</em></strong>的答案； 第三，在精炼你的 bug 报告的过程中，你很可能就自己找到了解决方法或权宜之计。</p><h3 id="别动辄声称找到-Bug"><a href="#别动辄声称找到-Bug" class="headerlink" title="别动辄声称找到 Bug"></a>别动辄声称找到 Bug</h3><p>当你在使用软件中遇到问题，除非你非常、<strong><em>非常</em></strong>的有根据，不要动辄声称找到了 Bug。提示：除非你能提供解决问题的源代码补丁，或者提供回归测试来表明前一版本中行为不正确，否则你都多半不够完全确信。这同样适用在网页和文件，如果你（声称）发现了文件的<code>Bug</code>，你应该能提供相应位置的修正或替代文件。</p><p>请记得，还有许多其它使用者没遇到你发现的问题，否则你在阅读文件或搜索网页时就应该发现了（你在抱怨前<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#%E5%9C%A8%E6%8F%90%E9%97%AE%E4%B9%8B%E5%89%8D" target="_blank" rel="noopener">已经做了这些，是吧</a>？）。这也意味着很有可能是你弄错了而不是软件本身有问题。</p><p>编写软件的人总是非常辛苦地使它尽可能完美。如果你声称找到了 Bug，也就是在质疑他们的能力，即使你是对的，也有可能会冒犯到其中某部分人。当你在标题中嚷嚷着有<code>Bug</code>时，这尤其严重。</p><p>提问时，即使你私下非常确信已经发现一个真正的 Bug，最好写得像是<strong><em>你</em></strong>做错了什么。如果真的有 Bug，你会在回复中看到这点。这样做的话，如果真有 Bug，维护者就会向你道歉，这总比你惹恼别人然后欠别人一个道歉要好一点。</p><h3 id="低声下气不能代替你的功课"><a href="#低声下气不能代替你的功课" class="headerlink" title="低声下气不能代替你的功课"></a>低声下气不能代替你的功课</h3><p>有些人明白他们不该粗鲁或傲慢的提问并要求得到答复，但他们选择另一个极端 – 低声下气：<code>我知道我只是个可悲的新手，一个撸瑟，但...</code>。这既使人困扰，也没有用，尤其是伴随着与实际问题含糊不清的描述时更令人反感。</p><p>别用原始灵长类动物的把戏来浪费你我的时间。取而代之的是，尽可能清楚地描述背景条件和你的问题情况。这比低声下气更好地定位了你的位置。</p><p>有时网页论坛会设有专为新手提问的版面，如果你真的认为遇到了初学者的问题，到那去就是了，但一样别那么低声下气。</p><h3 id="描述问题症状而非你的猜测"><a href="#描述问题症状而非你的猜测" class="headerlink" title="描述问题症状而非你的猜测"></a>描述问题症状而非你的猜测</h3><p>告诉程序员们你认为问题是怎样造成的并没什么帮助。（如果你的推断如此有效，还用向别人求助吗？），因此要确信你原原本本告诉了他们问题的症状，而不是你的解释和理论；让程序员们来推测和诊断。如果你认为陈述自己的猜测很重要，清楚地说明这只是你的猜测，并描述为什么它们不起作用。</p><p><strong>蠢问题</strong></p><blockquote><p>我在编译内核时接连遇到 SIG11 错误， 我怀疑某条飞线搭在主板的走线上了，这种情况应该怎样检查最好？</p></blockquote><p><strong>聪明问题</strong></p><blockquote><p>我的组装电脑是 FIC-PA2007 主机板搭载 AMD K6/233 CPU（威盛 Apollo VP2 芯片组）， 256MB Corsair PC133 SDRAM 内存，在编译内核时，从开机 20 分钟以后就频频产生 SIG11 错误， 但是在头 20 分钟内从没发生过相同的问题。重新启动也没有用，但是关机一晚上就又能工作 20 分钟。 所有内存都换过了，没有效果。相关部分的标准编译记录如下…。</p></blockquote><p>由于以上这点似乎让许多人觉得难以配合，这里有句话可以提醒你：<code>所有的诊断专家都来自密苏里州。</code> 美国国务院的官方座右铭则是：<code>让我看看</code>（出自国会议员 Willard D. Vandiver 在 1899 年时的讲话：<code>我来自一个出产玉米，棉花，牛蒡和民主党人的国家，滔滔雄辩既不能说服我，也不会让我满意。我来自密苏里州，你必须让我看看。</code>） 针对诊断者而言，这并不是一种怀疑，而只是一种真实而有用的需求，以便让他们看到的是与你看到的原始证据尽可能一致的东西，而不是你的猜测与归纳的结论。所以，大方的展示给我们看吧！</p><h3 id="按发生时间先后列出问题症状"><a href="#按发生时间先后列出问题症状" class="headerlink" title="按发生时间先后列出问题症状"></a>按发生时间先后列出问题症状</h3><p>问题发生前的一系列操作，往往就是对找出问题最有帮助的线索。因此，你的说明里应该包含你的操作步骤，以及机器和软件的反应，直到问题发生。在命令行处理的情况下，提供一段操作记录（例如运行脚本工具所生成的），并引用相关的若干行（如 20 行）记录会非常有帮助。</p><p>如果挂掉的程序有诊断选项（如 -v 的详述开关），试着选择这些能在记录中增加调试信息的选项。记住，<code>多</code>不等于<code>好</code>。试着选取适当的调试级别以便提供有用的信息而不是让读者淹没在垃圾中。</p><p>如果你的说明很长（如超过四个段落），在开头简述问题，接下来再按时间顺序详述会有所帮助。这样程序员们在读你的记录时就知道该注意哪些内容了。</p><h3 id="描述目标而不是过程"><a href="#描述目标而不是过程" class="headerlink" title="描述目标而不是过程"></a>描述目标而不是过程</h3><p>如果你想弄清楚如何做某事（而不是报告一个 Bug），在开头就描述你的目标，然后才陈述重现你所卡住的特定步骤。</p><p>经常寻求技术帮助的人在心中有个更高层次的目标，而他们在自以为能达到目标的特定道路上被卡住了，然后跑来问该怎么走，但没有意识到这条路本身就有问题。结果要费很大的劲才能搞定。</p><p><strong>蠢问题</strong></p><blockquote><p>我怎样才能从某绘图程序的颜色选择器中取得十六进制的的 RGB 值？</p></blockquote><p><strong>聪明问题</strong></p><blockquote><p>我正试着用替换一幅图片的色码（color table）成自己选定的色码，我现在知道的唯一方法是编辑每个色码区块（table slot）， 但却无法从某绘图程序的颜色选择器取得十六进制的的 RGB 值。</p></blockquote><p>第二种提问法比较聪明，你可能得到像是<code>建议采用另一个更合适的工具</code>的回复。</p><h3 id="清楚明确的表达你的问题以及需求"><a href="#清楚明确的表达你的问题以及需求" class="headerlink" title="清楚明确的表达你的问题以及需求"></a>清楚明确的表达你的问题以及需求</h3><p>漫无边际的提问是近乎无休无止的时间黑洞。最有可能给你有用答案的人通常也正是最忙的人（他们忙是因为要亲自完成大部分工作）。这样的人对无节制的时间黑洞相当厌恶，所以他们也倾向于厌恶那些漫无边际的提问。</p><p>如果你明确表述需要回答者做什么（如提供指点、发送一段代码、检查你的补丁、或是其他等等），就最有可能得到有用的答案。因为这会定出一个时间和精力的上限，便于回答者能集中精力来帮你。这么做很棒。</p><p>要理解专家们所处的世界，请把专业技能想像为充裕的资源，而回复的时间则是稀缺的资源。你要求他们奉献的时间越少，你越有可能从真正专业而且很忙的专家那里得到解答。</p><p>所以，界定一下你的问题，使专家花在辨识你的问题和回答所需要付出的时间减到最少，这技巧对你有用答案相当有帮助 – 但这技巧通常和简化问题有所区别。因此，问<code>我想更好的理解 X，可否指点一下哪有好一点说明？</code>通常比问<code>你能解释一下 X 吗？</code>更好。如果你的代码不能运作，通常请别人看看哪里有问题，比要求别人替你改正要明智得多。</p><h3 id="询问有关代码的问题时"><a href="#询问有关代码的问题时" class="headerlink" title="询问有关代码的问题时"></a>询问有关代码的问题时</h3><p>别要求他人帮你调试有问题的代码，不提示一下应该从何入手。张贴几百行的代码，然后说一声：<code>它不能工作</code>会让你完全被忽略。只贴几十行代码，然后说一句：<code>在第七行以后，我期待它显示 &lt;x&gt;，但实际出现的是 &lt;y&gt;</code>比较有可能让你得到回应。</p><p>最有效描述程序问题的方法是提供最精简的 Bug 展示测试用例（bug-demonstrating test case）。什么是最精简的测试用例？那是问题的缩影；一小个程序片段能<strong>刚好</strong>展示出程序的异常行为，而不包含其他令人分散注意力的内容。怎么制作最精简的测试用例？如果你知道哪一行或哪一段代码会造成异常的行为，复制下来并加入足够重现这个状况的代码（例如，足以让这段代码能被编译/直译/被应用程序处理）。如果你无法将问题缩减到一个特定区块，就复制一份代码并移除不影响产生问题行为的部分。总之，测试用例越小越好。</p><p>一般而言，要得到一段相当精简的测试用例并不太容易，但永远先尝试这样做的是种好习惯。这种方式可以帮助你了解如何自行解决这个问题 —- 而且即使你的尝试不成功，程序员们也会看到你在尝试取得答案的过程中付出了努力，这可以让他们更愿意与你合作。</p><p>如果你只是想让别人帮忙审查（Review）一下代码，在信的开头就要说出来，并且一定要提到你认为哪一部分特别需要关注以及为什么。</p><h3 id="别把自己家庭作业的问题贴上来"><a href="#别把自己家庭作业的问题贴上来" class="headerlink" title="别把自己家庭作业的问题贴上来"></a>别把自己家庭作业的问题贴上来</h3><p>程序员们很擅长分辨哪些问题是家庭作业式的问题；因为我们中的大多数都曾自己解决这类问题。同样，这些问题得由<strong>你</strong>来搞定，你会从中学到东西。你可以要求给点提示，但别要求得到完整的解决方案。</p><p>如果你怀疑自己碰到了一个家庭作业式的问题，但仍然无法解决，试试在使用者群组，论坛或（最后一招）在项目的<strong>使用者</strong>邮件列表或论坛中提问。尽管程序员们<strong>会</strong>看出来，但一些有经验的使用者也许仍会给你一些提示。</p><h3 id="去掉无意义的提问句"><a href="#去掉无意义的提问句" class="headerlink" title="去掉无意义的提问句"></a>去掉无意义的提问句</h3><p>避免用无意义的话结束提问，例如<code>有人能帮我吗？</code>或者<code>这有答案吗？</code>。</p><p>首先：如果你对问题的描述不是很好，这样问更是画蛇添足。</p><p>其次：由于这样问是画蛇添足，程序员们会很厌烦你 – 而且通常会用逻辑上正确，但毫无意义的回答来表示他们的蔑视， 例如：<code>没错，有人能帮你</code>或者<code>不，没答案</code>。</p><p>一般来说，避免用 <code>是或否</code>、<code>对或错</code>、<code>有或没有</code>类型的问句，除非你想得到<a href="http://homepage.ntlworld.com./jonathan.deboynepollard/FGA/questions-with-yes-or-no-answers.html" target="_blank" rel="noopener">是或否类型的回答</a>。</p><h3 id="礼多人不怪，而且有时还很有帮助"><a href="#礼多人不怪，而且有时还很有帮助" class="headerlink" title="礼多人不怪，而且有时还很有帮助"></a>礼多人不怪，而且有时还很有帮助</h3><p>彬彬有礼，多用<code>请</code>和<code>谢谢您的关注</code>，或<code>谢谢你的关照</code>。让大家都知道你对他们花时间免费提供帮助心存感激。</p><p>坦白说，这一点并没有比清晰、正确、精准并合法语法和避免使用专用格式重要（也不能取而代之）。程序员们一般宁可读有点唐突但技术上鲜明的 Bug 报告，而不是那种有礼但含糊的报告。（如果这点让你不解，记住我们是按问题能教给我们什么来评价问题的价值的）</p><p>然而，如果你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。</p><p>（我们注意到，自从本指南发布后，从资深程序员那里得到的唯一严重缺陷反馈，就是对预先道谢这一条。一些程序员觉得<code>先谢了</code>意味着事后就不用再感谢任何人的暗示。我们的建议是要么先说<code>先谢了</code>，<strong><em>然后</em></strong>事后再对回复者表示感谢，或者换种方式表达感激，譬如用<code>谢谢你的关注</code>或<code>谢谢你的关照</code>。）</p><h3 id="问题解决后，加个简短的补充说明"><a href="#问题解决后，加个简短的补充说明" class="headerlink" title="问题解决后，加个简短的补充说明"></a>问题解决后，加个简短的补充说明</h3><p>问题解决后，向所有帮助过你的人发个说明，让他们知道问题是怎样解决的，并再一次向他们表示感谢。如果问题在新闻组或者邮件列表中引起了广泛关注，应该在那里贴一个说明比较恰当。</p><p>最理想的方式是向最初提问的话题回复此消息，并在标题中包含<code>已修正</code>，<code>已解决</code>或其它同等含义的明显标记。在人来人往的邮件列表里，一个看见讨论串<code>问题 X</code>和<code>问题 X - 已解决</code>的潜在回复者就明白不用再浪费时间了（除非他个人觉得<code>问题 X</code>的有趣），因此可以利用此时间去解决其它问题。</p><p>补充说明不必很长或是很深入；简单的一句<code>你好，原来是网线出了问题！谢谢大家 – Bill</code>比什么也不说要来的好。事实上，除非结论真的很有技术含量，否则简短可爱的小结比长篇大论更好。说明问题是怎样解决的，但大可不必将解决问题的过程复述一遍。</p><p>对于有深度的问题，张贴调试记录的摘要是有帮助的。描述问题的最终状态，说明是什么解决了问题，在此<strong><em>之后</em></strong>才指明可以避免的盲点。避免盲点的部分应放在正确的解决方案和其它总结材料之后，而不要将此信息搞成侦探推理小说。列出那些帮助过你的名字，会让你交到更多朋友。</p><p>除了有礼貌和有内涵以外，这种类型的补充也有助于他人在邮件列表/新闻群组/论坛中搜索到真正解决你问题的方案，让他们也从中受益。</p><p>至少，这种补充有助于让每位参与协助的人因问题的解决而从中得到满足感。如果你自己不是技术专家或者程序员，那就相信我们，这种感觉对于那些你向他们求助的大师或者专家而言，是非常重要的。问题悬而未决会让人灰心；程序员们渴望看到问题被解决。好人有好报，满足他们的渴望，你会在下次提问时尝到甜头。</p><p>思考一下怎样才能避免他人将来也遇到类似的问题，自问写一份文件或加个常见问题（FAQ）会不会有帮助。如果是的话就将它们发给维护者。</p><p>在程序员中，这种良好的后继行动实际上比传统的礼节更为重要，也是你如何透过善待他人而赢得声誉的方式，这是非常有价值的资产。</p><h2 id="如何解读答案"><a href="#如何解读答案" class="headerlink" title="如何解读答案"></a>如何解读答案</h2><h3 id="RTFM-和-STFW：如何知道你已完全搞砸了"><a href="#RTFM-和-STFW：如何知道你已完全搞砸了" class="headerlink" title="RTFM 和 STFW：如何知道你已完全搞砸了"></a>RTFM 和 STFW：如何知道你已完全搞砸了</h3><p>有一个古老而神圣的传统：如果你收到<code>RTFM （Read The Fucking Manual）</code>的回应，回答者认为你<strong>应该去读他妈的手册</strong>。当然，基本上他是对的，你应该去读一读。</p><p>RTFM 有一个年轻的亲戚。如果你收到<code>STFW（Search The Fucking Web）</code>的回应，回答者认为你<strong>应该到他妈的网上搜索</strong>过了。那人多半也是对的，去搜索一下吧。（更温和一点的说法是 <strong>Google 是你的朋友</strong>！）</p><p>在论坛，你也可能被要求去爬爬论坛的旧文。事实上，有人甚至可能热心地为你提供以前解决此问题的讨论串。但不要依赖这种关照，提问前应该先搜索一下旧文。</p><p>通常，用这两句之一回答你的人会给你一份包含你需要内容的手册或者一个网址，而且他们打这些字的时候也正在读着。这些答复意味着回答者认为</p><ul><li><strong>你需要的信息非常容易获得</strong>；</li><li><strong>你自己去搜索这些信息比灌给你，能让你学到更多</strong>。</li></ul><p>你不应该因此不爽；<strong>依照程序员的标准，他已经表示了对你一定程度的关注，而没有对你的要求视而不见</strong>。你应该对他祖母般的慈祥表示感谢。</p><h3 id="如果还是搞不懂"><a href="#如果还是搞不懂" class="headerlink" title="如果还是搞不懂"></a>如果还是搞不懂</h3><p>如果你看不懂回应，别立刻要求对方解释。像你以前试着自己解决问题时那样（利用手册，FAQ，网络，身边的高手），先试着去搞懂他的回应。如果你真的需要对方解释，记得表现出你已经从中学到了点什么。</p><p>比方说，如果我回答你：<code>看来似乎是 zentry 卡住了；你应该先清除它。</code>，然后，这是一个<strong><em>很糟的</em></strong>后续问题回应：<code>zentry 是什么？</code> <strong><em>好</em></strong>的问法应该是这样：<code>哦~~~我看过说明了但是只有 -z 和 -p 两个参数中提到了 zentries，而且还都没有清楚的解释如何清除它。你是指这两个中的哪一个吗？还是我看漏了什么？</code></p><h3 id="处理无礼的回应"><a href="#处理无礼的回应" class="headerlink" title="处理无礼的回应"></a>处理无礼的回应</h3><p>很多程序员圈子中看似无礼的行为并不是存心冒犯。相反，它是直接了当，一针见血式的交流风格，这种风格更注重解决问题，而不是使人感觉舒服而却模模糊糊。</p><p>如果你觉得被冒犯了，试着平静地反应。如果有人真的做了出格的事，邮件列表、新闻群组或论坛中的前辈多半会招呼他。如果这<strong><em>没有</em></strong>发生而你却发火了，那么你发火对象的言语可能在程序员社区中看起来是正常的，而<strong><em>你</em></strong>将被视为有错的一方，这将伤害到你获取信息或帮助的机会。</p><p>另一方面，你偶而真的会碰到无礼和无聊的言行。与上述相反，对真正的冒犯者狠狠地打击，用犀利的语言将其驳得体无完肤都是可以接受的。然而，在行事之前一定要非常非常的有根据。纠正无礼的言论与开始一场毫无意义的口水战仅一线之隔，程序员们自己莽撞地越线的情况并不鲜见。如果你是新手或外人，避开这种莽撞的机会并不高。如果你想得到的是信息而不是消磨时光，这时最好不要把手放在键盘上以免冒险。</p><p>（有些人断言很多程序员都有轻度的自闭症或亚斯伯格综合症，缺少用于润滑人类社会<strong>正常</strong>交往所需的神经。这既可能是真也可能是假的。如果你自己不是程序员，兴许你认为我们脑袋有问题还能帮助你应付我们的古怪行为。只管这么干好了，我们不在乎。我们<strong><em>喜欢</em></strong>我们现在这个样子，并且通常对病患标记都有站得住脚的怀疑。）</p><p>Jeff Bigler 的观察总结和这个相关也值得一读 (<strong>tact filters</strong>)。</p><p>在下一节，我们会谈到另一个问题，当<strong><em>你</em></strong>行为不当时所会受到的<code>冒犯</code>。</p><h2 id="如何避免扮演失败者"><a href="#如何避免扮演失败者" class="headerlink" title="如何避免扮演失败者"></a>如何避免扮演失败者</h2><p>在程序员社区的论坛中有那么几次你可能会搞砸 – 以本指南所描述到的或类似的方式。而你会在公开场合中被告知你是如何搞砸的，也许攻击的言语中还会带点夹七夹八的颜色。</p><p>这种事发生以后，你能做的最糟糕的事莫过于哀嚎你的遭遇、宣称被口头攻击、要求道歉、高声尖叫、憋闷气、威胁诉诸法律、向其雇主报怨、忘了关马桶盖等等。相反地，你该这么做：</p><p>熬过去，这很正常。事实上，它是有益健康且合理的。</p><p>社区的标准不会自行维持，它们是通过参与者积极而<strong><em>公开地</em></strong>执行来维持的。不要哭嚎所有的批评都应该通过私下的邮件传送，它不是这样运作的。当有人评论你的一个说法有误或者提出不同看法时，坚持声称受到个人攻击也毫无益处，这些都是失败者的态度。</p><p>也有其它的程序员论坛，受过高礼节要求的误导，禁止参与者张贴任何对别人帖子挑毛病的消息，并声称<code>如果你不想帮助用户就闭嘴。</code> 结果造成有想法的参与者纷纷离开，这么做只会使它们沦为毫无意义的唠叨与无用的技术论坛。</p><p>夸张的讲法是：你要的是<strong>友善</strong>（以上述方式）还是有用？两个里面挑一个。</p><p>记着：当程序员说你搞砸了，并且（无论多么刺耳）告诉你别再这样做时，他正在为关心<strong>你</strong>和<strong>他的社区</strong>而行动。对他而言，不理你并将你从他的生活中滤掉更简单。如果你无法做到感谢，至少要表现得有点尊严，别大声哀嚎，也别因为自己是个有戏剧性超级敏感的灵魂和自以为有资格的新来者，就指望别人像对待脆弱的洋娃娃那样对你。</p><p>有时候，即使你没有搞砸（或者只是在他的想像中你搞砸了），有些人也会无缘无故地攻击你本人。在这种情况下，抱怨倒是<strong><em>真的</em></strong>会把问题搞砸。</p><p>这些来找麻烦的人要么是毫无办法但自以为是专家的不中用家伙，要么就是测试你是否真会搞砸的心理专家。其它读者要么不理睬，要么用自己的方式对付他们。这些来找麻烦的人在给他们自己找麻烦，这点你不用操心。</p><p>也别让自己卷入口水战，最好不要理睬大多数的口水战 – 当然，这是在你检验它们只是口水战，并且未指出你有搞砸的地方，同时也没有巧妙地将问题真正的答案藏于其后（这也是有可能的）。</p><h2 id="不该问的问题"><a href="#不该问的问题" class="headerlink" title="不该问的问题"></a>不该问的问题</h2><p>以下是几个经典蠢问题，以及程序员没回答时心中所想的：</p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q1" target="_blank" rel="noopener">我能在哪找到 X 程序或 X 资源？</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q2" target="_blank" rel="noopener">我怎样用 X 做 Y？</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q3" target="_blank" rel="noopener">如何设定我的 shell 提示？</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q4" target="_blank" rel="noopener">我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q5" target="_blank" rel="noopener">我的程序/设定/SQL 语句没有用</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q6" target="_blank" rel="noopener">我的 Windows 电脑有问题，你能帮我吗？</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q7" target="_blank" rel="noopener">我的程序不会动了，我认为系统工具 X 有问题</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q8" target="_blank" rel="noopener">我在安装 Linux（或者 X ）时有问题，你能帮我吗？</a></p><p>问题：<a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#q9" target="_blank" rel="noopener">我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？</a></p><hr><blockquote><p>问题：我能在哪找到 X 程序或 X 资源？</p></blockquote><p>回答：就在我找到它的地方啊，白痴 – 搜索引擎的那一头。天哪！难道还有人不会用 <a href="http://www.google.com/" target="_blank" rel="noopener">Google</a> 吗？</p><blockquote><p>问题：我怎样用 X 做 Y？</p></blockquote><p>回答：如果你想解决的是 Y ，提问时别给出可能并不恰当的方法。这种问题说明提问者不但对 X 完全无知，也对 Y 要解决的问题糊涂，还被特定形势禁锢了思维。最好忽略这种人，等他们把问题搞清楚了再说。</p><blockquote><p>问题：如何设定我的 shell 提示？？</p></blockquote><p>回答：如果你有足够的智慧提这个问题，你也该有足够的智慧去 <a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#RTFM" target="_blank" rel="noopener">RTFM</a>，然后自己去找出来。</p><blockquote><p>问题：我可以用 Bass-o-matic 文件转换工具将 AcmeCorp 档案转换为 TeX 格式吗？</p></blockquote><p>回答：试试看就知道了。如果你试过，你既知道了答案，就不用浪费我的时间了。</p><blockquote><p>问题：我的{程序/设定/SQL 语句}不工作</p></blockquote><p>回答：这不算是问题吧，我对要我问你二十个问题才找得出你真正问题的问题没兴趣 – 我有更有意思的事要做呢。在看到这类问题的时候，我的反应通常不外如下三种</p><ul><li>你还有什么要补充的吗？</li><li>真糟糕，希望你能搞定。</li><li>这关我有什么屁事？</li></ul><blockquote><p>问题：我的 Windows 电脑有问题，你能帮我吗？</p></blockquote><p>回答：能啊，扔掉微软的垃圾，换个像 Linux 或 BSD 的开放源代码操作系统吧。</p><p>注意：如果程序有官方版 Windows 或者与 Windows 有互动（如 Samba），你<strong><em>可以</em></strong>问与 Windows 相关的问题， 只是别对问题是由 Windows 操作系统而不是程序本身造成的回复感到惊讶， 因为 Windows 一般来说实在太烂，这种说法通常都是对的。</p><blockquote><p>问题：我的程序不会动了，我认为系统工具 X 有问题</p></blockquote><p>回答：你完全有可能是第一个注意到被成千上万用户反复使用的系统调用与函数库档案有明显缺陷的人，更有可能的是你完全没有根据。不同凡响的说法需要不同凡响的证据，当你这样声称时，你必须有清楚而详尽的缺陷说明文件作后盾。</p><blockquote><p>问题：我在安装 Linux（或者 X ）时有问题，你能帮我吗？</p></blockquote><p>回答：不能，我只有亲自在你的电脑上动手才能找到毛病。还是去找你当地的 Linux 使用群组者寻求实际的指导吧（你能在<a href="http://www.linux.org/groups/index.html" target="_blank" rel="noopener">这儿</a>找到使用者群组的清单）。</p><p>注意：如果安装问题与某 Linux 的发行版有关，在它的邮件列表、论坛或本地使用者群组中提问也许是恰当的。此时，应描述问题的准确细节。在此之前，先用 <code>Linux</code> 和<strong><em>所有</em></strong>被怀疑的硬件作关键词仔细搜索。</p><blockquote><p>问题：我怎么才能破解 root 帐号/窃取 OP 特权/读别人的邮件呢？</p></blockquote><p>回答：想要这样做，说明了你是个卑鄙小人；想找个程序员帮你，说明你是个白痴！</p><h2 id="好问题与蠢问题"><a href="#好问题与蠢问题" class="headerlink" title="好问题与蠢问题"></a>好问题与蠢问题</h2><p>最后，我将透过举一些例子，来说明怎样聪明的提问；同一个问题的两种问法被放在一起，一种是愚蠢的，另一种才是明智的。</p><p><strong>蠢问题</strong>：</p><blockquote><p>我可以在哪儿找到关于 Foonly Flurbamatic 的资料？</p></blockquote><p>这种问法无非想得到 <a href="https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way#RTFM" target="_blank" rel="noopener">STFW</a> 这样的回答。</p><p><strong>聪明问题</strong>：</p><blockquote><p>我用 Google 搜索过 “Foonly Flurbamatic 2600”，但是没找到有用的结果。谁知道上哪儿去找对这种设备编程的资料？</p></blockquote><p>这个问题已经 STFW 过了，看起来他真的遇到了麻烦。</p><p><strong>蠢问题</strong></p><blockquote><p>我从 foo 项目找来的源码没法编译。它怎么这么烂？</p></blockquote><p>他觉得都是别人的错，这个傲慢自大的提问者。</p><p><strong>聪明问题</strong></p><blockquote><p>foo 项目代码在 Nulix 6.2 版下无法编译通过。我读过了 FAQ，但里面没有提到跟 Nulix 有关的问题。这是我编译过程的记录，我有什么做的不对的地方吗？</p></blockquote><p>提问者已经指明了环境，也读过了 FAQ，还列出了错误，并且他没有把问题的责任推到别人头上，他的问题值得被关注。</p><p><strong>蠢问题</strong></p><blockquote><p>我的主机板有问题了，谁来帮我？</p></blockquote><p>某程序员对这类问题的回答通常是：<code>好的，还要帮你拍拍背和换尿布吗？</code>，然后按下删除键。</p><p><strong>聪明问题</strong></p><blockquote><p>我在 S2464 主机板上试过了 X 、 Y 和 Z ，但没什么作用，我又试了 A 、 B 和 C 。请注意当我尝试 C 时的奇怪现象。显然 florbish 正在 grommicking，但结果出人意料。通常在 Athlon MP 主机板上引起 grommicking 的原因是什么？有谁知道接下来我该做些什么测试才能找出问题？</p></blockquote><p>这个家伙，从另一个角度来看，值得去回答他。他表现出了解决问题的能力，而不是坐等天上掉答案。</p><p>在最后一个问题中，注意<code>告诉我答案</code>和<code>给我启示，指出我还应该做什么诊断工作</code>之间微妙而又重要的区别。</p><p>事实上，后一个问题源自于 2001 年 8 月在 Linux 内核邮件列表（lkml）上的一个真实的提问。我（Eric）就是那个提出问题的人。我在 Tyan S2464 主板上观察到了这种无法解释的锁定现象，列表成员们提供了解决这一问题的重要信息。</p><p>通过我的提问方法，我给了别人可以咀嚼玩味的东西；我设法让人们很容易参与并且被吸引进来。我显示了自己具备和他们同等的能力，并邀请他们与我共同探讨。通过告诉他们我所走过的弯路，以避免他们再浪费时间，我也表明了对他们宝贵时间的尊重。</p><p>事后，当我向每个人表示感谢，并且赞赏这次良好的讨论经历的时候， 一个 Linux 内核邮件列表的成员表示，他觉得我的问题得到解决并非由于我是这个列表中的<strong><em>名人</em></strong>，而是因为我用了正确的方式来提问。</p><p>程序员从某种角度来说是拥有丰富知识但缺乏人情味的家伙；我相信他是对的，如果我<strong><em>像</em></strong>个乞讨者那样提问，不论我是谁，一定会惹恼某些人或者被他们忽视。他建议我记下这件事，这直接导致了本指南的出现。</p><h2 id="如果得不到回答"><a href="#如果得不到回答" class="headerlink" title="如果得不到回答"></a>如果得不到回答</h2><p>如果仍得不到回答，请不要以为我们觉得无法帮助你。有时只是看到你问题的人不知道答案罢了。没有回应不代表你被忽视，虽然不可否认这种差别很难区分。</p><p>总的来说，简单的重复张贴问题是个很糟的点子。这将被视为无意义的喧闹。有点耐心，知道你问题答案的人可能生活在不同的时区，可能正在睡觉，也有可能你的问题一开始就没有组织好。</p><p>你可以通过其他渠道获得帮助，这些渠道通常更适合初学者的需要。</p><p>有许多网上的以及本地的使用者群组，由热情的软件爱好者（即使他们可能从没亲自写过任何软件）组成。通常人们组建这样的团体来互相帮助并帮助新手。</p><p>另外，你可以向很多商业公司寻求帮助，不论公司大还是小。别为要付费才能获得帮助而感到沮丧！毕竟，假使你的汽车发动机汽缸密封圈爆掉了– 完全可能如此 –你还得把它送到修车铺，并且为维修付费。就算软件没花费你一分钱，你也不能强求技术支持总是免费的。</p><p>对像是 Linux 这种大众化的软件，每个开发者至少会对应到上万名使用者。根本不可能由一个人来处理来自上万名使用者的求助电话。要知道，即使你要为这些协助付费，和你所购买的同类软件相比，你所付出的也是微不足道的（通常封闭源代码软件的技术支持费用比开放源代码软件的要高得多，且内容也没那么丰富）。</p><h2 id="如何更好地回答问题"><a href="#如何更好地回答问题" class="headerlink" title="如何更好地回答问题"></a>如何更好地回答问题</h2><p><strong>态度和善一点</strong>。问题带来的压力常使人显得无礼或愚蠢，其实并不是这样。</p><p><strong>对初犯者私下回复</strong>。对那些坦诚犯错之人没有必要当众羞辱，一个真正的新手也许连怎么搜索或在哪找常见问题都不知道。</p><p><strong>如果你不确定，一定要说出来</strong>！一个听起来权威的错误回复比没有还要糟，别因为听起来像个专家很好玩，就给别人乱指路。要谦虚和诚实，给提问者与同行都树个好榜样。</p><p><strong>如果帮不了忙，也别妨碍他</strong>。不要在实际步骤上开玩笑，那样也许会毁了使用者的设置 –有些可怜的呆瓜会把它当成真的指令。</p><p><strong>试探性的反问以引出更多的细节</strong>。如果你做得好，提问者可以学到点东西 –你也可以。试试将蠢问题转变成好问题，别忘了我们都曾是新手。</p><p>尽管对那些懒虫抱怨一声 RTFM 是正当的，能指出文件的位置（即使只是建议个 Google 搜索关键词）会更好。</p><p><strong>如果你决定回答，就请给出好的答案</strong>。当别人正在用错误的工具或方法时别建议笨拙的权宜之计（wordaround），应推荐更好的工具，重新界定问题。</p><p><strong>正面的回答问题</strong>！如果这个提问者已经很深入的研究而且也表明已经试过 X 、 Y 、 Z 、 A 、 B 、 C 但没得到结果，回答 <code>试试看 A 或是 B</code> 或者 <code>试试 X 、 Y 、 Z 、 A 、 B 、 C</code> 并附上一个链接一点用都没有。</p><p><strong>帮助你的社区从问题中学习</strong>。当回复一个好问题时，问问自己<code>如何修改相关文件或常见问题文件以免再次解答同样的问题？</code>，接着再向文件维护者发一份补丁。</p><p>如果你是在研究一番后才做出的回答，<strong>展现你的技巧而不是直接端出结果</strong>。毕竟<code>授人以鱼不如授人以渔</code>。</p><blockquote><p>tips：还有一点博主我觉得挺重要的：如果有妹子私聊你请教问题，请务必不要介意本文介绍的反例。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;每一个不恰当的提问都在消耗别人对你的耐心，程序员届早已经有了诸如《提问的智慧》之类的经典文章介绍了什么是蠢问题，如何避免问蠢问题。然而，常年混迹于十几个技术交流微信群的我，发现很多小白程序员并不懂得这一点，为改善微信群的技术交流氛围，转此文，意图是让大家在担任提问者的角色时，尽可能提高提问的素质，让自己成为值得被教的人。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;原文出处：&lt;a href=&quot;https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/aptx4869yuyang2017/How-To-Ask-Questions-The-Smart-Way&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术杂谈" scheme="http://lexburner.github.io/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="技术杂谈" scheme="http://lexburner.github.io/tags/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>一种心跳，两种设计</title>
    <link href="http://lexburner.github.io/heartbeat-design/"/>
    <id>http://lexburner.github.io/heartbeat-design/</id>
    <published>2019-01-11T22:24:09.000Z</published>
    <updated>2019-01-27T05:03:53.927Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h3><p>在前一篇文章<strong>《聊聊 TCP 长连接和心跳那些事》</strong>中，我们已经聊过了 TCP 中的 KeepAlive，以及在应用层设计心跳的意义，但却对长连接心跳的设计方案没有做详细地介绍。事实上，设计一个好的心跳机制并不是一件容易的事，就我所熟知的几个 RPC 框架，它们的心跳机制可以说大相径庭，这篇文章我将探讨一下<strong>如何设计一个优雅的心跳机制，主要从 Dubbo 的现有方案以及一个改进方案来做分析</strong>。</p><a id="more"></a><h3 id="2-预备知识"><a href="#2-预备知识" class="headerlink" title="2 预备知识"></a>2 预备知识</h3><p>因为后续我们将从源码层面来进行介绍，所以一些服务治理框架的细节还需要提前交代一下，方便大家理解。</p><h4 id="2-1-客户端如何得知请求失败了？"><a href="#2-1-客户端如何得知请求失败了？" class="headerlink" title="2.1 客户端如何得知请求失败了？"></a>2.1 客户端如何得知请求失败了？</h4><p>高性能的 RPC 框架几乎都会选择使用 Netty 来作为通信层的组件，非阻塞式通信的高效不需要我做过多的介绍。但也由于非阻塞的特性，导致其发送数据和接收数据是一个异步的过程，所以当存在服务端异常、网络问题时，客户端接是接收不到响应的，那我们如何判断一次 RPC 调用是失败的呢？</p><p>误区一：Dubbo 调用不是默认同步的吗？</p><p>Dubbo 在通信层是异步的，呈现给使用者同步的错觉是因为内部做了阻塞等待，实现了异步转同步。</p><p>误区二： <code>Channel.writeAndFlush</code> 会返回一个 <code>channelFuture</code>，我只需要判断 <code>channelFuture.isSuccess</code> 就可以判断请求是否成功了。</p><p>注意，writeAndFlush 成功并不代表对端接受到了请求，返回值为 true 只能保证写入网络缓冲区成功，并不代表发送成功。</p><p>避开上述两个误区，我们再来回到本小节的标题：客户端如何得知请求失败？<strong>正确的逻辑应当是以客户端接收到失败响应为判断依据</strong>。等等，前面不还在说在失败的场景中，服务端是不会返回响应的吗？没错，既然服务端不会返回，那就只能客户端自己造了。</p><p>一个常见的设计是：客户端发起一个 RPC 请求，会设置一个超时时间 <code>client_timeout</code>，发起调用的同时，客户端会开启一个延迟 <code>client_timeout</code> 的定时器</p><ul><li>接收到正常响应时，移除该定时器。</li><li>定时器倒计时完毕，还没有被移除，则认为请求超时，构造一个失败的响应传递给客户端。</li></ul><p>Dubbo 中的超时判定逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> DefaultFuture <span class="title">newFuture</span><span class="params">(Channel channel, Request request, <span class="keyword">int</span> timeout)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> DefaultFuture future = <span class="keyword">new</span> DefaultFuture(channel, request, timeout);</span><br><span class="line">    <span class="comment">// timeout check</span></span><br><span class="line">    timeoutCheck(future);</span><br><span class="line">    <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">timeoutCheck</span><span class="params">(DefaultFuture future)</span> </span>&#123;</span><br><span class="line">    TimeoutCheckTask task = <span class="keyword">new</span> TimeoutCheckTask(future);</span><br><span class="line">    TIME_OUT_TIMER.newTimeout(task, future.getTimeout(), TimeUnit.MILLISECONDS);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeoutCheckTask</span> <span class="keyword">implements</span> <span class="title">TimerTask</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> DefaultFuture future;</span><br><span class="line">    TimeoutCheckTask(DefaultFuture future) &#123;</span><br><span class="line">        <span class="keyword">this</span>.future = future;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Timeout timeout)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (future == <span class="keyword">null</span> || future.isDone()) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// create exception response.</span></span><br><span class="line">        Response timeoutResponse = <span class="keyword">new</span> Response(future.getId());</span><br><span class="line">        <span class="comment">// set timeout status.</span></span><br><span class="line">        timeoutResponse.setStatus(future.isSent() ? Response.SERVER_TIMEOUT : Response.CLIENT_TIMEOUT);</span><br><span class="line">        timeoutResponse.setErrorMessage(future.getTimeoutMessage(<span class="keyword">true</span>));</span><br><span class="line">        <span class="comment">// handle response.</span></span><br><span class="line">        DefaultFuture.received(future.getChannel(), timeoutResponse);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要逻辑涉及的类：<code>DubboInvoker</code>，<code>HeaderExchangeChannel</code>，<code>DefaultFuture</code> ，通过上述代码，我们可以得知一个细节，无论是何种调用，都会经过这个定时器的检测，<strong>超时即调用失败，一次 RPC 调用的失败，必须以客户端收到失败响应为准</strong>。</p><h4 id="2-2-心跳检测需要容错"><a href="#2-2-心跳检测需要容错" class="headerlink" title="2.2 心跳检测需要容错"></a>2.2 心跳检测需要容错</h4><p>网络通信永远要考虑到最坏的情况，一次心跳失败，不能认定为连接不通，多次心跳失败，才能采取相应的措施。</p><h4 id="2-3-心跳检测不需要忙检测"><a href="#2-3-心跳检测不需要忙检测" class="headerlink" title="2.3 心跳检测不需要忙检测"></a>2.3 心跳检测不需要忙检测</h4><p>忙检测的对立面是空闲检测，我们做心跳的初衷，是为了保证连接的可用性，以保证及时采取断连，重连等措施。如果一条通道上有频繁的 RPC 调用正在进行，我们不应该为通道增加负担去发送心跳包。<strong>心跳扮演的角色应当是晴天收伞，雨天送伞。</strong></p><h3 id="3-Dubbo-现有方案"><a href="#3-Dubbo-现有方案" class="headerlink" title="3 Dubbo 现有方案"></a>3 Dubbo 现有方案</h3><blockquote><p>本文的源码对应 Dubbo  2.7.x 版本，在 apache 孵化的该版本中，心跳机制得到了增强。</p></blockquote><p>介绍完了一些基础的概念，我们再来看看 Dubbo 是如何设计应用层心跳的。Dubbo 的心跳是双向心跳，客户端会给服务端发送心跳，反之，服务端也会向客户端发送心跳。</p><h4 id="3-1-连接建立时创建定时器"><a href="#3-1-连接建立时创建定时器" class="headerlink" title="3.1 连接建立时创建定时器"></a>3.1 连接建立时创建定时器</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeaderExchangeClient</span> <span class="keyword">implements</span> <span class="title">ExchangeClient</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> heartbeat;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> heartbeatTimeout;</span><br><span class="line">    <span class="keyword">private</span> HashedWheelTimer heartbeatTimer;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HeaderExchangeClient</span><span class="params">(Client client, <span class="keyword">boolean</span> needHeartbeat)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.client = client;</span><br><span class="line">        <span class="keyword">this</span>.channel = <span class="keyword">new</span> HeaderExchangeChannel(client);</span><br><span class="line">        <span class="keyword">this</span>.heartbeat = client.getUrl().getParameter(Constants.HEARTBEAT_KEY, dubbo != <span class="keyword">null</span> &amp;&amp; dubbo.startsWith(<span class="string">"1.0."</span>) ? Constants.DEFAULT_HEARTBEAT : <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">this</span>.heartbeatTimeout = client.getUrl().getParameter(Constants.HEARTBEAT_TIMEOUT_KEY, heartbeat * <span class="number">3</span>);</span><br><span class="line">        <span class="keyword">if</span> (needHeartbeat) &#123; &lt;<span class="number">1</span>&gt;</span><br><span class="line">            <span class="keyword">long</span> tickDuration = calculateLeastDuration(heartbeat);</span><br><span class="line">            heartbeatTimer = <span class="keyword">new</span> HashedWheelTimer(<span class="keyword">new</span> NamedThreadFactory(<span class="string">"dubbo-client-heartbeat"</span>, <span class="keyword">true</span>), tickDuration,</span><br><span class="line">                    TimeUnit.MILLISECONDS, Constants.TICKS_PER_WHEEL); &lt;<span class="number">2</span>&gt;</span><br><span class="line">            startHeartbeatTimer();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p><1> <strong>默认开启心跳检测的定时器</strong></1></p><p><2> <strong>创建了一个 <code>HashedWheelTimer</code> 开启心跳检测</strong>，这是 Netty 所提供的一个经典的时间轮定时器实现，至于它和 jdk 的实现有何不同，不了解的同学也可以关注下，我就不拓展了。</2></p><p>不仅 <code>HeaderExchangeClient</code> 客户端开起了定时器，<code>HeaderExchangeServer</code> 服务端同样开起了定时器，由于服务端的逻辑和客户端几乎一致，所以后续我并不会重复粘贴服务端的代码。</p><blockquote><p>Dubbo 在早期版本版本中使用的是 schedule 方案，在 2.7.x 中替换成了 HashWheelTimer。</p></blockquote><h4 id="3-2-开启两个定时任务"><a href="#3-2-开启两个定时任务" class="headerlink" title="3.2 开启两个定时任务"></a>3.2 开启两个定时任务</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startHeartbeatTimer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> heartbeatTick = calculateLeastDuration(heartbeat);</span><br><span class="line">    <span class="keyword">long</span> heartbeatTimeoutTick = calculateLeastDuration(heartbeatTimeout);</span><br><span class="line">    HeartbeatTimerTask heartBeatTimerTask = <span class="keyword">new</span> HeartbeatTimerTask(cp, heartbeatTick, heartbeat); &lt;<span class="number">1</span>&gt;</span><br><span class="line">    ReconnectTimerTask reconnectTimerTask = <span class="keyword">new</span> ReconnectTimerTask(cp, heartbeatTimeoutTick, heartbeatTimeout); &lt;<span class="number">2</span>&gt;</span><br><span class="line"></span><br><span class="line">    heartbeatTimer.newTimeout(heartBeatTimerTask, heartbeatTick, TimeUnit.MILLISECONDS);</span><br><span class="line">    heartbeatTimer.newTimeout(reconnectTimerTask, heartbeatTimeoutTick, TimeUnit.MILLISECONDS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Dubbo 在 <code>startHeartbeatTimer</code> 方法中主要开启了两个定时器： <code>HeartbeatTimerTask</code>，<code>ReconnectTimerTask</code> </p><p><1> <code>HeartbeatTimerTask</code> 主要用于定时发送心跳请求</1></p><p><2> <code>ReconnectTimerTask</code>  主要用于心跳失败之后处理重连，断连的逻辑</2></p><p>至于方法中的其他代码，其实也是本文的重要分析内容，先容我卖个关子，后面再来看追溯。</p><h4 id="3-3-定时任务一：发送心跳请求"><a href="#3-3-定时任务一：发送心跳请求" class="headerlink" title="3.3 定时任务一：发送心跳请求"></a>3.3 定时任务一：发送心跳请求</h4><p>详细解析下心跳检测定时任务的逻辑 <code>HeartbeatTimerTask#doTask</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doTask</span><span class="params">(Channel channel)</span> </span>&#123;</span><br><span class="line">    Long lastRead = lastRead(channel);</span><br><span class="line">    Long lastWrite = lastWrite(channel);</span><br><span class="line">    <span class="keyword">if</span> ((lastRead != <span class="keyword">null</span> &amp;&amp; now() - lastRead &gt; heartbeat)</span><br><span class="line">        || (lastWrite != <span class="keyword">null</span> &amp;&amp; now() - lastWrite &gt; heartbeat)) &#123;</span><br><span class="line">            Request req = <span class="keyword">new</span> Request();</span><br><span class="line">            req.setVersion(Version.getProtocolVersion());</span><br><span class="line">            req.setTwoWay(<span class="keyword">true</span>);</span><br><span class="line">            req.setEvent(Request.HEARTBEAT_EVENT);</span><br><span class="line">            channel.send(req);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>前面已经介绍过，<strong>Dubbo 采取的是是双向心跳设计</strong>，即服务端会向客户端发送心跳，客户端也会向服务端发送心跳，接收的一方更新 lastRead 字段，发送的一方更新 lastWrite 字段，超过心跳间隙的时间，便发送心跳请求给对端。这里的 lastRead/lastWrite 同样会被同一个通道上的普通调用更新，通过更新这两个字段，实现了只在连接空闲时才会真正发送空闲报文的机制，符合我们一开始科普的做法。</p><blockquote><p>注意：不仅仅心跳请求会更新 lastRead 和 lastWrite，普通请求也会。这对应了我们预备知识中的空闲检测机制。</p></blockquote><h4 id="3-4-定时任务二：处理重连和断连"><a href="#3-4-定时任务二：处理重连和断连" class="headerlink" title="3.4 定时任务二：处理重连和断连"></a>3.4 定时任务二：处理重连和断连</h4><p>继续研究下重连和断连定时器都实现了什么 <code>ReconnectTimerTask#doTask</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doTask</span><span class="params">(Channel channel)</span> </span>&#123;</span><br><span class="line">    Long lastRead = lastRead(channel);</span><br><span class="line">    Long now = now();</span><br><span class="line">    <span class="keyword">if</span> (lastRead != <span class="keyword">null</span> &amp;&amp; now - lastRead &gt; heartbeatTimeout) &#123;</span><br><span class="line">        <span class="keyword">if</span> (channel <span class="keyword">instanceof</span> Client) &#123;</span><br><span class="line">            ((Client) channel).reconnect();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            channel.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二个定时器则负责根据客户端、服务端类型来对连接做不同的处理，当超过设置的心跳总时间之后，客户端选择的是重新连接，服务端则是选择直接断开连接。这样的考虑是合理的，客户端调用是强依赖可用连接的，而服务端可以等待客户端重新建立连接。</p><blockquote><p>细心的朋友会发现，这个类被命名为 ReconnectTimerTask 是不太准确的，因为它处理的是重连和断连两个逻辑。</p></blockquote><h4 id="3-5-定时不精确的问题"><a href="#3-5-定时不精确的问题" class="headerlink" title="3.5 定时不精确的问题"></a>3.5 定时不精确的问题</h4><p>在 Dubbo 的 issue 中曾经有人反馈过定时不精确的问题，我们来看看是怎么一回事。</p><p>Dubbo 中默认的心跳周期是 60s，设想如下的时序：</p><ul><li>第 0 秒，心跳检测发现连接活跃</li><li>第 1 秒，连接实际断开</li><li>第 60 秒，心跳检测发现连接不活跃</li></ul><p>由于<strong>时间窗口的问题，死链不能够被及时检测出来，最坏情况为一个心跳周期</strong>。</p><p>为了解决上述问题，我们再倒回去看一下上面的 <code>startHeartbeatTimer()</code> 方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> heartbeatTick = calculateLeastDuration(heartbeat); </span><br><span class="line"><span class="keyword">long</span> heartbeatTimeoutTick = calculateLeastDuration(heartbeatTimeout);</span><br></pre></td></tr></table></figure><p>其中 <code>calculateLeastDuration</code> 根据心跳时间和超时时间分别计算出了一个 tick 时间，实际上就是将两个变量除以了 3，使得他们的值缩小，并传入了 <code>HashedWheelTimer</code> 的第二个参数之中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">heartbeatTimer.newTimeout(heartBeatTimerTask, heartbeatTick, TimeUnit.MILLISECONDS);</span><br><span class="line">heartbeatTimer.newTimeout(reconnectTimerTask, heartbeatTimeoutTick, TimeUnit.MILLISECONDS);</span><br></pre></td></tr></table></figure><p>tick 的含义便是定时任务执行的频率。这样，通过减少检测间隔时间，增大了及时发现死链的概率，原先的最坏情况是 60s，如今变成了 20s。这个频率依旧可以加快，但需要考虑资源消耗的问题。</p><blockquote><p>定时不准确的问题出现在 Dubbo 的两个定时任务之中，所以都做了 tick 操作。事实上，所有的定时检测的逻辑都存在类似的问题。</p></blockquote><h4 id="3-6-Dubbo-心跳总结"><a href="#3-6-Dubbo-心跳总结" class="headerlink" title="3.6 Dubbo 心跳总结"></a>3.6 Dubbo 心跳总结</h4><p>Dubbo 对于建立的每一个连接，同时在客户端和服务端开启了 2 个定时器，一个用于定时发送心跳，一个用于定时重连、断连，执行的频率均为各自检测周期的 1/3。定时发送心跳的任务负责在连接空闲时，向对端发送心跳包。定时重连、断连的任务负责检测 lastRead 是否在超时周期内仍未被更新，如果判定为超时，客户端处理的逻辑是重连，服务端则采取断连的措施。</p><p>先不急着判断这个方案好不好，再来看看改进方案是怎么设计的。</p><h3 id="4-Dubbo-改进方案"><a href="#4-Dubbo-改进方案" class="headerlink" title="4 Dubbo 改进方案"></a>4 Dubbo 改进方案</h3><p>实际上我们可以更优雅地实现心跳机制，本小节开始，我将介绍一个新的心跳机制。</p><h4 id="4-1-IdleStateHandler-介绍"><a href="#4-1-IdleStateHandler-介绍" class="headerlink" title="4.1 IdleStateHandler 介绍"></a>4.1 IdleStateHandler 介绍</h4><p>Netty 对空闲连接的检测提供了天然的支持，使用 <code>IdleStateHandler</code> 可以很方便的实现空闲检测逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">IdleStateHandler</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">long</span> readerIdleTime, <span class="keyword">long</span> writerIdleTime, <span class="keyword">long</span> allIdleTime,</span></span></span><br><span class="line"><span class="function"><span class="params">            TimeUnit unit)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure><ul><li>readerIdleTime：读超时时间</li><li>writerIdleTime：写超时时间</li><li>allIdleTime：所有类型的超时时间</li></ul><p><code>IdleStateHandler</code> 这个类会根据设置的超时参数，循环检测 channelRead 和 write 方法多久没有被调用。当在 pipeline 中加入 <code>IdleSateHandler</code> 之后，可以在此 pipeline 的任意 Handler 的 <code>userEventTriggered</code> 方法之中检测 <code>IdleStateEvent</code> 事件，</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">userEventTriggered</span><span class="params">(ChannelHandlerContext ctx, Object evt)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (evt <span class="keyword">instanceof</span> IdleStateEvent) &#123;</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">    &#125;</span><br><span class="line">    ctx.fireUserEventTriggered(evt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么需要介绍 <code>IdleStateHandler</code> 呢？其实提到它的空闲检测 + 定时的时候，大家应该能够想到了，这不天然是给心跳机制服务的吗？很多服务治理框架都选择了借助 <code>IdleStateHandler</code> 来实现心跳。</p><blockquote><p>IdleStateHandler 内部使用了 eventLoop.schedule(task) 的方式来实现定时任务，使用 eventLoop 线程的好处是还同时保证了<strong>线程安全</strong>，这里是一个小细节。 </p></blockquote><h4 id="4-2-客户端和服务端配置"><a href="#4-2-客户端和服务端配置" class="headerlink" title="4.2 客户端和服务端配置"></a>4.2 客户端和服务端配置</h4><p>首先是将 <code>IdleStateHandler</code> 加入 pipeline 中。</p><p><strong>客户端：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.handler(<span class="keyword">new</span> ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(NioSocketChannel ch)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ch.pipeline().addLast(<span class="string">"clientIdleHandler"</span>, <span class="keyword">new</span> IdleStateHandler(<span class="number">60</span>, <span class="number">0</span>, <span class="number">0</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><strong>服务端：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">serverBootstrap.childHandler(<span class="keyword">new</span> ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(NioSocketChannel ch)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ch.pipeline().addLast(<span class="string">"serverIdleHandler"</span>,<span class="keyword">new</span> IdleStateHandler(<span class="number">0</span>, <span class="number">0</span>, <span class="number">200</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>客户端配置了 read 超时为 60s，服务端配置了 write/read 超时为 200s，先在此埋下两个伏笔：</p><ol><li>为什么客户端和服务端配置的超时时间不一致？</li><li>为什么客户端检测的是读超时，而服务端检测的是读写超时？</li></ol><h4 id="4-3-空闲超时逻辑-—-客户端"><a href="#4-3-空闲超时逻辑-—-客户端" class="headerlink" title="4.3 空闲超时逻辑 — 客户端"></a>4.3 空闲超时逻辑 — 客户端</h4><p>对于空闲超时的处理逻辑，客户端和服务端是不同的。首先来看客户端</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">userEventTriggered</span><span class="params">(ChannelHandlerContext ctx, Object evt)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (evt <span class="keyword">instanceof</span> IdleStateEvent) &#123;</span><br><span class="line">        <span class="comment">// send heartbeat</span></span><br><span class="line">        sendHeartBeat();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">super</span>.userEventTriggered(ctx, evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>检测到空闲超时之后，采取的行为是向服务端发送心跳包，具体是如何发送，以及处理响应的呢？伪代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendHeartBeat</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Invocation invocation = <span class="keyword">new</span> Invocation();</span><br><span class="line">    invocation.setInvocationType(InvocationType.HEART_BEAT);</span><br><span class="line">    channel.writeAndFlush(invocation).addListener(<span class="keyword">new</span> CallbackFuture() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">callback</span><span class="params">(Future future)</span> </span>&#123;</span><br><span class="line">            RPCResult result = future.get();</span><br><span class="line">            <span class="comment">//超时 或者 写失败</span></span><br><span class="line">            <span class="keyword">if</span> (result.isError()) &#123;</span><br><span class="line">                channel.addFailedHeartBeatTimes();</span><br><span class="line">                <span class="keyword">if</span> (channel.getFailedHeartBeatTimes() &gt;= channel.getMaxHeartBeatFailedTimes()) &#123;</span><br><span class="line">                    channel.reconnect();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                channel.clearHeartBeatFailedTimes();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>行为并不复杂，构造一个心跳包发送到服务端，接受响应结果</p><ul><li>响应成功，清空请求失败标记</li><li>响应失败，心跳失败标记+1，如果超过配置的失败次数，则重新连接</li></ul><blockquote><p>不仅仅是心跳，普通请求返回成功响应时也会清空标记</p></blockquote><h4 id="4-4-空闲超时逻辑-—-服务端"><a href="#4-4-空闲超时逻辑-—-服务端" class="headerlink" title="4.4 空闲超时逻辑 — 服务端"></a>4.4 空闲超时逻辑 — 服务端</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">userEventTriggered</span><span class="params">(ChannelHandlerContext ctx, Object evt)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (evt <span class="keyword">instanceof</span> IdleStateEvent) &#123;</span><br><span class="line">        channel.close();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">super</span>.userEventTriggered(ctx, evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>服务端处理空闲连接的方式非常简单粗暴，直接关闭连接。</p><h4 id="4-5-改进方案心跳总结"><a href="#4-5-改进方案心跳总结" class="headerlink" title="4.5 改进方案心跳总结"></a>4.5 改进方案心跳总结</h4><ol><li><p>为什么客户端和服务端配置的超时时间不一致？</p><p>因为客户端有重试逻辑，不断发送心跳失败 n 次之后，才认为是连接断开；而服务端是直接断开，留给服务端时间得长一点。60 * 3 &lt; 200 还说明了一个问题，双方都拥有断开连接的能力，但连接的创建是由客户端主动发起的，那么客户端也更有权利去主动断开连接。</p></li><li><p>为什么客户端检测的是读超时，而服务端检测的是读写超时？</p><p>这其实是一个心跳的共识了，仔细思考一下，定时逻辑是由客户端发起的，所以整个链路中不通的情况只有可能是：服务端接收，服务端发送，客户端接收。也就是说，只有客户端的 pong，服务端的 ping，pong 的检测是有意义的。</p></li></ol><blockquote><p>主动追求别人的是你，主动说分手的也是你。</p></blockquote><p>利用 <code>IdleStateHandler</code> 实现心跳机制可以说是十分优雅的，借助 Netty 提供的空闲检测机制，利用客户端维护单向心跳，在收到 3 次心跳失败响应之后，客户端断开连接，交由异步线程重连，本质还是表现为客户端重连。服务端在连接空闲较长时间后，主动断开连接，以避免无谓的资源浪费。</p><h3 id="5-心跳设计方案对比"><a href="#5-心跳设计方案对比" class="headerlink" title="5 心跳设计方案对比"></a>5 心跳设计方案对比</h3><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Dubbo 现有方案</th><th style="text-align:center">Dubbo 改进方案</th></tr></thead><tbody><tr><td style="text-align:center"><strong>主体设计</strong></td><td style="text-align:center">开启两个定时器</td><td style="text-align:center">借助 IdleStateHandler，底层使用 schedule</td></tr><tr><td style="text-align:center"><strong>心跳方向</strong></td><td style="text-align:center">双向</td><td style="text-align:center">单向（客户端 -&gt; 服务端）</td></tr><tr><td style="text-align:center"><strong>心跳失败判定方式</strong></td><td style="text-align:center">心跳成功更新标记，借助定时器定时扫描标记，如果超过心跳超时周期未更新标记，认为心跳失败。</td><td style="text-align:center">通过判断心跳响应是否失败，超过失败次数，认为心跳失败</td></tr><tr><td style="text-align:center"><strong>扩展性</strong></td><td style="text-align:center">Dubbo 存在 mina，grizzy 等其他通信层实现，自定义定时器很容易适配多种扩展</td><td style="text-align:center">多通信层各自实现心跳，不做心跳的抽象</td></tr><tr><td style="text-align:center"><strong>设计性</strong></td><td style="text-align:center">编码复杂度高，代码量大，方案复杂，不易维护</td><td style="text-align:center">编码量小，可维护性强</td></tr></tbody></table><p>私下请教过<strong>美团点评的长连接负责人：俞超（闪电侠）</strong>，美点使用的心跳方案和 Dubbo 改进方案几乎一致，可以说该方案是标准实现了。</p><h3 id="6-Dubbo-实际改动点建议"><a href="#6-Dubbo-实际改动点建议" class="headerlink" title="6 Dubbo 实际改动点建议"></a>6 Dubbo 实际改动点建议</h3><p>鉴于 Dubbo 存在一些其他通信层的实现，所以可以保留现有的定时发送心跳的逻辑。</p><ul><li><strong>建议改动点一：</strong></li></ul><p>双向心跳的设计是不必要的，兼容现有的逻辑，可以让客户端在连接空闲时发送单向心跳，服务端定时检测连接可用性。定时时间尽量保证：客户端超时时间 * 3 ≈ 服务端超时时间</p><ul><li><strong>建议改动点二：</strong></li></ul><p>去除处理重连和断连的定时任务，Dubbo 可以判断心跳请求是否响应失败，可以借鉴改进方案的设计，在连接级别维护一个心跳失败次数的标记，任意响应成功，清除标记；连续心跳失败 n 次，客户端发起重连。这样可以减少一个不必要的定时器，任何轮询的方式，都是不优雅的。</p><p>最后再聊聊可扩展性这个话题。其实我是建议把定时器交给更加底层的 Netty 去做，也就是完全使用 <code>IdleStateHandler</code> ，其他通信层组件各自实现自己的空闲检测逻辑，但是 Dubbo 中 mina，grizzy 的兼容问题囿住了我的拳脚，但试问一下，如今的 2019 年，又有多少人在使用 mina 和 grizzy？因为一些不太可能用的特性，而限制了主流用法的优化，这肯定不是什么好事。抽象，功能，可扩展性并不是越多越好，开源产品的人力资源是有限的，框架使用者的理解能力也是有限的，能解决大多数人问题的设计，才是好的设计。哎，谁让我不会 mina，grizzy，还懒得去学呢[摊手]。</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1 前言&quot;&gt;&lt;/a&gt;1 前言&lt;/h3&gt;&lt;p&gt;在前一篇文章&lt;strong&gt;《聊聊 TCP 长连接和心跳那些事》&lt;/strong&gt;中，我们已经聊过了 TCP 中的 KeepAlive，以及在应用层设计心跳的意义，但却对长连接心跳的设计方案没有做详细地介绍。事实上，设计一个好的心跳机制并不是一件容易的事，就我所熟知的几个 RPC 框架，它们的心跳机制可以说大相径庭，这篇文章我将探讨一下&lt;strong&gt;如何设计一个优雅的心跳机制，主要从 Dubbo 的现有方案以及一个改进方案来做分析&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="RPC" scheme="http://lexburner.github.io/categories/RPC/"/>
    
    
      <category term="TCP" scheme="http://lexburner.github.io/tags/TCP/"/>
    
      <category term="心跳" scheme="http://lexburner.github.io/tags/%E5%BF%83%E8%B7%B3/"/>
    
  </entry>
  
  <entry>
    <title>聊聊 TCP 长连接和心跳那些事</title>
    <link href="http://lexburner.github.io/tcp-talk/"/>
    <id>http://lexburner.github.io/tcp-talk/</id>
    <published>2019-01-06T10:24:09.000Z</published>
    <updated>2019-01-08T12:58:34.953Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>可能很多 Java 程序员对 TCP 的理解只有一个三次握手，四次握手的认识，我觉得这样的原因主要在于 TCP 协议本身稍微有点抽象（相比较于应用层的 HTTP 协议）；其次，非框架开发者不太需要接触到 TCP 的一些细节。其实我个人对 TCP 的很多细节也并没有完全理解，这篇文章主要针对微信交流群里有人提出的长连接，心跳问题，做一个统一的整理。 </p><p>在 Java 中，使用 TCP 通信，大概率会涉及到 Socket、Netty，本文将借用它们的一些 API 和设置参数来辅助介绍。</p><a id="more"></a><h3 id="长连接与短连接"><a href="#长连接与短连接" class="headerlink" title="长连接与短连接"></a>长连接与短连接</h3><p><strong>TCP 本身并没有长短连接的区别</strong>，长短与否，完全取决于我们怎么用它。</p><ul><li>短连接：每次通信时，创建 Socket；一次通信结束，调用 socket.close()。这就是一般意义上的短连接，短连接的好处是管理起来比较简单，存在的连接都是可用的连接，不需要额外的控制手段。</li><li>长连接：每次通信完毕后，不会关闭连接，这样可以做到连接的复用。<strong>长连接的好处是省去了创建连接的耗时。</strong></li></ul><p>短连接和长连接的优势，分别是对方的劣势。想要图简单，不追求高性能，使用短连接合适，这样我们就不需要操心连接状态的管理；想要追求性能，使用长连接，我们就需要担心各种问题：比如<strong>端对端连接的维护，连接的保活</strong>。</p><p>长连接还常常被用来做数据的推送，我们大多数时候对通信的认知还是 request/response 模型，但 TCP 双工通信的性质决定了它还可以被用来做双向通信。在长连接之下，可以很方便的实现 push 模型，长连接的这一特性在本文并不会进行探讨，有兴趣的同学可以专门去搜索相关的文章。</p><p>短连接没有太多东西可以讲，所以下文我们将目光聚焦在长连接的一些问题上。纯讲理论未免有些过于单调，所以下文我借助一些 RPC 框架的实践来展开 TCP 的相关讨论。</p><h3 id="服务治理框架中的长连接"><a href="#服务治理框架中的长连接" class="headerlink" title="服务治理框架中的长连接"></a>服务治理框架中的长连接</h3><p>前面已经提到过，追求性能时，必然会选择使用长连接，所以借助 Dubbo 可以很好的来理解 TCP。我们开启两个 Dubbo 应用，一个 server 负责监听本地 20880 端口（众所周知，这是 Dubbo 协议默认的端口），一个 client 负责循环发送请求。执行 <code>lsof -i:20880</code> 命令可以查看端口的相关使用情况：</p><p><img src="http://kirito.iocoder.cn/image-20190106203341694.png" alt="image-20190106203341694"></p><ul><li><code>*:20880 (LISTEN)</code> 说明了 Dubbo 正在监听本地的 20880 端口，处理发送到本地 20880 端口的请求</li><li>后两条信息说明请求的发送情况，验证了 TCP 是一个双向的通信过程，由于我是在同一个机器开启了两个 Dubbo 应用，所以你能够看到是本地的 53078 端口与 20880 端口在通信。我们并没有手动设置 53078 这个客户端端口，它是随机的。通过这两条信息，阐释了一个事实：<strong>即使是发送请求的一方，也需要占用一个端口</strong>。</li><li>稍微说一下 FD 这个参数，他代表了<strong>文件句柄</strong>，每新增一条连接都会占用新的文件句柄，如果你在使用 TCP 通信的过程中出现了 <code>open too many files</code> 的异常，那就应该检查一下，你是不是创建了太多连接，而没有关闭。细心的读者也会联想到长连接的另一个好处，那就是会占用较少的文件句柄。</li></ul><h3 id="长连接的维护"><a href="#长连接的维护" class="headerlink" title="长连接的维护"></a>长连接的维护</h3><p>因为客户端请求的服务可能分布在多个服务器上，客户端自然需要跟对端创建多条长连接，我们遇到的第一个问题就是如何维护长连接。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 客户端</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NettyHandler</span> <span class="keyword">extends</span> <span class="title">SimpleChannelHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, Channel&gt; channels = <span class="keyword">new</span> ConcurrentHashMap&lt;String, Channel&gt;(); <span class="comment">// &lt;ip:port, channel&gt;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 服务端</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NettyServer</span> <span class="keyword">extends</span> <span class="title">AbstractServer</span> <span class="keyword">implements</span> <span class="title">Server</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Channel&gt; channels; <span class="comment">// &lt;ip:port, channel&gt;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Dubbo 中，客户端和服务端都使用 <code>ip:port</code> 维护了端对端的长连接，Channel 便是对连接的抽象。我们主要关注 NettyHandler 中的长连接，服务端同时维护一个长连接的集合是 Dubbo 的额外设计，我们将在后面提到。</p><p>这里插一句，解释下为什么我认为客户端的连接集合要重要一点。TCP 是一个双向通信的协议，任一方都可以是发送者，接受者，那为什么还抽象了 Client 和 Server 呢？因为<strong>建立连接这件事就跟谈念爱一样，必须要有主动的一方，你主动我们就会有故事</strong>。Client 可以理解为主动建立连接的一方，实际上两端的地位可以理解为是对等的。</p><h3 id="连接的保活"><a href="#连接的保活" class="headerlink" title="连接的保活"></a>连接的保活</h3><p>这个话题就有的聊了，会牵扯到比较多的知识点。首先需要明确一点，为什么需要连接的保活？当双方已经建立了连接，但因为网络问题，链路不通，这样长连接就不能使用了。需要明确的一点是，通过 netstat，lsof 等指令查看到连接的状态处于 <code>ESTABLISHED</code> 状态并不是一件非常靠谱的事，因为连接可能已死，但没有被系统感知到，更不用提假死这种疑难杂症了。如果保证长连接可用是一件技术活。</p><h3 id="连接的保活：KeepAlive"><a href="#连接的保活：KeepAlive" class="headerlink" title="连接的保活：KeepAlive"></a>连接的保活：KeepAlive</h3><p>首先想到的是 TCP 中的 KeepAlive 机制。KeepAlive 并不是 TCP 协议的一部分，但是大多数操作系统都实现了这个机制（所以需要在操作系统层面设置 KeepAlive 的相关参数）。KeepAlive 机制开启后，在一定时间内（一般时间为 7200s，参数 <code>tcp_keepalive_time</code>）在链路上没有数据传送的情况下，TCP 层将发送相应的 KeepAlive 探针以确定连接可用性，探测失败后重试 10（参数 <code>tcp_keepalive_probes</code>）次，每次间隔时间 75s（参数 <code>tcp_keepalive_intvl</code>），所有探测失败后，才认为当前连接已经不可用。</p><p>在 Netty 中开启 KeepAlive：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.option(ChannelOption.SO_KEEPALIVE, <span class="keyword">true</span>)</span><br></pre></td></tr></table></figure><p>Linux 操作系统中设置 KeepAlive 相关参数，修改 <code>/etc/sysctl.conf</code> 文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=90</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=15</span><br><span class="line">net.ipv4.tcp_keepalive_probes=2</span><br></pre></td></tr></table></figure><p><strong>KeepAlive 机制是在网络层面保证了连接的可用性</strong>，但站在应用框架层面我们认为这还不够。主要体现在三个方面：</p><ul><li>KeepAlive 的开关是在应用层开启的，但是具体参数（如重试测试，重试间隔时间）的设置却是操作系统级别的，位于操作系统的 <code>/etc/sysctl.conf</code> 配置中，这对于应用来说不够灵活。</li><li>KeepAlive 的保活机制只在链路空闲的情况下才会起到作用，假如此时有数据发送，且物理链路已经不通，操作系统这边的链路状态还是 <code>ESTABLISHED</code>，这时会发生什么？自然会走 TCP 重传机制，要知道默认的 TCP 超时重传，指数退避算法也是一个相当长的过程。</li><li>KeepAlive 本身是面向网络的，并不面向于应用，当连接不可用，可能是由于应用本身的 GC 频繁，系统 load 高等情况，但网络仍然是通的，此时，应用已经失去了活性，连接应该被认为是不可用的。</li></ul><p>我们已经为应用层面的连接保活做了足够的铺垫，下面就来一起看看，怎么在应用层做连接保活。</p><h3 id="连接的保活：应用层心跳"><a href="#连接的保活：应用层心跳" class="headerlink" title="连接的保活：应用层心跳"></a>连接的保活：应用层心跳</h3><p>终于点题了，文题中提到的<strong>心跳</strong>便是一个本文想要重点强调的另一个重要的知识点。上一节我们已经解释过了，网络层面的 KeepAlive 不足以支撑应用级别的连接可用性，本节就来聊聊应用层的心跳机制是实现连接保活的。</p><p>如何理解应用层的心跳？简单来说，就是客户端会开启一个定时任务，定时对已经建立连接的对端应用发送请求（这里的请求是特殊的心跳请求），服务端则需要特殊处理该请求，返回响应。如果心跳持续多次没有收到响应，客户端会认为连接不可用，主动断开连接。不同的服务治理框架对心跳，建连，断连，拉黑的机制有不同的策略，但大多数的服务治理框架都会在应用层做心跳，Dubbo/HSF 也不例外。</p><h3 id="应用层心跳的设计细节"><a href="#应用层心跳的设计细节" class="headerlink" title="应用层心跳的设计细节"></a>应用层心跳的设计细节</h3><p>以 Dubbo 为例，支持应用层的心跳，客户端和服务端都会开启一个 <code>HeartBeatTask</code>，客户端在 <code>HeaderExchangeClient</code> 中开启，服务端将在 <code>HeaderExchangeServer</code> 开启。文章开头埋了一个坑：Dubbo 为什么在服务端同时维护 <code>Map&lt;String,Channel&gt;</code> 呢？主要就是为了给心跳做贡献，心跳定时任务在发现连接不可用时，会根据当前是客户端还是服务端走不同的分支，客户端发现不可用，是重连；服务端发现不可用，是直接 close。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// HeartBeatTask</span></span><br><span class="line"><span class="keyword">if</span> (channel <span class="keyword">instanceof</span> Client) &#123;</span><br><span class="line">    ((Client) channel).reconnect();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    channel.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Dubbo 2.7.x 相比 2.6.x 做了定时心跳的优化，使用 <code>HashedWheelTimer</code> 更加精准的控制了只在连接闲置时发送心跳。</p></blockquote><p>再看看 HSF 的实现，并没有设置应用层的心跳，准确的说，是在 HSF2.2 之后，使用 Netty 提供的 <code>IdleStateHandler</code> 更加优雅的实现了应用的心跳。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ch.pipeline()</span><br><span class="line">        .addLast(<span class="string">"clientIdleHandler"</span>, <span class="keyword">new</span> IdleStateHandler(getHbSentInterval(), <span class="number">0</span>, <span class="number">0</span>));</span><br></pre></td></tr></table></figure><p>处理 <code>userEventTriggered</code> 中的 <code>IdleStateEvent</code> 事件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">userEventTriggered</span><span class="params">(ChannelHandlerContext ctx, Object evt)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (evt <span class="keyword">instanceof</span> IdleStateEvent) &#123;</span><br><span class="line">        callConnectionIdleListeners(client, (ClientStream) StreamUtils.streamOfChannel(ctx.channel()));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">super</span>.userEventTriggered(ctx, evt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于客户端，HSF 使用 <code>SendHeartbeat</code> 来进行心跳，每次失败累加心跳失败的耗时，当超过最大限制时断开乱接；对于服务端 HSF 使用 <code>CloseIdle</code> 来处理闲置连接，直接关闭连接。一般来说，服务端的闲置时间会设置的稍长。</p><p>熟悉其他 RPC 框架的同学会发现，不同框架的心跳机制真的是差距非常大。心跳设计还跟连接创建，重连机制，黑名单连接相关，还需要具体框架具体分析。</p><p>除了定时任务的设计，还需要在协议层面支持心跳。最简单的例子可以参考 nginx 的健康检查，而针对 Dubbo 协议，自然也需要做心跳的支持，如果将心跳请求识别为正常流量，会造成服务端的压力问题，干扰限流等诸多问题。</p><p><img src="http://kirito.iocoder.cn/359310b9-b980-3254-aed6-78aa6c482e53.png" alt="dubbo protocol"></p><p>其中 Flag 代表了 Dubbo 协议的标志位，一共 8 个地址位。低四位用来表示消息体数据用的序列化工具的类型（默认 hessian），高四位中，第一位为1表示是 request 请求，第二位为 1 表示双向传输（即有返回response），<strong>第三位为 1 表示是心跳事件</strong>。</p><blockquote><p>心跳请求应当和普通请求区别对待。</p></blockquote><h3 id="注意和-HTTP-的-KeepAlive-区别对待"><a href="#注意和-HTTP-的-KeepAlive-区别对待" class="headerlink" title="注意和 HTTP 的 KeepAlive 区别对待"></a>注意和 HTTP 的 KeepAlive 区别对待</h3><ul><li>HTTP 协议的 KeepAlive 意图在于连接复用，同一个连接上串行方式传递请求-响应数据</li><li>TCP 的 KeepAlive 机制意图在于保活、心跳，检测连接错误。</li></ul><p>这压根是两个概念。</p><h3 id="KeepAlive-常见错误"><a href="#KeepAlive-常见错误" class="headerlink" title="KeepAlive 常见错误"></a>KeepAlive 常见错误</h3><p>启用 TCP KeepAlive 的应用程序，一般可以捕获到下面几种类型错误</p><ol><li><p>ETIMEOUT 超时错误，在发送一个探测保护包经过 (tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes)时间后仍然没有接收到 ACK 确认情况下触发的异常，套接字被关闭</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: Connection timed out</span><br></pre></td></tr></table></figure></li><li><p>EHOSTUNREACH host unreachable(主机不可达)错误，这个应该是 ICMP 汇报给上层应用的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: No route to host</span><br></pre></td></tr></table></figure></li><li><p>链接被重置，终端可能崩溃死机重启之后，接收到来自服务器的报文，然物是人非，前朝往事，只能报以无奈重置宣告之。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: Connection reset by peer</span><br></pre></td></tr></table></figure></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>有三种使用 KeepAlive 的实践方案：</p><ol><li>默认情况下使用 KeepAlive 周期为 2 个小时，如不选择更改，属于误用范畴，造成资源浪费：内核会为每一个连接都打开一个保活计时器，N 个连接会打开 N 个保活计时器。 优势很明显：<ul><li>TCP 协议层面保活探测机制，系统内核完全替上层应用自动给做好了</li><li>内核层面计时器相比上层应用，更为高效</li><li>上层应用只需要处理数据收发、连接异常通知即可</li><li>数据包将更为紧凑</li></ul></li><li>关闭 TCP 的 KeepAlive，完全使用应用层心跳保活机制。由应用掌管心跳，更灵活可控，比如可以在应用级别设置心跳周期，适配私有协议。</li><li>业务心跳 + TCP KeepAlive 一起使用，互相作为补充，但 TCP 保活探测周期和应用的心跳周期要协调，以互补方可，不能够差距过大，否则将达不到设想的效果。</li></ol><p>各个框架的设计都有所不同，例如 Dubbo 使用的是方案三，但阿里内部的 HSF 框架则没有设置 TCP 的 KeepAlive，仅仅由应用心跳保活。和心跳策略一样，这和框架整体的设计相关。</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;可能很多 Java 程序员对 TCP 的理解只有一个三次握手，四次握手的认识，我觉得这样的原因主要在于 TCP 协议本身稍微有点抽象（相比较于应用层的 HTTP 协议）；其次，非框架开发者不太需要接触到 TCP 的一些细节。其实我个人对 TCP 的很多细节也并没有完全理解，这篇文章主要针对微信交流群里有人提出的长连接，心跳问题，做一个统一的整理。 &lt;/p&gt;
&lt;p&gt;在 Java 中，使用 TCP 通信，大概率会涉及到 Socket、Netty，本文将借用它们的一些 API 和设置参数来辅助介绍。&lt;/p&gt;
    
    </summary>
    
      <category term="RPC" scheme="http://lexburner.github.io/categories/RPC/"/>
    
    
      <category term="TCP" scheme="http://lexburner.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo 中的 URL 统一模型</title>
    <link href="http://lexburner.github.io/dubbo-url/"/>
    <id>http://lexburner.github.io/dubbo-url/</id>
    <published>2018-12-25T02:24:09.000Z</published>
    <updated>2018-12-26T12:37:38.729Z</updated>
    
    <content type="html"><![CDATA[<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>在不谈及 dubbo 时，我们大多数人对 URL 这个概念并不会感到陌生。统一资源定位器 (<a href="https://kimnote.com/rfc/cn/rfc1738.txt" target="_blank" rel="noopener">RFC1738</a>――Uniform Resource Locators (URL)）应该是最广为人知的一个 RFC 规范，它的定义也非常简单</p><blockquote><p>因特网上的可用资源可以用简单字符串来表示，该文档就是描述了这种字符串的语法和语<br>义。而这些字符串则被称为：“统一资源定位器”（URL）</p></blockquote><p><strong>一个标准的 URL 格式</strong>至多可以包含如下的几个部分</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protocol://username:password@host:port/path?key=value&amp;key=value</span><br></pre></td></tr></table></figure><a id="more"></a><p><strong>一些典型 URL</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http://www.facebook.com/friends?param1=value1&amp;amp;param2=value2</span><br><span class="line">https://username:password@10.20.130.230:8080/list?version=1.0.0</span><br><span class="line">ftp://username:password@192.168.1.7:21/1/read.txt</span><br></pre></td></tr></table></figure><p>当然，也有一些<strong>不太符合常规的 URL</strong>，也被归类到了 URL 之中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.3:20880</span><br><span class="line">url protocol = null, url host = 192.168.1.3, port = 20880, url path = null</span><br><span class="line"></span><br><span class="line">file:///home/user1/router.js?type=script</span><br><span class="line">url protocol = file, url host = null, url path = home/user1/router.js</span><br><span class="line"></span><br><span class="line">file://home/user1/router.js?type=script&lt;br&gt;</span><br><span class="line">url protocol = file, url host = home, url path = user1/router.js</span><br><span class="line"></span><br><span class="line">file:///D:/1/router.js?type=script</span><br><span class="line">url protocol = file, url host = null, url path = D:/1/router.js</span><br><span class="line"></span><br><span class="line">file:/D:/1/router.js?type=script</span><br><span class="line">同上 file:///D:/1/router.js?type=script</span><br><span class="line"></span><br><span class="line">/home/user1/router.js?type=script</span><br><span class="line">url protocol = null, url host = null, url path = home/user1/router.js</span><br><span class="line"></span><br><span class="line">home/user1/router.js?type=script</span><br><span class="line">url protocol = null, url host = home, url path = user1/router.js</span><br></pre></td></tr></table></figure><h3 id="Dubbo-中的-URL"><a href="#Dubbo-中的-URL" class="headerlink" title="Dubbo 中的 URL"></a>Dubbo 中的 URL</h3><p>在 dubbo 中，也使用了类似的 URL，主要用于在各个扩展点之间传递数据，组成此 URL 对象的具体参数如下:</p><ul><li>protocol：一般是 dubbo 中的各种协议 如：dubbo thrift http zk </li><li>username/password：用户名/密码</li><li>host/port：主机/端口</li><li>path：接口名称</li><li>parameters：参数键值对</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">URL</span><span class="params">(String protocol, String username, String password, String host, <span class="keyword">int</span> port, String path, Map&lt;String, String&gt; parameters)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> ((username == <span class="keyword">null</span> || username.length() == <span class="number">0</span>) </span><br><span class="line">         &amp;&amp; password != <span class="keyword">null</span> &amp;&amp; password.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid url, password without username!"</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">this</span>.protocol = protocol;</span><br><span class="line">   <span class="keyword">this</span>.username = username;</span><br><span class="line">   <span class="keyword">this</span>.password = password;</span><br><span class="line">   <span class="keyword">this</span>.host = host;</span><br><span class="line">   <span class="keyword">this</span>.port = (port &lt; <span class="number">0</span> ? <span class="number">0</span> : port);</span><br><span class="line">   <span class="keyword">this</span>.path = path;</span><br><span class="line">   <span class="comment">// trim the beginning "/"</span></span><br><span class="line">   <span class="keyword">while</span>(path != <span class="keyword">null</span> &amp;&amp; path.startsWith(<span class="string">"/"</span>)) &#123;</span><br><span class="line">       path = path.substring(<span class="number">1</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (parameters == <span class="keyword">null</span>) &#123;</span><br><span class="line">       parameters = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       parameters = <span class="keyword">new</span> HashMap&lt;String, String&gt;(parameters);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">this</span>.parameters = Collections.unmodifiableMap(parameters);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出，dubbo 认为 protocol，username，passwored，host，port，path 是主要的 URL 参数，其他键值对村房子啊 parameters 之中。</p><p><strong>一些典型的 Dubbo URL</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dubbo://192.168.1.6:20880/moe.cnkirito.sample.HelloService?timeout=3000</span><br><span class="line">描述一个 dubbo 协议的服务</span><br><span class="line"></span><br><span class="line">zookeeper://127.0.0.1:2181/org.apache.dubbo.registry.RegistryService?application=demo-consumer&amp;dubbo=2.0.2&amp;interface=org.apache.dubbo.registry.RegistryService&amp;pid=1214&amp;qos.port=33333&amp;timestamp=1545721981946</span><br><span class="line">描述一个 zookeeper 注册中心</span><br><span class="line"></span><br><span class="line">consumer://30.5.120.217/org.apache.dubbo.demo.DemoService?application=demo-consumer&amp;category=consumers&amp;check=false&amp;dubbo=2.0.2&amp;interface=org.apache.dubbo.demo.DemoService&amp;methods=sayHello&amp;pid=1209&amp;qos.port=33333&amp;side=consumer&amp;timestamp=1545721827784</span><br><span class="line">描述一个消费者</span><br></pre></td></tr></table></figure><p>可以说，任意的一个领域中的一个实现都可以认为是一类 URL，dubbo 使用 URL 来统一描述了元数据，配置信息，贯穿在整个框架之中。</p><h3 id="URL-相关的生命周期"><a href="#URL-相关的生命周期" class="headerlink" title="URL 相关的生命周期"></a>URL 相关的生命周期</h3><h4 id="解析服务"><a href="#解析服务" class="headerlink" title="解析服务"></a>解析服务</h4><p>基于 dubbo.jar 内的 <code>META-INF/spring.handlers</code> 配置，Spring 在遇到 dubbo 名称空间时，会回调 <code>DubboNamespaceHandler</code>。</p><p>所有 dubbo 的标签，都统一用 <code>DubboBeanDefinitionParser</code> 进行解析，基于一对一属性映射，将 XML 标签解析为 Bean 对象。</p><p>在 <code>ServiceConfig.export()</code> 或 <code>ReferenceConfig.get()</code> 初始化时，将 Bean 对象转换 URL 格式，所有 Bean 属性转成 URL 的参数。</p><p>然后将 URL 传给协议扩展点，基于扩展点自适应机制，根据 URL 的协议头，进行不同协议的服务暴露或引用。</p><h4 id="暴露服务"><a href="#暴露服务" class="headerlink" title="暴露服务"></a>暴露服务</h4><p><strong>1. 只暴露服务端口：</strong></p><p>在没有注册中心，直接暴露提供者的情况下，<code>ServiceConfig</code> 解析出的 URL 的格式为：<code>dubbo://service-host/com.foo.FooService?version=1.0.0</code>。</p><p>基于扩展点自适应机制，通过 URL 的 <code>dubbo://</code> 协议头识别，直接调用 <code>DubboProtocol</code>的 <code>export()</code> 方法，打开服务端口。</p><p><strong>2. 向注册中心暴露服务：</strong></p><p>在有注册中心，需要注册提供者地址的情况下，<code>ServiceConfig</code> 解析出的 URL 的格式为: <code>registry://registry-host/org.apache.dubbo.registry.RegistryService?export=URL.encode(&quot;dubbo://service-host/com.foo.FooService?version=1.0.0&quot;)</code>，</p><p>基于扩展点自适应机制，通过 URL 的 <code>registry://</code> 协议头识别，就会调用 <code>RegistryProtocol</code> 的 <code>export()</code> 方法，将 <code>export</code> 参数中的提供者 URL，先注册到注册中心。</p><p>再重新传给 <code>Protocol</code> 扩展点进行暴露： <code>dubbo://service-host/com.foo.FooService?version=1.0.0</code>，然后基于扩展点自适应机制，通过提供者 URL 的 <code>dubbo://</code> 协议头识别，就会调用 <code>DubboProtocol</code> 的 <code>export()</code> 方法，打开服务端口。</p><h4 id="引用服务"><a href="#引用服务" class="headerlink" title="引用服务"></a>引用服务</h4><p><strong>1. 直连引用服务：</strong></p><p>在没有注册中心，直连提供者的情况下，<code>ReferenceConfig</code> 解析出的 URL 的格式为：<code>dubbo://service-host/com.foo.FooService?version=1.0.0</code>。</p><p>基于扩展点自适应机制，通过 URL 的 <code>dubbo://</code> 协议头识别，直接调用 <code>DubboProtocol</code> 的 <code>refer()</code> 方法，返回提供者引用。</p><p><strong>2. 从注册中心发现引用服务：</strong></p><p>在有注册中心，通过注册中心发现提供者地址的情况下，<code>ReferenceConfig</code> 解析出的 URL 的格式为：<code>registry://registry-host/org.apache.dubbo.registry.RegistryService?refer=URL.encode(&quot;consumer://consumer-host/com.foo.FooService?version=1.0.0&quot;)</code>。</p><p>基于扩展点自适应机制，通过 URL 的 <code>registry://</code> 协议头识别，就会调用 <code>RegistryProtocol</code> 的 <code>refer()</code> 方法，基于 <code>refer</code> 参数中的条件，查询提供者 URL，如： <code>dubbo://service-host/com.foo.FooService?version=1.0.0</code>。</p><p>基于扩展点自适应机制，通过提供者 URL 的 <code>dubbo://</code> 协议头识别，就会调用 <code>DubboProtocol</code> 的 <code>refer()</code> 方法，得到提供者引用。</p><p>然后 <code>RegistryProtocol</code> 将多个提供者引用，通过 <code>Cluster</code> 扩展点，伪装成单个提供者引用返回。</p><h3 id="URL-统一模型的意义"><a href="#URL-统一模型的意义" class="headerlink" title="URL 统一模型的意义"></a>URL 统一模型的意义</h3><p>对于 dubbo 中的 URL，有人理解为配置总线，有人理解为统一配置模型，说法虽然不同，但都是在表达一个意思，这样的 URL 在 dubbo 中被当做是<a href="http://dubbo.incubator.apache.org/zh-cn/docs/dev/contract.html" target="_blank" rel="noopener">公共契约</a>，所有扩展点参数都包含 URL 参数，URL 作为上下文信息贯穿整个扩展点设计体系。</p><p>在没有 URL 之前，只能以字符串传递参数，不停的解析和拼装，导致相同类型的接口，参数时而 Map, 时而 Parameters 类包装：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export(String url) </span><br><span class="line">createExporter(String host, <span class="keyword">int</span> port, Parameters params)</span><br></pre></td></tr></table></figure><p>使用 URL 一致性模型：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export(URL url) </span><br><span class="line">createExporter(URL url)</span><br></pre></td></tr></table></figure><p>在最新的 dubbo 代码中，我们可以看到大量使用 URL 来进行上下文之间信息的传递，这样的好处是显而易见的：</p><ol><li>使得代码编写者和阅读者能够将一系列的参数联系起来，进而形成规范，使得代码易写，易读。</li><li>可扩展性强，URL 相当于参数的集合(相当于一个 Map)，他所表达的含义比单个参数更丰富，当我们在扩展代码时，可以将新的参数追加到 URL 之中，而不需要改变入参，返参的结构。</li><li>统一模型，它位于 org.apache.dubbo.common 包中，各个扩展模块都可以使用它作为参数的表达形式，简化了概念，降低了代码的理解成本。</li></ol><p>如果你能够理解 final 契约和 restful 契约，那我相信你会很好地理解 URL 契约。契约的好处我还是啰嗦一句：大家都这么做，就形成了默契，沟通是一件很麻烦的事，统一 URL 模型可以省去很多沟通成本，这边是 URL 统一模型存在的意义。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;定义&quot;&gt;&lt;a href=&quot;#定义&quot; class=&quot;headerlink&quot; title=&quot;定义&quot;&gt;&lt;/a&gt;定义&lt;/h3&gt;&lt;p&gt;在不谈及 dubbo 时，我们大多数人对 URL 这个概念并不会感到陌生。统一资源定位器 (&lt;a href=&quot;https://kimnote.com/rfc/cn/rfc1738.txt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RFC1738&lt;/a&gt;――Uniform Resource Locators (URL)）应该是最广为人知的一个 RFC 规范，它的定义也非常简单&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;因特网上的可用资源可以用简单字符串来表示，该文档就是描述了这种字符串的语法和语&lt;br&gt;义。而这些字符串则被称为：“统一资源定位器”（URL）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;一个标准的 URL 格式&lt;/strong&gt;至多可以包含如下的几个部分&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;protocol://username:password@host:port/path?key=value&amp;amp;key=value&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="RPC" scheme="http://lexburner.github.io/categories/RPC/"/>
    
    
      <category term="DUBBO" scheme="http://lexburner.github.io/tags/DUBBO/"/>
    
  </entry>
  
  <entry>
    <title>PolarDB数据库性能大赛Java选手分享</title>
    <link href="http://lexburner.github.io/polardb-race/"/>
    <id>http://lexburner.github.io/polardb-race/</id>
    <published>2018-12-10T10:43:56.000Z</published>
    <updated>2019-01-07T02:32:36.746Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h3><p><img src="http://kirito.iocoder.cn/image-20181210184521001.png" alt="排名"></p><p>国际惯例，先报成绩，熬了无数个夜晚，最后依旧被绝杀出了第一页，最终排名第 21 名。前十名的成绩分布为 413.69~416.94，我最终的耗时是 422.43。成绩虽然不是特别亮眼，但与众多参赛选手使用 C++ 作为参赛语言不同，我使用的是 Java，一方面是我 C++ 的能力早已荒废，另一方面是我想验证一下使用 Java 编写存储引擎是否与 C++ 差距巨大(当然，主要还是前者 QAQ)。所以在本文中，我除了介绍整体的架构之外，还会着重笔墨来探讨 Java 编写存储类型应用的一些最佳实践，文末会给出 github 的开源地址。</p><a id="more"></a><h3 id="2-赛题概览"><a href="#2-赛题概览" class="headerlink" title="2 赛题概览"></a>2 赛题概览</h3><p>比赛总体分成了初赛和复赛两个阶段，整体要求实现一个简化、高效的 kv 存储引擎</p><p>初赛要求支持 Write、Read 接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value)</span></span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">byte</span>[] read(<span class="keyword">byte</span>[] key);</span><br></pre></td></tr></table></figure><p>复赛在初赛题目基础上，还需要额外实现一个 Range 接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">range</span><span class="params">(<span class="keyword">byte</span>[] lower, <span class="keyword">byte</span>[] upper, AbstractVisitor visitor)</span></span>;</span><br></pre></td></tr></table></figure><p>程序评测逻辑 分为2个阶段：<br>1）Recover 正确性评测：<br>此阶段评测程序会并发写入特定数据（key 8B、value 4KB）同时进行任意次 kill -9 来模拟进程意外退出（参赛引擎需要保证进程意外退出时数据持久化不丢失），接着重新打开 DB，调用 Read、Range 接口来进行正确性校验</p><p>2）性能评测</p><ul><li>随机写入：64 个线程并发随机写入，每个线程使用 Write 各写 100 万次随机数据（key 8B、value 4KB）</li><li>随机读取：64 个线程并发随机读取，每个线程各使用 Read 读取 100 万次随机数据</li><li>顺序读取：64 个线程并发顺序读取，每个线程各使用 Range 有序（增序）遍历全量数据 2 次<br>注：<br>2.2 阶段会对所有读取的 kv 校验是否匹配，如不通过则终止，评测失败；<br>2.3 阶段除了对迭代出来每条的 kv校 验是否匹配外，还会额外校验是否严格字典序递增，如不通过则终止，评测失败。</li></ul><p>语言限定：C++ &amp; JAVA，一起排名</p><h3 id="3-赛题剖析"><a href="#3-赛题剖析" class="headerlink" title="3 赛题剖析"></a>3 赛题剖析</h3><p>关于文件 IO 操作的一些基本常识，我已经在专题文章中进行了介绍，如果你没有浏览那篇文章，建议先行浏览一下：<a href="https://www.cnkirito.moe/file-io-best-practise/" target="_blank" rel="noopener">文件IO操作的一些最佳实践</a>。再回归赛题，先对赛题中的几个关键词来进行解读。</p><h4 id="3-1-key-8B-value-4kb"><a href="#3-1-key-8B-value-4kb" class="headerlink" title="3.1 key 8B, value 4kb"></a>3.1 key 8B, value 4kb</h4><p>key 为固定的 8 字节，因此可使用 long 来表示。</p><p>value 为 4kb，这节省了我们很大的工作量，因为 4kb 的整数倍落盘是非常磁盘 IO 友好的。</p><p>value 为 4kb 的另一个好处是我们再内存做索引时，可以使用 int 而不是 long，来记录数据的逻辑偏移量：LogicOffset = PhysicalOffset / 4096，可以将 offset 的内存占用量减少一半。</p><h4 id="3-2-kill-9-数据不丢失"><a href="#3-2-kill-9-数据不丢失" class="headerlink" title="3.2 kill -9 数据不丢失"></a>3.2 kill -9 数据不丢失</h4><p>首先赛题明确表示会进行 kill -9 并验证数据的一致性，这加大了我们在内存中做 write buffer 的难度。但它并没有要求断电不丢失，这间接地阐释了一点：我们可以使用 pageCache 来做写入缓存，在具体代码中我使用了 PageCache 来充当数据和索引的写入缓冲（两者策略不同）。同时这点也限制了参赛选手，不能使用 AIO 这样的异步落盘方式。</p><h4 id="3-3-分阶段测评"><a href="#3-3-分阶段测评" class="headerlink" title="3.3 分阶段测评"></a>3.3 分阶段测评</h4><p>赛题分为了随机写，随机读，顺序读三个阶段，每个阶段都会重新 open，且不会发生随机写到一半校验随机读这样的行为，所以我们在随机写阶段不需要在内存维护索引，而是直接落盘。随机读和顺序读阶段，磁盘均存在数据，open 阶段需要恢复索引，可以使用多线程并发恢复。</p><p><strong>同时，赛题还有存在一些隐性的测评细节没有披露给大家，但通过测试，我们可以得知这些信息。</strong></p><h4 id="3-4-清空-PageCache-的耗时"><a href="#3-4-清空-PageCache-的耗时" class="headerlink" title="3.4 清空 PageCache 的耗时"></a>3.4 清空 PageCache 的耗时</h4><p>虽然我们可以使用 PageCache，但评测程序在每个阶段之后都使用脚本清空了 PageCache，并且将这部分时间也算进了最终的成绩之中，所以有人感到奇怪：三个阶段的耗时相加比输出出来的成绩要差，其实那几秒便是清空 PageCache 的耗时。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>清理 pagecache (页缓存)</span><br><span class="line">sysctl -w vm.drop_caches=1</span><br><span class="line"><span class="meta">#</span>清理 dentries（目录缓存）和 inodes</span><br><span class="line">sysctl -w vm.drop_caches=2</span><br><span class="line"><span class="meta">#</span>清理pagecache、dentries和inodes</span><br><span class="line">sysctl -w vm.drop_caches=3</span><br></pre></td></tr></table></figure><p>这一点启发我们，不能毫无节制的使用 PageCache，也正是因为这一点，一定程度上使得 Direct IO 这一操作成了本次竞赛的银弹。</p><h4 id="3-5-key-的分布"><a href="#3-5-key-的分布" class="headerlink" title="3.5 key 的分布"></a>3.5 key 的分布</h4><p>这一个隐性条件可谓是本次比赛的关键，因为它涉及到 Range 部分的架构设计。本次比赛的 key 共计 6400w，但是他们的分布都是<strong>均匀</strong>的，在<a href="https://www.cnkirito.moe/file-io-best-practise/" target="_blank" rel="noopener">《文件IO操作的一些最佳实践》</a> 一文中我们已经提到了数据分区的好处，可以大大减少顺序读写的锁冲突，而 key 的分布均匀这一特性，启发我们在做数据分区时，可以按照 key 的搞 n 位来做 hash，从而确保 key 两个分区之间整体有序(分区内部无序)。实际我尝试了将数据分成 1024、2048 个分区，效果最佳。</p><h4 id="3-6-Range-的缓存设计"><a href="#3-6-Range-的缓存设计" class="headerlink" title="3.6 Range 的缓存设计"></a>3.6 Range 的缓存设计</h4><p>赛题要求 64 个线程 Range 两次全量的数据，限时 1h，这也启发了我们，如果不对数据进行缓存，想要在 1h 内完成比赛是不可能的，所以，我们的架构设计应该尽量以 Range 为核心，兼顾随机写和随机读。Range 部分也是最容易拉开差距的一个环节。</p><h3 id="4-架构详解"><a href="#4-架构详解" class="headerlink" title="4 架构详解"></a>4 架构详解</h3><p>首先需要明确的是，随机写指的是 key 的写入是随机的，但我们可以根据 key hash，将随机写转换为对应分区文件的顺序写。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * using high ten bit of the given key to determine which file it hits.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HighTenPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitionable</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(<span class="keyword">byte</span>[] key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ((key[<span class="number">0</span>] &amp; <span class="number">0xff</span>) &lt;&lt; <span class="number">2</span>) | ((key[<span class="number">1</span>] &amp; <span class="number">0xff</span>) &gt;&gt; <span class="number">6</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>明确了高位分区的前提再来看整体的架构就变得明朗了</p><p><strong>全局视角</strong></p><p><img src="http://kirito.iocoder.cn/KiritoDB.png" alt="全局视角"></p><p><strong>分区视角</strong></p><p><img src="http://kirito.iocoder.cn/image-20181210204156199.png" alt="分区视角"></p><p><strong>内存视角</strong></p><p>内存中仅仅维护有序的 <code>key[1024][625000]</code> 数组和 <code>offset[1024][625000]</code> 数组。</p><p>上述两张图对整体的架构进行了一个很好的诠释，利用数据分布均匀的特性，可以将全局数据 hash 成 1024 个分区，在每个分区中存放两类文件：索引文件和数据文件。在随机写入阶段，根据 key 获得该数据对应分区位置，并按照时序，顺序追加到文件末尾，将全局随机写转换为局部顺序写。利用索引和数据一一对应的特性，我们也不需要将 data 的逻辑偏移量落盘，在 recover 阶段可以按照恢复 key 的次序，反推出 value 的逻辑偏移量。</p><p>在 range 阶段，由于我们事先按照 key 的高 10 为做了分区，所以我们可以认定一个事实，patition(N) 中的任何一个数据一定大于 partition(N-1) 中的任何一个数据，于是我们可以采用大块读，将一个 partition 整体读进内存，供 64 个 visit 线程消费。到这儿便奠定了整体的基调：读盘线程负责按分区读盘进入内存，64 个 visit 线程负责消费内存，按照 key 的次序随机访问内存，进行 Visitor 的回调。</p><h3 id="5-随机写流程"><a href="#5-随机写流程" class="headerlink" title="5 随机写流程"></a>5 随机写流程</h3><p>介绍完了整体架构，我们分阶段来看一下各个阶段的一些细节优化点，有一些优化在各个环节都会出现，未避免重复，第二次出现的同一优化点我就不赘述了，仅一句带过。</p><h4 id="使用-pageCache-实现写入缓冲区"><a href="#使用-pageCache-实现写入缓冲区" class="headerlink" title="使用 pageCache 实现写入缓冲区"></a>使用 pageCache 实现写入缓冲区</h4><p>主要看数据落盘，后讨论索引落盘。磁盘 IO 类型的比赛，第一步便是测量磁盘的 IOPS 以及多少个线程一次读写多大的缓存能够打满 IO，在固定 64 线程写入的前提下，16kb，64kb 均可以达到最理想 IOPS，所以理所当然的想到，可以为每一个分区分配一个写入缓存，凑齐 4 个 value 落盘。但是此次比赛，要做到 kill -9 不丢失数据，不能简单地在内存中分配一个 <code>ByteBuffer.allocate(4096 * 4);</code>， 而是可以考虑使用 mmap 内存映射出一片写入缓冲，凑齐 4 个刷盘，这样在 kill -9 之后，PageCache 不会丢失。实测 16kb 落盘比 4kb 落盘要快 6s 左右。</p><p>索引文件的落盘则没有太大的争议，由于 key 的数据量为固定的 8B，所以 mmap 可以发挥出它写小数据的优势，将 pageCache 利用起来，实测 mmap 相比 filechannel 写索引要快 3s 左右，相信如果把 polardb 这块盘换做其他普通的 ssd，这个数值还要增加。</p><h4 id="写入时不维护内存索引，不写入数据偏移"><a href="#写入时不维护内存索引，不写入数据偏移" class="headerlink" title="写入时不维护内存索引，不写入数据偏移"></a>写入时不维护内存索引，不写入数据偏移</h4><p>一开始审题不清，在随机写之后误以为会立刻随机读，实际上每个阶段都是独立的，所以不需要在写入时维护内存索引；其次，之前的架构图中也已经提及，不需要写入连带 key+offset 一起写入文件，recover 阶段可以按照恢复索引的顺序，反推出 data 的逻辑偏移，因为我们的 key 和 data 在同一个分区内的位置是一一对应的。</p><h3 id="6-恢复流程"><a href="#6-恢复流程" class="headerlink" title="6 恢复流程"></a>6 恢复流程</h3><p>recover 阶段的逻辑实际上包含在程序的 open 接口之中，我们需要再数据库引擎启动时，将索引从数据文件恢复到内存之中，在这之中也存在一些细节优化点。</p><p>由于 1024 个分区的存在，我们可以使用 64 个线程 (经验值) 并发地恢复索引，使用快速排序对 <code>key[1024][625000]</code> 数组和 <code>offset[1024][625000]</code> 进行 sort，之后再 compact，对 key 进行去重。需要注意的一点是，不要使用结构体，将 key 和 offset 封装在一起，这会使得排序和之后的二分效率非常低，这之中涉及到 CPU 缓存行的知识点，不了解的读者可以翻阅我之前的博客: <a href="https://www.cnkirito.moe/cache-line/" target="_blank" rel="noopener">《CPU Cache 与缓存行》</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// wrong</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KeyOffset</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> key;</span><br><span class="line">    <span class="keyword">int</span> offset;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整个 recover 阶段耗时为 1s，跟 cpp 选手交流后发现恢复流程比之慢了 600ms，这中间让我觉得比较诡异，加载索引和排序不应该这么慢才对，最终也没有优化成功。</p><h3 id="7-随机读流程"><a href="#7-随机读流程" class="headerlink" title="7 随机读流程"></a>7 随机读流程</h3><p>随机读流程没有太大的优化点，优化空间实在有限，实现思路便是先根据 key 定位到分区，之后在有序的 key 数据中二分查找到 key/offset，拿到 data 的逻辑偏移和分区编号，便可以愉快的随机读了，随机读阶段没有太大的优化点，但仍然比 cpp 选手慢了 2-3s，可能是语言无法越过的差距。</p><h3 id="8-顺序读流程"><a href="#8-顺序读流程" class="headerlink" title="8 顺序读流程"></a>8 顺序读流程</h3><p>Range 环节是整个比赛的大头，也是拉开差距的分水岭。前面我们已经大概提到了 Range 的整体思路是一个生产者消费者模型，n 个生成者负责从磁盘读数据进入内存（n 作为变量，通过 benchmark 来确定多少合适，最终实测 n 为 4 时效果最佳），64 个消费者负责调用 visit 回调，来验证数据，visit 过程就是随机读内存的过程。在 Range 阶段，剩余的内存还有大概 1G 左右，所以我分配了 4 个堆外缓冲，一个 256M，从而可以缓存 4 个分区的数据，并且，我为每一个分区分配了一个读盘线程，负责 load 数据进入缓存，供 64 个消费者消费。</p><p>具体的顺序读架构可以参见下图：</p><p><img src="http://kirito.iocoder.cn/image-20181210215200345.png" alt="range"></p><p>大体来看，便是 4 个 fetch 线程负责读盘，fetch thread n 负责 <code>partitionNo % 4 == n</code> 编号的分区，完成后通知 visit 消费。这中间充斥着比较多的互斥等待逻辑，并未在图中体现出来，大体如下：</p><ol><li>fetch thread 1~4 加载磁盘数据进入缓存是并发的</li><li>visit group 1~64 访问同一个 buffer 是并发的</li><li>visit group 1~64 访问不同 partition 对应的 buffer 是按照次序来进行的(打到全局有序)</li><li>加载 partitonN 会阻塞 visit bufferN，visit bufferN 会阻塞加载 partitionN+4(相当于复用4块缓存)</li></ol><p>大块的加载读进缓存，最大程度复用，是 ReadSeq 部分的关键。顺序读两轮的成绩在 196~198s 左右，相比 C++ 又慢了 4s 左右。</p><h3 id="9-魔鬼在细节中"><a href="#9-魔鬼在细节中" class="headerlink" title="9 魔鬼在细节中"></a>9 魔鬼在细节中</h3><p>这儿是个分水岭，介绍完了整体架构和四个阶段的细节实现，下面就是介绍下具体的优化点了。</p><h3 id="10-Java-实现-Direct-IO"><a href="#10-Java-实现-Direct-IO" class="headerlink" title="10 Java 实现 Direct IO"></a>10 Java 实现 Direct IO</h3><p>由于这次比赛将 drop cache 的时间算进了测评程序之中，所以在不必要的地方应当尽量避免 pageCache，也就是说除了写索引之外，其他阶段不应该出现 pageCache。这对于 Java 选手来说可能是不小的障碍，因为 Java 原生没有提供 Direct IO，需要自己封装一套 JNA 接口，封装这套接口借鉴了开源框架 jaydio 的思路，感谢@尘央的协助，大家可以在文末的代码中看到实现细节。这一点可以说是拦住了一大票 Java 选手。</p><p>Direct IO 需要注意的两个细节：</p><ol><li>分配的内存需要对齐，对应 jna 方法：posix_memalign</li><li>写入的数据需要对齐通常是 pageSize 的整数倍，实际使用了 pread 的 O_DIRECT</li></ol><h3 id="11-直接内存优于堆内内存"><a href="#11-直接内存优于堆内内存" class="headerlink" title="11 直接内存优于堆内内存"></a>11 直接内存优于堆内内存</h3><p>这一点在《文件IO操作的一些最佳实践》中有所提及，堆外内存的两大好处是减少了一份内存拷贝，并且对 gc 友好，在 Direct IO 的实现中，应该配备一套堆外内存的接口，才能发挥出最大的功效。尤其在 Range 阶段，一个缓存区的大小便对应一个 partition 数据分区的大小：256M，大块的内存，更加适合用 DirectByteBuffer 装载。</p><h3 id="12-JVM-调优"><a href="#12-JVM-调优" class="headerlink" title="12 JVM 调优"></a>12 JVM 调优</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-server -Xms2560m -Xmx2560m -XX:MaxDirectMemorySize=1024m -XX:NewRatio=4 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:-UseBiasedLocking</span><br></pre></td></tr></table></figure><p>众所周知 newRatio 控制的是 young 区和 old 区大小的比例，官方推荐参数为  <code>-XX:NewRatio=1</code>，很多不注意的 Java 选手可能没有意识去修改它，会在无形中被 gc 拖累。经过和@阿杜的讨论，最终得出的结论：</p><ol><li>young 区过大，对象在年轻代待得太久，多次拷贝</li><li>old 区过小，会频繁触发 old 区的 cms gc</li></ol><p>在比赛中这显得尤为重要，<code>-XX:NewRatio=4</code> 放大老年代可以有效的减少 cms gc 的次数，将 126 次 cms gc，下降到最终的 5 次。</p><h3 id="13-池化对象"><a href="#13-池化对象" class="headerlink" title="13 池化对象"></a>13 池化对象</h3><p>无论是 apache 的 ObjectPool 还是 Netty 中的 Recycler，还是 RingBuffer 中预先分配的对象，都在传达一种思想，对于那些反复需要 new 出来的东西，都可以池化，分配内存再回收，这也是一笔不小的开销。在此次比赛的场景下，没必要大费周章地动用对象池，直接一个 ThreadLocal 即可搞定，事实上我对 key/value 的写入和读取都进行了 ThreadLocal 的缓存，做到了永远不再循环中分配对象。</p><h3 id="14-减少线程切换"><a href="#14-减少线程切换" class="headerlink" title="14 减少线程切换"></a>14 减少线程切换</h3><p>无论是网络 IO 还是磁盘 IO，io worker 线程的时间片都显得尤为的可贵，在我的架构中，range 阶段主要分为了两类线程：64 个 visit 线程并发随机读内存，4 个 io 线程并发读磁盘。木桶效应，我们很容易定位到瓶颈在于 4 个 io 线程，在 wait/notify 的模型中，为了尽可能的减少 io 线程的时间片流失，可以考虑使用 while(true) 进行轮询，而 visit 线程则可以 sleep(1us) 避免 cpu 空转带来的整体性能下降，由于评测机拥有 64 core，所以这样的分配算是较为合理的，为此我实现了一个简单粗暴的信号量。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoopQuerySemaphore</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> permit;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LoopQuerySemaphore</span><span class="params">(<span class="keyword">boolean</span> permit)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.permit = permit;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// for 64 visit thread</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">acquire</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (!permit) &#123;</span><br><span class="line">            Thread.sleep(<span class="number">0</span>,<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        permit = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// for 4 fetch thread</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">acquireNoSleep</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (!permit) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        permit = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        permit = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>正确的在 IO 中 acquireNoSleep，在 Visit 中 acquire，可以让成绩相比使用普通的阻塞 Semaphore 提升 6s 左右。</p><h3 id="15-绑核"><a href="#15-绑核" class="headerlink" title="15 绑核"></a>15 绑核</h3><p>线上机器的抖动在所难免，避免 IO 线程的切换也并不仅仅能够用依靠 while(true) 的轮询，一个 CPU 级别的优化便是腾出 4 个核心专门给 IO 线程使用，完全地避免 IO 线程的时间片争用。在 Java 中这也不难实现，依赖万能的 github，我们可以轻松地实现 Affinity。github 传送门：<a href="https://github.com/OpenHFT/Java-Thread-Affinity" target="_blank" rel="noopener">https://github.com/OpenHFT/Java-Thread-Affinity</a></p><p>使用方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="keyword">final</span> AffinityLock al2 = AffinityLock.acquireLock()) &#123;</span><br><span class="line">    <span class="comment">// do fetch ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方式可以让你的代码快 1~2 s，并且保持测评的稳定性。</p><h3 id="0-聊聊-FileChannel，MMAP，Direct-IO，聊聊比赛"><a href="#0-聊聊-FileChannel，MMAP，Direct-IO，聊聊比赛" class="headerlink" title="0 聊聊 FileChannel，MMAP，Direct IO，聊聊比赛"></a>0 聊聊 FileChannel，MMAP，Direct IO，聊聊比赛</h3><p>我在最终版本的代码中，几乎完全抛弃了 FileChannel，事实上，在不 Drop Cache 的场景下，它已经可以发挥出它利用 PageCache 的一些优势，并且优秀的 Java 存储引擎都主要使用了 FileChannel 来进行读写，在少量的场景下，使用了 MMAP 作为辅助，毕竟，MMAP 在写小数据量文件时存在其价值。</p><p>另外需要注意的一点，在跟@96年的亚普长谈的一个夜晚，发现 FileChannel 中出人意料的一个实现，在分配对内内存时，它仍然会拷贝一份堆外内存，这对于实际使用 FileChannel 的场景需要额外注意，这部分意料之外分配的内存很容易导致线上的问题（实际上已经遇到了，和 glibc 的 malloc 相关，当 buffer 大于 128k 时，会使用 mmap 分配一块内存作为缓存）</p><p>说回 FileChannel，MMAP，最容易想到的是 RocketMQ 之中对两者灵活的运用，不知道在其他 Java 实现的存储引擎之中，是不是可以考虑使用 Direct IO 来提升存储引擎的性能呢？我们可以设想一下，利用有限并且少量的 PageCache 来保证一致性，在主流程中使用 Direct IO 配合顺序读写是不是一种可以配套使用的方案，不仅仅 PolarDB，算作是参加本次比赛给予我的一个启发。</p><p>虽然无缘决赛，但使用 Java 取得这样的成绩还算不是特别难过，在 6400w 数据随机写，随机读，顺序读的场景下，Java 可以做到仅仅相差 C++ 不到 10s 的 overhead，我倒是觉得完全是可以接受的，哈哈。还有一些小的优化点就不在此赘述了，欢迎留言与我交流优化点和比赛感悟。</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1 前言&quot;&gt;&lt;/a&gt;1 前言&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://kirito.iocoder.cn/image-20181210184521001.png&quot; alt=&quot;排名&quot;&gt;&lt;/p&gt;
&lt;p&gt;国际惯例，先报成绩，熬了无数个夜晚，最后依旧被绝杀出了第一页，最终排名第 21 名。前十名的成绩分布为 413.69~416.94，我最终的耗时是 422.43。成绩虽然不是特别亮眼，但与众多参赛选手使用 C++ 作为参赛语言不同，我使用的是 Java，一方面是我 C++ 的能力早已荒废，另一方面是我想验证一下使用 Java 编写存储引擎是否与 C++ 差距巨大(当然，主要还是前者 QAQ)。所以在本文中，我除了介绍整体的架构之外，还会着重笔墨来探讨 Java 编写存储类型应用的一些最佳实践，文末会给出 github 的开源地址。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://lexburner.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="PolarDB性能挑战赛" scheme="http://lexburner.github.io/tags/PolarDB%E6%80%A7%E8%83%BD%E6%8C%91%E6%88%98%E8%B5%9B/"/>
    
  </entry>
  
  <entry>
    <title>文件IO操作的一些最佳实践</title>
    <link href="http://lexburner.github.io/file-io-best-practise/"/>
    <id>http://lexburner.github.io/file-io-best-practise/</id>
    <published>2018-11-27T15:22:22.000Z</published>
    <updated>2019-01-07T02:32:28.140Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>已经过去的中间件性能挑战赛，和正在进行中的 <a href="https://tianchi.aliyun.com/programming/introduction.htm?spm=5176.11165320.5678.1.483b4682l8fBSf&amp;raceId=231689" target="_blank" rel="noopener">第一届 PolarDB 数据性能大赛</a> 都涉及到了文件操作，合理地设计架构以及正确地压榨机器的读写性能成了比赛中获取较好成绩的关键。正在参赛的我收到了几位公众号读者朋友的反馈，他们大多表达出了这样的烦恼：“对比赛很感兴趣，但不知道怎么入门”，“能跑出成绩，但相比前排的选手，成绩相差10倍有余”…为了能让更多的读者参与到之后相类似的比赛中来，我简单整理一些文件IO操作的最佳实践，而不涉及整体系统的架构设计，希望通过这篇文章的介绍，让你能够欢快地参与到之后类似的性能挑战赛之中来。</p><a id="more"></a><h3 id="知识点梳理"><a href="#知识点梳理" class="headerlink" title="知识点梳理"></a>知识点梳理</h3><p>本文主要关注的 Java 相关的文件操作，理解它们需要一些前置条件，比如 PageCache，Mmap(内存映射)，DirectByteBuffer(堆外缓存)，顺序读写，随机读写…不一定需要完全理解，但至少知道它们是个啥，因为本文将会主要围绕这些知识点来展开描述。</p><h3 id="初识-FileChannel-和-MMAP"><a href="#初识-FileChannel-和-MMAP" class="headerlink" title="初识 FileChannel 和 MMAP"></a>初识 FileChannel 和 MMAP</h3><p>首先，文件IO类型的比赛最重要的一点，就是选择好读写文件的方式，那 JAVA 中文件IO有多少种呢？原生的读写方式大概可以被分为三种：普通IO，FileChannel(文件通道)，MMAP(内存映射)。区分他们也很简单，例如 FileWriter,FileReader 存在于 java.io 包中，他们属于普通IO；FileChannel 存在于 java.nio 包中，属于 NIO 的一种，但是注意 NIO 并不一定意味着非阻塞，这里的 FileChannel 就是阻塞的；较为特殊的是后者 MMAP，它是由 FileChannel 调用 map 方法衍生出来的一种特殊读写文件的方式，被称之为内存映射。</p><p>使用 FIleChannel 的方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FileChannel fileChannel = <span class="keyword">new</span> RandomAccessFile(<span class="keyword">new</span> File(<span class="string">"db.data"</span>), <span class="string">"rw"</span>).getChannel();</span><br></pre></td></tr></table></figure><p>获取 MMAP 的方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, filechannel.size();</span><br></pre></td></tr></table></figure><p>MappedByteBuffer 便是 JAVA 中 MMAP 的操作类。</p><p>面向于字节传输的传统 IO 方式遭到了我们的唾弃，我们重点探讨 FileChannel 和 MMAP 这两种读写方式的区别。</p><h3 id="FileChannel-读写"><a href="#FileChannel-读写" class="headerlink" title="FileChannel 读写"></a>FileChannel 读写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写</span></span><br><span class="line"><span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4096</span>];</span><br><span class="line"><span class="keyword">long</span> position = <span class="number">1024L</span>;</span><br><span class="line"><span class="comment">//指定 position 写入 4kb 的数据</span></span><br><span class="line">fileChannel.write(ByteBuffer.wrap(data), position);</span><br><span class="line"><span class="comment">//从当前文件指针的位置写入 4kb 的数据</span></span><br><span class="line">fileChannel.write(ByteBuffer.wrap(data));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读</span></span><br><span class="line">ByteBuffer buffer = ByteBuffer.allocate(<span class="number">4096</span>);</span><br><span class="line"><span class="keyword">long</span> position = <span class="number">1024L</span>;</span><br><span class="line"><span class="comment">//指定 position 读取 4kb 的数据</span></span><br><span class="line">fileChannel.read(buffer,position)；</span><br><span class="line"><span class="comment">//从当前文件指针的位置读取 4kb 的数据</span></span><br><span class="line">fileChannel.read(buffer);</span><br></pre></td></tr></table></figure><p>FileChannel 大多数时候是和 ByteBuffer 这个类打交道，你可以将它理解为一个 byte[] 的封装类，提供了丰富的 API 去操作字节，不了解的同学可以去熟悉下它的 API。值得一提的是，write 和 read 方法均是<strong>线程安全</strong>的，FileChannel 内部通过一把 <code>private final Object positionLock = new Object();</code> 锁来控制并发。</p><p>FileChannel 为什么比普通 IO 要快呢？这么说可能不严谨，因为你要用对它，FileChannel 只有在一次写入 4kb 的整数倍时，才能发挥出实际的性能，这得益于 FileChannel 采用了 ByteBuffer 这样的内存缓冲区，让我们可以非常精准的控制写盘的大小，这是普通 IO 无法实现的。4kb 一定快吗？也不严谨，这主要取决你机器的磁盘结构，并且受到操作系统，文件系统，CPU 的影响，例如中间件性能挑战赛时的那块盘，一次至少写入 64kb 才能发挥出最高的 IOPS。</p><p><img src="http://kirito.iocoder.cn/image-20180714180739936.png" alt="中间件性能挑战复赛的盘"></p><p>然而 PolarDB 这块盘就完全不一样了，可谓是异常彪悍，具体是如何的表现由于比赛仍在进行中，不予深究，但凭借着 benchmark everyting 的技巧，我们完全可以测出来。</p><p>另外一点，成就了 FileChannel 的高效，介绍这点之前，我想做一个提问：FileChannel 是直接把 ByteBuffer 中的数据写入到磁盘吗？思考几秒…答案是：NO。ByteBuffer 中的数据和磁盘中的数据还隔了一层，这一层便是 PageCache，是用户内存和磁盘之间的一层缓存。我们都知道磁盘 IO 和内存 IO 的速度可是相差了好几个数量级。我们可以认为 filechannel.write 写入 PageCache 便是完成了落盘操作，但实际上，操作系统最终帮我们完成了 PageCache 到磁盘的最终写入，理解了这个概念，你就应该能够理解 FileChannel 为什么提供了一个 force() 方法，用于通知操作系统进行及时的刷盘。</p><p>同理，当我们使用 FileChannel 进行读操作时，同样经历了：磁盘-&gt;PageCache-&gt;用户内存这三个阶段，对于日常使用者而言，你可以忽略掉 PageCache，但作为挑战者参赛，PageCache 在调优过程中是万万不能忽视的，关于读操作这里不做过多的介绍，我们再下面的小结中还会再次提及，这里当做是引出 PageCache 的概念。</p><h3 id="MMAP-读写"><a href="#MMAP-读写" class="headerlink" title="MMAP 读写"></a>MMAP 读写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写</span></span><br><span class="line"><span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>];</span><br><span class="line"><span class="keyword">int</span> position = <span class="number">8</span>;</span><br><span class="line"><span class="comment">//从当前 mmap 指针的位置写入 4b 的数据</span></span><br><span class="line">mappedByteBuffer.put(data);</span><br><span class="line"><span class="comment">//指定 position 写入 4b 的数据</span></span><br><span class="line">MappedByteBuffer subBuffer = mappedByteBuffer.slice();</span><br><span class="line">subBuffer.position(position);</span><br><span class="line">subBuffer.put(data);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读</span></span><br><span class="line"><span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>];</span><br><span class="line"><span class="keyword">int</span> position = <span class="number">8</span>;</span><br><span class="line"><span class="comment">//从当前 mmap 指针的位置读取 4b 的数据</span></span><br><span class="line">mappedByteBuffer.get(data)；</span><br><span class="line"><span class="comment">//指定 position 读取 4b 的数据</span></span><br><span class="line">MappedByteBuffer subBuffer = mappedByteBuffer.slice();</span><br><span class="line">subBuffer.position(position);</span><br><span class="line">subBuffer.get(data);</span><br></pre></td></tr></table></figure><p>FileChannel 已经足够强大了，MappedByteBuffer 还能玩出什么花来呢？请容许我卖个关子先，先介绍一下 MappedByteBuffer 的使用注意点。</p><p>当我们执行 <code>fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, 1.5 * 1024 * 1024 * 1024);</code> 之后，观察一下磁盘上的变化，会立刻获得一个 1.5G 的文件，但此时文件的内容全部是 0（字节 0）。这符合 MMAP 的中文描述：内存映射文件，我们之后对内存中 MappedByteBuffer 做的任何操作，都会被最终映射到文件之中，</p><blockquote><p>mmap 把文件映射到用户空间里的虚拟内存，省去了从内核缓冲区复制到用户空间的过程，文件中的位置在虚拟内存中有了对应的地址，可以像操作内存一样操作这个文件，相当于已经把整个文件放入内存，但在真正使用到这些数据前却不会消耗物理内存，也不会有读写磁盘的操作，只有真正使用这些数据时，也就是图像准备渲染在屏幕上时，虚拟内存管理系统 VMS 才根据缺页加载的机制从磁盘加载对应的数据块到物理内存进行渲染。这样的文件读写文件方式少了数据从内核缓存到用户空间的拷贝，效率很高</p></blockquote><p>看了稍微官方一点的描述，你可能对 MMAP 有了些许的好奇，有这么厉害的黑科技存在的话，还有 FileChannel 存在的意义吗！并且网上很多文章都在说，MMAP 操作大文件性能比 FileChannel 搞出一个数量级！然而，通过我比赛的认识，MMAP 并非是文件 IO 的银弹，它只有在<strong>一次写入很小量数据的场景</strong>下才能表现出比 FileChannel 稍微优异的性能。紧接着我还要告诉你一些令你沮丧的事，至少在 JAVA 中使用 MappedByteBuffer 是一件非常麻烦并且痛苦的事，主要表现为三点：</p><ol><li>MMAP 使用时必须实现指定好内存映射的大小，并且一次 map 的大小限制在 1.5G 左右，重复 map 又会带来虚拟内存的回收、重新分配的问题，对于文件不确定大小的情形实在是太不友好了。</li><li>MMAP 使用的是虚拟内存，和 PageCache 一样是由操作系统来控制刷盘的，虽然可以通过 force() 来手动控制，但这个时间把握不好，在小内存场景下会很令人头疼。</li><li>MMAP 的回收问题，当 MappedByteBuffer 不再需要时，可以手动释放占用的虚拟内存，但…方式非常的诡异。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">clean</span><span class="params">(MappedByteBuffer mappedByteBuffer)</span> </span>&#123;</span><br><span class="line">    ByteBuffer buffer = mappedByteBuffer;</span><br><span class="line">    <span class="keyword">if</span> (buffer == <span class="keyword">null</span> || !buffer.isDirect() || buffer.capacity() == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    invoke(invoke(viewed(buffer), <span class="string">"cleaner"</span>), <span class="string">"clean"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Object <span class="title">invoke</span><span class="params">(<span class="keyword">final</span> Object target, <span class="keyword">final</span> String methodName, <span class="keyword">final</span> Class&lt;?&gt;... args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> AccessController.doPrivileged(<span class="keyword">new</span> PrivilegedAction&lt;Object&gt;() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Object <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Method method = method(target, methodName, args);</span><br><span class="line">                method.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">                <span class="keyword">return</span> method.invoke(target);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Method <span class="title">method</span><span class="params">(Object target, String methodName, Class&lt;?&gt;[] args)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> NoSuchMethodException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> target.getClass().getMethod(methodName, args);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchMethodException e) &#123;</span><br><span class="line">        <span class="keyword">return</span> target.getClass().getDeclaredMethod(methodName, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> ByteBuffer <span class="title">viewed</span><span class="params">(ByteBuffer buffer)</span> </span>&#123;</span><br><span class="line">    String methodName = <span class="string">"viewedBuffer"</span>;</span><br><span class="line">    Method[] methods = buffer.getClass().getMethods();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; methods.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (methods[i].getName().equals(<span class="string">"attachment"</span>)) &#123;</span><br><span class="line">            methodName = <span class="string">"attachment"</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ByteBuffer viewedBuffer = (ByteBuffer) invoke(buffer, methodName);</span><br><span class="line">    <span class="keyword">if</span> (viewedBuffer == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> buffer;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> viewed(viewedBuffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对的，你没看错，这么长的代码仅仅是为了干回收 MappedByteBuffer 这一件事。</p><p>所以我建议，优先使用 FileChannel 去完成初始代码的提交，在必须使用小数据量(例如几个字节)刷盘的场景下，再换成 MMAP 的实现，其他场景 FileChannel 完全可以 cover(前提是你理解怎么合理使用 FileChannel)。至于 MMAP 为什么在一次写入少量数据的场景下表现的比 FileChannel 优异，我还没有查到理论根据，如果你有相关的线索，欢迎留言。理论分析下，FileChannel 同样是写入内存，但比 MMAP 多了一次内核缓冲区与用户空间互相复制的过程，所以在极端场景下，MMAP 表现的更加优秀。至于 MMAP 分配的虚拟内存是否就是真正的 PageCache 这一点，我觉得可以近似理解成 PageCache。</p><h3 id="顺序读比随机读快，顺序写比随机写快"><a href="#顺序读比随机读快，顺序写比随机写快" class="headerlink" title="顺序读比随机读快，顺序写比随机写快"></a>顺序读比随机读快，顺序写比随机写快</h3><p>无论你是机械硬盘还是 SSD，这个结论都是一定成立的，虽然背后的原因不太一样，我们今天不讨论机械硬盘这种古老的存储介质，重点 foucs 在 SSD 上，来看看在它之上进行的随机读写为什么比顺序读写要慢。即使各个 SSD 和文件系统的构成具有差异性，但我们今天的分析同样具备参考价值。</p><p>首先，什么是顺序读，什么是随机读，什么是顺序写，什么是随机写？可能我们刚接触文件 IO 操作时并不会有这样的疑惑，但写着写着，自己都开始怀疑自己的理解了，不知道你有没有经历过这样类似的阶段，反正我有一段时间的确怀疑过。那么，先来看看两段代码：</p><p>写入方式一：64个线程，用户自己使用一个 atomic 变量记录写入指针的位置，并发写入</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService executor = Executors.newFixedThreadPool(<span class="number">64</span>);</span><br><span class="line">AtomicLong wrotePosition = <span class="keyword">new</span> AtomicLong(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1024</span>;i++)&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    executor.execute(()-&gt;&#123;</span><br><span class="line">        fileChannel.write(ByteBuffer.wrap(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>*<span class="number">1024</span>]),wrote.getAndAdd(<span class="number">4</span>*<span class="number">1024</span>));</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>写入方式二：给 write 加了锁，保证了同步。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService executor = Executors.newFixedThreadPool(<span class="number">64</span>);</span><br><span class="line">AtomicLong wrotePosition = <span class="keyword">new</span> AtomicLong(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1024</span>;i++)&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    executor.execute(()-&gt;&#123;</span><br><span class="line">        write(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>*<span class="number">1024</span>]);</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span>[] data)</span></span>&#123;</span><br><span class="line">    fileChannel.write(ByteBuffer.wrap(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span>*<span class="number">1024</span>]),wrote.getAndAdd(<span class="number">4</span>*<span class="number">1024</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>答案是方式二才算顺序写，顺序读也是同理。对于文件操作，加锁并不是一件非常可怕的事，不敢同步 write/read 才可怕！有人会问：FileChannel 内部不是已经有 positionLock 保证写入的线程安全了吗，为什么还要自己加同步？为什么这样会快？我用大白话来回答的话就是多线程并发 write 并且不加同步，会导致文件空洞，它的执行次序可能是 </p><p>时序1：thread1 write position[0~4096)</p><p>时序2：thread3 write position[8194~12288)</p><p>时序2：thread2 write position[4096~8194)</p><p>所以并不是完全的“顺序写”。不过你也别担心加锁会导致性能下降，我们会在下面的小结介绍一个优化：通过文件分片来减少多线程读写时锁的冲突。</p><p>在来分析原理，顺序读为什么会比随机读要快？顺序写为什么比随机写要快？这两个对比其实都是一个东西在起作用：PageCache，前面我们已经提到了，它是位于 application buffer(用户内存)和 disk file(磁盘)之间的一层缓存。</p><p><img src="http://kirito.iocoder.cn/1364556742_9652.gif" alt="PageCache"></p><p>以顺序读为例，当用户发起一个 fileChannel.read(4kb) 之后，实际发生了两件事</p><ol><li>操作系统从磁盘加载了 16kb 进入 PageCache，这被称为预读</li><li>操作通从 PageCache 拷贝 4kb 进入用户内存</li></ol><p>最终我们在用户内存访问到了 4kb，为什么顺序读快？很容量想到，当用户继续访问接下来的[4kb,16kb]的磁盘内容时，便是直接从 PageCache 去访问了。试想一下，当需要访问 16kb 的磁盘内容时，是发生4次磁盘 IO 快，还是发生1次磁盘 IO+4 次内存 IO 快呢？答案是显而易见的，这一切都是 PageCache 带来的优化。</p><p>深度思考：当内存吃紧时，PageCache 的分配会受影响吗？PageCache 的大小如何确定，是固定的 16kb 吗？我可以监控 PageCache 的命中情况吗？ PageCache 会在哪些场景失效，如果失效了，我们又要哪些补救方式呢？</p><p>我进行简单的自问自答，背后的逻辑还需要读者去推敲：</p><ul><li>当内存吃紧时，PageCache 的预读会受到影响，实测，并没有搜到到文献支持</li><li>PageCache 是动态调整的，可以通过 linux 的系统参数进行调整，默认是占据总内存的 20%</li><li><a href="https://github.com/brendangregg/perf-tools" target="_blank" rel="noopener">https://github.com/brendangregg/perf-tools</a> github 上一款工具可以监控 PageCache</li><li>这是很有意思的一个优化点，如果用 PageCache 做缓存不可控，不妨自己做预读如何呢？</li></ul><p>顺序写的原理和顺序读一致，都是收到了 PageCache 的影响，留给读者自己推敲一下。</p><h3 id="直接内存-堆外-VS-堆内内存"><a href="#直接内存-堆外-VS-堆内内存" class="headerlink" title="直接内存(堆外) VS 堆内内存"></a>直接内存(堆外) VS 堆内内存</h3><p>前面 FileChannel 的示例代码中已经使用到了堆内内存： <code>ByteBuffer.allocate(4 * 1024)</code>，ByteBuffer 提供了另外的方式让我们可以分配堆外内存 ： <code>ByteBuffer.allocateDirect(4 * 1024)</code>。这就引来的一系列的问题，我什么时候应该使用堆内内存，什么时候应该使用直接内存？</p><p>我不花太多笔墨去阐述了，直接上对比：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">堆内内存</th><th style="text-align:center">堆外内存</th></tr></thead><tbody><tr><td style="text-align:center"><strong>底层实现</strong></td><td style="text-align:center">数组，JVM 内存</td><td style="text-align:center">unsafe.allocateMemory(size)返回直接内存</td></tr><tr><td style="text-align:center"><strong>分配大小限制</strong></td><td style="text-align:center">-Xms-Xmx 配置的 JVM 内存相关，并且数组的大小有限制，在做测试时发现，当 JVM free memory 大于 1.5G 时，ByteBuffer.allocate(900M) 时会报错</td><td style="text-align:center">可以通过 -XX:MaxDirectMemorySize 参数从 JVM 层面去限制，同时受到机器虚拟内存（说物理内存不太准确）的限制</td></tr><tr><td style="text-align:center"><strong>垃圾回收</strong></td><td style="text-align:center">不必多说</td><td style="text-align:center">当 DirectByteBuffer 不再被使用时，会出发内部 cleaner 的钩子，保险起见，可以考虑手动回收：((DirectBuffer) buffer).cleaner().clean();</td></tr><tr><td style="text-align:center"><strong>拷贝方式</strong></td><td style="text-align:center">用户态<->内核态</-></td><td style="text-align:center">内核态</td></tr></tbody></table><p>关于堆内内存和堆外内存的一些最佳实践：</p><ol><li>当需要申请大块的内存时，堆内内存会受到限制，只能分配堆外内存。</li><li>堆外内存适用于生命周期中等或较长的对象。( 如果是生命周期较短的对象，在 YGC 的时候就被回收了，就不存在大内存且生命周期较长的对象在 FGC 对应用造成的性能影响 )。</li><li>直接的文件拷贝操作，或者 I/O 操作。直接使用堆外内存就能少去内存从用户内存拷贝到系统内存的消耗</li><li>同时，还可以使用池+堆外内存 的组合方式，来对生命周期较短，但涉及到 I/O 操作的对象进行堆外内存的再使用( Netty中就使用了该方式 )。在比赛中，尽量不要出现在频繁 <code>new byte[]</code> ，创建内存区域再回收也是一笔不小的开销，使用 <code>ThreadLocal&lt;ByteBuffer&gt;</code>  和 <code>ThreadLocal&lt;byte[]&gt;</code> 往往会给你带来意外的惊喜~</li><li>创建堆外内存的消耗要大于创建堆内内存的消耗，所以当分配了堆外内存之后，尽可能复用它。</li></ol><h3 id="黑魔法：UNSAFE"><a href="#黑魔法：UNSAFE" class="headerlink" title="黑魔法：UNSAFE"></a>黑魔法：UNSAFE</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UnsafeUtil</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe UNSAFE;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field field = Unsafe.class.getDeclaredField(<span class="string">"theUnsafe"</span>);</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            UNSAFE = (Unsafe) field.get(<span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以使用 UNSAFE 这个黑魔法实现很多无法想象的事，我这里就稍微介绍一两点吧。</p><p>实现直接内存与内存的拷贝：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer buffer = ByteBuffer.allocateDirect(<span class="number">4</span> * <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line"><span class="keyword">long</span> addresses = ((DirectBuffer) buffer).address();</span><br><span class="line"><span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span> * <span class="number">1024</span> * <span class="number">1024</span>];</span><br><span class="line">UNSAFE.copyMemory(data, <span class="number">16</span>, <span class="keyword">null</span>, addresses, <span class="number">4</span> * <span class="number">1024</span> * <span class="number">1024</span>);</span><br></pre></td></tr></table></figure><p>copyMemory 方法可以实现内存之间的拷贝，无论是堆内和堆外，1~2 个参数是 source 方，3~4 是 target 方，第 5 个参数是 copy 的大小。如果是堆内的字节数组，则传递数组的首地址和 16 这个固定的 ARRAY_BYTE_BASE_OFFSET 偏移常量；如果是堆外内存，则传递 null 和直接内存的偏移量，可以通过 ((DirectBuffer) buffer).address() 拿到。为什么不直接拷贝，而要借助 UNSAFE？当然是因为它快啊！少年！另外补充：MappedByteBuffer 也可以使用 UNSAFE 来 copy 从而达到写盘/读盘的效果哦。</p><p>至于 UNSAFE 还有那些黑科技，可以专门去了解下，我这里就不过多赘述了。</p><h3 id="文件分区"><a href="#文件分区" class="headerlink" title="文件分区"></a>文件分区</h3><p>前面已经提到了顺序读写时我们需要对 write，read 加锁，并且我一再强调的一点是：加锁并不可怕，文件 IO 操作并没有那么依赖多线程。但是加锁之后的顺序读写必然无法打满磁盘 IO，如今系统强劲的 CPU 总不能不压榨吧？我们可以采用文件分区的方式来达到一举两得的效果：既满足了顺序读写，又减少了锁的冲突。</p><p>那么问题又来了，分多少合适呢？文件多了，锁冲突变降低了；文件太多了，碎片化太过严重，单个文件的值太少，缓存也就不容易命中，这样的 trade off 如何平衡？没有理论答案，benchmark everything~</p><h3 id="Direct-IO"><a href="#Direct-IO" class="headerlink" title="Direct IO"></a>Direct IO</h3><p><img src="http://kirito.iocoder.cn/linux-io.png" alt="linux io"></p><p>最后我们来探讨一下之前从没提到的一种 IO 方式，Direct IO，什么，Java 还有这东西？博主你骗我？之前怎么告诉我只有三种 IO 方式！别急着骂我，严谨来说，这并不是 JAVA 原生支持的方式，但可以通过 JNA/JNI 调用 native 方法做到。从上图我们可以看到 ：Direct IO 绕过了 PageCache，但我们前面说到过，PageCache 可是个好东西啊，干嘛不用他呢？再仔细推敲一下，还真有一些场景下，Direct IO 可以发挥作用，没错，那就是我们前面没怎么提到的：<strong>随机读</strong>。当使用 fileChannel.read() 这类会触发 PageCache 预读的 IO 方式时，我们其实并不希望操作系统帮我们干太多事，除非真的踩了狗屎运，随机读都能命中 PageCache，但几率可想而知。Direct IO 虽然被 Linus 无脑喷过，但在随机读的场景下，依旧存在其价值，减少了 Block IO Layed（近似理解为磁盘） 到 Page Cache 的 overhead。</p><p>话说回来，Java 怎么用 Direct IO 呢？有没有什么限制呢？前面说过，Java 目前原生并不支持，但也有好心人封装好了 Java 的 JNA 库，实现了 Java 的 Direct IO，github 地址：<a href="https://github.com/smacke/jaydio" target="_blank" rel="noopener">https://github.com/smacke/jaydio</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> bufferSize = <span class="number">20</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">DirectRandomAccessFile directFile = <span class="keyword">new</span> DirectRandomAccessFile(<span class="keyword">new</span> File(<span class="string">"dio.data"</span>), <span class="string">"rw"</span>, bufferSize);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i= <span class="number">0</span>;i&lt; bufferSize / <span class="number">4096</span>;i++)&#123;</span><br><span class="line">    <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">4</span> * <span class="number">1024</span>];</span><br><span class="line">    directFile.read(buffer);</span><br><span class="line">    directFile.readFully(buffer);</span><br><span class="line">&#125;</span><br><span class="line">directFile.close();</span><br></pre></td></tr></table></figure><p>但需要注意的是，<strong>只有 Linux 系统才支持 DIO</strong>! 所以，少年，是时候上手装一台 linux 了。值得一提的是，据说在 Jdk10 发布之后，Direct IO 将会得到原生的支持，让我们拭目以待吧！</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上均是个人的实践积累而来的经验，有部分结论没有找到文献的支撑，所以如有错误，欢迎指正。关于 PolarDB 数据性能大赛的比赛分析，等复赛结束后我会专门另起一篇文章，分析下具体如何使用这些优化点，当然这些小技巧其实很多人都知道，决定最后成绩的还是整体设计的架构，以及对文件IO，操作系统，文件系统，CPU 和语言特性的理解。虽然 JAVA 搞这种性能挑战赛并不吃香，但依旧是乐趣无穷，希望这些文件 IO 的知识能够帮助你，等下次比赛时看到你的身影~</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;已经过去的中间件性能挑战赛，和正在进行中的 &lt;a href=&quot;https://tianchi.aliyun.com/programming/introduction.htm?spm=5176.11165320.5678.1.483b4682l8fBSf&amp;amp;raceId=231689&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;第一届 PolarDB 数据性能大赛&lt;/a&gt; 都涉及到了文件操作，合理地设计架构以及正确地压榨机器的读写性能成了比赛中获取较好成绩的关键。正在参赛的我收到了几位公众号读者朋友的反馈，他们大多表达出了这样的烦恼：“对比赛很感兴趣，但不知道怎么入门”，“能跑出成绩，但相比前排的选手，成绩相差10倍有余”…为了能让更多的读者参与到之后相类似的比赛中来，我简单整理一些文件IO操作的最佳实践，而不涉及整体系统的架构设计，希望通过这篇文章的介绍，让你能够欢快地参与到之后类似的性能挑战赛之中来。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://lexburner.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="PolarDB性能挑战赛" scheme="http://lexburner.github.io/tags/PolarDB%E6%80%A7%E8%83%BD%E6%8C%91%E6%88%98%E8%B5%9B/"/>
    
  </entry>
  
  <entry>
    <title>八个层面比较 Java 8, RxJava, Reactor</title>
    <link href="http://lexburner.github.io/comparing-rxjava/"/>
    <id>http://lexburner.github.io/comparing-rxjava/</id>
    <published>2018-10-15T17:25:14.000Z</published>
    <updated>2019-01-22T13:27:44.600Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>这是一篇译文，原文出处 <a href="http://alexsderkach.io/comparing-java-8-rxjava-reactor/" target="_blank" rel="noopener">戳这里</a>。其实很久以前我就看完了这篇文章，只不过个人对响应式编程研究的不够深入，羞于下笔翻译，在加上这类译文加了原创还有争议性，所以一直没有动力。恰逢今天交流群里两个大佬对响应式编程的话题辩得不可开交，趁印象还算深刻，借机把这篇文章翻译一下。说道辩论的点，不妨也在这里抛出来：</p><blockquote><p>响应式编程在单机环境下是否鸡肋？</p></blockquote><p>结论是：没有结论，我觉得只能抱着怀疑的眼光审视这个问题了。另外还聊到了 RSocket 这个最近在 SpringOne 大会上比较火爆的响应式”新“网络协议，github 地址<a href="https://github.com/rsocket/rsocket" target="_blank" rel="noopener">戳这里</a>，为什么给”新“字打了个引号，仔细观察下 RSocket 的 commit log，其实三年前就有了。有兴趣的同学自行翻阅，说不定就是今年这最后两三个月的热点技术哦。</p><p> Java 圈子有一个怪事，那就是对 RxJava，Reactor，WebFlux 这些响应式编程的名词、框架永远处于渴望了解，感到新鲜，却又不甚了解，使用贫乏的状态。之前转载小马哥的那篇《Reactive Programming 一种技术，各自表述》时，就已经聊过这个关于名词之争的话题了，今天群里的讨论更是加深了我的映像。Java 圈子里面很多朋友一直对响应式编程处于一个了解名词，知道基本原理，而不是深度用户的状态(我也是之一)。可能真的和圈子有关，按石冲兄的说法，其实 Scala 圈子里面的那帮人，不知道比咱们高到哪里去了（就响应式编程而言）。</p><p>实在是好久没发文章了，向大家说声抱歉，以后的更新频率肯定是没有以前那么勤了（说的好像以前很勤快似的），一部分原因是在公司内网写的文章没法贴到公众号中和大家分享讨论，另一部分是目前我也处于学习公司内部框架的阶段，不太方便提炼成文章，最后，最大的一部分原因还是我这段时间需要学(tou)习(lan)其(da)他(you)东(xi)西啦。好了，废话也说完了，下面是译文的正文部分。</p><a id="more"></a><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>关于响应式编程(Reactive Programming)，你可能有过这样的疑问：我们已经有了 Java8 的 Stream, CompletableFuture, 以及 Optional，为什么还必要存在 RxJava 和 Reactor？</p><p>回答这个问题并不难，如果在响应式编程中处理的问题非常简单，你的确不需要那些第三方类库的支持。 但随着复杂问题的出现，你写出了一堆难看的代码。然后这些代码变得越来越复杂，难以维护，而 RxJava 和 Reactor 具有许多方便的功能，可以解决你当下问题，并保障了未来一些可预见的需求。本文从响应式编程模型中抽象出了8个标准，这将有助于我们理解标准特性与这些库之间的区别：</p><ol><li>Composable（可组合）</li><li>Lazy（惰性执行）</li><li>Reusable（可复用）</li><li>Asynchronous（异步）</li><li>Cacheable（可缓存）</li><li>Push or Pull（推拉模型）</li><li>Backpressure（回压）(译者注：按照石冲老哥的建议，这个词应当翻译成”回压”而不是”背压”)</li><li>Operator fusion（操作融合）</li></ol><p>我们将会对以下这些类进行这些特性的对比：</p><ol><li>CompletableFuture（Java 8）</li><li>Stream（Java 8）</li><li>Optional（Java 8）</li><li>Observable (RxJava 1)</li><li>Observable (RxJava 2)</li><li>Flowable (RxJava 2)</li><li>Flux (Reactor Core)</li></ol><p>让我们开始吧~</p><h3 id="1-Composable（可组合）"><a href="#1-Composable（可组合）" class="headerlink" title="1. Composable（可组合）"></a>1. Composable（可组合）</h3><p>这些类都是支持 Composable 特性的，使得各位使用者很便利地使用函数式编程的思想去思考问题，这也正是我们拥趸它们的原因。</p><p><strong>CompletableFuture</strong> - 众多的 <code>.then*()</code> 方法使得我们可以构建一个 pipeline, 用以传递空值，单一的值，以及异常.</p><p><strong>Stream</strong> - 提供了许多链式操作的编程接口，支持在各个操作之间传递多个值。</p><p><strong>Optional</strong> - 提供了一些中间操作 <code>.map()</code>, <code>.flatMap()</code>, <code>.filter()</code>.</p><p><strong>Observable, Flowable, Flux</strong> - 和 <strong>Stream</strong> 相同</p><h3 id="2-Lazy（惰性执行）"><a href="#2-Lazy（惰性执行）" class="headerlink" title="2. Lazy（惰性执行）"></a>2. Lazy（惰性执行）</h3><p><strong>CompletableFuture</strong> - 不具备惰性执行的特性，它本质上只是一个异步结果的容器。这些对象的创建是用来表示对应的工作，CompletableFuture 创建时，对应的工作已经开始执行了。但它并不知道任何工作细节，只关心结果。所以，没有办法从上至下执行整个 pipeline。当结果被设置给 CompletableFuture 时，下一个阶段才开始执行。</p><p><strong>Stream</strong> - 所有的中间操作都是延迟执行的。所有的终止操作(terminal operations)，会触发真正的计算(译者注：如 collect() 就是一个终止操作)。</p><p><strong>Optional</strong> - 不具备惰性执行的特性，所有的操作会立刻执行。</p><p><strong>Observable, Flowable, Flux</strong> - 惰性执行，只有当订阅者出现时才会执行，否则不执行。</p><h3 id="3-Reusable（可复用）"><a href="#3-Reusable（可复用）" class="headerlink" title="3. Reusable（可复用）"></a>3. Reusable（可复用）</h3><p><strong>CompletableFuture</strong> - 可以复用，它仅仅是一个实际值的包装类。但需要注意的是，这个包装是可更改的。<code>.obtrude*()</code>方法会修改它的内容，如果你确定没有人会调用到这类方法，那么重用它还是安全的。</p><p><strong>Stream</strong> - 不能复用。Java Doc 注释道：</p><blockquote><p>A stream should be operated on (invoking an intermediate or terminal stream operation) only once. A stream implementation may throw IllegalStateException if it detects that the stream is being reused. However, since some stream operations may return their receiver rather than a new stream object, it may not be possible to detect reuse in all cases. </p></blockquote><p>（译者注：Stream 只能被调用一次。如果被校测到流被重复使用了，它会跑出抛出一个 IllegalStateException 异常。但是某些流操作会返回他们的接受者，而不是一个新的流对象，所以无法在所有情况下检测出是否可以重用）</p><p><strong>Optional</strong> - 完全可重用，因为它是不可变对象，而且所有操作都是立刻执行的。</p><p><strong>Observable, Flowable, Flux</strong> - 生而重用，专门设计成如此。当存在订阅者时，每一次执行都会从初始点开始完整地执行一边。</p><h3 id="4-Asynchronous（异步）"><a href="#4-Asynchronous（异步）" class="headerlink" title="4. Asynchronous（异步）"></a>4. Asynchronous（异步）</h3><p><strong>CompletableFuture</strong> - 这个类的要点在于它异步地把多个操作连接了起来。<code>CompletableFuture</code> 代表一项操作，它会跟一个 <code>Executor</code> 关联起来。如果不明确指定一个 <code>Executor</code>，那么会默认使用公共的 <code>ForkJoinPool</code> 线程池来执行。这个线程池可以用 <code>ForkJoinPool.commonPool()</code> 获取到。默认设置下它会创建系统硬件支持的线程数一样多的线程（通常和 CPU 的核心数相等，如果你的 CPU 支持超线程(hyperthreading)，那么会设置成两倍的线程数）。不过你也可以使用 JVM 参数指定 ForkJoinPool 线程池的线程数，</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Djava.util.concurrent.ForkJoinPool.common.parallelism=?</span><br></pre></td></tr></table></figure><p>或者在创建 <code>CompletableFuture</code> 时提供一个指定的 Executor。</p><p><strong>Stream</strong> - 不支持创建异步执行流程，但是可以使用 <code>stream.parallel()</code> 等方式创建并行流。</p><p><strong>Optional</strong> - 不支持，它只是一个容器。</p><p><strong>Observable, Flowable, Flux</strong> - 专门设计用以构建异步系统，但默认情况下是同步的。<code>subscribeOn</code> 和 <code>observeOn</code>允许你来控制订阅以及接收（这个线程会调用 observer 的 <code>onNext</code> / <code>onError</code> / <code>onCompleted</code>方法）。</p><p><code>subscribeOn</code> 方法使得你可以决定由哪个 <code>Scheduler</code> 来执行 <code>Observable.create</code> 方法。即便你没有调用创建方法，系统内部也会做同样的事情。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Observable</span><br><span class="line">  .fromCallable(() -&gt; &#123;</span><br><span class="line">    log.info(<span class="string">"Reading on thread: "</span> + currentThread().getName());</span><br><span class="line">    <span class="keyword">return</span> readFile(<span class="string">"input.txt"</span>);</span><br><span class="line">  &#125;)</span><br><span class="line">  .map(text -&gt; &#123;</span><br><span class="line">    log.info(<span class="string">"Map on thread: "</span> + currentThread().getName());</span><br><span class="line">    <span class="keyword">return</span> text.length();</span><br><span class="line">  &#125;)</span><br><span class="line">  .subscribeOn(Schedulers.io()) <span class="comment">// &lt;-- setting scheduler</span></span><br><span class="line">  .subscribe(value -&gt; &#123;</span><br><span class="line">     log.info(<span class="string">"Result on thread: "</span> + currentThread().getName());</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Reading file on thread: RxIoScheduler-<span class="number">2</span></span><br><span class="line">Map on thread: RxIoScheduler-<span class="number">2</span></span><br><span class="line">Result on thread: RxIoScheduler-<span class="number">2</span></span><br></pre></td></tr></table></figure><p>相反的，<code>observeOn()</code> 控制在 <code>observeOn()</code> 之后，用哪个 <code>Scheduler</code> 来运行下游的执行阶段。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Observable</span><br><span class="line">  .fromCallable(() -&gt; &#123;</span><br><span class="line">    log.info(<span class="string">"Reading on thread: "</span> + currentThread().getName());</span><br><span class="line">    <span class="keyword">return</span> readFile(<span class="string">"input.txt"</span>);</span><br><span class="line">  &#125;)</span><br><span class="line">  .observeOn(Schedulers.computation()) <span class="comment">// &lt;-- setting scheduler</span></span><br><span class="line">  .map(text -&gt; &#123;</span><br><span class="line">    log.info(<span class="string">"Map on thread: "</span> + currentThread().getName());</span><br><span class="line">    <span class="keyword">return</span> text.length();</span><br><span class="line">  &#125;)</span><br><span class="line">  .subscribeOn(Schedulers.io()) <span class="comment">// &lt;-- setting scheduler</span></span><br><span class="line">  .subscribe(value -&gt; &#123;</span><br><span class="line">     log.info(<span class="string">"Result on thread: "</span> + currentThread().getName());</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Reading file on thread: RxIoScheduler-<span class="number">2</span></span><br><span class="line">Map on thread: RxComputationScheduler-<span class="number">1</span></span><br><span class="line">Result on thread: RxComputationScheduler-<span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="5-Cacheable（可缓存）"><a href="#5-Cacheable（可缓存）" class="headerlink" title="5. Cacheable（可缓存）"></a>5. Cacheable（可缓存）</h3><p>可缓存和可复用之间的区别是什么？假如我们有 pipeline <code>A</code>，重复使用它两次，来创建两个新的 pipeline <code>B = A + X</code> 以及 <code>C = A + Y</code></p><ul><li>如果 B 和 C 都能成功执行，那么这个 A 就是是可重用的。</li><li>如果 B 和 C 都能成功执行，并且 A 在这个过程中，整个 pipeline 只执行了一次，那么我们便称 A 是可缓存的。这意味着，可缓存一定代表可重用。</li></ul><p><strong>CompletableFuture</strong> - 跟可重用的答案一样。</p><p><strong>Stream</strong> - 不能缓存中间操作的结果，除非调用了终止操作。</p><p><strong>Optional</strong> - 可缓存，所有操作立刻执行，并且进行了缓存。</p><p><strong>Observable, Flowable, Flux</strong> - 默认不可缓存的，但是可以调用 <code>.cache()</code> 把这些类变成可缓存的。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Observable&lt;Integer&gt; work = Observable.fromCallable(() -&gt; &#123;</span><br><span class="line">  System.out.println(<span class="string">"Doing some work"</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">10</span>;</span><br><span class="line">&#125;);</span><br><span class="line">work.subscribe(System.out::println);</span><br><span class="line">work.map(i -&gt; i * <span class="number">2</span>).subscribe(System.out::println);</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Doing some work</span><br><span class="line"><span class="number">10</span></span><br><span class="line">Doing some work</span><br><span class="line"><span class="number">20</span></span><br></pre></td></tr></table></figure><p>使用 <code>.cache()</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Observable&lt;Integer&gt; work = Observable.fromCallable(() -&gt; &#123;</span><br><span class="line">  System.out.println(<span class="string">"Doing some work"</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">10</span>;</span><br><span class="line">&#125;).cache(); <span class="comment">// &lt;- apply caching</span></span><br><span class="line">work.subscribe(System.out::println);</span><br><span class="line">work.map(i -&gt; i * <span class="number">2</span>).subscribe(System.out::println);</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Doing some work</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="number">20</span></span><br></pre></td></tr></table></figure><h3 id="6-Push-or-Pull（推拉模型）"><a href="#6-Push-or-Pull（推拉模型）" class="headerlink" title="6. Push or Pull（推拉模型）"></a>6. Push or Pull（推拉模型）</h3><p><strong>Stream 和 Optional</strong> - 拉模型。调用不同的方法（<code>.get()</code>, <code>.collect()</code> 等）从 pipeline 拉取结果。拉模型通常和阻塞、同步关联，那也是公平的。当调用方法时，线程会一直阻塞，直到有数据到达。</p><p><strong>CompletableFuture, Observable, Flowable, Flux</strong> - 推模型。当订阅一个 pipeline ，并且某些事件被执行后，你会得到通知。推模型通常和非阻塞、异步这些词关联在一起。当 pipeline 在某个线程上执行时，你可以做任何事情。你已经定义了一段待执行的代码，当通知到达的时候，这段代码就会在下个阶段被执行。</p><h3 id="7-Backpressure（回压）"><a href="#7-Backpressure（回压）" class="headerlink" title="7. Backpressure（回压）"></a>7. Backpressure（回压）</h3><p><em>支持回压的前提是 pipeline 必须是推模型。</em></p><p><strong>Backpressure（回压）</strong> 描述了 pipeline 中的一种场景：某些异步阶段的处理速度跟不上，需要告诉上游生产者放慢速度。直接失败是不能接受的，这会导致大量数据的丢失。</p><p><img src="http://kirito.iocoder.cn/backpressure.jpg" alt="backpressure.jpg"></p><p><strong>Stream &amp; Optional</strong> - 不支持回压，因为它们是拉模型。</p><p><strong>CompletableFuture</strong> - 不存在这个问题，因为它只产生 0 个或者 1 个结果。</p><p><strong>Observable(RxJava 1), Flowable, Flux</strong> - 支持。常用策略如下：</p><ul><li><p>Buffering - 缓冲所有的 <code>onNext</code> 的值，直到下游消费它们。 </p></li><li><p>Drop Recent - 如果下游处理速率跟不上，丢弃最近的 <code>onNext</code> 值。</p></li><li><p>Use Latest - 如果下游处理速率跟不上，只提供最近的 <code>onNext</code> 值，之前的值会被覆盖。</p></li><li><p>None - <code>onNext</code> 事件直接被触发，不做缓冲和丢弃。</p></li><li>Exception - 如果下游处理跟不上的话，抛出异常。</li></ul><p><strong>Observable(RxJava 2)</strong> - 不支持。很多 RxJava 1 的使用者用 <code>Observable</code> 来处理不适用回压的事件，或者是使用 <code>Observable</code> 的时候没有配置任何策略，导致了不可预知的异常。所以，RxJava 2 明确地区分两种情况，提供支持回压的 <code>Flowable</code> 和不支持回压的 <code>Observable</code>。</p><h3 id="8-Operator-fusion（操作融合）"><a href="#8-Operator-fusion（操作融合）" class="headerlink" title="8. Operator fusion（操作融合）"></a>8. Operator fusion（操作融合）</h3><p>操作融合的内涵在于，它使得生命周期的不同点上的执行阶段得以改变，从而消除类库的架构因素所造成的系统开销。所有这些优化都在内部被处理完毕，从而让外部用户觉得这一切都是透明的。</p><p>只有 RxJava 2 和 Reactor 支持这个特性，但支持的方式不同。总的来说，有两种类型的优化：</p><p><strong>Macro-fusion</strong> - 用一个操作替换 2 个或更多的相继的操作</p><p><img src="http://kirito.iocoder.cn/7fec27a062235dff88ef1d56ee2ce483.png" alt="macro-fusion_.png"></p><p><strong>Micro-fusion</strong> - 一个输出队列的结束操作，和在一个输入队列的开始操作，能够共享一个队列的实例。比如说，与其调用 <code>request(1)</code> 然后处理 onNext()`：</p><p><img src="http://kirito.iocoder.cn/6d4b0b357777b8caa2f87283027206ff.png" alt="micro-fusion-1_1.png"></p><p>不然让订阅者直接从父 <code>observable</code> 拉取值。</p><p><img src="http://kirito.iocoder.cn/fac526768bed14d11933464646eb6471.png" alt="micro-fusion-2.png"></p><p>更多信息可以参考 <a href="http://akarnokd.blogspot.com/2016/03/operator-fusion-part-1.html" target="_blank" rel="noopener">Part1</a> 和 <a href="http://akarnokd.blogspot.com/2016/04/operator-fusion-part-2-final.html" target="_blank" rel="noopener">Part2</a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>一图胜千言</p><p><img src="http://kirito.iocoder.cn/5a57f2b1b694cc0f41320763a0cb1c0a.png" alt="2018-04-12_20-38-07.png"></p><p><code>Stream</code>，<code>CompletableFuture</code> 和 <code>Optional</code> 这些类的创建，都是为了解决特定的问题。 并且他们非常适合用于解决这些问题。 如果它们满足你的需求，你可以立马使用它们。</p><p>然而，不同的问题具有不同的复杂度，并且某些问题只有新技术才能很好的解决，新技术的出现也是为了解决那些高复杂度的问题。 RxJava 和 Reactor 是通用的工具，它们帮助你以声明方式来解决问题，而不是使用那些不够专业的工具，生搬硬套的使用其他的工具来解决响应式编程的问题，只会让你的解决方案变成一种 hack 行为。</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;这是一篇译文，原文出处 &lt;a href=&quot;http://alexsderkach.io/comparing-java-8-rxjava-reactor/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;戳这里&lt;/a&gt;。其实很久以前我就看完了这篇文章，只不过个人对响应式编程研究的不够深入，羞于下笔翻译，在加上这类译文加了原创还有争议性，所以一直没有动力。恰逢今天交流群里两个大佬对响应式编程的话题辩得不可开交，趁印象还算深刻，借机把这篇文章翻译一下。说道辩论的点，不妨也在这里抛出来：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;响应式编程在单机环境下是否鸡肋？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;结论是：没有结论，我觉得只能抱着怀疑的眼光审视这个问题了。另外还聊到了 RSocket 这个最近在 SpringOne 大会上比较火爆的响应式”新“网络协议，github 地址&lt;a href=&quot;https://github.com/rsocket/rsocket&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;戳这里&lt;/a&gt;，为什么给”新“字打了个引号，仔细观察下 RSocket 的 commit log，其实三年前就有了。有兴趣的同学自行翻阅，说不定就是今年这最后两三个月的热点技术哦。&lt;/p&gt;
&lt;p&gt; Java 圈子有一个怪事，那就是对 RxJava，Reactor，WebFlux 这些响应式编程的名词、框架永远处于渴望了解，感到新鲜，却又不甚了解，使用贫乏的状态。之前转载小马哥的那篇《Reactive Programming 一种技术，各自表述》时，就已经聊过这个关于名词之争的话题了，今天群里的讨论更是加深了我的映像。Java 圈子里面很多朋友一直对响应式编程处于一个了解名词，知道基本原理，而不是深度用户的状态(我也是之一)。可能真的和圈子有关，按石冲兄的说法，其实 Scala 圈子里面的那帮人，不知道比咱们高到哪里去了（就响应式编程而言）。&lt;/p&gt;
&lt;p&gt;实在是好久没发文章了，向大家说声抱歉，以后的更新频率肯定是没有以前那么勤了（说的好像以前很勤快似的），一部分原因是在公司内网写的文章没法贴到公众号中和大家分享讨论，另一部分是目前我也处于学习公司内部框架的阶段，不太方便提炼成文章，最后，最大的一部分原因还是我这段时间需要学(tou)习(lan)其(da)他(you)东(xi)西啦。好了，废话也说完了，下面是译文的正文部分。&lt;/p&gt;
    
    </summary>
    
      <category term="响应式编程" scheme="http://lexburner.github.io/categories/%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="RxJava" scheme="http://lexburner.github.io/tags/RxJava/"/>
    
      <category term="Reactor" scheme="http://lexburner.github.io/tags/Reactor/"/>
    
  </entry>
  
  <entry>
    <title>关于阿里面试、学习路线、公众号的一些想法</title>
    <link href="http://lexburner.github.io/thinking-2/"/>
    <id>http://lexburner.github.io/thinking-2/</id>
    <published>2018-09-27T18:18:51.000Z</published>
    <updated>2019-01-12T11:57:12.894Z</updated>
    
    <content type="html"><![CDATA[<p>还记得上一篇记录我心情的随笔是写在离开魔都，去往南京的时候，此时的我，又来到了杭州。工作发生了变故，心境也发生了变化，倒是有不少东西想跟各位来聊一聊，择其三汇成此文。</p><a id="more"></a><h3 id="阿里面试"><a href="#阿里面试" class="headerlink" title="阿里面试"></a>阿里面试</h3><p>入职阿里第一天，我发了一条入职阿里的朋友圈，很多朋友发表了评论：羡慕，恭喜，也有一些前辈给了我忠告，首先在这儿谢谢大家。</p><p>微信群中自然有很多人会关注：“阿里面试都面了什么？有什么回答技巧吗？能不能分享下面经？”。但今天想跟大家说的是，我并不觉得分享那些面试题，甚至把答案都告诉你，会对你有多大的帮助。</p><p>其一，那是我的面试题，不是你的。每个人的工作经历不一样，合格的面试官必定是针对个人的简历进行提问，而不是地毯式的来一次 mq，redis，rpc，database，spring 的大扫荡。</p><p>其二，平时的知识储备，远胜于那些事先准备好答案的面试题。这和学生时代一样，成绩好的学霸即使期末不用复习，依旧可以考出高分；临时抱佛脚的学渣，大概率会在考试中露出马脚。众所周知，微信公众号文章中阅读量最高的往往是面经类文章，我群里有一名程序媛分享了一篇自己「阿里7面」的经历，一早上便有了 3000 多的阅读量。这背后很大程度是出于个人的焦虑，若你的知识储备不足，看的面试题越多，你就会越焦虑；反观我了解的那些技术水平不错的朋友，往往都对这些面试题嗤之以鼻。这背后反映出了一些问题，对于一些老生常谈的面试题，诸如“ConcurrentHashMap的原理”，“ThreadLocal的原理”，你即使回答的再好，我相信依旧称不上出彩；而对于一些技术的使用场景你能够说出自己的理解，那才是优秀之处，无招胜有招。</p><p>总结下这两点，无非就是想告诉那些新手玩家，面试并不存在什么奇技淫巧，那些在实战积累出来的经验，以及你自己探索源码获得的经验才是面试中的金子。如果你非要我说一两个注意点，那我反而觉得应聘部门的 HC 和面试官的心情更重要一些。</p><blockquote><p>你只是个孩子，你根本不晓得你在说什么。</p><p>我问你「艺术」，你可能会提出艺术书籍中的粗浅论调，有关米开朗基罗，你知道很多，他的满腔政治热情，他与教皇相交莫逆；但你不知道西斯汀教堂的气味，你从没站在那儿观赏美丽的天花板。</p><p>如果我问关于「女人」的事，你八成会说出个人偏好的谬论，你可能上过几次床，但你说不出在女人身旁醒来，那份内心幸福的滋味</p><p>当谈论「战争」，你会说出莎士比亚的话，“共赴战场，亲爱的朋友”。但你从未亲临战阵，从没把把挚友的头抱在膝盖里，看着他吸着最后一口气，凝望着你，希望你能够帮到他</p><p>我问你「爱情」，你会引述十四行诗，但你从未看过女人的脆弱，她能以双眼击倒你，感觉上帝让天使为你下凡，从地狱中拯救你。</p><p>— 心灵捕手</p></blockquote><h3 id="学习路线与技术标签"><a href="#学习路线与技术标签" class="headerlink" title="学习路线与技术标签"></a>学习路线与技术标签</h3><p>至于群友关于学习路线的建议，我还是打算在这一话题中提供一点我的看法，仅供参考。如果你是我博客的忠实读者，应当能够知道我的学习路线是什么样的。</p><ol><li>在初入职场实习时，主要的任务是巩固 Java 基础，那些 J2SE 的基础知识，不至于说精通源码，至少应该能做到侃侃而谈。这个过程，面很重要，所以适合看书，按照章节的梳理，知识点被串联在一起，日后可以将其对号入座。至于推荐书籍，新的旧的，差异不是很大，可以自行翻阅我博客中或者其他大V的推荐书单。</li><li>有些人觉得看视频很 low，切不要有这样的偏见，我一直觉得好的视频会给人非常直观的学习体验，虽说不如书籍高效，但学习起来十分轻松，我最近看的视频就包括闪电侠的 netty 源码解读以及小马哥的一些公开课视频，受益很多（互联网鄙视培训，但我初学时也看过传智播客和尚硅谷的一些培训视频，的确讲的很好，没什么丢人不丢人的，学到知识就是王道）</li><li>官方文档和源码，这是我目前学习新知识最主要的途径，话不多说，不愿意接受如此高效的学习方法的人，大多数是因为懒。</li></ol><p>如上可能还算不上学习路线，顶多算作学习方法，可以说是老生常谈的三点了，拿出来权当是强调一次。我理解的路线是一个人掌握了必备的 IT 基础技能之后，发展一到两个自己非常擅长的路线，如果做的足够的好，你的路线会成为你的技术标签，比如我的好友当中就不乏这样具有技术标签的人物，闪电侠的 netty，厮大的 mq，艿艿的源码解析，亚普的 96/调色大师/系统监控。再回到我自己，短期内，rpc 服务治理可能就是我打算走的路线。</p><h2 id="公众号的一些运营想法"><a href="#公众号的一些运营想法" class="headerlink" title="公众号的一些运营想法"></a>公众号的一些运营想法</h2><p>也是在最近一个月，粉丝数突破了 5000，我也创了自己的技术交流群「Kirito的技术分享」。我原本并没有创群的打算，一方面担心自己管理不好，另一方面是加入的微信交流群实在是太多，人员也存在很大程度的重叠。促使我创立交流群（或许称之为「小密圈」可能更为合适）的初衷我也给我的读者交代一下</p><blockquote><p>现在各个微信公众号的知识分享处于一种过剩的状态，优质的原创文，不走心的水文，面向于小白的基础文，广告贴，蹭时事热点的贴子…实在是鱼龙混杂，各个群里面铺天盖地的铺天盖地的文章，使得大家应接不暇。所以，我创了自己的交流圈，初衷便是和关注我的读者们安安静静地讨论文章中知识点和观点，我也并不排斥优质的原创文章，群规便有一点比较独特的地方：只建议推广<strong>个人</strong>的<strong>原创</strong>文章。</p></blockquote><p>关于互推和广告贴，我的个人原则是参与，不推广。互推文这种形式是指几个公众号的维护者一起发文，达到互相增粉的效果，由于微信公众号的文章是闭环的，推广的途径有限，而我希望更多的人能够看到我的文章，所以适度地互推是有必要的，我也希望读者能够不要排斥这种行为，一般我的标题就可以让你知道：这篇文章是一篇互推文，而一般互推文需要一定阅读量的支撑，点击阅读+关注互推的公众号，都是对我的支持，可以视自己的接受程度来决策。同理，还有广告贴，一般比较浮夸的标题就是广告跑不了了，同样是有阅读量的需求，广告商的经济鼓励会让博主有更大的动力创作优质的原创文章。</p><p>写作圈子里面也有一些坏味道，接广告的公众号瞧不起发水文的公众号，发水文的公众号眼红有广告的公众号，还有一些公众号存在刷粉，刷阅读量的行为，也有一些公众号存在不尊重原创的行为，我也聊聊自己的公众号价值观。</p><p>水文：不为了发文而发文，宁缺毋滥。拒绝写水文。</p><p>原创：转载需要在文首注明出处，第一时间告诉读者这是一篇转载的文章；翻译文章不能标注原创；转载他人博客的文章不得标明原创，他人主动要求除外；不洗文；多个公众号不要过度转载同样的文章，造成信息的过度消费；未经授权不要随意转载他人文章或标明侵删；微信公众号的转载文章可以不贴对方的二维码，因为微信文章下方自带导流链接。</p><p>广告：不做误人子弟的广告如 p2p 理财；不做标题党，明确这是一篇广告；适度</p><p>互推：确保互推中其他公众号的质量；适度</p><p>热点文：确认事实后再发文，不应煽动</p><p>毕竟道德、价值观这些个东西只能用来约束自己，不能用来约束别人，我只能向各位读者保证，我公众号运营的信条如上。</p><p>感谢各位读者的关注，今后无论多忙，我一定会坚持把博客写下去。</p><p>End</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;还记得上一篇记录我心情的随笔是写在离开魔都，去往南京的时候，此时的我，又来到了杭州。工作发生了变故，心境也发生了变化，倒是有不少东西想跟各位来聊一聊，择其三汇成此文。&lt;/p&gt;
    
    </summary>
    
      <category term="技术杂谈" scheme="http://lexburner.github.io/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="技术杂谈" scheme="http://lexburner.github.io/tags/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>Java随机数探秘</title>
    <link href="http://lexburner.github.io/java-random/"/>
    <id>http://lexburner.github.io/java-random/</id>
    <published>2018-09-12T11:47:28.000Z</published>
    <updated>2018-11-20T11:52:04.292Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文的前3节参考修改自微信公众号「咖啡拿铁」的文章，感谢李钊同学对这个话题热情的讨论。</p></blockquote><h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h3><p>一提到 Java 中的随机数，很多人就会想到 <code>Random</code>，当出现生成随机数这样需求时，大多数人都会选择使用 Random 来生成随机数。Random 类是线程安全的，但其内部使用 CAS 来保证线程安全性，在多线程并发的情况下的时候它的表现是存在优化空间的。在 JDK1.7 之后，Java 提供了更好的解决方案 ThreadLocalRandom，接下来，我们一起探讨下这几个随机数生成器的实现到底有何不同。</p><h3 id="2-Random"><a href="#2-Random" class="headerlink" title="2 Random"></a>2 Random</h3><p>Random 这个类是 JDK 提供的用来生成随机数的一个类，这个类并不是真正的随机，而是伪随机，伪随机的意思是生成的随机数其实是有一定规律的，而这个规律出现的周期随着伪随机算法的优劣而不同，一般来说周期比较长，但是可以预测。通过下面的代码我们可以对 Random 进行简单的使用: <img src="https://user-gold-cdn.xitu.io/2018/8/28/165808ef9aa120a4?w=875&amp;h=325&amp;f=png&amp;s=48454&amp;ynotemdtimestamp=1536657462341" alt="img"></p><h4 id="Random原理"><a href="#Random原理" class="headerlink" title="Random原理"></a>Random原理</h4><p>Random 中的方法比较多，这里就针对比较常见的 nextInt() 和 nextInt(int bound) 方法进行分析，前者会计算出 int 范围内的随机数，后者如果我们传入 10，那么他会求出 [0,10) 之间的 int 类型的随机数，左闭右开。我们首先看一下 Random() 的构造方法: <img src="https://user-gold-cdn.xitu.io/2018/8/29/165839a7af1b2bf4?w=1175&amp;h=1065&amp;f=png&amp;s=208341&amp;ynotemdtimestamp=1536657462341" alt="img"></p><p>可以发现在构造方法当中，根据当前时间的种子生成了一个 AtomicLong 类型的 seed，这也是我们后续的关键所在。</p><p>####nextInt()</p><p>nextInt() 的代码如下所示：</p><p> <img src="https://user-gold-cdn.xitu.io/2018/8/29/165835e5dc06e0b0?w=455&amp;h=253&amp;f=png&amp;s=17651&amp;ynotemdtimestamp=1536657462341" alt="img"></p><p>这个里面直接调用的是 next() 方法，传入的 32，代指的是 Int 类型的位数。</p><p><img src="https://user-gold-cdn.xitu.io/2018/8/29/16583a202542c345?w=1117&amp;h=565&amp;f=png&amp;s=109411&amp;ynotemdtimestamp=1536657462341" alt="img"></p><p>这里会根据 seed 当前的值，通过一定的规则(伪随机算法)算出下一个 seed，然后进行 CAS，如果 CAS 失败则继续循环上面的操作。最后根据我们需要的 bit 位数来进行返回。核心便是 CAS 算法。</p><h4 id="nextInt-int-bound"><a href="#nextInt-int-bound" class="headerlink" title="nextInt(int bound)"></a>nextInt(int bound)</h4><p>nextInt(int bound) 的代码如下所示：<img src="https://user-gold-cdn.xitu.io/2018/8/29/16583af1dc803706?w=1086&amp;h=772&amp;f=png&amp;s=120184&amp;ynotemdtimestamp=1536657462341" alt="img"></p><p>这个流程比 nextInt() 多了几步，具体步骤如下:</p><ol><li>首先获取 31 位的随机数，注意这里是 31 位，和上面 32 位不同，因为在 nextInt() 方法中可以获取到随机数可能是负数，而 nextInt(int bound) 规定只能获取到 [0,bound) 之前的随机数，也就意味着必须是正数，预留一位符号位，所以只获取了31位。(不要想着使用取绝对值这样操作，会导致性能下降)</li><li>然后进行取 bound 操作。</li><li>如果 bound 是2的幂次方，可以直接将第一步获取的值乘以 bound 然后右移31位，解释一下:如果 bound 是4，那么乘以4其实就是左移2位，其实就是变成了33位，再右移31位的话，就又会变成2位，最后，2位 int 的范围其实就是 [0,4) 了。</li><li>如果不是 2 的幂，通过模运算进行处理。</li></ol><h4 id="并发瓶颈"><a href="#并发瓶颈" class="headerlink" title="并发瓶颈"></a>并发瓶颈</h4><p>在我之前的文章中就有相关的介绍，一般而言，CAS 相比加锁有一定的优势，但并不一定意味着高效。一个立刻被想到的解决方案是每次使用 Random 时都去 new 一个新的线程私有化的 Random 对象，或者使用 ThreadLocal 来维护线程私有化对象，但除此之外还存在更高效的方案，下面便来介绍本文的主角 ThreadLocalRandom。</p><h3 id="3-ThreadLocalRandom"><a href="#3-ThreadLocalRandom" class="headerlink" title="3 ThreadLocalRandom"></a>3 ThreadLocalRandom</h3><p>在 JDK1.7 之后提供了新的类 ThreadLocalRandom 用来在并发场景下代替 Random。使用方法比较简单: </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ThreadLocalRandom.current().nextInt();</span><br><span class="line">ThreadLocalRandom.current().nextInt(<span class="number">10</span>);</span><br></pre></td></tr></table></figure><p>在 current 方法中有:</p><p><img src="https://user-gold-cdn.xitu.io/2018/8/29/16583ef88efdeb38?w=1115&amp;h=623&amp;f=png&amp;s=133206&amp;ynotemdtimestamp=1536657462341" alt="img">可以看见如果没有初始化会对其进行初始化，而这里我们的 seed 不再是一个全局变量，在我们的Thread中有三个变量: <img src="https://user-gold-cdn.xitu.io/2018/8/29/16584270d8e58e00?w=1309&amp;h=610&amp;f=png&amp;s=117360&amp;ynotemdtimestamp=1536657462341" alt="img"></p><ul><li>threadLocalRandomSeed：ThreadLocalRandom 使用它来控制随机数种子。</li><li>threadLocalRandomProbe：ThreadLocalRandom 使用它来控制初始化。</li><li>threadLocalRandomSecondarySeed：二级种子。</li></ul><p>可以看见所有的变量都加了 @sun.misc.Contended 这个注解，用来处理伪共享问题。</p><p>在 nextInt() 方法当中代码如下:</p><p><img src="https://user-gold-cdn.xitu.io/2018/8/29/165846e544b493ae?w=1089&amp;h=457&amp;f=png&amp;s=72760&amp;ynotemdtimestamp=1536657462341" alt="img"></p><p>我们的关键代码如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UNSAFE.putLong(t = Thread.currentThread(), SEED,r=UNSAFE.getLong(t, SEED) + GAMMA);</span><br></pre></td></tr></table></figure><p>可以看见由于我们每个线程各自都维护了种子，这个时候并不需要 CAS，直接进行 put，在这里利用线程之间隔离，减少了并发冲突；相比较 <code>ThreadLocal&lt;Random&gt;</code>，ThreadLocalRandom 不仅仅减少了对象维护的成本，其内部实现也更轻量级。所以 ThreadLocalRandom 性能很高。</p><h3 id="4-性能测试"><a href="#4-性能测试" class="headerlink" title="4 性能测试"></a>4 性能测试</h3><p>除了文章中详细介绍的 Random，ThreadLocalRandom，我还将 netty4 实现的 ThreadLocalRandom，以及 <code>ThreadLocal&lt;Random&gt;</code> 作为参考对象，一起参与 JMH 测评。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@BenchmarkMode</span>(&#123;Mode.AverageTime&#125;)</span><br><span class="line"><span class="meta">@OutputTimeUnit</span>(TimeUnit.NANOSECONDS)</span><br><span class="line"><span class="meta">@Warmup</span>(iterations = <span class="number">3</span>, time = <span class="number">5</span>)</span><br><span class="line"><span class="meta">@Measurement</span>(iterations = <span class="number">3</span>, time = <span class="number">5</span>)</span><br><span class="line"><span class="meta">@Threads</span>(<span class="number">50</span>)</span><br><span class="line"><span class="meta">@Fork</span>(<span class="number">1</span>)</span><br><span class="line"><span class="meta">@State</span>(Scope.Benchmark)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RandomBenchmark</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Random random = <span class="keyword">new</span> Random();</span><br><span class="line"></span><br><span class="line">    ThreadLocal&lt;Random&gt; threadLocalRandomHolder = ThreadLocal.withInitial(Random::<span class="keyword">new</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Benchmark</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">random</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> random.nextInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Benchmark</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">threadLocalRandom</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ThreadLocalRandom.current().nextInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Benchmark</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">threadLocalRandomHolder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> threadLocalRandomHolder.get().nextInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Benchmark</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">nettyThreadLocalRandom</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> io.netty.util.internal.ThreadLocalRandom.current().nextInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> RunnerException </span>&#123;</span><br><span class="line">        Options opt = <span class="keyword">new</span> OptionsBuilder()</span><br><span class="line">                .include(RandomBenchmark.class.getSimpleName())</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Runner(opt).run();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测评结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Benchmark                                Mode  Cnt     Score     Error  Units</span><br><span class="line">RandomBenchmark.nettyThreadLocalRandom   avgt    3   192.202 ± 295.897  ns/op</span><br><span class="line">RandomBenchmark.random                   avgt    3  3197.620 ± 380.981  ns/op</span><br><span class="line">RandomBenchmark.threadLocalRandom        avgt    3    90.731 ±  39.098  ns/op</span><br><span class="line">RandomBenchmark.threadLocalRandomHolder  avgt    3   229.502 ± 267.144  ns/op</span><br></pre></td></tr></table></figure><p>从上图可以发现，JDK1.7 的 <code>ThreadLocalRandom</code> 取得了最好的成绩，仅仅需要 90 ns 就可以生成一次随机数，netty 实现的<code>ThreadLocalRandom</code>  以及使用 ThreadLocal 维护 Random 的方式差距不是很大，位列 2、3 位，共享的 Random 变量则效果最差。</p><p>可见，在并发场景下，ThreadLocalRandom 可以明显的提升性能。</p><h3 id="5-注意点"><a href="#5-注意点" class="headerlink" title="5 注意点"></a>5 注意点</h3><p>注意，ThreadLocalRandom 切记不要调用 current 方法之后，作为共享变量使用</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WrongCase</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    ThreadLocalRandom threadLocalRandom = ThreadLocalRandom.current();</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">concurrentNextInt</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> threadLocalRandom.nextInt();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是因为 ThreadLocalRandom.current() 会使用初始化它的线程来填充随机种子，这会带来导致多个线程使用相同的 seed。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ThreadLocalRandom threadLocalRandom = ThreadLocalRandom.current();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)</span><br><span class="line">        <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(threadLocalRandom.nextInt());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出相同的随机数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br><span class="line">-1667209487</span><br></pre></td></tr></table></figure><p>请在确保不同线程获取不同的 seed，最简单的方式便是每次调用都是使用 current()：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RightCase</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">concurrentNextInt</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ThreadLocalRandom.current().nextInt();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="彩蛋1"><a href="#彩蛋1" class="headerlink" title="彩蛋1"></a>彩蛋1</h3><p>梁飞博客中一句话常常在我脑海中萦绕：魔鬼在细节中。优秀的代码都是一个个小细节堆砌出来，今天介绍的 ThreadLocalRandom 也不例外。</p><p><img src="http://kirito.iocoder.cn/image-20180911184147013.png" alt="dubbo"></p><p>在 incubator-dubbo-2.7.0 中，随机负载均衡器的一个小改动便是将 Random 替换为了 ThreadLocalRandom，用于优化并发性能。</p><h3 id="彩蛋2"><a href="#彩蛋2" class="headerlink" title="彩蛋2"></a>彩蛋2</h3><p>ThreadLocalRandom 的 nextInt(int bound) 方法中，当 bound 不为 2 的幂次方时，使用了一个循环来修改 r 的值，我认为这可能不必要，你觉得呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">nextInt</span><span class="params">(<span class="keyword">int</span> bound)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (bound &lt;= <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(BadBound);</span><br><span class="line">    <span class="keyword">int</span> r = mix32(nextSeed());</span><br><span class="line">    <span class="keyword">int</span> m = bound - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> ((bound &amp; m) == <span class="number">0</span>) <span class="comment">// power of two</span></span><br><span class="line">        r &amp;= m;</span><br><span class="line">    <span class="keyword">else</span> &#123; <span class="comment">// reject over-represented candidates</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> u = r &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">             u + m - (r = u % bound) &lt; <span class="number">0</span>;</span><br><span class="line">             u = mix32(nextSeed()) &gt;&gt;&gt; <span class="number">1</span>)</span><br><span class="line">            ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>欢迎关注李钊同学的微信公众号：「咖啡拿铁」</strong></p><p><img src="http://kirito.iocoder.cn/image-20180911185754582.png" alt="咖啡拿铁"></p><p><strong>当然，也欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文的前3节参考修改自微信公众号「咖啡拿铁」的文章，感谢李钊同学对这个话题热情的讨论。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1 前言&quot;&gt;
      
    
    </summary>
    
      <category term="JAVA并发合集" scheme="http://lexburner.github.io/categories/JAVA%E5%B9%B6%E5%8F%91%E5%90%88%E9%9B%86/"/>
    
    
      <category term="JAVA" scheme="http://lexburner.github.io/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>Spring中的XML schema扩展机制</title>
    <link href="http://lexburner.github.io/spring-xsd/"/>
    <id>http://lexburner.github.io/spring-xsd/</id>
    <published>2018-09-03T11:47:28.000Z</published>
    <updated>2018-11-20T11:54:20.843Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>很久没有写关于 Spring 的文章了，最近在系统梳理 Dubbo 代码的过程中发现了 XML schema 这个被遗漏的知识点。由于工作中使用 SpringBoot 比较多的原因，几乎很少接触 XML，此文可以算做是亡羊补牢，另一方面，也为后续的 Dubbo 源码解析做个铺垫。</p><p>XML schema 扩展机制是啥？这并不是一块很大的知识点，翻阅一下 Spring 的文档，我甚至没找到一个贯穿上下文的词来描述这个功能，<code>XML Schema Authoring</code> 是文档中对应的标题，简单来说：<br><a id="more"></a></p><blockquote><p>Spring 为基于 XML 构建的应用提供了一种扩展机制，用于定义和配置 Bean。 它允许使用者编写自定义的 XML bean 解析器，并将解析器本身以及最终定义的 Bean 集成到 Spring IOC 容器中。</p></blockquote><p><img src="http://kirito.iocoder.cn/image-20180903175207354.png" alt="dubbo.xml"></p><p>Dubbo 依赖了 Spring，并提供了一套自定义的 XML 标签，<code>&lt;dubbo:application&gt;</code> ,<code>&lt;dubbo:registry&gt;</code> ,<code>&lt;dubbo:protocol&gt;</code>,<code>&lt;dubbo:service&gt;</code>。作为使用者，大多数人只需要关心这些参数如何配置，但不知道有没有人好奇过，它们是如何加载进入 Spring 的 IOC 容器中被其他组件使用的呢？这便牵扯出了今天的主题：Spring 对 XML schema 的扩展支持。</p><h3 id="自定义-XML-扩展"><a href="#自定义-XML-扩展" class="headerlink" title="自定义 XML 扩展"></a>自定义 XML 扩展</h3><p>为了搞懂 Spring 的 XML 扩展机制，最直接的方式便是实现一个自定义的扩展。实现的步骤也非常简单，分为四步：</p><ol><li>编写一个 XML schema 文件描述的你节点元素。</li><li>编写一个 <code>NamespaceHandler</code> 的实现类</li><li>编写一个或者多个 <code>BeanDefinitionParser</code> 的实现 (关键步骤).</li><li>注册上述的 schema 和 handler。</li></ol><p>我们的目的便是想要实现一个 <code>kirito XML schema</code>，我们的项目中可以自定义 kirito.xml，在其中会以 kirito 为标签来定义不同的类，并在最终的测试代码中验证这些声明在 kirito.xml 的类是否被 Spring 成功加载。大概像这样，是不是和 dubbo.xml 的格式很像呢？</p><p><img src="http://kirito.iocoder.cn/image-20180903180938053.png" alt="kirito.xml"></p><h3 id="动手实现"><a href="#动手实现" class="headerlink" title="动手实现"></a>动手实现</h3><p>有了明确的目标，我们逐步开展自己的工作。</p><h4 id="1-编写kirito-xsd"><a href="#1-编写kirito-xsd" class="headerlink" title="1 编写kirito.xsd"></a>1 编写kirito.xsd</h4><p><strong>resources/META-INF/kirito.xsd</strong> </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">xsd:schema</span> <span class="attr">xmlns</span>=<span class="string">"http://www.cnkirito.moe/schema/kirito"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">xmlns:xsd</span>=<span class="string">"http://www.w3.org/2001/XMLSchema"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">xmlns:beans</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">targetNamespace</span>=<span class="string">"http://www.cnkirito.moe/schema/kirito"</span>&gt;</span>  ①</span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">xsd:import</span> <span class="attr">namespace</span>=<span class="string">"http://www.springframework.org/schema/beans"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">xsd:element</span> <span class="attr">name</span>=<span class="string">"application"</span>&gt;</span> ②</span><br><span class="line">        <span class="tag">&lt;<span class="name">xsd:complexType</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">xsd:complexContent</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">xsd:extension</span> <span class="attr">base</span>=<span class="string">"beans:identifiedType"</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">xsd:attribute</span> <span class="attr">name</span>=<span class="string">"name"</span> <span class="attr">type</span>=<span class="string">"xsd:string"</span> <span class="attr">use</span>=<span class="string">"required"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">xsd:extension</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">xsd:complexContent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">xsd:complexType</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">xsd:element</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">xsd:element</span> <span class="attr">name</span>=<span class="string">"service"</span>&gt;</span> ②</span><br><span class="line">        <span class="tag">&lt;<span class="name">xsd:complexType</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">xsd:complexContent</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">xsd:extension</span> <span class="attr">base</span>=<span class="string">"beans:identifiedType"</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">xsd:attribute</span> <span class="attr">name</span>=<span class="string">"name"</span> <span class="attr">type</span>=<span class="string">"xsd:string"</span> <span class="attr">use</span>=<span class="string">"required"</span>/&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">xsd:extension</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">xsd:complexContent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">xsd:complexType</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">xsd:element</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">xsd:schema</span>&gt;</span></span><br></pre></td></tr></table></figure><p>① 注意这里的 <code>targetNamespace=&quot;http://www.cnkirito.moe/schema/kirito&quot;</code> 这便是之后 kirito 标签的关键点。</p><p>② kirito.xsd 定义了两个元素： application 和 service，出于简单考虑，都只有一个 name 字段。</p><blockquote><p>schema 的意义在于它可以和 eclipse/IDEA 这样智能化的集成开发环境形成很好的搭配，在编辑 XML 的过程中，用户可以获得告警和提示。 如果配置得当，可以使用自动完成功能让用户在事先定义好的枚举类型中进行选择。</p></blockquote><h4 id="2-编写KiritoNamespaceHandler"><a href="#2-编写KiritoNamespaceHandler" class="headerlink" title="2 编写KiritoNamespaceHandler"></a>2 编写KiritoNamespaceHandler</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KiritoNamespaceHandler</span> <span class="keyword">extends</span> <span class="title">NamespaceHandlerSupport</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.registerBeanDefinitionParser(<span class="string">"application"</span>, <span class="keyword">new</span> KiritoBeanDefinitionParser(ApplicationConfig.class));</span><br><span class="line">        <span class="keyword">super</span>.registerBeanDefinitionParser(<span class="string">"service"</span>, <span class="keyword">new</span> KiritoBeanDefinitionParser(ServiceBean.class));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成 schema 之后，还需要一个 NamespaceHandler 来帮助 Spring 解析 XML 中不同命名空间的各类元素。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">kirito:application</span> <span class="attr">name</span>=<span class="string">"kirito"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dubbo:application</span> <span class="attr">name</span>=<span class="string">"dubbo"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">motan:application</span> <span class="attr">name</span>=<span class="string">"motan"</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>不同的命名空间需要不同的 NamespaceHandler 来处理，在今天的示例中，我们使用 KiritoNamespaceHandler 来解析 kirito 命名空间。KiritoNamespaceHandler 继承自 NamespaceHandlerSupport 类，并在其 init() 方法中注册了两个 BeanDefinitionParser ，用于解析 kirito 命名空间/kirito.xsd 约束中定义的两个元素：application，service。BeanDefinitionParser 是下一步的主角，我们暂且跳过，将重心放在父类 NamespaceHandlerSupport 之上。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">NamespaceHandler</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function">BeanDefinition <span class="title">parse</span><span class="params">(Element element, ParserContext parserContext)</span></span>;</span><br><span class="line">   <span class="function">BeanDefinitionHolder <span class="title">decorate</span><span class="params">(Node source, BeanDefinitionHolder definition, ParserContext parserContext)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NamespaceHandlerSupport 是 NamespaceHandler 命名空间处理器的抽象实现，我粗略看了NamespaceHandler 的几个实现类，parse 和 decorate 方法可以完成元素节点的组装并通过 ParserContext 注册到 Ioc 容器中，但实际我们并没有调用这两个方法，而是通过 init() 方法注册 BeanDefinitionParser 来完成解析节点以及注册 Bean 的工作，所以对于 NamespaceHandler，我们主要关心 init 中注册的两个 BeanDefinitionParser 即可。</p><h4 id="3-编写KiritoBeanDefinitionParser"><a href="#3-编写KiritoBeanDefinitionParser" class="headerlink" title="3 编写KiritoBeanDefinitionParser"></a>3 编写KiritoBeanDefinitionParser</h4><p>在文章开始我们便标记到 BeanDefinitionParser 是最为关键的一环，每一个 BeanDefinitionParser 实现类都负责一个映射，将一个 XML 节点解析成 IOC 容器中的一个实体类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KiritoBeanDefinitionParser</span> <span class="keyword">implements</span> <span class="title">BeanDefinitionParser</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Class&lt;?&gt; beanClass;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">KiritoBeanDefinitionParser</span><span class="params">(Class&lt;?&gt; beanClass)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.beanClass = beanClass;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> BeanDefinition <span class="title">parse</span><span class="params">(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass)</span> </span>&#123;</span><br><span class="line">        RootBeanDefinition beanDefinition = <span class="keyword">new</span> RootBeanDefinition();</span><br><span class="line">        beanDefinition.setBeanClass(beanClass);</span><br><span class="line">        beanDefinition.setLazyInit(<span class="keyword">false</span>);</span><br><span class="line">        String name = element.getAttribute(<span class="string">"name"</span>);</span><br><span class="line">        beanDefinition.getPropertyValues().addPropertyValue(<span class="string">"name"</span>, name);</span><br><span class="line">        parserContext.getRegistry().registerBeanDefinition(name, beanDefinition);</span><br><span class="line">        <span class="keyword">return</span> beanDefinition;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> BeanDefinition <span class="title">parse</span><span class="params">(Element element, ParserContext parserContext)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> parse(element, parserContext, beanClass);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于我们的实体类是非常简单的，所以不存在很复杂的解析代码，而实际项目中，往往需要大量的解析步骤。parse 方法会解析一个个 XML 中的元素，使用 RootBeanDefinition 组装成对象，并最终通过 parserContext 注册到 IOC 容器中。</p><p>至此，我们便完成了 XML 文件中定义的对象到 IOC 容器的映射。</p><h4 id="4-注册schema和handler"><a href="#4-注册schema和handler" class="headerlink" title="4 注册schema和handler"></a>4 注册schema和handler</h4><p>最后一步还需要通知 Spring，告知其自定义 schema 的所在之处以及对应的处理器。</p><p><strong>resources/META-INF/spring.handlers</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http\://www.cnkirito.moe/schema/kirito=moe.cnkirito.sample.xsd.KiritoNamespaceHandler</span><br></pre></td></tr></table></figure><p><strong>resources/META-INF/spring.schemas</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http\://www.cnkirito.moe/schema/kirito/kirito.xsd=META-INF/kirito.xsd</span><br></pre></td></tr></table></figure><p>没有太多可以说的，需要遵守 Spring 的约定。</p><p>至此一个自定义的 XML schema 便扩展完成了，随后来验证一下。</p><h3 id="验证扩展"><a href="#验证扩展" class="headerlink" title="验证扩展"></a>验证扩展</h3><p>我们首先定义好 kirito.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:kirito</span>=<span class="string">"http://www.cnkirito.moe/schema/kirito"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xsi:schemaLocation</span>=<span class="string">" http://www.springframework.org/schema/beans</span></span></span><br><span class="line"><span class="tag"><span class="string">                                http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">                                http://www.cnkirito.moe/schema/kirito</span></span></span><br><span class="line"><span class="tag"><span class="string">                                http://www.cnkirito.moe/schema/kirito/kirito.xsd"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">kirito:application</span> <span class="attr">name</span>=<span class="string">"kirito-demo-application"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">kirito:service</span> <span class="attr">name</span>=<span class="string">"kirito-demo-service"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure><p>使用 Spring 去加载它，并验证 IOC 容器中是否存在注册成功的 Bean。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@ImportResource</span>(locations = &#123;<span class="string">"classpath:kirito.xml"</span>&#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">XmlSchemaAuthoringSampleApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ConfigurableApplicationContext applicationContext = SpringApplication.run(XmlSchemaAuthoringSampleApplication.class, args);</span><br><span class="line">        ServiceBean serviceBean = applicationContext.getBean(ServiceBean.class);</span><br><span class="line">        System.out.println(serviceBean.getName());</span><br><span class="line">        ApplicationConfig applicationConfig = applicationContext.getBean(ApplicationConfig.class);</span><br><span class="line">        System.out.println(applicationConfig.getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>观察控制台的输出：</p><blockquote><p>kirito-demo-service<br>kirito-demo-application</p></blockquote><p>一个基础的基于 XML schema 的扩展便完成了。</p><h3 id="Dubbo中的XML-schema扩展"><a href="#Dubbo中的XML-schema扩展" class="headerlink" title="Dubbo中的XML schema扩展"></a>Dubbo中的XML schema扩展</h3><p>最后我们以 Dubbo 为例，看看一个成熟的 XML schema 扩展是如何被应用的。</p><p><img src="http://kirito.iocoder.cn/image-20180903190429383.png" alt="Dubbo中的应用"></p><p>刚好对应了四个标准的扩展步骤，是不是对 XML 配置下的 Dubbo 应用有了更好的理解了呢？</p><p>顺带一提，仅仅完成 Bean 的注册还是不够的，在“注册”的同时，Dubbo 还进行了一系列其他操作如：暴露端口，开启服务器，完成注册中心的注册，生成代理对象等等行为，由于不在本文的范围内，后续的 Dubbo 专题会专门介绍这些细节，本文便是了解 Dubbo 加载流程的前置文章了。</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;很久没有写关于 Spring 的文章了，最近在系统梳理 Dubbo 代码的过程中发现了 XML schema 这个被遗漏的知识点。由于工作中使用 SpringBoot 比较多的原因，几乎很少接触 XML，此文可以算做是亡羊补牢，另一方面，也为后续的 Dubbo 源码解析做个铺垫。&lt;/p&gt;
&lt;p&gt;XML schema 扩展机制是啥？这并不是一块很大的知识点，翻阅一下 Spring 的文档，我甚至没找到一个贯穿上下文的词来描述这个功能，&lt;code&gt;XML Schema Authoring&lt;/code&gt; 是文档中对应的标题，简单来说：&lt;br&gt;
    
    </summary>
    
      <category term="Spring" scheme="http://lexburner.github.io/categories/Spring/"/>
    
    
      <category term="Spring" scheme="http://lexburner.github.io/tags/Spring/"/>
    
      <category term="XML" scheme="http://lexburner.github.io/tags/XML/"/>
    
  </entry>
  
  <entry>
    <title>JCTools -- 高性能内存队列探秘(写作中...)</title>
    <link href="http://lexburner.github.io/high-performance-queue/"/>
    <id>http://lexburner.github.io/high-performance-queue/</id>
    <published>2018-09-01T11:47:28.000Z</published>
    <updated>2018-11-20T11:51:40.693Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Benchmark                    (burstSize)  (qCapacity)            (queueType)  Mode  Cnt        Score        Error  Units</span><br><span class="line">QueueBenchmark.offerAndPoll       100000       132000     ArrayBlockingQueue  avgt   15  3746839.904 ± 214308.618  ns/op</span><br><span class="line">QueueBenchmark.offerAndPoll       100000       132000    LinkedBlockingQueue  avgt   15  6537598.922 ± 611003.544  ns/op</span><br><span class="line">QueueBenchmark.offerAndPoll       100000       132000  ConcurrentLinkedQueue  avgt   15  2944479.279 ±  41621.277  ns/op</span><br><span class="line">QueueBenchmark.offerAndPoll       100000       132000         MpscArrayQueue  avgt   15  1199839.760 ±  65991.348  ns/op</span><br></pre></td></tr></table></figure><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class
      
    
    </summary>
    
      <category term="JAVA并发合集" scheme="http://lexburner.github.io/categories/JAVA%E5%B9%B6%E5%8F%91%E5%90%88%E9%9B%86/"/>
    
    
      <category term="JCTools" scheme="http://lexburner.github.io/tags/JCTools/"/>
    
      <category term="队列" scheme="http://lexburner.github.io/tags/%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>如何向开源项目做贡献(以incubator-dubbo为例)</title>
    <link href="http://lexburner.github.io/contribute-to-opensource/"/>
    <id>http://lexburner.github.io/contribute-to-opensource/</id>
    <published>2018-08-22T11:47:28.000Z</published>
    <updated>2018-11-20T11:50:55.213Z</updated>
    
    <content type="html"><![CDATA[<p>Github 上有众多优秀的开源项目，大多数 IT 从业者将其当做了予取予求的工具库，遇到什么需求，先去 Github 搜一把，但有没有想过有一天自己也可以给开源事业做一些贡献呢？本文将会以 incubator-dubbo 项目为例，向你阐释，给开源项目做贡献并不是一件难事。<br><a id="more"></a></p><h3 id="1-为何要给开源贡献力量"><a href="#1-为何要给开源贡献力量" class="headerlink" title="1 为何要给开源贡献力量"></a>1 为何要给开源贡献力量</h3><p>为开源项目做贡献得到的收益是多方面的，为了让你有足够的信心加入到开源项目中，我在文章最开始列举出它的诸多好处。</p><h4 id="1-1-巩固技能"><a href="#1-1-巩固技能" class="headerlink" title="1.1 巩固技能"></a>1.1 巩固技能</h4><p>无论你是提交代码，撰写文档，提交 Issue，组织活动，当你切身参与到一个开源项目中，相关的技能都会得到历练，并且在开源项目中找到自己的位置。一方面，日常工作中我们中的大多数人接触到的是业务场景，并没有太多机会接触到基础架构组件，开源项目为我们提供了一个平台，在这里，你可以尽情挑选自己熟悉的项目为它添砖加瓦（以 Dubbo 为例，并不是所有 IT 公司都有能力自研服务治理框架）；另一方面，你所提交的代码，会有管理员协助审核，他们会给出专业的建议，更好的代码规范以及更优的编程思路最终都会变成你的经验。</p><h4 id="1-2-结交朋友"><a href="#1-2-结交朋友" class="headerlink" title="1.2 结交朋友"></a>1.2 结交朋友</h4><p>开源社区为你提供了一个平台，在这里，你可以认识很多纯粹的技术爱好者，开源贡献者是最符合 geek 定义的那群人，你所接触到的往往是某个领域最厉害的那批人。</p><h4 id="1-3-建立口碑"><a href="#1-3-建立口碑" class="headerlink" title="1.3 建立口碑"></a>1.3 建立口碑</h4><p>这是一个很好的展示个人实力的地方，俗话说：talk is cheap，show me the code. 作为技术人员，没有什么比一个漂亮的 Github 主页更有说服力的了。如果你能够为开源项目做出可观的贡献，你也将收获到业界的知名度，此时开源项目的成就和你是密不可分的。</p><h4 id="1-4-传承开源精神"><a href="#1-4-传承开源精神" class="headerlink" title="1.4 传承开源精神"></a>1.4 传承开源精神</h4><p>只有源源不断的贡献者给开源项目添砖加瓦，才可以为 Github 一类的开源社区形成良好的开源风气。否则，只有输出没有输入，开源会失去活力。</p><h4 id="1-5-养成习惯"><a href="#1-5-养成习惯" class="headerlink" title="1.5 养成习惯"></a>1.5 养成习惯</h4><p>相信我，一旦养成了每天提交代码的习惯，就像你不想中断打卡一样，你绝不想中断 commit。不止有英语打卡，健身打卡，还有开源打卡！</p><p><img src="http://kirito.iocoder.cn/image-20180827141007663.png" alt="开源程序员的日常"></p><h3 id="2-贡献代码时的一些疑难杂症"><a href="#2-贡献代码时的一些疑难杂症" class="headerlink" title="2 贡献代码时的一些疑难杂症"></a>2 贡献代码时的一些疑难杂症</h3><p>如果你是一名开源界的新手，可能会对贡献的流程心生畏惧。比如：我该怎么修改代码并提交？我的代码要是存在bug怎么办？我的代码别人会不会很 low？我该如何寻找合适的开源项目？开源社区那么多的工具和词汇都是什么意思？</p><p>文章的第二部分将从一个<strong>小白</strong>的角度，介绍一下开源中的一些常见问题。</p><h4 id="2-1-git-常规操作"><a href="#2-1-git-常规操作" class="headerlink" title="2.1 git 常规操作"></a>2.1 git 常规操作</h4><p>一般而言，我们选择使用 git 来作为版本管理的工具，你不一定要非常熟练的使用它，在我看来掌握 clone，add，commit，pull，push 即可，遇到复杂的场景，你还有谷歌。</p><p><strong>fork 与 clone</strong></p><p><img src="http://kirito.iocoder.cn/image-20180827143942178.png" alt="fork 与 clone"></p><p>如果你只是想下载源码，查看他的源码实现，使用 Clone or download 按钮即可。</p><p>如果你想要给开源项目做改动，并且最终请求合并，让开源项目存在你贡献的代码，就应该使用 fork。</p><p>fork 将会复制一份当前主分支的代码进入到你的仓库中，之后你所有的修改，应当基于自己的仓库进行，在功能开发/bug 修复之后，可以使用你的仓库向源仓库提交 pull request。只有源仓库的管理员才有权利合并你的请求。</p><p>一些可能对你有帮助的高级指令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 设置源仓库</span><br><span class="line">git remote add upstream https://github.com/apache/incubator-dubbo.git</span><br><span class="line"><span class="meta">#</span> 拉取源仓库的更新</span><br><span class="line">git fetch upstream</span><br><span class="line"><span class="meta">#</span> 将自己仓库的主分支合并源仓库的更新</span><br><span class="line">git checkout master</span><br><span class="line">git merge upstream/master</span><br></pre></td></tr></table></figure><p><strong>pull request</strong></p><p><img src="http://kirito.iocoder.cn/image-20180827150703869.png" alt="pull request"></p><p>pull request 经常被缩写为 PR，指的是一次向源仓库请求合并的行为，如上是我 fork 了 incubator-dubbo 的仓库之后才存在的操作按钮。</p><p><strong>源仓库视角的 pull request</strong></p><p><img src="http://kirito.iocoder.cn/image-20180827155239155.png" alt="pull request management"></p><p>管理者会对 pull request 涉及的改动进行 review，以确保你的代码是符合规范的，逻辑有没有偏差，以及符合框架的功能需求。</p><h4 id="2-2-Travis-CI"><a href="#2-2-Travis-CI" class="headerlink" title="2.2 Travis CI"></a>2.2 Travis CI</h4><p>一些自动化的 CI 流程被植入在每一次 pull request 的构建之中，用于给开源仓库去校验提交者的代码是否符合既定的规范，如：是否有编译问题，单元测试是否通过，覆盖率是否达标，代码风格是否合规等等。</p><p><img src="http://kirito.iocoder.cn/image-20180827160503114.png" alt="CI报告"></p><p>一般情况下，必须通过 CI，你的 pull request 才会被管理 review。</p><h4 id="2-3-Mailing-list"><a href="#2-3-Mailing-list" class="headerlink" title="2.3 Mailing list"></a>2.3 Mailing list</h4><p>每个开源项目都会有自己的贡献规范，可以参考首页的 Contributing，来获取具体的信息。incubator-dubbo 作为一个孵化中的 apache 项目，遵守了 apache 的传统，在 <a href="https://github.com/apache/incubator-dubbo/blob/master/CONTRIBUTING.md" target="_blank" rel="noopener">Contributing</a> 中描述道：当你有新特性想要贡献给 Dubbo 时，官方推荐使用 Mailing list 的方式描述一遍你想要做的改动。</p><p>Mailing list 简单来说，就是一个邮件通知机制，所有的 Dubbo 开发者都会订阅该邮箱：<a href="mailto:dev@dubbo.incubator.apache.org" target="_blank" rel="noopener">dev@dubbo.incubator.apache.org</a>。有任何新特性的改动，或者什么建议想要通知其他开发者，都可以通过向该邮箱发送邮件来达到这个目的，相同地，你也会收到其转发的其他开发者的邮件。</p><p>或者你是一个 Dubbo 的使用者，你想要得知开发者的改造方向，也可以订阅，这个<a href="https://github.com/apache/incubator-dubbo/wiki/Mailing-list-subscription-guide" target="_blank" rel="noopener">指南</a>可以帮助你订阅 Dubbo 的 Mailing list。</p><blockquote><p>作为一个 modern developer，你可能觉得 mailing list 的交流方式存在滞后性，这样的沟通方式不是特别的高效，但它作为 apache 项目的推荐交流方式存在其特殊的原因，在此不多赘述。总之遵循一个原则：bug fix或者讨论，可以在 github issue 中进行，影响较大的特性和讨论则推荐在 mailing list 中展开。</p></blockquote><h3 id="3-其他贡献形式"><a href="#3-其他贡献形式" class="headerlink" title="3 其他贡献形式"></a>3 其他贡献形式</h3><p>不仅仅只有贡献代码，修复 bug 等行为才算作为开源做贡献，以下这些行为也属于主要形式：</p><h4 id="3-1-撰写文档"><a href="#3-1-撰写文档" class="headerlink" title="3.1 撰写文档"></a>3.1 撰写文档</h4><p> <a href="http://dubbo.apache.org/zh-cn/" target="_blank" rel="noopener">Dubbo文档</a>是其开源组成成分的重要一环，其内容源文件位于：<a href="https://github.com/apache/incubator-dubbo-website。同样也是一个" target="_blank" rel="noopener">https://github.com/apache/incubator-dubbo-website。同样也是一个</a> Git 仓库，任何你想要对 dubbo 知识点的补充，都可以在这儿提交 pull request，只需要一些 markdown 的语法知识，和一些可有可无的 npm 语法即可。如果你觉得贡献代码对于现在的自己仍然有点难度，不妨从贡献文档开始接触开源。</p><h4 id="3-2-ISSUE"><a href="#3-2-ISSUE" class="headerlink" title="3.2 ISSUE"></a>3.2 ISSUE</h4><p>无论是 Github 中的 Issue 还是 mailing list 中的讨论，无论是提出问题，汇报 bug，还是回答问题（bugfix 则不仅仅需要 Issue 了），协助管理者 review pull request，都是贡献的一种形式，勿以善小而不为。</p><h4 id="3-3-其他行为"><a href="#3-3-其他行为" class="headerlink" title="3.3 其他行为"></a>3.3 其他行为</h4><p>任何你能够想到的，可以帮助开源项目变得更好的的行为，都属于开源贡献。例如，给每个 Issue 打上合适的 tag，关闭重复的 Issue，链接相关联的 Issue，线下组织沙龙，回答 Stack Overflow 上相关的问题，以及文档中一个错别字的修改等等。</p><h3 id="4-开源最佳实践"><a href="#4-开源最佳实践" class="headerlink" title="4 开源最佳实践"></a>4 开源最佳实践</h3><h4 id="4-1-有效沟通"><a href="#4-1-有效沟通" class="headerlink" title="4.1 有效沟通"></a>4.1 有效沟通</h4><p>无论你处于什么样的目的：仅仅是一次性的贡献，亦或是永久性的加入社区，都的和他人进行沟通和交往，这是你要在开源圈发展必须修炼的技能。</p><p>在你开启一个isse或PR之前，或者是在聊天室问问题之前，请牢记下面所列出的几点建议，会让你的工作更加的高效。</p><p><strong>给出上下文</strong> 以便于让其他人能够快速的理解。比方说你运行程序时遇到一个错误，要解释你是如何做的，并描述如何才能再现错误现象。又比方说你是提交一个新的想法，要解释你为什么这么想，对于项目有用处吗（不仅仅是只有你！）</p><blockquote><p>😇 <em>“当我做 Y 的时候 X 不能工作”</em></p><p>😢 <em>“X 出问题! 请修复它。”</em></p></blockquote><p><strong>在进一步行动前，做好准备工作。</strong> 不知道没关系，但是要展现你尝试过、努力过。在寻求帮助之前，请确认阅读了项目的 README、文档、问题（开放的和关闭的）、邮件列表，并搜索了网络。当你表现出很强烈的求知欲的时候，人们是非常欣赏这点的，会很乐意的帮助你。</p><blockquote><p>😇 <em>“我不确定 X 是如何实现的，我查阅了相关的帮助文档，然而毫无所获。”</em></p><p>😢 <em>“我该怎么做 X ?”</em></p></blockquote><p><strong>保持请求内容短小而直接。</strong> 正如发送一份邮件，每一次的贡献，无论是多么的简单，都是需要他人去查阅的。很多项目都是请求的人多，提供帮助的人少。相信我，保持简洁，你能得到他人帮助的机会会大大的增加。</p><blockquote><p>😇 <em>“我很乐意写 API 教程。”</em></p><p>😢 <em>” 有一天我驾驶汽车行驶在高速公路上，在某个加油站加油的时候，突发奇想，我们应该这么做，不过在我进一步解释之前，我先和大家展示一下。。。”</em></p></blockquote><p><strong>让所有的沟通都是在公开场合下进行。</strong> 哪怕是很不起眼的小事，也不要去给维护者发私信，除非是你要分享一些敏感信息（诸如安全问题或严重的过失）。你若能够保持谈话是公开的，很多人可以你们交换的意见中学习和受益。</p><blockquote><p>😇 <em>(评论) “@维护者 你好！我们该如何处理这个PR？”</em></p><p>😢 <em>(邮件) “你好，非常抱歉给发信，但是我实在很希望你能看一下我提交的PR。”</em></p></blockquote><p><strong>大胆的提问（但是要谨慎！）。</strong> 每个人参与社区，开始的时候都是新手，哪怕是非常有经验的贡献者也一样，在刚进入一个新的项目的时候，也是新手。出于同样的原因,甚至长期维护人员并不总是熟悉一个项目的每一部分。给他们同样的耐心,你也会得到同样的回报。</p><blockquote><p>😇 <em>“感谢查看了这个错误，我按照您的建议做了，这是输出结果。”</em></p><p>😢 <em>“你为什么不修复我的问题？这难道不是你的项目吗？”</em></p></blockquote><p><strong>尊重社区的决定。</strong> 你的想法可能会和社区的优先级、愿景等有差异，他们可能对于你的想法提供了反馈和最后的决定的理由，这时你应该去积极的讨论，并寻求妥协的办法，维护者必须慎重的考虑你的想法。但是如果你实在是不能同意社区的做法，你可以坚持自己！保持自己的分支，或者另起炉灶。</p><blockquote><p>😇 <em>“你不能支持我的用例，我蛮失望，但是你的解释仅仅是对一小部分用户起作用，我理解是为什么。感谢你的耐心倾听。”</em></p><p>😢 <em>“你为什么不支持我的用例？这是不可接受的！”</em></p></blockquote><p><strong>以上几点，要铭记在心。</strong> 开源是由来自世界各地的人们共同协作实现的。面临的问题是跨语言、跨文化、不同的地理为止、不同的时区，另外，撰写文字的沟通更是难上加难，无法传达语气和情绪。请让这些会话都充满善意吧！在以下情形中请保持礼貌：推动一个想法、请求更多的上下文、进一步澄清你的立场。既然你在互联网找到了自己的所需，那么请尝试让它变得更好！</p><h4 id="4-2-创建-issue"><a href="#4-2-创建-issue" class="headerlink" title="4.2 创建 issue"></a>4.2 创建 issue</h4><p>你应该在遇到下列情况下，去创建一个 issue：</p><ul><li>报告你自己无法解决的错误</li><li>讨论一个高级主题或想法</li><li>期望实现某新的特性，或者其它项目的想法</li></ul><p>在 issue 的沟通中几点实用的技巧:</p><ul><li><strong>如果你刚好看到一个开放的issue，恰是你打算解决的，</strong> 添加评论，告诉他人你将对此展开工作，并及时响应。这样的话，可以避免他人重复劳动。</li><li><strong>如果说某个issue已经开放很久了，</strong> 这可能是已经有人正在解决中，又或者是早已经解决过了，所以也请添加评论，在打算开始工作之前，最好是确认一下。</li><li><strong>如果你创建了一个issue，但是没多久自己解决了，</strong> 也要添加评论，让其他人知道，然后关闭该issue。记录本身就是对社区的贡献。</li></ul><h4 id="4-3-创建-pull-request"><a href="#4-3-创建-pull-request" class="headerlink" title="4.3 创建 pull request"></a>4.3 创建 pull request</h4><p>在下面的情形时，请你务必使用 PR：</p><ul><li>提交补丁 (例如，纠正拼写错误、损坏的链接、或者是其它较明显的错误）</li><li>开始一项别人请求的任务，或者是过去在issue中早就讨论过的</li></ul><p>一个 PR 并不代表着工作已经完成。它通常是尽早的开启一个PR，是为了其他人可以观看或者给作者反馈意见。只需要在子标题标记为“WIP”（正在进行中）。作者可以在后面添加很多评论。</p><p>如果说项目是托管在 GitHub上的，以下是我们总结出的提交RP的建议：</p><ul><li><strong>Fork 代码仓库</strong> 并克隆到本地，在本地的仓库配置“上游”为远端仓库。这样你可以在提交你的PR时保持和“上游”同步，会减少很多解决冲突的时间。(更多关于同步的说明，请参考<a href="https://help.github.com/articles/syncing-a-fork/" target="_blank" rel="noopener">这里</a>.)</li><li><strong>创建一个分支</strong> 用于自己编辑。</li><li><strong>参考任何相关的issue</strong> 或者在你的RP中支持文档(比如. “Closes #37.”)</li><li><strong>包含之前和之后的快照</strong> 如果你的改动是包含了不同的 HTML/CSS。在你的PR中拖拉相应的图片。</li><li><strong>测试你的改动！</strong> 若测试用例存在的话，跑一遍，以覆盖你的更改，若没有的话，则创建相应的用例。无论测试是否存在，一定要确保你的改动不会破坏掉现有的项目。</li><li><strong>和项目现有的风格保持一致</strong> 尽你最大的努力，这也就是意味着在使用缩进、分号、以及注释很可能和你自己的风格大相径庭，但是为了节省维护者的精力，以及未来他人更好的理解和维护，还请你容忍一下。</li></ul><h3 id="5-成为一个开源贡献者"><a href="#5-成为一个开源贡献者" class="headerlink" title="5 成为一个开源贡献者"></a>5 成为一个开源贡献者</h3><p>如果你有志于参与开源事业，可以尝试从自己最熟悉的项目开始，开源并不是属于高级开发者的专属词汇，它就是由你我这样的人在需求，修复，构建中演进下去的。Let’s try it !</p><p><strong>参考资料</strong> <a href="https://ocselected.github.io/open-source-guide/how-to-contribute/" target="_blank" rel="noopener">如何为开源做贡献</a></p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Github 上有众多优秀的开源项目，大多数 IT 从业者将其当做了予取予求的工具库，遇到什么需求，先去 Github 搜一把，但有没有想过有一天自己也可以给开源事业做一些贡献呢？本文将会以 incubator-dubbo 项目为例，向你阐释，给开源项目做贡献并不是一件难事。&lt;br&gt;
    
    </summary>
    
      <category term="技术杂谈" scheme="http://lexburner.github.io/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="开源" scheme="http://lexburner.github.io/tags/%E5%BC%80%E6%BA%90/"/>
    
      <category term="Dubbo" scheme="http://lexburner.github.io/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>Java并发计数器探秘</title>
    <link href="http://lexburner.github.io/java-concurrent-counter/"/>
    <id>http://lexburner.github.io/java-concurrent-counter/</id>
    <published>2018-08-22T11:47:28.000Z</published>
    <updated>2018-11-20T11:51:48.712Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>一提到线程安全的并发计数器，AtomicLong 必然是第一个被联想到的工具。Atomic* 一系列的原子类以及它们背后的 CAS 无锁算法，常常是高性能，高并发的代名词。本文将会阐释，在并发场景下，使用 AtomicLong 来充当并发计数器将会是一个糟糕的设计，实际上存在不少 AtomicLong 之外的计数器方案。近期我研究了一些 Jdk1.8 以及 JCTools 的优化方案，并将它们的对比与实现细节整理于此。</p><p>相关面试题：</p><blockquote><p>单机场景下，有比 AtomicLong 更高效的并发计数器方案吗？</p></blockquote><a id="more"></a><h3 id="阅读本文前"><a href="#阅读本文前" class="headerlink" title="阅读本文前"></a>阅读本文前</h3><p>本文相关的基准测试代码均可在博主的 github 中找到，测试方式全部采用 JMH，这篇文章可以帮助你<a href="https://www.cnkirito.moe/java-jmh/" target="_blank" rel="noopener">入门 JMH</a>。 </p><h3 id="AtomicLong-的前世今生"><a href="#AtomicLong-的前世今生" class="headerlink" title="AtomicLong 的前世今生"></a>AtomicLong 的前世今生</h3><p>在 Java 中，Atomic* 是高效的，这得益于 <code>sun.misc.Unsafe</code> 提供的一系列底层 API，使得 Java 这样的高级语言能够直接和硬件层面的 CPU 指令打交道。并且在  Jdk1.7 中，这样的底层指令可以配合 CAS 操作，达到 Lock-Free。</p><p>在 Jdk1.7 中，AtomicLong 的关键代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">getAndIncrement</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        <span class="keyword">long</span> current = get();</span><br><span class="line">        <span class="keyword">long</span> next = current + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (compareAndSet(current, next))</span><br><span class="line">            <span class="keyword">return</span> current;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">long</span> expect, <span class="keyword">long</span> update)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> unsafe.compareAndSwapLong(<span class="keyword">this</span>, valueOffset, expect, update);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>get() 方法 volatile 读当前 long 值</li><li>自增</li><li>自旋判断新值与当前值</li><li>自旋成功，返回；否则返回 1</li></ol><p>我们特别留意到 Jdk1.7 中 unsafe 使用的方法是 compareAndSwapLong，它与 x86 CPU 上的 LOCK CMPXCHG 指令对应，并且在应用层使用 while(true) 完成自旋，这个细节在 Jdk1.8 中发生了变化。</p><p>在 Jdk1.8 中，AtomicLong 的关键代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">getAndIncrement</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> unsafe.getAndAddLong(<span class="keyword">this</span>, valueOffset, <span class="number">1L</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Jdk1.7 的 CAS 操作已经不复存在了，转而使用了 getAndAddLong 方法，它与 x86 CPU 上的 LOCK XADD 指令对应，以原子方式返回当前值并递增（fetch and add）。</p><blockquote><p>当问及 Atomic* 高效的原因，回答 CAS 是不够全面且不够严谨的，Jdk1.7 的 unsafe.compareAndSwapLong 以及 Jdk1.8 的 unsafe.getAndAddLong 才是关键，且 Jdk1.8 中不存在 CAS。</p></blockquote><p> Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。</p><h3 id="AtomicLong-真的高效吗？"><a href="#AtomicLong-真的高效吗？" class="headerlink" title="AtomicLong 真的高效吗？"></a>AtomicLong 真的高效吗？</h3><p>无论在 Jdk1.7 还是 Jdk1.8 中，Atomic* 的开销都是很大的，主要体现在：</p><ol><li>高并发下，CAS 操作可能会频繁失败，真正更新成功的线程占少数。(Jdk1.7 独有的问题)</li><li>我之前的文章中介绍过“伪共享” (false sharing) 问题，但在 CAS 中，问题则表现的更为直接，这是“真共享”，与”伪共享“存在相同的问题：缓存行失效，缓存一致性开销变大。</li><li>底层指令的开销不见得很低，无论是 LOCK XADD 还是 LOCK CMPXCHG，想深究的朋友可以参考 <a href="https://www.agner.org/optimize/instruction_tables.pdf" target="_blank" rel="noopener">instruction_tables</a> ，（这一点可能有点钻牛角尖，但不失为一个角度去分析高并发下可行的优化）</li><li>Atomic<em> 所做的，比我们的诉求可能更大，有时候我们只需要计数器具备线程安全地递增这样的特性，但 Atomic</em> 的相关操作每一次都伴随着值的返回。他是个带返回值的方法，而不是 void 方法，而多做了活大概率意味着额外的开销。</li></ol><p>抛开上述导致 AtomicLong 慢的原因，AtomicLong 仍然具备优势：</p><ol><li>上述的第 4 点换一个角度也是 AtomicLong 的有点，相比下面要介绍的其他计数器方案，AtomicLong 能够保证每次操作都精确的返回真实的递增值。你可以借助 AtomicLong 来做并发场景下的递增序列号方案，注意，本文主要讨论的是计数器方案，而不是序列号方案。</li><li>实现简单，回到那句话：“简单的架构通常性能不高，高性能的架构通常复杂度很高”，AtomicLong 属于性能相对较高，但实现极其简单的那种方案，因为大部分的复杂性，由 JMM 和 JNI 方法屏蔽了。相比下面要介绍的其他计数器实现，AtomicLong 真的太“简易”了。</li></ol><p>看一组 AtomicLong 在不同并发量下的性能表现。</p><table><thead><tr><th>线程数</th><th>increment</th><th>get</th></tr></thead><tbody><tr><td>1</td><td>22.31 ns/op</td><td>11.75  ns/op</td></tr><tr><td>3</td><td>78.80 ns/op</td><td>26.58  ns/op</td></tr><tr><td>5</td><td>132.85  ns/op</td><td>38.57  ns/op</td></tr><tr><td>10</td><td>242.61  ns/op</td><td>67.58  ns/op</td></tr><tr><td>20</td><td>488.74  ns/op</td><td>121.22  ns/op</td></tr></tbody></table><p>横向对比，写的性能相比读的性能要差很多，在 20 个线程下写性能比读性能差距了 4~5 倍。</p><p>纵向对比，主要关注并发写，线程竞争激烈的情况下，单次自增耗时从 22 ns 增长为了 488 ns，有明显的性能下降。</p><p>实际场景中，我们需要统计系统的 qps、接口调用次数，都需要使用到计数的功能，写才是关键，并不是每时每刻都需要关注自增后的返回值，而 AtomicLong 恰恰在核心的写性能上有所欠缺。由此引出其他计数器方案。</p><h3 id="认识-LongAdder"><a href="#认识-LongAdder" class="headerlink" title="认识 LongAdder"></a>认识 LongAdder</h3><p>Doug Lea 在 JDK1.8 中找到了一个上述问题的解决方案，他实现了一个 LongAdder 类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@since</span> <span class="number">1.8</span></span><br><span class="line"><span class="meta">@author</span> Doug Lea</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LongAdder</span> <span class="keyword">extends</span> <span class="title">Striped64</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>LongAdder 的 API 如下</p><p><img src="http://kirito.iocoder.cn/LongAdder.png" alt="LongAdder"></p><p>你应当发现，LongAdder 和 AtomicLong 明显的区别在于，increment 是一个 void 方法。直接来看看 LongAdder 的性能表现如何。(LA = LongAdder, AL = AtomicLong, 单位  ns/op)</p><table><thead><tr><th>线程数</th><th>LA.incr</th><th>AL.incr</th><th>LA.get</th><th>AL.get</th></tr></thead><tbody><tr><td>1</td><td>25.51</td><td>22.31</td><td>11.82</td><td>11.75</td></tr><tr><td>3</td><td>14.99</td><td>78.80</td><td>52.94</td><td>26.58</td></tr><tr><td>5</td><td>30.26</td><td>132.85</td><td>75.88</td><td>38.57</td></tr><tr><td>10</td><td>44.33</td><td>160.61</td><td>139.59</td><td>67.58</td></tr><tr><td>20</td><td>77.81</td><td>488.74</td><td>306.39</td><td>121.22</td></tr></tbody></table><p>我们从中可以发现一些有意思的现象，网上不少很多文章没有从读写上对比二者，直接宣称 LongAdder 性能优于 AtomicLong，其实不太严谨。在单线程下，并发问题没有暴露，两者没有体现出差距；随着并发量加大，LongAdder 的 increment 操作更加优秀，而 AtomicLong 的 get 操作则更加优秀。鉴于在计数器场景下的特点—写多读少，所以写性能更高的 LongAdder 更加适合。</p><h3 id="LongAdder-写速度快的背后"><a href="#LongAdder-写速度快的背后" class="headerlink" title="LongAdder 写速度快的背后"></a>LongAdder 写速度快的背后</h3><p>网上分析 LongAdder 源码的文章并不少，我不打算详细分析源码，而是挑选了一些必要的细节以及多数文章没有提及但我认为值得分析的内容。</p><ol><li>Cell 设计减少并发修改时的冲突</li></ol><p><img src="http://kirito.iocoder.cn/LongAdder-layer.png" alt="LongAdder"></p><p>在 LongAdder 的父类 Striped64 中存在一个 <code>volatile Cell[] cells;</code> 数组，其长度是 2 的幂次方，每个 Cell 都填充了一个 @Contended 的 Long 字段，为了避免伪共享问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@sun</span>.misc.Contended <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Cell</span> </span>&#123;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">long</span> value;</span><br><span class="line">    Cell(<span class="keyword">long</span> x) &#123; value = x; &#125;</span><br><span class="line">    <span class="comment">// ... ignore</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>LongAdder 通过一系列算法，将计数结果分散在了多个 Cell 中，Cell 会随着并发量升高时发生扩容，最坏情况下 Cell == CPU core 的数量。Cell 也是 LongAdder 高效的关键，它将计数的总值分散在了各个 Cell 中，例如 5 = 3 + 2，下一刻，某个线程完成了 3 + (2 + 1) = 6 的操作，而不是在 5 的基础上完成直接相加操作。通过 LongAdder 的 sum() 方法可以直观的感受到这一点（LongAdder 不存在 get 方法）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">sum</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Cell[] as = cells; Cell a;</span><br><span class="line">    <span class="keyword">long</span> sum = base;</span><br><span class="line">    <span class="keyword">if</span> (as != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; as.length; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((a = as[i]) != <span class="keyword">null</span>)</span><br><span class="line">                sum += a.value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种惰性求值的思想，在 ConcurrentHashMap 中的 size() 中也存在，毕竟他们的作者都是 Doug Lea。</p><ol><li>并发场景下高效获取随机数</li></ol><p>LongAdder 内部算法需要获取随机数，而 Random 类在并发场景下也是可以优化的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ThreadLocalRandom random =  ThreadLocalRandom.current();</span><br><span class="line">random.nextInt(<span class="number">5</span>);</span><br></pre></td></tr></table></figure><p>使用 ThreadLocalRandom 替代 Random，同样出现在了 LongAdder 的代码中。</p><ol><li>longAccumulate</li></ol><p>longAccumulate 方法是 LongAdder 的核心方法，内部存在大量的分支判断。首先和 Jdk1.7 的 AtomicLong 一样，它使用的是 UNSAFE.compareAndSwapLong 来完成自旋，不同之处在于，其在初次 cas 方式失败的情况下(说明多个线程同时想更新这个值)，尝试将这个值分隔成多个 Cell，让这些竞争的线程只负责更新自己所属的 Cell，这样将竞争压力分散开。</p><h3 id="LongAdder-的前世今生"><a href="#LongAdder-的前世今生" class="headerlink" title="LongAdder 的前世今生"></a>LongAdder 的前世今生</h3><p>其实在 Jdk1.7 时代，LongAdder 还未诞生时，就有一些人想着自己去实现一个高性能的计数器了，比如一款 Java 性能监控框架 <a href="https://github.com/dropwizard/metrics" target="_blank" rel="noopener">dropwizard/metrics</a> 就做了这样事，在早期版本中，其优化手段并没有 Jdk1.8 的 LongAdder 丰富，而在 metrics 的最新版本中，其已经使用 Jdk1.8 的 LongAdder 替换掉了自己的轮子。在最后的测评中，我们将 metrics 版本的 LongAdder 也作为一个参考对象。</p><h3 id="JCTools-中的-ConcurrentAutoTable"><a href="#JCTools-中的-ConcurrentAutoTable" class="headerlink" title="JCTools 中的 ConcurrentAutoTable"></a>JCTools 中的 ConcurrentAutoTable</h3><p>并非只有 LongAdder 考虑到了并发场景下计数器的优化，大名鼎鼎的并发容器框架 JCTool 中也提供了和今天主题相关的实现，虽然其名称和 Counter 看似没有关系，但通过其 Java 文档和 API ，可以发现其设计意图考虑到了计数器的场景。</p><blockquote><p>An auto-resizing table of longs, supporting low-contention CAS operations.Updates are done with CAS’s to no particular table element.The intent is to support <strong>highly scalable counters</strong>, r/w locks, and other structures where the updates are associative, loss-free (no-brainer), and otherwise happen at such a high volume that the cache contention for CAS’ing a single word is unacceptable.</p></blockquote><p><img src="http://kirito.iocoder.cn/ConcurrentAutoTable.png" alt="ConcurrentAutoTable"></p><p>在最后的测评中，我们将 JCTools 的 ConcurrentAutoTable 也作为一个参考对象。</p><h3 id="最终测评"><a href="#最终测评" class="headerlink" title="最终测评"></a>最终测评</h3><p>Jdk1.7 的 AtomicLong，Jdk1.8 的 AtomicLong，Jdk 1.8 的 LongAdder，Metrics 的 LongAdder，JCTools 的 ConcurrentAutoTable，我对这五种类型的计数器使用 JMH 进行基准测试。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">inc</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">get</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将 5 个类都适配成 Counter 接口的实现类，采用 @State(Scope.Group)，@Group 将各组测试用例进行隔离，尽可能地排除了互相之间的干扰，由于计数器场景的特性，我安排了 20 个线程进行并发写，1 个线程与之前的写线程共存，进行并发读。Mode=avgt 代表测试的是方法的耗时，越低代表性能越高。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Benchmark                      (counterType)  Mode  Cnt     Score       Error  Units</span><br><span class="line">CounterBenchmark.rw                  Atomic7  avgt    <span class="number">3</span>  <span class="number">1049.906</span> ±  <span class="number">2146.838</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:get              Atomic7  avgt    <span class="number">3</span>   <span class="number">143.352</span> ±   <span class="number">125.388</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:inc              Atomic7  avgt    <span class="number">3</span>  <span class="number">1095.234</span> ±  <span class="number">2247.913</span>  ns/op</span><br><span class="line">CounterBenchmark.rw                  Atomic8  avgt    <span class="number">3</span>   <span class="number">441.837</span> ±   <span class="number">364.270</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:get              Atomic8  avgt    <span class="number">3</span>   <span class="number">149.817</span> ±    <span class="number">66.134</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:inc              Atomic8  avgt    <span class="number">3</span>   <span class="number">456.438</span> ±   <span class="number">384.646</span>  ns/op</span><br><span class="line">CounterBenchmark.rw      ConcurrentAutoTable  avgt    <span class="number">3</span>   <span class="number">144.490</span> ±   <span class="number">577.390</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:get  ConcurrentAutoTable  avgt    <span class="number">3</span>  <span class="number">1243.494</span> ± <span class="number">14313.764</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:inc  ConcurrentAutoTable  avgt    <span class="number">3</span>    <span class="number">89.540</span> ±   <span class="number">166.375</span>  ns/op</span><br><span class="line">CounterBenchmark.rw         LongAdderMetrics  avgt    <span class="number">3</span>   <span class="number">105.736</span> ±   <span class="number">114.330</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:get     LongAdderMetrics  avgt    <span class="number">3</span>   <span class="number">313.087</span> ±   <span class="number">307.381</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:inc     LongAdderMetrics  avgt    <span class="number">3</span>    <span class="number">95.369</span> ±   <span class="number">132.379</span>  ns/op</span><br><span class="line">CounterBenchmark.rw               LongAdder8  avgt    <span class="number">3</span>    <span class="number">98.338</span> ±    <span class="number">80.112</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:get           LongAdder8  avgt    <span class="number">3</span>   <span class="number">274.169</span> ±   <span class="number">113.247</span>  ns/op</span><br><span class="line">CounterBenchmark.rw:inc           LongAdder8  avgt    <span class="number">3</span>    <span class="number">89.547</span> ±    <span class="number">78.720</span>  ns/op</span><br></pre></td></tr></table></figure><p>如果我们只关注 inc 即写性能，可以发现 jdk1.8 的 LongAdder 表现的最为优秀，ConcurrentAutoTable 以及两个版本的 LongAdder 在一个数量级之上；1.8 的 AtomicLong 相比 1.7 的 AtomicLong 优秀很多，可以得出这样的结论，1.7 的 CAS+LOCK CMPXCHG 方案的确不如 1.8 的 LOCK XADD 来的优秀，但如果与特地优化过的其他计数器方案来进行比较，便相形见绌了。</p><p>如果关注 get 性能，虽然这意义不大，但可以见得，AtomicLong 的 get 性能在高并发下表现依旧优秀，而 LongAdder 组合求值的特性，导致其性能必然存在一定下降，位列第二梯队，而 ConcurrentAutoTable 的并发读性能最差。</p><p>关注整体性能，CounterBenchmark.rw 是对一组场景的整合打分，可以发现，在我们模拟的高并发计数器场景下，1.8 的 LongAdder 获得整体最低的延迟 98 ns，相比性能最差的 Jdk1.7 AtomicLong 实现，高了整整 10 倍有余，并且，随着并发度提升，这个数值还会增大。</p><h3 id="AtomicLong-可以被废弃吗？"><a href="#AtomicLong-可以被废弃吗？" class="headerlink" title="AtomicLong 可以被废弃吗？"></a>AtomicLong 可以被废弃吗？</h3><p>既然 LongAdder 的性能高出 AtomicLong 这么多，我们还有理由使用 AtomicLong 吗？</p><p>本文重点讨论的角度还是比较局限的：单机场景下并发计数器的高效实现。AtomicLong 依然在很多场景下有其存在的价值，例如一个内存中的序列号生成器，AtomicLong 可以满足每次递增之后都精准的返回其递增值，而 LongAdder 并不具备这样的特性。LongAdder 为了性能而丧失了一部分功能，这体现了计算机的哲学，无处不在的 trade off。</p><h3 id="高性能计数器总结"><a href="#高性能计数器总结" class="headerlink" title="高性能计数器总结"></a>高性能计数器总结</h3><ul><li>AtomicLong ：并发场景下读性能优秀，写性能急剧下降，不适合作为高性能的计数器方案。内存需求量少。</li><li>LongAdder ：并发场景下写性能优秀，读性能由于组合求值的原因，不如直接读值的方案，但由于计数器场景写多读少的缘故，整体性能在几个方案中最优，是高性能计数器的首选方案。由于 Cells 数组以及缓存行填充的缘故，占用内存较大。</li><li>ConcurrentAutoTable ：拥有和 LongAdder 相近的写入性能，读性能则更加不如 LongAdder。它的使用需要引入 JCTools 依赖，相比 Jdk 自带的 LongAdder 并没有优势。但额外说明一点，ConcurrentAutoTable 的使用并非局限于计数器场景，其仍然存在很大的价值。</li></ul><p>在前面提到的性能监控框架 <a href="https://github.com/dropwizard/metrics" target="_blank" rel="noopener">Metrics</a>，以及著名的熔断框架 <a href="https://github.com/Netflix/Hystrix" target="_blank" rel="noopener">Hystrix</a> 中，都存在 LongAdder 的使用场景，有兴趣的朋友快去实践一下 LongAdder 吧。</p><p>本文所有的 JMH 测试代码，均可在我的 github 中获得：<a href="https://github.com/lexburner/JMH-samples.git" target="_blank" rel="noopener">https://github.com/lexburner/JMH-samples.git</a></p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;一提到线程安全的并发计数器，AtomicLong 必然是第一个被联想到的工具。Atomic* 一系列的原子类以及它们背后的 CAS 无锁算法，常常是高性能，高并发的代名词。本文将会阐释，在并发场景下，使用 AtomicLong 来充当并发计数器将会是一个糟糕的设计，实际上存在不少 AtomicLong 之外的计数器方案。近期我研究了一些 Jdk1.8 以及 JCTools 的优化方案，并将它们的对比与实现细节整理于此。&lt;/p&gt;
&lt;p&gt;相关面试题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;单机场景下，有比 AtomicLong 更高效的并发计数器方案吗？&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="JAVA并发合集" scheme="http://lexburner.github.io/categories/JAVA%E5%B9%B6%E5%8F%91%E5%90%88%E9%9B%86/"/>
    
    
      <category term="JAVA" scheme="http://lexburner.github.io/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>JAVA拾遗 — JMH与8个测试陷阱</title>
    <link href="http://lexburner.github.io/java-jmh/"/>
    <id>http://lexburner.github.io/java-jmh/</id>
    <published>2018-08-13T11:47:28.000Z</published>
    <updated>2018-11-20T11:51:59.310Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p><a href="http://openjdk.java.net/projects/code-tools/jmh/" target="_blank" rel="noopener">JMH</a> 是 Java Microbenchmark Harness（微基准测试）框架的缩写（2013年首次发布）。与其他众多测试框架相比，其特色优势在于它是由 Oracle 实现 JIT 的相同人员开发的。在此，我想特别提一下 <a href="http://shipilev.net/" target="_blank" rel="noopener">Aleksey Shipilev </a>（JMH 的作者兼布道者）和他优秀的博客文章。笔者花费了一个周末，将 Aleksey 大神的博客，特别是那些和 JMH 相关的文章通读了几遍，外加一部公开课视频 <a href="https://www.youtube.com/watch?v=VaWgOCDBxYw&amp;feature=youtu.be" target="_blank" rel="noopener">《”The Lesser of Two Evils” Story》</a> ，将自己的收获归纳在这篇文章中，文中不少图片都来自 Aleksey 公开课视频。</p><a id="more"></a><h3 id="阅读本文前"><a href="#阅读本文前" class="headerlink" title="阅读本文前"></a>阅读本文前</h3><p>本文没有花费专门的篇幅在文中介绍 JMH 的语法，如果你使用过 JMH，那当然最好，但如果没听过它，也不需要担心（跟我一周前的状态一样）。我会从 Java Developer 角度来谈谈一些常见的代码测试陷阱，分析他们和操作系统底层以及 Java 底层的关联性，并借助 JMH 来帮助大家摆脱这些陷阱。</p><p>通读本文，需要一些操作系统相关以及部分 JIT 的基础知识，如果遇到陌生的知识点，可以留意章节中的维基百科链接，以及笔者推荐的博客。</p><p>笔者能力有限，未能完全理解 JMH 解决的全部问题，如有错误以及疏漏欢迎留言与我交流。</p><h3 id="初识-JMH"><a href="#初识-JMH" class="headerlink" title="初识 JMH"></a>初识 JMH</h3><h4 id="测试精度"><a href="#测试精度" class="headerlink" title="测试精度"></a>测试精度</h4><p><img src="http://kirito.iocoder.cn/image-20180815170601353.png" alt="测试精度"></p><p>上图给出了不同类型测试的耗时数量级，可以发现 JMH 可以达到<strong>微秒</strong>级别的的精度。</p><p>这样几个数量级的测试所面临的挑战也是不同的。</p><ul><li>毫秒级别的测试并不是很困难</li><li>微秒级别的测试是具备挑战性的，但并非无法完成，JMH 就做到了</li><li>纳秒级别的测试，目前还没有办法精准测试</li><li>皮秒级别…Holy Shit</li></ul><blockquote><p>图解：</p><p>Linpack : Linpack benchmark 一类基础测试，度量系统的浮点计算能力</p><p>SPEC：Standard Performance Evaluation Corporation 工业界的测试标准组织</p><p>pipelining：系统总线通信的耗时</p></blockquote><h4 id="Benchmark-分类"><a href="#Benchmark-分类" class="headerlink" title="Benchmark 分类"></a>Benchmark 分类</h4><p>测试在不同的维度可以分为很多类：集成测试，单元测试，API 测试，压力测试… 而 Benchmark 通常译为基准测试（性能测试）。你可以在很多开源框架的包层级中发现 Benchmark，用于阐释该框架的基准水平，从而量化其性能。</p><p>基准测试又可以细分为 ：Micro benchmark，Kernels，Synthetic benchmark，Application benchmarks.etc.本文的主角便属于 Benchmark 的 Micro benchmark。基础测试分类详细介绍 <a href="http://prof.ict.ac.cn/DComputing/uploads/2013/DC_1_3_benchmark.pdf" target="_blank" rel="noopener">here</a></p><p><img src="http://kirito.iocoder.cn/image-20180815172655473.png" alt="motan中的benchmark"></p><h4 id="为什么需要有-Benchmark"><a href="#为什么需要有-Benchmark" class="headerlink" title="为什么需要有 Benchmark"></a>为什么需要有 Benchmark</h4><blockquote><p>If you cannot measure it, you cannot improve it. </p><p> –Lord Kelvin</p></blockquote><p>俗话说，没有实践就没有发言权，Benchmark 为应用提供了数据支持，是评价和比较方法好坏的基准，Benchmark 的准确性，多样性便显得尤为重要。</p><p>Benchmark 作为应用框架，产品的基准画像，存在统一的标准，避免了不同测评对象自说自话的尴尬，应用框架各自使用有利于自身场景的测评方式必然不可取，例如 Standard Performance Evaluation Corporation (SPEC) 即上文“测试精度”提到的词便是工业界的标准组织之一，JMH 的作者 Aleksey 也是其中的成员。</p><h4 id="JMH-长这样"><a href="#JMH-长这样" class="headerlink" title="JMH 长这样"></a>JMH 长这样</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">measure</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// this method was intentionally left blank.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用起来和单元测试一样的简单</p><p>它的测评结果</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Benchmark</span>                                <span class="type">Mode</span>  <span class="type">Cnt</span>           <span class="type">Score</span>           <span class="type">Error</span>  <span class="type">Units</span></span><br><span class="line"><span class="type">JMHSample_HelloWorld</span>.measure  thrpt    <span class="number">5</span>  <span class="number">3126699413.430</span> ± <span class="number">179167212.838</span>  ops/s</span><br></pre></td></tr></table></figure><h4 id="为什么需要-JMH-测试"><a href="#为什么需要-JMH-测试" class="headerlink" title="为什么需要 JMH 测试"></a>为什么需要 JMH 测试</h4><p>你可能会想，我用下面的方式来测试有什么不好？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">measure();</span><br><span class="line">System.out.println(System.currentTimeMillis()-start);</span><br></pre></td></tr></table></figure><p>难道 JMH 不是这么测试的吗？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">measure</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>事实上，这是本文的核心问题，建议在阅读时时刻带着这样的疑问，为什么不使用第一种方式来测试。<strong>在下面的章节中，我将列举诸多的测试陷阱，他们都会为这个问题提供论据，这些陷阱会启发那些对“测试”不感冒的开发者。</strong>。</p><h4 id="预热"><a href="#预热" class="headerlink" title="预热"></a>预热</h4><p>在初识 JMH 小节的最后，花少量的篇幅来给 JMH 涉及的知识点开个头，介绍一个 Java 测试中比较老生常谈的话题 — 预热(warm up)，它存在于下面所有的测试中。</p><blockquote><p>«Warmup» = waiting for the transient responses to settle down</p></blockquote><p>特别是在编写 Java 测试程序时，预热从来都是不可或缺的一环，它使得结果更加真实可信。</p><p><img src="http://kirito.iocoder.cn/image-20180816102535090.png" alt="warmup plateaus"></p><p>上图展示了一个样例测评程序随着迭代次数增多执行耗时变化的曲线，可以发现在 120 次迭代之后，性能才趋于最终稳定，这意味着：预热阶段需要有至少 120 次迭代，才能得到准确的基础测试报告。（JVM 初始化时的一些准备工作以及 JIT 优化是主要原因，但不是唯一原因）。需要被说明的事，JMH 的运行相对耗时，因为，预热被前置在每一个测评任务之前。</p><h3 id="使用-JMH-解决-12-个测试陷阱"><a href="#使用-JMH-解决-12-个测试陷阱" class="headerlink" title="使用 JMH 解决 12 个测试陷阱"></a>使用 JMH 解决 12 个测试陷阱</h3><h4 id="陷阱1：死码消除"><a href="#陷阱1：死码消除" class="headerlink" title="陷阱1：死码消除"></a>陷阱1：死码消除</h4><p><img src="http://kirito.iocoder.cn/image-20180816164617507.png" alt="死码消除"></p><p>measureWrong 方法想要测试 Math.log 的性能，得到的结果和空方法 baseline 一致，而 measureRight 相比 measureWrong 多了一个 return，正确的得到了测试结果。</p><p>这是由于 JIT 擅长删除“无效”的代码，这给我们的测试带来了一些意外，当你意识到 DCE 现象后，应当有意识的去消费掉这些孤立的代码，例如 return。JMH 不会自动实施对冗余代码的消除。</p><p><a href="https://zh.wikipedia.org/wiki/%E6%AD%BB%E7%A2%BC%E5%88%AA%E9%99%A4" target="_blank" rel="noopener">死码消除</a>这个概念很多人其实并不陌生，注释的代码，不可达的代码块，可达但不被使用的代码等等，我这里补充一些 Aleksey 提到的概念，用以阐释为何一般测试方法难以避免引用对象发生死码消除现象：</p><ol><li>Fast object combinator.</li><li>Need to escape object to limit thread-local optimizations. </li><li>Publishing the object ⇒ reference heap write ⇒ store barrier.</li></ol><p>很绝望，个人水平有限，我没能 get 到这些点，只能原封不动地贴给大家看了。</p><p>JMH 提供了专门的 API — Blockhole 来避免死码消除问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">measureRight</span><span class="params">(Blackhole bh)</span> </span>&#123;</span><br><span class="line">    bh.consume(Math.log(PI));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="陷阱2：常量折叠与常量传播"><a href="#陷阱2：常量折叠与常量传播" class="headerlink" title="陷阱2：常量折叠与常量传播"></a>陷阱2：常量折叠与常量传播</h4><p><a href="https://zh.wikipedia.org/wiki/%E5%B8%B8%E6%95%B8%E6%8A%98%E7%96%8A#%E5%B8%B8%E6%95%B8%E5%82%B3%E6%92%AD" target="_blank" rel="noopener">常量折叠</a> (Constant folding) 是一个在编译时期简化常数的一个过程，常数在表示式中仅仅代表一个简单的数值，就像是整数 <code>2</code>，若是一个变数从未被修改也可作为常数，或者直接将一个变数被明确地被标注为常数，例如下面的描述：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">320</span> * <span class="number">200</span> * <span class="number">32</span>;</span><br></pre></td></tr></table></figure><p>多数的现代编译器不会真的产生两个乘法的指令再将结果储存下来，取而代之的，他们会辨识出语句的结构，并在编译时期将数值计算出来（在这个例子，结果为 2,048,000）。</p><p>有些编译器，常数折叠会在初期就处理完，例如 Java 中的 final 关键字修饰的变量就会被特殊处理。而将常数折叠放在较后期的阶段的编译器，也相当常见。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">double</span> x = Math.PI;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 编译器会对 final 变量特殊处理 </span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">double</span> wrongX = Math.PI;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">baseline</span><span class="params">()</span> </span>&#123; <span class="comment">// 2.220 ± 0.352 ns/op</span></span><br><span class="line">    <span class="keyword">return</span> Math.PI;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">measureWrong_1</span><span class="params">()</span> </span>&#123; <span class="comment">// 2.220 ± 0.352 ns/op</span></span><br><span class="line">    <span class="comment">// 错误，结果可以被预测，会发生常量折叠</span></span><br><span class="line">    <span class="keyword">return</span> Math.log(Math.PI);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">measureWrong_2</span><span class="params">()</span> </span>&#123; <span class="comment">// 2.220 ± 0.352 ns/op</span></span><br><span class="line">    <span class="comment">// 错误，结果可以被预测，会发生常量折叠</span></span><br><span class="line">    <span class="keyword">return</span> Math.log(wrongX);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">measureRight</span><span class="params">()</span> </span>&#123; <span class="comment">// 22.590 ± 2.636  ns/op</span></span><br><span class="line">    <span class="keyword">return</span> Math.log(x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经过 JMH 可以验证这一点：只有最后的 measureRight 正确测试出了 Math.log 的性能，measureWrong_1，measureWrong_2 都受到了常量折叠的影响。</p><p><strong>常数传播(</strong>Constant propagation<strong>)</strong> 是一个替代表示式中已知常数的过程，也是在编译时期进行，包含前述所定义，内建函数也适用于常数，以下列描述为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">14</span>;</span><br><span class="line"><span class="keyword">int</span> y = <span class="number">7</span> - x / <span class="number">2</span>;</span><br><span class="line"><span class="keyword">return</span> y * (<span class="number">28</span> / x + <span class="number">2</span>);</span><br></pre></td></tr></table></figure><p>传播可以理解变量的替换，如果进行持续传播，上式会变成：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">14</span>;</span><br><span class="line"><span class="keyword">int</span> y = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><h4 id="陷阱3：永远不要在测试中写循环"><a href="#陷阱3：永远不要在测试中写循环" class="headerlink" title="陷阱3：永远不要在测试中写循环"></a>陷阱3：永远不要在测试中写循环</h4><p>这个陷阱对我们做日常测试时的影响也是巨大的，所以我直接将他作为了标题：永远不要在测试中写循环！</p><p>本节设计不少知识点，<a href="https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80" target="_blank" rel="noopener">循环展开</a>(loop unrolling)，JIT &amp; OSR 对循环的优化。对于前者循环展开的定义，建议读者直接查看 wiki 的定义，而对于后者 JIT &amp; OSR 对循环的优化，推荐两篇 R 大的知乎回答：</p><p><a href="https://www.zhihu.com/question/45910849/answer/100636125java" target="_blank" rel="noopener">循环长度的相同、循环体代码相同的两次for循环的执行时间相差了100倍?</a></p><p><a href="https://www.zhihu.com/question/45910849/answer/100636125" target="_blank" rel="noopener">OSR（On-Stack Replacement）是怎样的机制？</a></p><p>对于第一个回答，建议不要看问题，直接看答案；第二个回答，阐释了 OSR 都对循环做了哪些手脚。</p><p>测试一个耗时较短的方法，入门级程序员（不了解动态编译的同学）会这样写，通过循环放大，再求均值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BadMicrobenchmark</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> startTime = System.nanoTime();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10_000_000</span>; i++) &#123;</span><br><span class="line">            reps();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> endTime = System.nanoTime();</span><br><span class="line">        System.out.println(<span class="string">"ns/op : "</span> + (endTime - startTime));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上，这段代码的结果是不可预测的，太多影响因子会干扰结果。原理暂时不表，通过 JMH 来看看几个测试方法，下面的 Benchmark 尝试对 reps 方法迭代不同的次数，想从中获得 reps 真实的性能。（注意，在 JMH 中使用循环也是不可取的，除非你是 Benchmark 方面的专家，否则在任何时候，你都不应该写循环）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> y = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measureRight</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (x + y);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">reps</span><span class="params">(<span class="keyword">int</span> reps)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> s = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; reps; i++) &#123;</span><br><span class="line">        s += (x + y);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(<span class="number">1</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measureWrong_1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> reps(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(<span class="number">10</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measureWrong_10</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> reps(<span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(<span class="number">100</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measureWrong_100</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> reps(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(<span class="number">1000</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measureWrong_1000</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> reps(<span class="number">1000</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(<span class="number">10000</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measureWrong_10000</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> reps(<span class="number">10000</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(<span class="number">100000</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measureWrong_100000</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> reps(<span class="number">100000</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Benchmark</span>                               <span class="type">Mode</span>  <span class="type">Cnt</span>  <span class="type">Score</span>   <span class="type">Error</span>  <span class="type">Units</span></span><br><span class="line"><span class="type">JMHSample_11_Loops</span>.measureRight         avgt    <span class="number">5</span>  <span class="number">2.343</span> ± <span class="number">0.199</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_11_Loops</span>.measureWrong_1       avgt    <span class="number">5</span>  <span class="number">2.358</span> ± <span class="number">0.166</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_11_Loops</span>.measureWrong_10      avgt    <span class="number">5</span>  <span class="number">0.326</span> ± <span class="number">0.354</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_11_Loops</span>.measureWrong_100     avgt    <span class="number">5</span>  <span class="number">0.032</span> ± <span class="number">0.011</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_11_Loops</span>.measureWrong_1000    avgt    <span class="number">5</span>  <span class="number">0.025</span> ± <span class="number">0.002</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_11_Loops</span>.measureWrong_10000   avgt    <span class="number">5</span>  <span class="number">0.022</span> ± <span class="number">0.005</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_11_Loops</span>.measureWrong_100000  avgt    <span class="number">5</span>  <span class="number">0.019</span> ± <span class="number">0.001</span>  ns/op</span><br></pre></td></tr></table></figure><p>如果不看事先给出的错误和正确的提示，上述的结果，你会选择相信哪一个？实际上跑分耗时从 2.358 随着迭代次数变大，降为了 0.019。手动测试循环的代码 BadMicrobenchmark 也存在同样的问题，实际上它没有做预热，效果只会比 JMH 测试循环更加不可信。</p><p>Aleksey 在视频中给出结论：假设单词迭代的耗时是 𝑀 ns. 在 JIT，OSR，循环展开等因素的多重作用下，多次迭代的耗时理论值为 𝛼𝑀 ns, 其中 𝛼 ∈ [0; +∞)。</p><p>正确的测试循环的姿势可以看这里：<a href="https://github.com/lexburner/JMH-samples/blob/master/src/main/java/org/openjdk/jmh/samples/JMHSample_34_SafeLooping.java" target="_blank" rel="noopener">here</a></p><h4 id="陷阱4：使用-Fork-隔离多个测试方法"><a href="#陷阱4：使用-Fork-隔离多个测试方法" class="headerlink" title="陷阱4：使用 Fork 隔离多个测试方法"></a>陷阱4：使用 Fork 隔离多个测试方法</h4><p>相信我，这个陷阱中涉及到的例子绝对是 JMH sample 中最诡异的，并且我还没有找到科学的解释（说实话视频中这一段我尝试听了好几遍，没听懂，原谅我的听力）</p><p>首先定义一个 Counter 接口，并实现了两份代码完全相同的实现类：Counter1，Counter2</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">inc</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter1</span> <span class="keyword">implements</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> x;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">inc</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter2</span> <span class="keyword">implements</span> <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> x;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">inc</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着让他们在<strong>同一个 VM</strong> 中按照先手顺序进行评测：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measure</span><span class="params">(Counter c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> s = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        s += c.inc();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * These are two counters.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Counter c1 = <span class="keyword">new</span> Counter1();</span><br><span class="line">Counter c2 = <span class="keyword">new</span> Counter2();</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * We first measure the Counter1 alone...</span></span><br><span class="line"><span class="comment"> * Fork(0) helps to run in the same JVM.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@Fork</span>(<span class="number">0</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measure_1_c1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> measure(c1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Then Counter2...</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@Fork</span>(<span class="number">0</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measure_2_c2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> measure(c1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Then Counter1 again...</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@Fork</span>(<span class="number">0</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measure_3_c1_again</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> measure(c1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@Fork</span>(<span class="number">1</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measure_4_forked_c1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> measure(c1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@Fork</span>(<span class="number">1</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">measure_5_forked_c2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> measure(c2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一个例子中多了一个 Fork 注解，让我来简单介绍下它。Fork 这个关键字顾名思义，是用来将运行环境复制一份的意思，在我们之前的多个测试中，实际上每次测评都是默认使用了<strong>相互隔离的，完全一致</strong>的测评环境，这得益于 JMH。每个试验运行在单独的 JVM 进程中。也可以指定(额外的) JVM 参数，例如这里为了演示运行在同一个 JVM 中的弊端，特地做了反面的教材：Fork(0)。试想一下 c1，c2，c1 again 的耗时结果会如何？</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Benchmark</span>                                 <span class="type">Mode</span>  <span class="type">Cnt</span>   <span class="type">Score</span>   <span class="type">Error</span>  <span class="type">Units</span></span><br><span class="line"><span class="type">JMHSample_12_Forking</span>.measure_1_c1         avgt    <span class="number">5</span>   <span class="number">2.518</span> ± <span class="number">0.622</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_12_Forking</span>.measure_2_c2         avgt    <span class="number">5</span>  <span class="number">14.080</span> ± <span class="number">0.283</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_12_Forking</span>.measure_3_c1_again   avgt    <span class="number">5</span>  <span class="number">13.462</span> ± <span class="number">0.164</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_12_Forking</span>.measure_4_forked_c1  avgt    <span class="number">5</span>   <span class="number">3.861</span> ± <span class="number">0.712</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_12_Forking</span>.measure_5_forked_c2  avgt    <span class="number">5</span>   <span class="number">3.574</span> ± <span class="number">0.220</span>  ns/op</span><br></pre></td></tr></table></figure><p>你会不会感到惊讶，第一次运行的 c1 竟然耗时最低，在我的认知中，JIT 起码会启动预热的作用，无论如何都不可能先运行的方法比之后的方法快这么多！但这个结果也和 Aleksey 视频中介绍的相符。</p><p>JMH samples 中的这个示例主要还是想要表达同一个 JVM 中运行的测评代码会互相影响，从结果也可以发现：c1,c2,c1_again 的实现相同，跑分却不同，因为运行在同一个 JVM 中；而 forked_c1 和 forked_c2 则表现出了一致的性能。所以没有特殊原因，Fork 的值一般都需要设置为 &gt;0。</p><h4 id="陷阱5：方法内联"><a href="#陷阱5：方法内联" class="headerlink" title="陷阱5：方法内联"></a>陷阱5：方法内联</h4><p>熟悉 C/C++ 的朋友不会对方法内联感到陌生，方法内联就是把目标方法的代码“复制”到发起调用的方法之中，避免发生真实的方法调用（减少了操作指令周期）。在 Java 中，无法手动编写内联方法，但 JVM 会自动识别热点方法，并对它们使用方法内联优化。一段代码需要执行多少次才会触发 JIT 优化通常这个值由 -XX:CompileThreshold 参数进行设置：</p><ul><li>1、使用 client 编译器时，默认为1500；</li><li>2、使用 server 编译器时，默认为10000；</li></ul><p>但是一个方法就算被 JVM 标注成为热点方法，JVM 仍然不一定会对它做方法内联优化。其中有个比较常见的原因就是这个方法体太大了，分为两种情况。</p><ul><li>如果方法是经常执行的，默认情况下，方法大小小于 325 字节的都会进行内联（可以通过<code>-XX:MaxFreqInlineSize=N</code>来设置这个大小）</li><li>如果方法不是经常执行的，默认情况下，方法大小小于 35 字节才会进行内联（可以通过<code>-XX:MaxInlineSize=N</code>来设置这个大小）</li></ul><blockquote><p>我们可以通过增加这个大小，以便更多的方法可以进行内联；但是除非能够显著提升性能，否则不推荐修改这个参数。因为更大的方法体会导致代码内存占用更多，更少的热点方法会被缓存，最终的效果不一定好。</p></blockquote><p>如果想要知道方法被内联的情况，可以使用下面的JVM参数来配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-XX:+PrintCompilation //在控制台打印编译过程信息</span><br><span class="line">-XX:+UnlockDiagnosticVMOptions //解锁对JVM进行诊断的选项参数。默认是关闭的，开启后支持一些特定参数对JVM进行诊断</span><br><span class="line">-XX:+PrintInlining //将内联方法打印出来</span><br></pre></td></tr></table></figure><p><strong>方法内联的其他隐含条件</strong></p><blockquote><ul><li>虽然 JIT 号称可以针对代码全局的运行情况而优化，但是 JIT 对一个方法内联之后，还是可能因为方法被继承，导致需要类型检查而没有达到性能的效果</li><li>想要对热点的方法使用上内联的优化方法，最好尽量使用<code>final、private、static</code>这些修饰符修饰方法，避免方法因为继承，导致需要额外的类型检查，而出现效果不好情况。</li></ul></blockquote><p>方法内联也可能对 Benchmark 产生影响；或者说有时候我们为了优化代码，而故意触发内联，也可以通过 JMH 来和非内联方法进行性能对比:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">target_blank</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// this method was intentionally left blank</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@CompilerControl</span>(CompilerControl.Mode.DONT_INLINE)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">target_dontInline</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// this method was intentionally left blank</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@CompilerControl</span>(CompilerControl.Mode.INLINE)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">target_inline</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// this method was intentionally left blank</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Benchmark</span>                                <span class="type">Mode</span>  <span class="type">Cnt</span>   <span class="type">Score</span>    <span class="type">Error</span>  <span class="type">Units</span></span><br><span class="line"><span class="type">JMHSample_16_CompilerControl</span>.blank       avgt    <span class="number">3</span>   <span class="number">0.323</span> ±  <span class="number">0.544</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_16_CompilerControl</span>.dontinline  avgt    <span class="number">3</span>   <span class="number">2.099</span> ±  <span class="number">7.515</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_16_CompilerControl</span>.inline      avgt    <span class="number">3</span>   <span class="number">0.308</span> ±  <span class="number">0.264</span>  ns/op</span><br></pre></td></tr></table></figure><p>可以发现，内联与不内联的性能差距是巨大的，有一些空间换时间的味道，在 JMH 中使用 CompilerControl.Mode 来控制内联是否开启。</p><h4 id="陷阱6：伪共享与缓存行"><a href="#陷阱6：伪共享与缓存行" class="headerlink" title="陷阱6：伪共享与缓存行"></a>陷阱6：伪共享与缓存行</h4><p>又遇到了我们的老朋友：CPU Cache 和缓存行填充。这个并发性能杀手，我在之前的文章中专门介绍过，如果你没有看过，可以戳这里：<a href="https://www.cnkirito.moe/cache-line/" target="_blank" rel="noopener">JAVA 拾遗 — CPU Cache 与缓存行</a>。在 Benchmark 中，有时也不能忽视缓存行对测评的影响。</p><p>受限于篇幅，在此不展开有关伪共享的陷阱，完整的测评可以戳这里：<a href="https://github.com/lexburner/JMH-samples/blob/master/src/main/java/org/openjdk/jmh/samples/JMHSample_22_FalseSharing.java" target="_blank" rel="noopener">JMHSample_22_FalseSharing</a></p><p>JMH 为解决伪共享问题，提供了 @State 注解，但并不能在单一对象内部对个别的字段增加，如果有必要，可以使用并发包中的 @Contended 注解来处理。</p><blockquote><p>Aleksey 曾为 Java 并发包提供过优化，其中就包括 @Contended 注解。</p></blockquote><h4 id="陷阱7：分支预测"><a href="#陷阱7：分支预测" class="headerlink" title="陷阱7：分支预测"></a>陷阱7：分支预测</h4><p>分支预测（Branch Prediction）是这篇文章中介绍的最后一个 Benchmark 中的“捣蛋鬼”。还是从一个具体的 Benchmark 中观察结果。下面的代码尝试遍历了两个长度相等的数组，一个有序，一个无序，并在迭代时加入了一个判断语句，这是分支预测的关键：if(v &gt; 0)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> COUNT = <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">byte</span>[] sorted;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">byte</span>[] unsorted;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Setup</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    sorted = <span class="keyword">new</span> <span class="keyword">byte</span>[COUNT];</span><br><span class="line">    unsorted = <span class="keyword">new</span> <span class="keyword">byte</span>[COUNT];</span><br><span class="line">    Random random = <span class="keyword">new</span> Random(<span class="number">1234</span>);</span><br><span class="line">    random.nextBytes(sorted);</span><br><span class="line">    random.nextBytes(unsorted);</span><br><span class="line">    Arrays.sort(sorted);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(COUNT)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sorted</span><span class="params">(Blackhole bh1, Blackhole bh2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">byte</span> v : sorted) &#123;</span><br><span class="line">        <span class="keyword">if</span> (v &gt; <span class="number">0</span>) &#123; <span class="comment">//关键</span></span><br><span class="line">            bh1.consume(v);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            bh2.consume(v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Benchmark</span></span><br><span class="line"><span class="meta">@OperationsPerInvocation</span>(COUNT)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unsorted</span><span class="params">(Blackhole bh1, Blackhole bh2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">byte</span> v : unsorted) &#123;</span><br><span class="line">        <span class="keyword">if</span> (v &gt; <span class="number">0</span>) &#123; <span class="comment">//关键</span></span><br><span class="line">            bh1.consume(v);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            bh2.consume(v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Benchmark</span>                               <span class="type">Mode</span>  <span class="type">Cnt</span>  <span class="type">Score</span>   <span class="type">Error</span>  <span class="type">Units</span></span><br><span class="line"><span class="type">JMHSample_36_BranchPrediction</span>.sorted    avgt   <span class="number">25</span>  <span class="number">2.752</span> ± <span class="number">0.154</span>  ns/op</span><br><span class="line"><span class="type">JMHSample_36_BranchPrediction</span>.unsorted  avgt   <span class="number">25</span>  <span class="number">8.175</span> ± <span class="number">0.883</span>  ns/op</span><br></pre></td></tr></table></figure><p>从结果看，有序数组的遍历比无序数组的遍历快了 2-3 倍。关于这点的介绍，最佳的解释来自于 Stack Overflow 一个 2w 多赞的答案：<a href="https://stackoverflow.com/questions/11227809/why-is-it-faster-to-process-a-sorted-array-than-an-unsorted-array" target="_blank" rel="noopener">Why is it faster to process a sorted array than an unsorted array?</a></p><p><img src="http://kirito.iocoder.cn/muxnt.png" alt="分叉路口"></p><p>假设我们是在 19 世纪，而你负责为火车选择一个方向，那时连电话和手机还没有普及，当火车开来时，你不知道火车往哪个方向开。于是你的做法（算法）是：叫停火车，此时火车停下来，你去问司机，然后你确定了火车往哪个方向开，并把铁轨扳到了对应的轨道。</p><p>还有一个需要注意的地方是，火车的惯性是非常大的，所以司机必须在很远的地方就开始减速。当你把铁轨扳正确方向后，火车从启动到加速又要经过很长的时间。</p><p>那么是否有更好的方式可以减少火车的等待时间呢？</p><p>有一个非常简单的方式，你提前把轨道扳到某一个方向。那么到底要扳到哪个方向呢，你使用的手段是——“瞎蒙”：</p><ul><li>如果蒙对了，火车直接通过，耗时为 0。</li><li>如果蒙错了，火车停止，然后倒回去，你将铁轨扳至反方向，火车重新启动，加速，行驶。</li></ul><p>如果你很幸运，每次都蒙对了，火车将从不停车，一直前行！如果不幸你蒙错了，那么将浪费很长的时间。</p><p>虽然不严谨，但你可以用同样的道理去揣测 CPU 的分支预测，有序数组使得这样的预测大部分情况下是正确的，所以带有判断条件时，有序数组的遍历要比无序数组要快。</p><p>这同时也启发我们：在大规模循环逻辑中要尽量避免大量判断（是不是可以抽取到循环外呢？）。</p><h4 id="陷阱8：多线程测试"><a href="#陷阱8：多线程测试" class="headerlink" title="陷阱8：多线程测试"></a>陷阱8：多线程测试</h4><p><img src="http://kirito.iocoder.cn/image-20180816110426619.png" alt="多线程测试"></p><p>在 4 核的系统之上运行一个测试方法，得到如上的测试结果， Ops/nsec 代表了单位时间内的运行次数，Scale 代表 2，4 线程相比 1 线程的运行次数倍率。</p><p>这个图可供我们提出两个问题：</p><ol><li>为什么 2 线程 -&gt; 4 线程几乎没有变化？</li><li><p>为什么 2 线程相比 1 线程只有 1.87 倍的变化，而不是 2 倍？</p><p><strong>1 电源管理</strong></p></li></ol><p><img src="http://kirito.iocoder.cn/image-20180816120810564.png" alt="降频"></p><p>第一个影响因素便是多线程测试会受到操作系统电源管理（Power Management）的影响，许多系统存在能耗和性能的优化管理。 (Ex: cpufreq, SpeedStep, Cool&amp;Quiet, TurboBoost) </p><p>当我们主动对机器进行降频之后，整体性能发生下降，但是 Scale 在线程数 1 -&gt; 2 的过程中变成了严谨的 2 倍。</p><p>这样的问题并非无法规避，补救方法便是禁用电源管理, 保证 CPU 的时钟频率 。</p><p>JMH 通过长时间运行，保证线程不出现 park(time waiting) 状态，来保证测试的精准性。</p><p><strong>2 操作系统调度和分时调用模型</strong></p><p>造成多线程测试陷阱的第二个问题，需要从线程调度模型出发来理解：分时调度模型和抢占式调度模型。</p><p>分时调度模型是指让所有的线程轮流获得 CPU 的使用权,并且平均分配每个线程占用的 CPU 的时间片，这个也比较好理解；抢占式调度模型，是指优先让可运行池中优先级高的线程占用 CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用 CPU。处于运行状态的线程会一直运行，直至它不得不放弃 CPU。一个线程会因为以下原因而放弃 CPU。</p><p>需要注意的是，线程的调度不是跨平台的，它不仅仅取决于 Java 虚拟机，还依赖于操作系统。在某些操作系统中，只要运行中的线程没有遇到阻塞，就不会放弃 CPU；在某些操作系统中，即使线程没有遇到阻塞，也会运行一段时间后放弃 CPU，给其它线程运行的机会。</p><p>无论是那种模型，线程上下文的切换都会造成损耗。到这儿为止，还是只回答了第一个问题：为什么 2 线程相比 1 线程只有 1.87 倍的变化，而不是 2 倍？</p><p>由于上述的两个图我都是从 Aleksey 的视频中抠出来的，并不清楚他的实际测试用例，对于 2 -&gt; 4 线程性能差距并不大只能理解为系统过载，按道理说 4 核的机器，运行 4 个线程应该不至于只比 2 个线程快这么一点。</p><p>对于线程分时调用以及线程调度带来的不稳定性，JMH 引入了 bogus iterations 的概念，它保障了在多线程测试过程中，只在线程处于忙碌状态的过程中进行测量。</p><p><img src="http://kirito.iocoder.cn/image-20180816160053038.png" alt="bogus iterations"></p><p>bogus iterations 这个值得一提，我理解为“伪迭代”，并且也只在 JVM 的注释以及 Aleksey 的几个博客中有介绍，可以理解为 JMH 的内部原理的专用词。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文花了大量的篇幅介绍了 JMH 存在的意义，以及 JMH sample 中提到的诸多陷阱，这些陷阱会非常容易地被那些不规范的测评程序所触发。我觉得作为 Java 语言的使用者，起码有必要了解这些现象的存在，毕竟 JMH 已经帮你解决了诸多问题了，你不用担心预热问题，不用自己写比较 low 的循环去评测，规避这些测试陷阱也变得相对容易。</p><p>实际上，本文设计的知识点，仅仅是 Aleksey 博客中的内容、 JMH 的 38 个 sample 的冰山一角，有兴趣的朋友可以戳这里查看所有的 <a href="https://github.com/lexburner/JMH-samples" target="_blank" rel="noopener">JMH sample</a></p><p>陷阱内心 os：像我这么diao的陷阱，还有 30 个！</p><p><img src="http://kirito.iocoder.cn/image-20180816193913833.png" alt="kafka"></p><p>例如 Kafka 这样优秀的开源框架，提供了专门的 module 来做 JMH 的基础测试。尝试使用 JMH 作为你的 Benchmark 工具吧。</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://openjdk.java.net/projects/code-tools/jmh/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;JMH&lt;/a&gt; 是 Java Microbenchmark Harness（微基准测试）框架的缩写（2013年首次发布）。与其他众多测试框架相比，其特色优势在于它是由 Oracle 实现 JIT 的相同人员开发的。在此，我想特别提一下 &lt;a href=&quot;http://shipilev.net/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Aleksey Shipilev &lt;/a&gt;（JMH 的作者兼布道者）和他优秀的博客文章。笔者花费了一个周末，将 Aleksey 大神的博客，特别是那些和 JMH 相关的文章通读了几遍，外加一部公开课视频 &lt;a href=&quot;https://www.youtube.com/watch?v=VaWgOCDBxYw&amp;amp;feature=youtu.be&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;《”The Lesser of Two Evils” Story》&lt;/a&gt; ，将自己的收获归纳在这篇文章中，文中不少图片都来自 Aleksey 公开课视频。&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://lexburner.github.io/categories/JAVA/"/>
    
    
      <category term="JAVA" scheme="http://lexburner.github.io/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>JAVA 拾遗 — CPU Cache 与缓存行</title>
    <link href="http://lexburner.github.io/cache-line/"/>
    <id>http://lexburner.github.io/cache-line/</id>
    <published>2018-07-21T11:47:28.000Z</published>
    <updated>2018-11-20T11:50:36.243Z</updated>
    
    <content type="html"><![CDATA[<p>最近的两篇文章，介绍了我参加的中间件比赛中一些相对重要的优化，但实际上还存在很多细节优化，出于篇幅限制并未提及，在最近的博文中，我会将他们整理成独立的知识点，并归类到我的系列文章「JAVA 拾遗」中。</p><a id="more"></a><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">long</span>[][] arr;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        arr = <span class="keyword">new</span> <span class="keyword">long</span>[<span class="number">1024</span> * <span class="number">1024</span>][<span class="number">8</span>];</span><br><span class="line">        <span class="comment">// 横向遍历</span></span><br><span class="line">        <span class="keyword">long</span> marked = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1024</span> * <span class="number">1024</span>; i += <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">8</span>; j++) &#123;</span><br><span class="line">                sum += arr[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"Loop times:"</span> + (System.currentTimeMillis() - marked) + <span class="string">"ms"</span>);</span><br><span class="line"></span><br><span class="line">        marked = System.currentTimeMillis();</span><br><span class="line">        <span class="comment">// 纵向遍历</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">8</span>; i += <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">1024</span> * <span class="number">1024</span>; j++) &#123;</span><br><span class="line">                sum += arr[j][i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"Loop times:"</span> + (System.currentTimeMillis() - marked) + <span class="string">"ms"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上述代码所示，定义了一个二维数组 <code>long[][] arr</code> 并且使用了横向遍历和纵向遍历两种顺序对这个二位数组进行遍历，遍历总次数相同，只不过循环的方向不同，代码中记录了这两种遍历方式的耗时，不妨先卖个关子，他们的耗时会有区别吗？</p><p>这问题问的和中小学试卷中的：“它们之间有区别吗？如有，请说出区别。”一样没有水准，没区别的话文章到这儿就结束了。事实上，在我的机器上（64 位 mac）多次运行后可以发现：横向遍历的耗时大约为 25 ms，纵向遍历的耗时大约为 60 ms，前者比后者快了 1 倍有余。如果你了解上述现象出现的原因，大概能猜到，今天这篇文章的主角便是他了— CPU Cache&amp;Cache Line。</p><p>在学生生涯时，不断收到这样建议：《计算机网络》、《计算机组成原理》、《计算机操作系统》、《数据结构》四门课程是至关重要的，而在我这些年的工作经验中也不断地意识到前辈们如此建议的原因。作为一个 Java 程序员，你可以选择不去理解操作系统，组成原理（相比这二者，网络和数据结构跟日常工作联系得相对紧密），这不会降低你的 KPI，但了解他们可以使你写出更加计算机友好（Mechanical Sympathy）的代码。</p><p>下面的章节将会出现不少操作系统相关的术语，我将逐个介绍他们，并最终将他们与 Java 联系在一起。</p><h3 id="什么是-CPU-高速缓存？"><a href="#什么是-CPU-高速缓存？" class="headerlink" title="什么是 CPU 高速缓存？"></a>什么是 CPU 高速缓存？</h3><p>CPU 是计算机的心脏，最终由它来执行所有运算和程序。主内存（RAM）是数据（包括代码行）存放的地方。这两者的定义大家应该不会陌生，那 CPU 高速缓存又是什么呢？</p><blockquote><p>在<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA" target="_blank" rel="noopener">计算机</a>系统中，<strong>CPU高速缓存</strong>是用于减少处理器访问内存所需平均时间的部件。在金字塔式<a href="https://zh.wikipedia.org/w/index.php?title=%E5%AD%98%E5%82%A8%E4%BD%93%E7%B3%BB&amp;action=edit&amp;redlink=1" target="_blank" rel="noopener">存储体系</a>中它位于自顶向下的第二层，仅次于<a href="https://zh.wikipedia.org/wiki/%E5%AF%84%E5%AD%98%E5%99%A8" target="_blank" rel="noopener">CPU寄存器</a>。其容量远小于<a href="https://zh.wikipedia.org/wiki/%E5%86%85%E5%AD%98" target="_blank" rel="noopener">内存</a>，但速度却可以接近处理器的频率。</p><p>当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。</p><p>缓存之所以有效，主要是因为程序运行时对内存的访问呈现局部性（Locality）特征。这种局部性既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality）。有效利用这种局部性，缓存可以达到极高的命中率。</p><p>在处理器看来，缓存是一个透明部件。因此，程序员通常无法直接干预对缓存的操作。但是，<strong>确实可以根据缓存的特点对程序代码实施特定优化，从而更好地利用缓存</strong>。</p><p>— 维基百科</p></blockquote><p><img src="http://kirito.iocoder.cn/10538467-7923f58c663c7db1.png" alt="CPU 缓存架构"></p><p>左图为最简单的高速缓存的架构，数据的读取和存储都经过高速缓存，CPU 核心与高速缓存有一条特殊的快速通道；主存与高速缓存都连在系统总线上（BUS），这条总线还用于其他组件的通信。简而言之，CPU 高速缓存就是位于 CPU 操作和主内存之间的一层缓存。</p><h3 id="为什么需要有-CPU-高速缓存？"><a href="#为什么需要有-CPU-高速缓存？" class="headerlink" title="为什么需要有 CPU 高速缓存？"></a>为什么需要有 CPU 高速缓存？</h3><p>随着工艺的提升，最近几十年 CPU 的频率不断提升，而受制于制造工艺和成本限制，目前计算机的内存在访问速度上没有质的突破。因此，CPU 的处理速度和内存的访问速度差距越来越大，甚至可以达到上万倍。这种情况下传统的 CPU 直连内存的方式显然就会因为内存访问的等待，导致计算资源大量闲置，降低 CPU 整体吞吐量。同时又由于内存数据访问的热点集中性，在 CPU 和内存之间用较为快速而成本较高（相对于内存）的介质做一层缓存，就显得性价比极高了。</p><h3 id="为什么需要有-CPU-多级缓存？"><a href="#为什么需要有-CPU-多级缓存？" class="headerlink" title="为什么需要有 CPU 多级缓存？"></a>为什么需要有 CPU 多级缓存？</h3><p>结合 图片 – CPU 缓存架构，再来看一组 CPU 各级缓存存取速度的对比</p><ol><li>各种寄存器，用来存储本地变量和函数参数，访问一次需要1cycle，耗时小于1ns；</li><li>L1 Cache，一级缓存，本地 core 的缓存，分成 32K 的数据缓存 L1d 和 32k 指令缓存 L1i，访问 L1 需要3cycles，耗时大约 1ns；</li><li>L2 Cache，二级缓存，本地 core 的缓存，被设计为 L1 缓存与共享的 L3 缓存之间的缓冲，大小为 256K，访问 L2 需要 12cycles，耗时大约 3ns；</li><li>L3 Cache，三级缓存，在同插槽的所有 core 共享 L3 缓存，分为多个 2M 的段，访问 L3 需要 38cycles，耗时大约 12ns；</li></ol><p>大致可以得出结论，缓存层级越接近于 CPU core，容量越小，速度越快，同时，没有披露的一点是其造价也更贵。所以为了支撑更多的热点数据，同时追求最高的性价比，多级缓存架构应运而生。</p><h3 id="什么是缓存行-Cache-Line-？"><a href="#什么是缓存行-Cache-Line-？" class="headerlink" title="什么是缓存行(Cache Line)？"></a>什么是缓存行(Cache Line)？</h3><p>上面我们介绍了 CPU 多级缓存的概念，而之后的章节我们将尝试忽略“多级”这个特性，将之合并为 CPU 缓存，这对于我们理解 CPU 缓存的工作原理并无大碍。</p><p>缓存行 (Cache Line) 便是 CPU Cache 中的最小单位，CPU Cache 由若干缓存行组成，一个缓存行的大小通常是 64 字节（这取决于 CPU），并且它有效地引用主内存中的一块地址。一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。</p><p><img src="http://kirito.iocoder.cn/%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98.png" alt="多级缓存"></p><p>试想一下你正在遍历一个长度为 16 的 long 数组 data[16]，原始数据自然存在于主内存中，访问过程描述如下</p><ol><li>访问 data[0]，CPU core 尝试访问 CPU Cache，未命中。</li><li>尝试访问主内存，操作系统一次访问的单位是一个 Cache Line 的大小 — 64 字节，这意味着：既从主内存中获取到了 data[0] 的值，同时将 data[0] ~ data[7] 加入到了 CPU Cache 之中，for free~</li><li>访问 data[1]~data[7]，CPU core 尝试访问 CPU Cache，命中直接返回。</li><li>访问 data[8]，CPU core 尝试访问 CPU Cache，未命中。</li><li>尝试访问主内存。重复步骤 2</li></ol><p>CPU 缓存在顺序访问连续内存数据时挥发出了最大的优势。试想一下上一篇文章中提到的 PageCache，其实发生在磁盘 IO 和内存之间的缓存，是不是有异曲同工之妙？只不过今天的主角— CPU Cache，相比 PageCache 更加的微观。</p><p>再回到文章的开头，为何横向遍历 <code>arr = new long[1024 * 1024][8]</code> 要比纵向遍历更快？此处得到了解答，正是更加友好地利用 CPU Cache 带来的优势，甚至有一个专门的词来修饰这种行为 — Mechanical Sympathy。</p><h3 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h3><p>通常提到缓存行，大多数文章都会提到伪共享问题（正如提到 CAS 便会提到 ABA 问题一般）。</p><p>伪共享指的是多个线程同时读写同一个缓存行的不同变量时导致的 CPU 缓存失效。尽管这些变量之间没有任何关系，但由于在主内存中邻近，存在于同一个缓存行之中，它们的相互覆盖会导致频繁的缓存未命中，引发性能下降。伪共享问题难以被定位，如果系统设计者不理解 CPU 缓存架构，甚至永远无法发现 — 原来我的程序还可以更快。</p><p><img src="http://kirito.iocoder.cn/%E4%BC%AA%E5%85%B1%E4%BA%AB.png" alt="伪共享">伪共享</p><p>正如图中所述，如果多个线程的变量共享了同一个 CacheLine，任意一方的修改操作都会使得整个 CacheLine 失效（因为 CacheLine 是 CPU 缓存的最小单位），也就意味着，频繁的多线程操作，CPU 缓存将会彻底失效，降级为 CPU core 和主内存的直接交互。</p><p>伪共享问题的解决方法便是字节填充。</p><p><img src="http://kirito.iocoder.cn/%E4%BC%AA%E5%85%B1%E4%BA%AB-%E5%AD%97%E8%8A%82%E5%A1%AB%E5%85%85.png" alt="伪共享-字节填充">伪共享-字节填充</p><p>我们只需要保证不同线程的变量存在于不同的 CacheLine 即可，使用多余的字节来填充可以做点这一点，这样就不会出现伪共享问题。在代码层面如何实现图中的字节填充呢？</p><h3 id="Java6-中实现字节填充"><a href="#Java6-中实现字节填充" class="headerlink" title="Java6 中实现字节填充"></a>Java6 中实现字节填充</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PaddingObject</span></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">volatile</span> <span class="keyword">long</span> value = <span class="number">0L</span>;    <span class="comment">// 实际数据</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span> p1, p2, p3, p4, p5, p6; <span class="comment">// 填充</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>PaddingObject 类中需要保存一个 long 类型的 value 值，如果多线程操作同一个 CacheLine 中的 PaddingObject 对象，便无法完全发挥出 CPU Cache 的优势（想象一下你定义了一个 PaddingObject[] 数组，数组元素在内存中连续，却由于伪共享导致无法使用 CPU Cache 带来的沮丧）。</p><p>不知道你注意到没有，实际数据 value + 用于填充的 p1~p6 总共只占据了 7 * 8 = 56 个字节，而 Cache Line 的大小应当是 64 字节，这是有意而为之，在 Java 中，<strong>对象头还占据了 8 个字节</strong>，所以一个 PaddingObject 对象可以恰好占据一个 Cache Line。</p><h3 id="Java7-中实现字节填充"><a href="#Java7-中实现字节填充" class="headerlink" title="Java7 中实现字节填充"></a>Java7 中实现字节填充</h3><p>在 Java7 之后，一个 JVM 的优化给字节填充造成了一些影响，上面的代码片段 <code>public long p1, p2, p3, p4, p5, p6;</code> 会被认为是无效代码被优化掉，有回归到了伪共享的窘境之中。</p><p>为了避免 JVM 的自动优化，需要使用继承的方式来填充。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractPaddingObject</span></span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">long</span> p1, p2, p3, p4, p5, p6;<span class="comment">// 填充</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PaddingObject</span> <span class="keyword">extends</span> <span class="title">AbstractPaddingObject</span></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">volatile</span> <span class="keyword">long</span> value = <span class="number">0L</span>;    <span class="comment">// 实际数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Tips:实际上我在本地 mac 下测试过 jdk1.8 下的字节填充，并不会出现无效代码的优化，个人猜测和 jdk 版本有关，不过为了保险起见，还是使用相对稳妥的方式去填充较为合适。</p></blockquote><p>如果你对这个现象感兴趣，测试代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">FalseSharing</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> NUM_THREADS = <span class="number">4</span>; <span class="comment">// change</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">long</span> ITERATIONS = <span class="number">500L</span> * <span class="number">1000L</span> * <span class="number">1000L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> arrayIndex;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> VolatileLong[] longs = <span class="keyword">new</span> VolatileLong[NUM_THREADS];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; longs.length; i++) &#123;</span><br><span class="line">            longs[i] = <span class="keyword">new</span> VolatileLong();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FalseSharing</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> arrayIndex)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.arrayIndex = arrayIndex;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(<span class="keyword">final</span> String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">        runTest();</span><br><span class="line">        System.out.println(<span class="string">"duration = "</span> + (System.currentTimeMillis() - start));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">runTest</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[NUM_THREADS];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; threads.length; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(<span class="keyword">new</span> FalseSharing(i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (Thread t : threads) &#123;</span><br><span class="line">            t.start();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (Thread t : threads) &#123;</span><br><span class="line">            t.join();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> i = ITERATIONS + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="number">0</span> != --i) &#123;</span><br><span class="line">            longs[arrayIndex].value = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileLong</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">volatile</span> <span class="keyword">long</span> value = <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">long</span> p1, p2, p3, p4, p5, p6; <span class="comment">// 填充，可以注释后对比测试</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Java8-中实现字节填充"><a href="#Java8-中实现字节填充" class="headerlink" title="Java8 中实现字节填充"></a>Java8 中实现字节填充</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Target</span>(&#123;ElementType.FIELD, ElementType.TYPE&#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Contended &#123;</span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span> <span class="keyword">default</span> ""</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意需要同时开启 JVM 参数：-XX:-RestrictContended=false</strong></p><blockquote><p>@Contended 注解会增加目标实例大小，要谨慎使用。默认情况下，除了 JDK 内部的类，JVM 会忽略该注解。要应用代码支持的话，要设置 -XX:-RestrictContended=false，它默认为 true（意味仅限 JDK 内部的类使用）。当然，也有个 –XX: EnableContented 的配置参数，来控制开启和关闭该注解的功能，默认是 true，如果改为 false，可以减少 Thread 和 ConcurrentHashMap 类的大小。参加《Java性能权威指南》210 页。</p><p>— @Im 的补充</p></blockquote><p>Java8 中终于提供了字节填充的官方实现，这无疑使得 CPU Cache 更加可控了，无需担心 jdk 的无效字段优化，无需担心 Cache Line 在不同 CPU 下的大小究竟是不是 64 字节。使用 @Contended 注解可以完美的避免伪共享问题。</p><h3 id="一些最佳实践"><a href="#一些最佳实践" class="headerlink" title="一些最佳实践"></a>一些最佳实践</h3><p>可能有读者会问：作为一个普通开发者，需要关心 CPU Cache 和 Cache Line 这些知识点吗？这就跟前几天比较火的话题：「程序员有必要懂 JVM 吗？」一样，仁者见仁了。但确实有不少优秀的源码在关注着这些问题。他们包括：</p><p><strong>ConcurrentHashMap</strong></p><p>面试中问到要吐的 ConcurrentHashMap 中，使用 @sun.misc.Contended 对静态内部类 CounterCell 进行修饰。另外还包括并发容器 Exchanger 也有相同的操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ---------------- Counter support -------------- */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A padded cell for distributing counts.  Adapted from LongAdder</span></span><br><span class="line"><span class="comment"> * and Striped64.  See their internal docs for explanation.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@sun</span>.misc.Contended <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">CounterCell</span> </span>&#123;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">long</span> value;</span><br><span class="line">    CounterCell(<span class="keyword">long</span> x) &#123; value = x; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Thread</strong></p><p>Thread 线程类的源码中，使用 @sun.misc.Contended 对成员变量进行修饰。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The following three initially uninitialized fields are exclusively</span></span><br><span class="line"><span class="comment">// managed by class java.util.concurrent.ThreadLocalRandom. These</span></span><br><span class="line"><span class="comment">// fields are used to build the high-performance PRNGs in the</span></span><br><span class="line"><span class="comment">// concurrent code, and we can not risk accidental false sharing.</span></span><br><span class="line"><span class="comment">// Hence, the fields are isolated with @Contended.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** The current seed for a ThreadLocalRandom */</span></span><br><span class="line"><span class="meta">@sun</span>.misc.Contended(<span class="string">"tlr"</span>)</span><br><span class="line"><span class="keyword">long</span> threadLocalRandomSeed;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Probe hash value; nonzero if threadLocalRandomSeed initialized */</span></span><br><span class="line"><span class="meta">@sun</span>.misc.Contended(<span class="string">"tlr"</span>)</span><br><span class="line"><span class="keyword">int</span> threadLocalRandomProbe;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Secondary seed isolated from public ThreadLocalRandom sequence */</span></span><br><span class="line"><span class="meta">@sun</span>.misc.Contended(<span class="string">"tlr"</span>)</span><br><span class="line"><span class="keyword">int</span> threadLocalRandomSecondarySeed;</span><br></pre></td></tr></table></figure><p><strong>RingBuffer</strong></p><p>来源于一款优秀的开源框架 Disruptor 中的一个数据结构 <strong>RingBuffer ，</strong>我后续会专门花一篇文章的篇幅来介绍这个数据结构</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RingBufferPad</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">long</span> p1, p2, p3, p4, p5, p6, p7;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RingBufferFields</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">RingBufferPad</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>使用字节填充和继承的方式来避免伪共享。</p><h3 id="面试题扩展"><a href="#面试题扩展" class="headerlink" title="面试题扩展"></a>面试题扩展</h3><p>问：说说数组和链表这两种数据结构有什么区别？</p><p>了解了 CPU Cache 和 Cache Line 之后想想可不可以有一些特殊的回答技巧呢？</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://tech.meituan.com/disruptor.html" target="_blank" rel="noopener">高性能队列——Disruptor</a></p><p><a href="http://ifeve.com/disruptor-cacheline-padding/" target="_blank" rel="noopener">神奇的缓存行填充</a></p><p><a href="https://www.cnblogs.com/Binhua-Liu/p/5620339.html" target="_blank" rel="noopener">伪共享和缓存行填充</a></p><p><a href="http://cenalulu.github.io/linux/all-about-cpu-cache/" target="_blank" rel="noopener">关于CPU Cache – 程序猿需要知道的那些事</a></p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近的两篇文章，介绍了我参加的中间件比赛中一些相对重要的优化，但实际上还存在很多细节优化，出于篇幅限制并未提及，在最近的博文中，我会将他们整理成独立的知识点，并归类到我的系列文章「JAVA 拾遗」中。&lt;/p&gt;
    
    </summary>
    
      <category term="JAVA" scheme="http://lexburner.github.io/categories/JAVA/"/>
    
    
      <category term="JAVA" scheme="http://lexburner.github.io/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>天池中间件大赛百万队列存储设计总结【复赛】</title>
    <link href="http://lexburner.github.io/mq-million-queue/"/>
    <id>http://lexburner.github.io/mq-million-queue/</id>
    <published>2018-07-13T11:47:28.000Z</published>
    <updated>2018-11-20T11:52:43.802Z</updated>
    
    <content type="html"><![CDATA[<p>维持了 20 天的复赛终于告一段落了，国际惯例先说结果，复赛结果不太理想，一度从第 10 名掉到了最后的第 36 名，主要是写入的优化卡了 5 天，一直没有进展，最终排名也是定格在了排行榜的第二页。痛定思痛，这篇文章将自己复赛中学习的知识，成功的优化，未成功的优化都罗列一下。</p><p><img src="http://kirito.iocoder.cn/image-20180713165417073.png" alt="最终排名"></p><a id="more"></a><h3 id="赛题介绍"><a href="#赛题介绍" class="headerlink" title="赛题介绍"></a>赛题介绍</h3><p>题面描述很简单：使用 Java 或者 C++ 实现一个进程内的队列引擎，单机可支持 100 万队列以上。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">QueueStore</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(String queueName, <span class="keyword">byte</span>[] message)</span></span>;</span><br><span class="line">    <span class="keyword">abstract</span> Collection&lt;<span class="keyword">byte</span>[]&gt; get(String queueName, <span class="keyword">long</span> offset, <span class="keyword">long</span> num);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写如上接口的实现。</p><p>put 方法将一条消息写入一个队列，这个接口需要是线程安全的，评测程序会并发调用该接口进行 put，每个queue 中的内容按发送顺序存储消息（可以理解为 Java 中的 List），同时每个消息会有一个索引，索引从 0 开始，不同 queue 中的内容，相互独立，互不影响，queueName 代表队列的名称，message 代表消息的内容，评测时内容会随机产生，大部分长度在 58 字节左右，会有少量消息在 1k 左右。</p><p>get 方法从一个队列中读出一批消息，读出的消息要按照发送顺序来，这个接口需要是线程安全的，也即评测程序会并发调用该接口进行 get，返回的 Collection 会被并发读，但不涉及写，因此只需要是线程读安全就可以了，queueName 代表队列的名字，offset 代表消息的在这个队列中的起始索引，num 代表读取的消息的条数，如果消息足够，则返回 num 条，否则只返回已有的消息即可，若消息不足，则返回一个空的集合。</p><p><strong>评测程序介绍</strong></p><ol><li>发送阶段：消息大小在 58 字节左右，消息条数在 20 亿条左右，即发送总数据在 100G 左右，总队列数 100w </li><li>索引校验阶段：会对所有队列的索引进行随机校验；平均每个队列会校验1~2次；(随机消费)</li><li>顺序消费阶段：挑选 20% 的队列进行<strong>全部</strong>读取和校验； (顺序消费)</li><li>发送阶段最大耗时不能超过 1800s；索引校验阶段和顺序消费阶段加在一起，最大耗时也不能超过 1800s；超时会被判断为评测失败。</li><li>各个阶段线程数在 20~30 左右 </li></ol><p>测试环境为 4c8g 的 ECS，限定使用的最大 JVM 大小为 4GB(-Xmx 4g)。带一块 300G 左右大小的 SSD 磁盘。对于 Java 选手而言，可使用的内存可以理解为：堆外 4g 堆内 4g。</p><h3 id="赛题剖析"><a href="#赛题剖析" class="headerlink" title="赛题剖析"></a>赛题剖析</h3><p>首先解析题面，接口描述是非常简单的，只有一个 put 和一个 get 方法。需要注意特别注意下评测程序，发送阶段需要对 100w 队列，每一次发送的量只有 58 字节，最后总数据量是 100g；索引校验和顺序消费阶段都是调用的 get 接口，不同之处在于前者索引校验是随机消费，后者是对 20% 的队列从 0 号索引开始进行全量的顺序消费，评测程序的特性对最终存储设计的影响是至关重要的。</p><p>复赛题目的难点之一在于单机百万队列的设计，据查阅的资料显示</p><ul><li>Kafka 单机超过 64 个队列/分区，Kafka 分区数不宜过多</li><li>RocketMQ 单机支持最高 5 万个队列</li></ul><p>至于百万队列的使用场景，只能想到 IOT 场景有这样的需求。相较于初赛，复赛的设计更加地具有不确定性，排名靠前的选手可能会选择大相径庭的设计方案。</p><p>复赛的考察点主要有以下几个方面：磁盘块读写，读写缓冲，顺序读写与随机读写，pageCache，稀疏索引，队列存储设计等。</p><p>由于复赛成绩并不是很理想，优化 put 接口的失败是导致失利的罪魁祸首，最终成绩是 126w TPS，而第一梯队的 TPS 则是到达了 200 w+ 的 TPS。鉴于此，不太想像初赛总结那样，按照优化历程罗列，而是将自己做的方案预研，以及设计思路分享给大家，对文件 IO 不甚了解的读者也可以将此文当做一篇科普向的文章来阅读。</p><h2 id="思路详解"><a href="#思路详解" class="headerlink" title="思路详解"></a>思路详解</h2><h3 id="确定文件读写方式"><a href="#确定文件读写方式" class="headerlink" title="确定文件读写方式"></a>确定文件读写方式</h3><p>作为忠实的  Java 粉丝，自然选择使用 Java 来作为参赛语言，虽然最终的排名是被 Cpp 大佬所垄断，但着实无奈，毕业后就把 Cpp 丢到一边去了。Java 中的文件读写接口大致可以分为三类：</p><ol><li>标准 IO 读写，位于 java.io 包下，相关类：FileInputStream，FileOuputStream</li><li>NIO 读写，位于 java.nio 包下，相关类：FileChannel，ByteBuffer</li><li>Mmap 内存映射，位于 java.nio 包下，相关类：FileChannel，MappedByteBuffer</li></ol><p>标准 IO 读写不具备调研价值，直接 pass，所以 NIO 和 Mmap 的抉择，成了第一步调研对象。</p><p>第一阶段调研了 Mmap。搜索一圈下来发现，几乎所有的文章都一致认为：Mmap 这样的内存映射技术是最快的。很多没有接触过内存映射技术的人可能还不太清楚这是一种什么样的技术，简而言之，Mmap 能够将文件直接映射到用户态的内存地址，使得对文件的操作不再是 write/read,而转化为直接对内存地址的操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    String dir = <span class="string">"/Users/kirito/data/"</span>;</span><br><span class="line">    ensureDirOK(dir);</span><br><span class="line">    RandomAccessFile memoryMappedFile;</span><br><span class="line">    <span class="keyword">int</span> size = <span class="number">1</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        memoryMappedFile = <span class="keyword">new</span> RandomAccessFile(dir + <span class="string">"testMmap.txt"</span>, <span class="string">"rw"</span>);</span><br><span class="line">        MappedByteBuffer mappedByteBuffer = memoryMappedFile.getChannel().map(FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, size);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            mappedByteBuffer.position(i * <span class="number">4</span>);</span><br><span class="line">            mappedByteBuffer.putInt(i);</span><br><span class="line">        &#125;</span><br><span class="line">        memoryMappedFile.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上的代码呈现了一个最简单的 Mmap 使用方式，速度也是没话说，一个字：快！我怀着将信将疑的态度去找了更多的佐证，优秀的源码总是第一参考对象，观察下 RocketMQ 的设计，可以发现 NIO 和 Mmap 都出现在了源码中，但更多的读写操作似乎更加青睐 Mmap。RocketMQ 源码 <code>org.apache.rocketmq.store.MappedFile</code>  中两种写方法同时存在，请教 @匠心零度 后大概得出结论：RocketMQ 主要的写是通过 Mmap 来完成。</p><p><img src="http://kirito.iocoder.cn/image-20180714165922905.png" alt="两种写入方式"></p><p>但是在实际使用 Mmap 来作为写方案时遇到了两大难题，单纯从使用角度来看，暴露出了 Mmap 的局限性：</p><ol><li>Mmap 在 Java 中一次只能映射 1.5~2G 的文件内存，但实际上我们的数据文件大于 100g，这带来了第一个问题：要么需要对文件做物理拆分，切分成多文件；要么需要对文件映射做逻辑拆分，大文件分段映射。RocketMQ 中限制了单文件大小来避免这个问题。</li></ol><p><img src="http://kirito.iocoder.cn/image-20180714170826926.png" alt="文件做物理拆分"></p><ol><li>Mmap 之所以快，是因为借助了内存来加速，mappedByteBuffer 的 put 行为实际是对内存进行的操作，实际的刷盘行为依赖于操作系统的定时刷盘或者手动调用 mappedByteBuffer.force() 接口来刷盘，否则将会导致机器卡死（实测后的结论）。由于复赛的环境下内存十分有限，所以使用 Mmap 存在较难的控制问题。</li></ol><p><img src="http://kirito.iocoder.cn/image-20180714175418301.png" alt="rocketmq存在定时force线程"></p><p>经过这么一折腾，再加上资料的搜集，最终确定，<strong>Mmap 在内存较为富足并且数据量小的场景下存在优势</strong>（大多数文章的结论认为 Mmap 适合大文件的读写，私以为是不严谨的结论）。</p><p>第二阶段调研 Nio 的 FileChannel，这也是我最终确定的读写方案。</p><p>由于每个消息只有 58 字节左右，直接通过 FileChannel 写入一定会遇到瓶颈，事实上，如果你这么做，复赛连成绩估计都跑不出来。另一个说法是 ssd 最小的写入单位是 4k，如果一次写入低于 4k，实际上耗时和 4k 一样。这里涉及到了赛题的一个重要考点：块读写。</p><p><img src="http://kirito.iocoder.cn/image-20180714180739936.png" alt="云盘ssd写入性能"></p><p>根据阿里云的 ssd 云盘介绍，只有一次写入 16kb ~ 64kb 才能获得理想的 IOPS。文件系统块存储的特性，启发我们需要设置一个内存的写入缓冲区，单个消息写入内存缓冲区，缓冲区满，使用 FileChannel 进行刷盘。经过实践，使用 FileChannel 搭配缓冲区发挥的写入性能和内存充足情况下的 Mmap 并无区别，并且 FileChannel 对文件大小并无限制，控制也相对简单，所以最终确定使用 FileChannel 进行读写。</p><h3 id="确定存储结构和索引结构"><a href="#确定存储结构和索引结构" class="headerlink" title="确定存储结构和索引结构"></a>确定存储结构和索引结构</h3><p>由于赛题的背景是消息队列，评测 2 阶段的随机检测以及 3 阶段的顺序消费一次会读取多条连续的消息，并且 3 阶段的顺序消费是从队列的 0 号索引一直消费到最后一条消息，这些因素都启发我们：应当将同一个队列的消息尽可能的存到一起。前面一节提到了写缓冲区，便和这里的设计非常契合，例如我们可以一个队列设置一个写缓冲区（比赛中 Java 拥有 4g 的堆外内存，100w 队列，一个队列使用 DirectByteBuffer 分配 4k 堆外内存 ，可以保证缓冲区不会爆内存），这样同一个缓冲区的消息一起落盘，就保证了块内消息的顺序性，即做到了”同一个队列的消息尽可能的存到一起“。按块存取消息目前看来有两个优势：</p><ol><li>按条读取消息=&gt;按块读取消息，发挥块读的优势，减少了 IO 次数</li><li>全量索引=&gt;稀疏索引。块内数据是连续的，所以只需要记录块的物理文件偏移量+块内消息数即可计算出某一条消息的物理位置。这样大大降低了索引的数量，稍微计算一下可以发现，完全可以使用一个 Map 数据结构，Key 为 queueName，Value 为 List<blockindex> 在内存维护队列块的索引。如果按照传统的设计方案：一个 queue 一个索引文件，百万文件必然会超过默认的系统文件句柄上限。索引存储在内存中既规避了文件句柄数的问题，速度也不必多数，文件 IO 和 内存 IO 不是一个量级。</blockindex></li></ol><p>由于赛题规定消息体是非定长的，大多数消息 58 字节，少量消息 1k 字节的数据特性，所以存储消息体时使用 short+byte[] 的结构即可，short 记录消息的实际长度，byte[] 记录完整的消息体。short 比 int 少了 2 个字节，2*20亿消息，可以减少 4g 的数据量。</p><p><img src="http://kirito.iocoder.cn/image-20180714194249525.png" alt="稠密索引"></p><p>稠密索引是对全量的消息进行索引，适用于无序消息，索引量大，数据可以按条存取。</p><p><img src="http://kirito.iocoder.cn/image-20180714194347125.png" alt="稀疏索引"></p><p>稀疏索引适用于按块存储的消息，块内有序，适用于有序消息，索引量小，数据按照块进行存取。</p><p>由于消息队列顺序存储，顺序消费的特性，加上 ssd 云盘最小存取单位为 4k（远大于单条消息）的限制，所以稀疏索引非常适用于这种场景。至于数据文件，可以做成参数，根据实际测试来判断到底是多文件效果好，还是单文件，此方案支持 100g 的单文件。</p><h3 id="内存读写缓冲区"><a href="#内存读写缓冲区" class="headerlink" title="内存读写缓冲区"></a>内存读写缓冲区</h3><p>在稀疏索引的设计中，我们提到了写入缓冲区的概念，根据计算可以发现，100w 队列如果一个队列分配一个写入缓冲区，最多只能分配 4k，这恰好是最小的 ssd 写入块大小（但根据之前 ssd 云盘给出的数据来看，一次写入 64k 才能打满 io）。</p><p>一次写入 4k，这导致物理文件中的块大小是 4k，在读取时一次同样读取出 4k。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写缓冲区</span></span><br><span class="line"><span class="keyword">private</span> ByteBuffer writeBuffer = ByteBuffer.allocateDirect(<span class="number">4</span> * <span class="number">1024</span>);</span><br><span class="line"><span class="comment">// 用 short 记录消息长度</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> SINGLE_MESSAGE_SIZE = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(String queueName,<span class="keyword">byte</span>[] message)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 缓冲区满，先落盘</span></span><br><span class="line">    <span class="keyword">if</span> (SINGLE_MESSAGE_SIZE + message.length  &gt; writeBuffer.remaining()) &#123;</span><br><span class="line">        <span class="comment">// 落盘</span></span><br><span class="line">        flush();</span><br><span class="line">    &#125;</span><br><span class="line">    writeBuffer.putInt(SINGLE_MESSAGE_SIZE);</span><br><span class="line">    writeBuffer.put(message);</span><br><span class="line">    <span class="keyword">this</span>.blockLength++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不足 4k 的部分可以选择补 0，也可以跳过。评测程序保证了在 queue 级别的写入是同步的，所以对于同一个队列，我们无法担心同步问题。写入搞定之后，同样的逻辑搞定读取，由于 get 操作是并发的，2阶段和3阶段会有 10~30 个线程并发消费同一个队列，所以 get 操作的读缓冲区可以设计成 <code>ThreadLocal&lt;ByteBuffer&gt;</code> ，每次使用时 clear 即可，保证了缓冲区每次读取时都是崭新的，同时减少了读缓冲区的创建，否则会导致频繁的 full gc。读取的伪代码暂时不贴，因为这样的 get 方案不是最终方案。</p><p>到这里整体的设计架构已经出来了，写入流程和读取流程的主要逻辑如下：</p><p>写入流程：</p><p><img src="http://kirito.iocoder.cn/put%E6%B5%81%E7%A8%8B.png" alt="put流程"></p><p>读取流程：</p><p><img src="http://kirito.iocoder.cn/%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B.png" alt="读取流程"></p><h3 id="内存读缓存优化"><a href="#内存读缓存优化" class="headerlink" title="内存读缓存优化"></a>内存读缓存优化</h3><p>方案设计经过好几次的推翻重来，才算是确定了上述的架构，这样的架构优势在于非常简单明了，实际上我的第一版设计方案的代码量是上述方案代码量的 2~3 倍，但实际效果却不理想。上述架构的跑分成绩大概可以达到 70~80w TPS，只能算作是第三梯队的成绩，在此基础上，进行了读取缓存的优化才达到了 126w 的 TPS。在介绍读取缓存优化之前，先容我介绍下 PageCache 的概念。</p><p><img src="http://kirito.iocoder.cn/1364556742_9652.gif" alt="PageCache"></p><p>Linux 内核会将它最近访问过的文件页面缓存在内存中一段时间，这个文件缓存被称为 PageCache。如上图所示。一般的 read() 操作发生在应用程序提供的缓冲区与 PageCache 之间。而预读算法则负责填充这个PageCache。应用程序的读缓存一般都比较小，比如文件拷贝命令 cp 的读写粒度就是 4KB；内核的预读算法则会以它认为更合适的大小进行预读  I/O，比如 16-128KB。</p><p>所以一般情况下我们认为顺序读比随机读是要快的，PageCache 便是最大的功臣。</p><p>回到题目，这简直 nice 啊，因为在磁盘中同一个队列的数据是部分连续（同一个块则连续），实际上一个 4KB 块中大概可以存储 70 多个数据，而在顺序消费阶段，一次的 offset 一般为 10，有了 PageCache 的预读机制，7 次文件 IO 可以减少为 1 次！这可是不得了的优化，但是上述的架构仅仅只有 70~80w 的 TPS，这让我产生了疑惑，经过多番查找资料，最终在 @江学磊 的提醒下，才定位到了问题。</p><p><img src="http://kirito.iocoder.cn/linux-io.png" alt="linux io"></p><p>两种可能导致比赛中无法使用 pageCache 来做缓存</p><ol><li>由于我使用 FIleChannel 进行读写，NIO 的读写可能走的正是 Direct IO，所以根本不会经过 PageCache 层。</li><li>测评环境中内存有限，在 IO 密集的情况下 PageCache 效果微乎其微。</li></ol><p>虽然说不确定到底是何种原因导致 PageCache 无法使用，但是我的存储方案仍然满足顺序读取的特性，完全可以自己使用堆外内存自己模拟一个“PageCache”，这样在 3 阶段顺序消费时，TPS 会有非常高的提升。</p><p>一个队列一个读缓冲区用于顺序读，又要使得 get 阶段不存在并发问题，所以我选择了复用读缓冲区，并且给 get 操作加上了队列级别的锁，这算是一个小的牺牲，因为 2 阶段不会发生冲突，3 阶段冲突概率也并不大。改造后的读取缓存方案如下：</p><p><img src="http://kirito.iocoder.cn/%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B-%E4%BC%98%E5%8C%96%20%281%29.png" alt="读取流程-优化"></p><p>经过缓存改造之后，使用 Direct IO 也可以实现类似于 PageCache 的优化，并且会更加的可控，不至于造成频繁的缺页中断。经过这个优化，加上一些 gc 的优化，可以达到 126w TPS。整体方案算是介绍完毕。</p><h3 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h3><p>还有一些优化对整体流程影响不大，拎出来单独介绍。</p><p>2 阶段的随机索引检测和 3 阶段的顺序消费可以采取不同的策略，2 阶段可以直接读取所需要的数据，而不需要进行缓存（因为是随机检测，所以读缓存肯定不会命中）。</p><p>将文件数做成参数，调整参数来判断到底是多文件 TPS 高还是单文件，实际上测试后发现，差距并不是很大，单文件效果略好，由于是 ssd 云盘，又不存在磁头，所以真的不太懂原理。</p><p>gc 优化，能用数组的地方不要用 List。尽量减少小对象的出现，可以用数组管理基本数据类型，小对象对 gc 非常不友好，无论是初赛还是复赛，Java 比 Cpp 始终差距一个垃圾回收机制。必须保证全程不出现 full gc。</p><h3 id="失败的优化与反思"><a href="#失败的优化与反思" class="headerlink" title="失败的优化与反思"></a>失败的优化与反思</h3><p>本次比赛算是留下了不小的遗憾，因为写入的优化一直没有做好，读取缓存做好之后我 2 阶段和 3阶段的总耗时相加是 400+s，算是不错的成绩，但是写入耗时在 1300+s。我上述的方案采用的是多线程同步刷盘，但也尝试过如下的写入方案：</p><ol><li>异步提交写缓冲区，单线程直接刷盘</li><li>异步提交写缓冲区，设置二级缓冲区 64k~64M，单线程使用二级缓冲区刷盘</li><li>同步将写缓冲区的数据拷贝至一个 LockFreeQueue，单线程平滑消费，以打满 IOPS</li><li>每 16 个队列共享一个写入缓冲区，这样控制写入缓冲区可以达到 64k，在刷盘时进行排序，将同一个 queue 的数据放置在一起。</li></ol><p>但都以失败告终，没有 get 到写入优化的要领，算是本次比赛最大的遗憾了。</p><p>还有一个失误在于，评测环境使用的云盘 ssd 和我的本地 Mac 下的 ssd 存储结构差距太大，加上 mac os 和 Linux 的一些差距，导致本地成功的优化在线上完全体现不出来，还是租个阿里云环境比较靠谱。</p><p>另一方面的反思，则是对存储和 MQ 架构设计的不熟悉，对于 Kafka 和 RocketMQ 所做的一些优化也都是现学现用，不太确定用的对不对，导致走了一些弯路，而比赛中认识的一个 96 年的小伙子王亚普，相比之下对中间件知识理解的深度和广度实在令我钦佩，实在还有很多知识需要学习。</p><h3 id="参赛感悟"><a href="#参赛感悟" class="headerlink" title="参赛感悟"></a>参赛感悟</h3><p>第一感受是累，第二感受是爽。相信很多选手和我一样是工作党，白天工作，只能腾出晚上的时间去搞比赛，对于966 的我真是太不友好了，初赛时间延长了一次还算给缓了一口气，复赛一眨眼就过去了，想翻盘都没机会，实在是遗憾。爽在于这次比赛真的是汗快淋漓地实践了不少中间件相关的技术，初赛的 Netty，复赛的存储设计，都是难以忘怀的回忆，比赛中也认识了不少朋友，有学生党，有工作党，感谢你们不厌其烦的教导与发人深省的讨论，从不同的人身上是真的可以学到很多自己缺失的知识。</p><p>据消息说，阿里中间件大赛很有可能是最后一届，无论是因为什么原因，作为参赛者，我都感到深深的惋惜，希望还能有机会参加下一届的中间件大赛，也期待能看到更多的相同类型的赛事被各大互联网公司举办，和大佬们同台竞技，一边认识更多新朋友的感觉真棒。</p><p>虽然最终无缘决赛，但还是期待进入决赛的 11 位选手能带来一场精彩的答辩，也好解答我始终优化失败的写入方案。后续会考虑吸收下前几名 JAVA 的优化思路，整理成最终完善的方案。<br>目前方案的 git 地址，仓库已公开：<a href="https://code.aliyun.com/250577914/queuerace2018.git" target="_blank" rel="noopener">https://code.aliyun.com/250577914/queuerace2018.git</a></p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;维持了 20 天的复赛终于告一段落了，国际惯例先说结果，复赛结果不太理想，一度从第 10 名掉到了最后的第 36 名，主要是写入的优化卡了 5 天，一直没有进展，最终排名也是定格在了排行榜的第二页。痛定思痛，这篇文章将自己复赛中学习的知识，成功的优化，未成功的优化都罗列一下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://kirito.iocoder.cn/image-20180713165417073.png&quot; alt=&quot;最终排名&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="MQ" scheme="http://lexburner.github.io/categories/MQ/"/>
    
    
      <category term="MQ" scheme="http://lexburner.github.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>选择Kong作为你的API网关</title>
    <link href="http://lexburner.github.io/kong-introduction/"/>
    <id>http://lexburner.github.io/kong-introduction/</id>
    <published>2018-07-12T11:47:28.000Z</published>
    <updated>2018-11-20T11:52:31.809Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Kong（<a href="https://github.com/Kong/kong）是一个云原生，高效，可扩展的分布式" target="_blank" rel="noopener">https://github.com/Kong/kong）是一个云原生，高效，可扩展的分布式</a> API 网关。 自 2015 年在 github 开源后，广泛受到关注，目前已收获 1.68w+ 的 star，其核心价值在于高性能和可扩展性。</p></blockquote><a id="more"></a><h3 id="为什么需要-API-网关"><a href="#为什么需要-API-网关" class="headerlink" title="为什么需要 API 网关"></a>为什么需要 API 网关</h3><p><img src="https://camo.githubusercontent.com/d4d0dcb22c223db0bf2e301aab0dddb3015f1729/68747470733a2f2f6b6f6e6768712e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30352f6b6f6e672d62656e65666974732d6769746875622d726561646d652e706e67" alt="img"></p><p>在微服务架构之下，服务被拆的非常零散，降低了耦合度的同时也给服务的统一管理增加了难度。如上图左所示，在旧的服务治理体系之下，鉴权，限流，日志，监控等通用功能需要在每个服务中单独实现，这使得系统维护者没有一个全局的视图来统一管理这些功能。API 网关致力于解决的问题便是为微服务纳管这些通用的功能，在此基础上提高系统的可扩展性。如右图所示，微服务搭配上 API 网关，可以使得服务本身更专注于自己的领域，很好地对服务调用者和服务提供者做了隔离。</p><h3 id="为什么是-Kong"><a href="#为什么是-Kong" class="headerlink" title="为什么是 Kong"></a>为什么是 Kong</h3><p>SpringCloud 玩家肯定都听说过 Zuul 这个路由组件，包括 Zuul2 和 Springcloud Gateway 等框架，在国内的知名度都不低。没错，我称呼这些为组件 Or 框架，而 Kong 则更衬的上产品这个词。在此我们可以简单对比下 Zuul 和 Kong。</p><p>举例而言，如果选择使用 Zuul，当需要为应用添加限流功能，由于 Zuul 只提供了基本的路由功能，开发者需要自己研发 Zuul Filter，可能你觉得一个功能还并不麻烦，但如果在此基础上对 Zuul 提出更多的要求，很遗憾，Zuul 使用者需要自行承担这些复杂性。而对于 Kong 来说，限流功能就是一个插件，只需要简单的配置，即可开箱即用。</p><p>Kong 的插件机制是其高可扩展性的根源，Kong 可以很方便地为路由和服务提供各种插件，网关所需要的基本特性，Kong 都如数支持：</p><ul><li><strong>云原生</strong>: 与平台无关，Kong可以从裸机运行到Kubernetes</li><li><strong>动态路由</strong>：Kong 的背后是 OpenResty+Lua，所以从 OpenResty 继承了动态路由的特性</li><li><strong>熔断</strong></li><li><strong>健康检查</strong> </li><li><strong>日志</strong>: 可以记录通过 Kong 的 HTTP，TCP，UDP 请求和响应。</li><li><strong>鉴权</strong>: 权限控制，IP 黑白名单，同样是 OpenResty 的特性</li><li><strong>SSL</strong>: Setup a Specific SSL Certificate for an underlying service or API.</li><li><strong>监控</strong>: Kong 提供了实时监控插件</li><li><strong>认证</strong>: 如数支持 HMAC, JWT, Basic, OAuth2.0 等常用协议</li><li><strong>限流</strong></li><li><strong>REST API</strong>: 通过 Rest API 进行配置管理，从繁琐的配置文件中解放</li><li><strong>可用性</strong>: 天然支持分布式</li><li><strong>高性能</strong>: 背靠非阻塞通信的 nginx，性能自不用说</li><li><strong>插件机制</strong>: 提供众多开箱即用的插件，且有易于扩展的自定义插件接口，用户可以使用 Lua 自行开发插件</li></ul><p>上面这些特性中，反复提及了 Kong 背后的 OpenResty，实际上，使用 Kong 之后，Nginx 可以完全摒弃，Kong 的功能是 Nginx 的父集。</p><p>而 Zuul 除了基础的路由特性以及其本身和 SpringCloud 结合较为紧密之外，并无任何优势。</p><h3 id="Kong-的架构"><a href="#Kong-的架构" class="headerlink" title="Kong 的架构"></a>Kong 的架构</h3><p><img src="http://kirito.iocoder.cn/image-20180712184740981.png" alt="image-20180712184740981"></p><p>从技术的角度讲，Kong 可以认为是一个 OpenResty 应用程序。 OpenResty 运行在 Nginx 之上，使用 Lua 扩展了 Nginx。 Lua 是一种非常容易使用的脚本语言，可以让你在 Nginx 中编写一些逻辑操作。之前我们提到过一个概念 Kong = OpenResty + Nginx + Lua，但想要从全局视角了解 Kong 的工作原理，还是直接看源码比较直接。我们定位到本地的 Kong 文件夹，按照上图中的目录层级来识识 Kong 的庐山真面目。</p><ol><li>Kong 文件下包含了全部源码和必要组件，分析他们，我们便得到了 Kong 的架构。0.13.x 是目前 Kong 的最新版本。</li><li>从 2 号块中可以看到 nginx.conf ，这其实便是一个标准的 Nginx 目录结构，这也揭示了 Kong 其实就是运行在 Nginx 的基础之上，而进行的二次封装。由 share 文件夹向下展开下一次分析。</li><li>share 文件夹中包含了 OpenResty 的相关内容，其实背后就是一堆 Lua 脚本，例如 lapis 包含了数据库操作，Nginx 生命周期，缓存控制等必要的 Lua 脚本，logging 包含了日志相关的 Lua 脚本，resty 包含了 dns，健康检查等相关功能的 Lua 脚本…而其中的 kong 目录值得我们重点分析，他包含了 Kong 的核心对象。</li><li>api 和 core 文件夹，封装了 Kong 对 service，route，upstream，target 等核心对象的操作代码（这四个核心对象将会在下面的小节重点介绍），而 plugins 文件夹则是 Kong 高可扩展性的根源，存放了 kong 的诸多扩展功能。</li><li>plugins 文件夹包含了上一节提到的 Kong 的诸多插件功能，如权限控制插件，跨域插件，jwt 插件，oauth2 插件…如果需要自定义插件，则需要将代码置于此处。</li></ol><p>从上述文件夹浏览下来，大概可以看到它和 Nginx 的相似之处，并在此基础之上借助于 Lua 对自身的功能进行了拓展，除了 nginx.conf 中的配置，和相对固定的文件层级，Kong 还需要连接一个数据库来管理路由配置，服务配置，upstream 配置等信息，是的，由于 Kong 支持动态路由的特性，所以几乎所有动态的配置都不是配置在文件中，而是借助于 Postgres 或者 Cassandra 进行管理。</p><p><img src="http://kirito.iocoder.cn/image-20180712192742718.png" alt="postgres"></p><p>Kong 对外暴露了 Restful API，最终的配置便是落地在了数据库之中。</p><h3 id="Kong-的管理方式"><a href="#Kong-的管理方式" class="headerlink" title="Kong 的管理方式"></a>Kong 的管理方式</h3><p>通过文件夹结构的分析，以及数据库中的表结构，我们已经对 Kong 的整体架构有了一个基本的认识，但肯定还存在一个疑问：我会配置 Nginx 来控制路由，但这个 Kong 应当怎么配置才能达到相同的目的呢？莫急，下面来看看 Kong 如何管理配置。</p><p>Kong 简单易用的背后，便是因为其所有的操作都是基于 HTTP Restful API 来进行的。</p><p><img src="http://blog.didispace.com/content/images/posts/hzf-ms-apigateway-2-9.png" alt="kong端点"></p><p>其中 8000/8443 分别是 Http 和 Https 的转发端口，等价于 Nginx 默认的 80 端口，而 8001 端口便是默认的管理端口，我们可以通过 HTTP Restful API 来动态管理 Kong 的配置。</p><p><strong>一个典型的 Nginx 配置</strong></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">upstream</span> helloUpstream &#123;</span><br><span class="line"><span class="attribute">server</span> localhost:<span class="number">3000</span> weight=<span class="number">100</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line"><span class="attribute">listen</span><span class="number">80</span>;</span><br><span class="line"><span class="attribute">location</span> /hello &#123;</span><br><span class="line"><span class="attribute">proxy_pass</span> http://helloUpstream;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上这个简单的 Nginx 配置，便可以转换为如下的 Http 请求。</p><p><strong>对应的 Kong 配置</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 配置 upstream</span><br><span class="line">curl -X POST http://localhost:8001/upstreams --data "name=helloUpstream"</span><br><span class="line"><span class="meta">#</span> 配置 target</span><br><span class="line">curl -X POST http://localhost:8001/upstreams/hello/targets --data "target=localhost:3000" --data "weight=100"</span><br><span class="line"><span class="meta">#</span> 配置 service</span><br><span class="line">curl -X POST http://localhost:8001/services --data "name=hello" --data "host=helloUpstream"</span><br><span class="line"><span class="meta">#</span> 配置 route</span><br><span class="line">curl -X POST http://localhost:8001/routes --data "paths[]=/hello" --data "service.id=8695cc65-16c1-43b1-95a1-5d30d0a50409"</span><br><span class="line">curl -X POST http://localhost:8001/routes --data "hosts[]=a.com,b.com,*.abc.com" --data "service.id=8695cc65-16c1-43b1-95a1-5d30d0a50409"</span><br></pre></td></tr></table></figure><p>这一切都是动态的，无需手动 reload nginx.conf。</p><p>我们为 Kong 新增路由信息时涉及到了 upstream，target，service，route 等概念，他们便是 Kong 最最核心的四个对象。（你可能在其他 Kong 的文章中见到了 api 这个对象，在最新版本 0.13 中已经被弃用，api 已经由 service 和 route 替代）</p><p>从上面的配置以及他们的字面含义大概能够推测出他们的职责，<strong>upstream 是对上游服务器的抽象；target 代表了一个物理服务，是 ip + port 的抽象；service 是抽象层面的服务，他可以直接映射到一个物理服务(host 指向 ip + port)，也可以指向一个 upstream 来做到负载均衡；route 是路由的抽象，他负责将实际的 request 映射到 service</strong>。</p><p>他们的关系如下</p><p>upstream 和 target ：1 对 n</p><p>service 和 upstream ：1 对 1 或 1 对 0 （service 也可以直接指向具体的 target，相当于不做负载均衡）</p><p>service 和 route：1 对 n</p><h3 id="高可扩展性的背后—插件机制"><a href="#高可扩展性的背后—插件机制" class="headerlink" title="高可扩展性的背后—插件机制"></a>高可扩展性的背后—插件机制</h3><p>Kong 的另一大特色便是其插件机制，这也是我认为的 Kong 最优雅的一个设计。</p><p>文章开始时我们便提到一点，微服务架构中，网关应当承担所有服务共同需要的那部分功能，这一节我们便来介绍下，Kong 如何添加 jwt 插件，限流插件。</p><p>插件（Plugins）装在哪儿？对于部分插件，可能是全局的，影响范围是整个 Kong 服务；大多数插件都是装在 service 或者 route 之上。这使得插件的影响范围非常灵活，我们可能只需要对核心接口进行限流控制，只需要对部分接口进行权限控制，这时候，对特定的 service 和 route 进行定向的配置即可。</p><p>为 hello 服务添加50次/秒的限流</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://localhost:8001/services/hello/plugins \</span><br><span class="line">--data "name=rate-limiting" \</span><br><span class="line">--data "config.second=50"</span><br></pre></td></tr></table></figure><p>为 hello 服务添加 jwt 插件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://localhost:8001/services/login/plugins \</span><br><span class="line">--data "name=jwt"</span><br></pre></td></tr></table></figure><p>同理，插件也可以安装在 route 之上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://localhost:8001/routes/&#123;routeId&#125;/plugins \</span><br><span class="line">--data "name=rate-limiting" \</span><br><span class="line">--data "config.second=50"</span><br><span class="line"></span><br><span class="line">curl -X POST http://localhost:8001/routes/&#123;routeId&#125;/plugins \</span><br><span class="line">--data "name=jwt"</span><br></pre></td></tr></table></figure><p>在官方文档中，我们可以获取全部的插件 <a href="https://konghq.com/plugins/，部分插件需要收费的企业版才可使用。" target="_blank" rel="noopener">https://konghq.com/plugins/，部分插件需要收费的企业版才可使用。</a></p><p><img src="http://kirito.iocoder.cn/image-20180712200520739.png" alt="kong插件"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Kong 是目前市场上相对较为成熟的开源 API 网关产品，无论是性能，扩展性，还是功能特性，都决定了它是一款优秀的产品，对 OpenResty 和 Lua 感兴趣的同学，Kong 也是一个优秀的学习参考对象。基于 OpenResty，可以在现有 Kong 的基础上进行一些扩展，从而实现更复杂的特性，比如我司内部的 ABTest 插件和定制化的认证插件，开发成本都相对较低。Kong 系列的文章将会在以后持续连载。</p><hr><p>阅读扩展</p><p>初识 Kong 之负载均衡 <a href="https://www.cnkirito.moe/kong-loadbalance/" target="_blank" rel="noopener">https://www.cnkirito.moe/kong-loadbalance/</a> </p><p>Kong 集成 Jwt 插件 <a href="https://www.cnkirito.moe/kong-jwt/" target="_blank" rel="noopener">https://www.cnkirito.moe/kong-jwt/</a></p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Kong（&lt;a href=&quot;https://github.com/Kong/kong）是一个云原生，高效，可扩展的分布式&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/Kong/kong）是一个云原生，高效，可扩展的分布式&lt;/a&gt; API 网关。 自 2015 年在 github 开源后，广泛受到关注，目前已收获 1.68w+ 的 star，其核心价值在于高性能和可扩展性。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Kong" scheme="http://lexburner.github.io/categories/Kong/"/>
    
    
      <category term="Kong" scheme="http://lexburner.github.io/tags/Kong/"/>
    
  </entry>
  
  <entry>
    <title>天池中间件大赛dubboMesh优化总结（qps从1000到6850）</title>
    <link href="http://lexburner.github.io/dubboMesh/"/>
    <id>http://lexburner.github.io/dubboMesh/</id>
    <published>2018-06-19T11:47:28.000Z</published>
    <updated>2018-11-20T11:51:14.541Z</updated>
    
    <content type="html"><![CDATA[<p>天池中间件大赛的初赛在今早终于正式结束了，公众号停更了一个月，主要原因就是博主的空余时间几乎全花在这个比赛上，第一赛季结束，做下参赛总结，总的来说，收获不小。</p><p><img src="http://kirito.iocoder.cn/image-20180619190732570.png" alt="最终排名"><br><a id="more"></a><br>先说结果，最终榜单排名是第 15 名（除去前排大佬的两个小号，加上作弊的第一名，勉强能算是第 12 名），说实话是挺满意的成绩。这篇文章主要是分享给以下读者：比赛中使用了 netty 却没有达到理想 qps 的朋友，netty 刚入门的朋友，对 dubbo mesh 感兴趣的朋友。</p><p>在比赛之前我个人对 netty 的认识也仅仅停留在了解的层面，在之前解读 RPC 原理的系列文章中涉及到 netty 传输时曾了解过一二，基本可以算零基础使用 netty 参赛，所以我会更多地站在一个小白的视角来阐述自己的优化历程，一步步地提高 qps，也不会绕开那些自己踩过的坑以及负优化。另一方面，由于自己对 netty 的理解并不是很深，所以文中如果出现错误，敬请谅解，欢迎指正。</p><h3 id="Dubbo-Mesh-是什么？"><a href="#Dubbo-Mesh-是什么？" class="headerlink" title="Dubbo Mesh 是什么？"></a>Dubbo Mesh 是什么？</h3><p>为了照顾那些不太了解这次比赛内容的读者，我先花少量的篇幅介绍下这次阿里举办的天池中间件大赛到底比的是个什么东西，那就不得不先介绍下 Dubbo Mesh 这个概念。</p><p>如果你用过 dubbo，并且对 service mesh 有所了解，那么一定可以秒懂 Dubbo Mesh 是为了解决什么问题。说白了，dubbo 原先是为了 java 语言而准备的，没有考虑到跨语言的问题，这意味着 nodejs，python，go 要想无缝使用 dubbo 服务，要么借助于各自语言的 dubbo 客户端，例如：node-dubbo-client，python-dubbo-client，go-dubbo-client；要么就是借助于 service mesh 的解决方案，让 dubbo 自己提供跨语言的解决方案，来屏蔽不同语言的处理细节，于是乎，dubbo 生态的跨语言 service mesh 解决方案就被命名为了 dubbo mesh。一图胜千言：</p><p><img src="https://work.alibaba-inc.com/aliwork_tfs/g01_alibaba-inc_com/tfscom/TB1ctUkXwZC2uNjSZFnXXaxZpXa.tfsprivate.png" alt="Dubbo Mesh"></p><p>在原先的 dubbo 生态下，只有 consumer，provider，注册中心的概念。dubbo mesh 生态下为每个服务（每个 consumer，provider 实例）启动一个 agent，服务间不再进行直接的通信，而是经由各自的 agent 完成交互，并且服务的注册发现也由 agent 完成。图中红色的 agent 便是这次比赛的核心，选手们可以选择合适的语言来实现 agent，最终比拼高并发下各自 agent 实现的 qps，qps 即最终排名的依据。</p><h3 id="赛题剖析"><a href="#赛题剖析" class="headerlink" title="赛题剖析"></a>赛题剖析</h3><p>这次比赛的主要考察点在于高并发下网络通信模型的实现，可以涵盖以下几个关键点：reactor 模型，负载均衡，线程，锁，io 通信，阻塞与非阻塞，零拷贝，序列化，http/tcp/udp与自定义协议，批处理，垃圾回收，服务注册发现等。它们对最终程序的 qps 起着或大或小的影响，对它们的理解越深，越能够编写出高性能的 dubbo mesh 方案。</p><p>语言的选择，初赛结束后的感受，大家主要还是在 java，c++，go 中进行了抉择。语言的选择考虑到了诸多的因素，通用性，轻量级，性能，代码量和qps的性价比，选手的习惯等等。虽然前几名貌似都是 c++，但总体来说，排名 top 10 之外，绝不会是因为语言特性在从中阻挠。c++ 选手高性能的背后，可能是牺牲了 600 多行代码在自己维护一个 etcd-lib（比赛限制使用 etcd，但据使用 c++ 的选手说，c++ 没有提供 etcd 的 lib）；且这次比赛提供了预热环节，java 党也露出了欣慰的笑容。java 的主流框架还是在 nio，akka，netty 之间的抉择，netty 应该是众多 java 选手中较为青睐的，博主也选择了 netty 作为 dubbo mesh 的实现；go 的协程和网络库也是两把利器，并不比 java 弱，加上其进程轻量级的特性，也作为了一个选择。</p><p>官方提供了一个 qps 并不是很高的 demo，来方便选手们理解题意，可以说是非常贴心了，来回顾一下最简易的 dubbo mesh 实现：</p><p><img src="http://kirito.iocoder.cn/image-20180619200219464.png" alt="dubbo mesh初始方案"></p><p>如上图所示，是整个初始 dubbo mesh 的架构图，其中 consumer 和 provider 以灰色表示，因为选手是不能修改其实现的，绿色部分的 agent 是可以由选手们自由发挥的部分。比赛中 consumer，consumer-agent 为 单个实例，provider、provider-agent 分别启动了三个性能不一的实例：small，medium，large，这点我没有在图中表示出来，大家自行脑补。所以所有选手都需要完成以下几件事：</p><ol><li>consumer-agent 需要启动一个 http 服务器，接收来自 consumer 的 http 请求</li><li>consumer-agent 需要转发该 http 请求给 provider-agent，并且由于 provider-agent 有多个实例，所以需要做负载均衡。consumer-agent 与 provider-agent 之间如何通信可以自由发挥。</li><li>provider-agent 拿到 consumer-agent 的请求之后，需要组装成 dubbo 协议， 使用 tcp 与 provider 完成通信。</li></ol><p>这样一个跨语言的简易 dubbo mesh 便呈现在大家面前了，从 consumer 发出的 http 协议，最终成功调用到了使用 java 语言编写的 dubbo 服务。这中间如何优化，如何使用各种黑科技成就了一场非常有趣的比赛。博主所有的优化都不是一蹴而就的，都是一天天的提交试出来的，所以恰好可以使用时间线顺序叙述自己的改造历程。</p><h3 id="优化历程"><a href="#优化历程" class="headerlink" title="优化历程"></a>优化历程</h3><p><strong>Qps 1000 到 2500 (CA 与 PA 使用异步 http 通信)</strong></p><p>官方提供的 demo 直接跑通了整个通信流程，省去了我们大量的时间，初始版本评测可以达到 1000+ 的 qps，所以 1000 可以作为 baseline 给大家提供参考。demo 中 consumer 使用 asyncHttpClient 发送异步的 http 请求， consumer-agent 使用了 springmvc 支持的 servlet3.0 特性；而 consumer-agent 到 provider-agent 之间的通信却使用了同步 http，所以 C 到 CA 这一环节相比 CA 到 PA 这一环节性能是要强很多的。改造起来也很简单，参照 C 到 CA 的设计，直接将 CA 到 PA 也替换成异步 http，qps 可以直接到达 2500。</p><p>主要得益于 async-http-client 提供的异步 http-client，以及 servlet3.0 提供的非阻塞 api。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.asynchttpclient<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>async-http-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 非阻塞发送 http 请求</span></span><br><span class="line">ListenableFuture&lt;org.asynchttpclient.Response&gt; responseFuture = asyncHttpClient.executeRequest(request);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 非阻塞返回 http 响应</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/invoke"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> DeferredResult&lt;ResponseEntity&gt; <span class="title">invoke</span><span class="params">()</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure><p><strong>Qps 2500 到 2800 (负载均衡优化为加权轮询)</strong></p><p>demo 中提供的负载均衡算法是随机算法，在 small-pa，medium-pa，large-pa 中随机选择一个访问，每个服务的性能不一样，响应时间自然也不同，随机负载均衡算法存在严重的不稳定性，无法按需分配请求，所以成了自然而然的第二个改造点。</p><p>优化为加权轮询算法，这一块的实现参考了 motan（weibo 开源的 rpc 框架）的实现，详见 <code>com.alibaba.dubbo.performance.demo.agent.cluster.loadbalance.WeightRoundRobinLoadBalance</code>(文末贴 git 地址)。</p><p>在启动脚本中配置权重信息，伴随 pa 启动注册服务地址到 etcd 时，顺带将权重信息一并注册到 etcd 中，ca 拉取服务列表时即可获取到负载比例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">large:</span><br><span class="line">-Dlb.weight=3</span><br><span class="line">medium:</span><br><span class="line">-Dlb.weight=2</span><br><span class="line">small:</span><br><span class="line">-Dlb.weight=1</span><br></pre></td></tr></table></figure><p>预热赛时最高并发为 256 连接，这样的比例可以充分发挥每个 pa 的性能。</p><p><strong>Qps 2800 到 3500 (future-&gt;callback)</strong></p><p>c 到 ca 以及 ca 到 pa 此时尽管是 http 通信，但已经实现了非阻塞的特性（请求不会阻塞 io 线程），但 dubbo mesh 的 demo 中 pa 到 p 的这一通信环节还是使用的 future.get + countDownLatch 的阻塞方式，一旦整个环节出现了锁和阻塞，qps 必然上不去。关于几种获取结果的方式，也是老生常谈的话题：</p><p><img src="https://cdn.yuque.com/yuque/0/2018/png/101192/1525856256886-9eefdf3f-9dd5-471b-94bb-1b76dcdd3bb3.png" alt="基础通信模型"></p><p>future 方式在调用过程中不会阻塞线程，但获取结果是会阻塞线程，provider 固定 sleep 了 50 ms，所以获取 future 结果依旧是一个耗时的过程，加上这种模型一般会使用锁来等待，性能会造成明显的下降。替换成 callback 的好处是，io 线程专注于 io 事件，降低了线程数，这和 netty 的 io 模型也是非常契合的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Promise&lt;Integer&gt; agentResponsePromise = <span class="keyword">new</span> DefaultPromise&lt;&gt;(ctx.executor());</span><br><span class="line">agentResponsePromise.addListener();</span><br></pre></td></tr></table></figure><p>netty 为此提供了默认的 Promise 的抽象，以及 DefaultPromise 的默认实现，我们可以 out-of-box 的使用 callback 特性。在 netty 的入站 handler 的 channelRead 事件中创建 promise，拿到 requestId，建立 requestId 和 promise 的映射；在出站 handler 的channelRead 事件中拿到返回的 requestId，查到 promise，调用 done 方法，便完成了非阻塞的请求响应。可参考： 入站 handler <code>ConsumerAgentHttpServerHandler</code> 和  和出站 handler  <code>ConsumerAgentClientHandler</code> 的实现。</p><p><strong>Qps 3500 到 4200 (http通信替换为tcp通信)</strong></p><p>ca 到 pa 的通信原本是异步 http 的通信方式，完全可以参考 pa 到 p 的异步 tcp 通信进行改造。自定义 agent 之间的通信协议也非常容易，考虑到 tcp 粘包的问题，使用定长头+字节数组来作为自定义协议是一个较为常用的做法。这里踩过一个坑，原本想使用 protoBuffer 来作为自定义协议，netty 也很友好的提供了基于 protoBuffer 协议的编解码器，只需要编写好 DubboMeshProto.proto 文件即可：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">AgentRequest</span> </span>&#123;</span><br><span class="line">    <span class="built_in">int64</span> requestId = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">string</span> interfaceName = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">string</span> method = <span class="number">3</span>;</span><br><span class="line">    <span class="built_in">string</span> parameterTypesString = <span class="number">4</span>;</span><br><span class="line">    <span class="built_in">string</span> parameter = <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">AgentResponse</span> </span>&#123;</span><br><span class="line">    <span class="built_in">int64</span> requestId = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">bytes</span> hash = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>protoBuffer 在实际使用中的优势是毋庸置疑的，其可以尽可能的压缩字节，减少 io 码流。在正式赛之前一直用的好好的，但后来的 512 并发下通过 jprofile 发现，DubboMeshProto 的 getSerializedSize ,getDescriptorForType 等方法存在不必要的耗时，对于这次比赛中如此简单的数据结构而言 protoBuffer 并不是那么优秀。最终还是采取了定长头+字节数组的自定义协议。参考：<code>com.alibaba.dubbo.performance.demo.agent.protocol.simple.SimpleDecoder</code></p><p>http 通信既然换了，干脆一换到底，ca 的 springmvc 服务器也可以使用 netty 实现，这样更加有利于实现 ca 整体的 reactive。使用 netty 实现 http 服务器很简单，使用 netty 提供的默认编码解码器即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerAgentHttpServerInitializer</span> <span class="keyword">extends</span> <span class="title">ChannelInitializer</span>&lt;<span class="title">SocketChannel</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(SocketChannel ch)</span> </span>&#123;</span><br><span class="line">        ChannelPipeline p = ch.pipeline();</span><br><span class="line">        p.addLast(<span class="string">"encoder"</span>, <span class="keyword">new</span> HttpResponseEncoder());</span><br><span class="line">        p.addLast(<span class="string">"decoder"</span>, <span class="keyword">new</span> HttpRequestDecoder());</span><br><span class="line">        p.addLast(<span class="string">"aggregator"</span>, <span class="keyword">new</span> HttpObjectAggregator(<span class="number">10</span> * <span class="number">1024</span> * <span class="number">1024</span>));</span><br><span class="line">        p.addLast(<span class="keyword">new</span> ConsumerAgentHttpServerHandler());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>http 服务器的实现也踩了一个坑，解码 http request 请求时没注意好 ByteBuf 的释放，导致 qps 跌倒了 2000+，反而不如 springmvc 的实现。在队友@闪电侠的帮助下成功定位到了内存泄露的问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">parse</span><span class="params">(FullHttpRequest req)</span> </span>&#123;</span><br><span class="line">    Map&lt;String, String&gt; params = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="comment">// 是POST请求</span></span><br><span class="line">    HttpPostRequestDecoder decoder = <span class="keyword">new</span> HttpPostRequestDecoder(<span class="keyword">new</span> DefaultHttpDataFactory(<span class="keyword">false</span>), req);</span><br><span class="line">    List&lt;InterfaceHttpData&gt; postList = decoder.getBodyHttpDatas();</span><br><span class="line">    <span class="keyword">for</span> (InterfaceHttpData data : postList) &#123;</span><br><span class="line">        <span class="keyword">if</span> (data.getHttpDataType() == InterfaceHttpData.HttpDataType.Attribute) &#123;</span><br><span class="line">            MemoryAttribute attribute = (MemoryAttribute) data;</span><br><span class="line">            params.put(attribute.getName(), attribute.getValue());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// resolve memory leak</span></span><br><span class="line">    decoder.destroy();</span><br><span class="line">    <span class="keyword">return</span> params;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在正式赛后发现还有更快的 decode 方式，不需要借助于上述的 HttpPostRequestDecoder，而是改用 QueryStringDecoder：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">fastParse</span><span class="params">(FullHttpRequest httpRequest)</span> </span>&#123;</span><br><span class="line">    String content = httpRequest.content().toString(StandardCharsets.UTF_8);</span><br><span class="line">    QueryStringDecoder qs = <span class="keyword">new</span> QueryStringDecoder(content, StandardCharsets.UTF_8, <span class="keyword">false</span>);</span><br><span class="line">    Map&lt;String, List&lt;String&gt;&gt; parameters = qs.parameters();</span><br><span class="line">    String interfaceName = parameters.get(<span class="string">"interface"</span>).get(<span class="number">0</span>);</span><br><span class="line">    String method = parameters.get(<span class="string">"method"</span>).get(<span class="number">0</span>);</span><br><span class="line">    String parameterTypesString = parameters.get(<span class="string">"parameterTypesString"</span>).get(<span class="number">0</span>);</span><br><span class="line">    String parameter = parameters.get(<span class="string">"parameter"</span>).get(<span class="number">0</span>);</span><br><span class="line">    Map&lt;String, String&gt; params = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    params.put(<span class="string">"interface"</span>, interfaceName);</span><br><span class="line">    params.put(<span class="string">"method"</span>, method);</span><br><span class="line">    params.put(<span class="string">"parameterTypesString"</span>, parameterTypesString);</span><br><span class="line">    params.put(<span class="string">"parameter"</span>, parameter);</span><br><span class="line">    <span class="keyword">return</span> params;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>节省篇幅，直接在这儿将之后的优化贴出来，后续不再对这个优化赘述了。</p><p><strong>Qps 4200 到 4400 (netty复用eventLoop)</strong></p><p>这个优化点来自于比赛认识的一位好友@半杯水，由于没有使用过 netty，比赛期间恶补了一下 netty 的线程模型，得知了 netty 可以从客户端引导 channel，从而复用 eventLoop。不了解 netty 的朋友可以把 eventLoop 理解为 io 线程，如果入站的 io 线程和 出站的 io 线程使用相同的线程，可以减少不必要的上下文切换，这一点在 256 并发下可能还不明显，只有 200 多 qps 的差距，但在 512 下尤为明显。复用 eventLoop 在《netty实战》中是一个专门的章节，篇幅虽然不多，但非常清晰地向读者阐释了如何复用 eventLoop（注意复用同时存在于 ca 和 pa 中）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 入站服务端的 eventLoopGroup</span></span><br><span class="line"><span class="keyword">private</span> EventLoopGroup workerGroup;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为出站客户端预先创建好的 channel</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initThreadBoundClient</span><span class="params">(EventLoopGroup workerGroup)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (EventExecutor eventExecutor : eventLoopGroup) &#123;</span><br><span class="line">        <span class="keyword">if</span> (eventExecutor <span class="keyword">instanceof</span> EventLoop) &#123;</span><br><span class="line">            ConsumerAgentClient consumerAgentClient = <span class="keyword">new</span> ConsumerAgentClient((EventLoop) eventExecutor);</span><br><span class="line">            consumerAgentClient.init();</span><br><span class="line">            ConsumerAgentClient.put(eventExecutor, consumerAgentClient);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用入站服务端的 eventLoopGroup 为出站客户端预先创建好 channel，这样可以达到复用 eventLoop 的目的。并且此时还有一个伴随的优化点，就是将存储 Map&lt;requestId,Promise&gt; 的数据结构，从 concurrentHashMap 替换为了 ThreadLocal<hashmap> ,因为入站线程和出站线程都是相同的线程，省去一个 concurrentHashMap 可以进一步降低锁的竞争。</hashmap></p><p>到了这一步，整体架构已经清晰了，c-&gt;ca，ca-&gt;pa，pa-&gt;p 都实现了异步非阻塞的 reactor 模型，qps 在 256 并发下，也达到了 4400 qps。</p><p><img src="http://kirito.iocoder.cn/image-20180619214121418.png" alt="优化后的dubbo mesh方案"></p><h3 id="正式赛-512-连接带来的新格局"><a href="#正式赛-512-连接带来的新格局" class="headerlink" title="正式赛 512 连接带来的新格局"></a>正式赛 512 连接带来的新格局</h3><p>上述这份代码在预热赛 256 并发下表现尚可，但正式赛为了体现出大家的差距，将最高并发数直接提升了一倍，但 qps 却并没有得到很好的提升，卡在了 5400 qps。和 256 连接下同样 4400 的朋友交流过后，发现我们之间的差距主要体现在 ca 和 pa 的 io 线程数，以及 pa 到 p 的连接数上。5400 qps 显然低于我的预期，为了降低连接数，我修改了原来 provider-agent 的设计。从以下优化开始，是正式赛 512 连接下的优化，预热赛只有 256 连接。</p><p><strong>Qps 5400 到 5800 (降低连接数)</strong></p><p>对 netty 中 channel 的优化搜了很多文章，依旧不是很确定连接数到底是不是影响我代码的关键因素，在和小伙伴沟通之后实在找不到 qps 卡在 5400 的原因，于是乎抱着试试的心态修改了下 provider-agent 的设计，采用了和 consumer-agent 一样的设计，预先拿到 provder-agent 入站服务器的 woker 线程组，创建出站请求的 channel，将原来的 4 个线程，4 个 channel 降低到了 1 个线程，一个 channel。其他方面未做任何改动，qps 顺利达到了 5800。</p><p>理论上来说，channel 数应该不至于成为性能的瓶颈，可能和 provider dubbo 的线程池策略有关，最终得出的经验就是：在 server 中合理的在 io 事件处理能力的承受范围内，使用尽可能少的连接数和线程数，可以提升 qps，减少不必要的线程切换。顺带一提（此时 ca 的线程数为 4，入站连接为 http 连接，最高为 512 连接，出站连接由于和线程绑定，又需要做负载均衡，所以为<br>$$<br>线程数<em>pa数=4</em>3=12<br>$$<br>这个阶段，还存在另一个问题，由于 provider 线程数固定为 200 个线程，如果 large-pa 继续分配 3/1+2+3=0.5 即 50% 的请求，很容易出现 provider 线程池饱满的异常，所以调整了加权值为 1：2：2。限制加权负载均衡的不再仅仅是机器性能，还要考虑到 provider 的连接处理能力。</p><p><strong>Qps 5800 到 6100 (Epoll替换Nio)</strong></p><p>依旧感谢@半杯水的提醒，由于评测环境使用了 linux 作为评测环境，所以可以使用 netty 自己封装的 EpollSocketChannel 来代替 NioSocketChannel，这个提升远超我的想象，直接帮助我突破了 6000 的关卡。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> EventLoopGroup bossGroup = Epoll.isAvailable() ? <span class="keyword">new</span> EpollEventLoopGroup(<span class="number">1</span>) : <span class="keyword">new</span> NioEventLoopGroup(<span class="number">1</span>);</span><br><span class="line"><span class="keyword">private</span> EventLoopGroup workerGroup = Epoll.isAvailable() ? <span class="keyword">new</span> EpollEventLoopGroup(<span class="number">2</span>) : <span class="keyword">new</span> NioEventLoopGroup(<span class="number">2</span>);</span><br><span class="line">bootstrap = <span class="keyword">new</span> ServerBootstrap();</span><br><span class="line">            bootstrap.group(bossGroup, workerGroup)</span><br><span class="line">                    .channel(Epoll.isAvailable() ? EpollServerSocketChannel.class : NioServerSocketChannel.class)</span><br></pre></td></tr></table></figure><p>本地调试由于我是 mac 环境，没法使用 Epoll，所以加了如上的判断。</p><p>NioServerSocketChannel 使用了 jdk 的 nio，其会根据操作系统选择使用不同的 io 模型，在 linux 下同样是 epoll，但默认是 level-triggered ，而 netty 自己封装的 EpollSocketChannel 默认是 edge-triggered。 我原先以为是 et 和 lt 的差距导致了 qps 如此大的悬殊，但后续优化 Epoll 参数时发现 EpollSocketChannel 也可以配置为 level-triggered，qps 并没有下降，在比赛的特殊条件下，个人猜想并不是这两种触发方式带来的差距，而仅仅是 netty 自己封装 epoll 带来的优化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//默认</span></span><br><span class="line">bootstrap.option(EpollChannelOption.EPOLL_MODE, EpollMode.EDGE_TRIGGERED);</span><br><span class="line"><span class="comment">//可修改触发方式</span></span><br><span class="line">bootstrap.option(EpollChannelOption.EPOLL_MODE, EpollMode.LEVEL_TRIGGERED);</span><br></pre></td></tr></table></figure><p><strong>Qps 6100 到 6300 (agent自定义协议优化)</strong></p><p>agent 之间的自定义协议我之前已经介绍过了，由于一开始我使用了 protoBuf，发现了性能问题，就是在这儿发现的。在 512 下 protoBuf 的问题尤为明显，最终为了保险起见，以及为了和我后面的一个优化兼容，最终替换为了自定义协议—Simple 协议，这一点优化之前提到了，不在过多介绍。</p><p><strong>Qps 6300 到 6500 (参数调优与zero-copy)</strong></p><p>这一段优化来自于和 @折袖-许华建 的交流，非常感谢。又是一个对 netty 不太了解而没注意的优化点：</p><ol><li>关闭 netty 的内存泄露检测：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Dio.netty.leakDetectionLevel=disabled</span><br></pre></td></tr></table></figure><p>netty 会在运行期定期抽取 1% 的 ByteBuf 进行内存泄露的检测，关闭这个参数后，可以获得性能的提升。</p><ol><li>开启 quick_ack：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.option(EpollChannelOption.TCP_QUICKACK, java.lang.Boolean.TRUE)</span><br></pre></td></tr></table></figure><p>tcp 相比 udp ，一个区别便是为了可靠传输而进行的 ack，netty 为 Epoll 提供了这个参数，可以进行 quick ack，具体原理没来及研究。</p><ol><li>开启 TCP_NODELAY</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">serverBootstrap.childOption(ChannelOption.TCP_NODELAY, <span class="keyword">true</span>)</span><br></pre></td></tr></table></figure><p>这个优化可能大多数人都知道，放在这儿一起罗列出来。网上搜到了一篇阿里毕玄的 rpc 优化文章，提到高并发下 <code>ChannelOption.TCP_NODELAY=false</code> 可能更好，但实测之后发现并不会。</p><p>其他调优的参数可能都是玄学了，对最终的 qps 影响微乎其微。参数调优并不能体现太多的技巧，但对结果产生的影响却是很可观的。</p><p>在这个阶段还同时进行了一个优化，和参数调优一起进行的，所以不知道哪个影响更大一些。demo 中 dubbo 协议编码没有做到 zero-copy，这无形中增加了一份数据从内核态到用户态的拷贝；自定义协议之间同样存在这个问题，在 dubbo mesh 的实践过程中应该尽可能做到：能用 ByteBuf 的地方就不要用其他对象，ByteBuf 提供的 slice 和 CompositeByteBuf 都可以很方便的实现 zero-copy。</p><p><strong>Qps 6500 到 6600 (自定义http协议编解码)</strong></p><p>看着榜单上的人 qps 逐渐上升，而自己依旧停留在 6500，于是乎动了歪心思，GTMD 的通用性，自己解析 http 协议得了，不要 netty 提供的 http 编解码器，不需要比 HttpPostRequestDecoder 更快的 QueryStringDecoder，就一个偏向于固定的 http 请求，实现自定义解析非常简单。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST / HTTP/1.1\r\n</span><br><span class="line"><span class="attribute">content-length</span>: 560\r\n</span><br><span class="line"><span class="attribute">content-type</span>: application/x-www-form-urlencoded\r\n</span><br><span class="line"><span class="attribute">host</span>: 127.0.0.1:20000\r\n</span><br><span class="line">\r\n</span><br><span class="line">interface=com.alibaba.dubbo.performance.demo.provider.IHelloService&amp;method=hash&amp;parameterTypesString=Ljava%32lang%32String;&amp;parameter=xxxxx</span><br></pre></td></tr></table></figure><p>http 文本协议本身还是稍微有点复杂的，所以 netty 的实现考虑到通用性，必然不如我们自己解析来得快，具体的粘包过程就不叙述了，有点 hack 的倾向。</p><p>同理，response 也自己解析：</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 <span class="number">200</span> OK\r\n</span><br><span class="line"><span class="attribute">Connection</span>: keep-alive\r\n</span><br><span class="line"><span class="attribute">Content-Type</span>: text/plain;charset=UTF-8\r\n</span><br><span class="line"><span class="attribute">Content-Length</span>: 6\r\n</span><br><span class="line">\r\n</span><br><span class="line"><span class="attribute">123456</span></span><br></pre></td></tr></table></figure><p><strong>Qps 6600 到 6700 (去除对象)</strong></p><p>继续丧心病狂，不考虑通用性，把之前所有的中间对象都省略，encode 和 decode 尽一切可能压缩到 handler 中去处理，这样的代码看起来非常难受，存在不少地方的 hardcoding。但效果是存在的，ygc 的次数降低了不少，全程使用 ByteBuf 和 byte[] 来进行数据交互。这个优化点同样存在存在 hack 倾向，不过多赘述。</p><p><strong>Qps 6700 到 6850 (批量flush，批量decode)</strong></p><p>事实上到了 6700 有时候还是需要看运气的，从群里的吐槽现象就可以发现，512 下的网路 io 非常抖，不清楚是机器的问题还是高并发下的固有现象，6700的代码都能抖到 5000 分。所以 6700 升 6850 的过程比较曲折，而且很不稳定，提交 20 次一共就上过两次 6800+。</p><p>所做的优化是来自队友@闪电侠的批量flush类，一次传输的字节数可以提升，使得网络 io 次数可以降低，原理可以简单理解为：netty 中 write 10 次，flush 1 次。一共实现了两个版本的批量 flush。一个版本是根据同一个 channel write 的次数积累，最终触发 flush；另一个版本是根据一次 eventLoop 结束才强制flush。经过很多测试，由于环境抖动太厉害，这两者没测出多少差距。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">handler(<span class="keyword">new</span> ChannelInitializer&lt;SocketChannel&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(SocketChannel ch)</span> </span>&#123;</span><br><span class="line">ch.pipeline()</span><br><span class="line">.addLast(<span class="keyword">new</span> SimpleDecoder())</span><br><span class="line">.addLast(<span class="keyword">new</span> BatchFlushHandler(<span class="keyword">false</span>))</span><br><span class="line">.addLast(<span class="keyword">new</span> ConsumerAgentClientHandler());</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>批量 decode 的思想来自于蚂蚁金服的 rpc 框架 sofa-bolt 中提供的一个抽象类：AbstractBatchDecoder</p><p><img src="https://cdn.yuque.com/yuque/0/2018/png/101192/1525856636255-170ec5a4-a826-47f6-b9f2-e2cc2b1acc59.png" alt="img"></p><p>Netty 提供了一个方便的解码工具类 <code>ByteToMessageDecoder</code> ，如图上半部分所示，这个类具备 <code>accumulate</code> 批量解包能力，可以尽可能的从 <code>socket</code> 里读取字节，然后同步调用 <code>decode</code> 方法，解码出业务对象，并组成一个 <code>List</code> 。最后再循环遍历该 <code>List</code> ，依次提交到 <code>ChannelPipeline</code> 进行处理。此处我们做了一个细小的改动，如图下半部分所示，即将提交的内容从单个 <code>command</code> ，改为整个 <code>List</code> 一起提交，如此能减少 <code>pipeline</code> 的执行次数，同时提升吞吐量。这个模式在低并发场景，并没有什么优势，而在高并发场景下对提升吞吐量有不小的性能提升。</p><p>值得指出的一点：这个对于 dubbo mesh 复用 eventLoop 的特殊场景下的优化效果其实是存疑的，但我的最好成绩的确是使用了 AbstractBatchDecoder 之后跑出来的。我曾经单独将 ByteToMessageDecoder 和 AbstractBatchDecoder 拉出跑了一次分，的确是后者 qps 更高。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>其实在 qps 6500 时，整体代码还是挺漂亮的，至少感觉能拿的出手给别人看。但最后为了性能，加上时间比较赶，不少地方都进行了 hardcoding，而实际能投入生产使用的代码必然要求通用性和扩展性，赛后有空会整理出两个分支：一个 highest-qps 追求性能，另一个分支保留下通用性。这次比赛从一个 netty 小白，最终学到了不少的知识点，还是收获很大的，最后感谢一下比赛中给过我指导的各位老哥。</p><p>最高 qps 分支：highest-qps</p><p>考虑通用性的分支（适合 netty 入门）：master</p><p><a href="https://code.aliyun.com/250577914/agent-demo.git" target="_blank" rel="noopener">https://code.aliyun.com/250577914/agent-demo.git</a></p><p>最后帮队友@闪电侠推广下他的 netty 视频教程，比赛中两个比较难的优化点，都是由他进行的改造。imooc.com 搜索 Netty，可以获取 netty 源码分析视频。</p><p><strong>欢迎关注我的微信公众号：「Kirito的技术分享」，关于文章的任何疑问都会得到回复，带来更多 Java 相关的技术分享。</strong></p><p><img src="http://kirito.iocoder.cn/qrcode_for_gh_c06057be7960_258%20%281%29.jpg" alt="关注微信公众号"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;天池中间件大赛的初赛在今早终于正式结束了，公众号停更了一个月，主要原因就是博主的空余时间几乎全花在这个比赛上，第一赛季结束，做下参赛总结，总的来说，收获不小。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://kirito.iocoder.cn/image-20180619190732570.png&quot; alt=&quot;最终排名&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="RPC" scheme="http://lexburner.github.io/categories/RPC/"/>
    
    
      <category term="RPC" scheme="http://lexburner.github.io/tags/RPC/"/>
    
  </entry>
  
</feed>
